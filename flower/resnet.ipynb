{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "cd1b1cc7-914a-4c94-b220-55ee416adac2"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/1: 1=\n",
      " 1/2: 1+2\n",
      " 1/3: import numpy\n",
      " 1/4:\n",
      "def NN(m1, m2, w1, w2, b):\n",
      "    z = m1*w1 + m2*w2 + b\n",
      "    return sigmoid(z)\n",
      "\n",
      "def sigmoid(x):\n",
      "    return (1 / (1+numpy.exp(x)))\n",
      " 1/5: import numpy as np\n",
      " 1/6:\n",
      "def NN(m1, m2, w1, w2, b):\n",
      "    z = m1*w1 + m2*w2 + b\n",
      "    return sigmoid(z)\n",
      "\n",
      "def sigmoid(x):\n",
      "    return (1 / (1+np.exp(x)))\n",
      " 1/7: w1, w2, b = np.random.randn()\n",
      " 1/8: w1, w2, b = np.random.randn() for i in range(3)a\n",
      " 1/9: w1, w2, b = (np.random.randn() for i in range(3))\n",
      "1/10: w1\n",
      "1/11: w2\n",
      "1/12: b\n",
      "1/13: w1, w2, b = np.random.randn() for i in range(3)\n",
      "1/14: w1, w2, b = (np.random.randn() for i in range(3))\n",
      "1/15: NN(3, 1.5, w1, w2, b)\n",
      "1/16: NN(2, 1, w1, w2, b)\n",
      "1/17:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def train(b):\n",
      "    b = np.random.randint\n",
      "    for i in range(100):\n",
      "        b = b - dx((b-4) ** 2, b)\n",
      "    return b\n",
      "\n",
      "print(train(4))\n",
      "1/18:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    b = np.random.randint\n",
      "    for i in range(100):\n",
      "        b = b - dx(f, b)\n",
      "    return b\n",
      "\n",
      "print(train(4))\n",
      "1/19:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train():\n",
      "    b = np.random.randint\n",
      "    for i in range(100):\n",
      "        b = b - dx(f, b)\n",
      "    return b\n",
      "\n",
      "print(train())\n",
      "1/20:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(100):\n",
      "        b = b - dx(f, b)\n",
      "    return b\n",
      "\n",
      "print(train(3))\n",
      "1/21:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(100):\n",
      "        b = b - dx(f, b)\n",
      "    return b\n",
      "\n",
      "print(train(5))\n",
      "1/22:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    x = b\n",
      "    for i in range(100):\n",
      "        x = x - dx(f, x)\n",
      "    return x\n",
      "\n",
      "print(train(5))\n",
      "1/23:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "print(dx(f, 4))\n",
      "1/24:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "print(dx(f, 2))\n",
      "1/25:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "print(dx(f, 3))\n",
      "1/26:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "b = 0 \n",
      "for i in range(10):\n",
      "    b = b - dx(f, b)\n",
      "    print(b)\n",
      "1/27:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "b = 0 \n",
      "for i in range(10):\n",
      "    b = b - 0.1 * dx(f, b)\n",
      "    print(b)\n",
      "1/28:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(100):\n",
      "        b = b - 0.1 * dx(f, b)\n",
      "    return(b)\n",
      "\n",
      "print(train(2))\n",
      "1/29:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(1000):\n",
      "        b = b - 0.1 * dx(f, b)\n",
      "    return(b)\n",
      "\n",
      "print(train(2))\n",
      "1/30:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(10000):\n",
      "        b = b - 0.1 * dx(f, b)\n",
      "    return(b)\n",
      "\n",
      "print(train(2))\n",
      "1/31:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(1000):\n",
      "        b = b - 0.1 * dx(f, b)\n",
      "    return(b)\n",
      "\n",
      "print(train(2))\n",
      "1/32:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(1000):\n",
      "        b = b - 0.1 * dx(f, b)\n",
      "    return(b)\n",
      "\n",
      "print(train(np.random.randn()))\n",
      "1/33:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(1000):\n",
      "        b = b - 0.1 * dx(f, b)\n",
      "    return(b)\n",
      "\n",
      "print(train(np.random.randn()))\n",
      "1/34:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(1000):\n",
      "        b = b - 0.1 * dx(f, b)\n",
      "    return(b)\n",
      "\n",
      "print(train(np.random.randn()))\n",
      "1/35:\n",
      "from scipy.misc import derivative as dx\n",
      "\n",
      "def f(x):\n",
      "    return (x-4)**2\n",
      "\n",
      "def train(b):\n",
      "    for i in range(1000):\n",
      "        b = b - 0.1 * dx(f, b)\n",
      "    return(b)\n",
      "\n",
      "print(train(np.random.randn()))\n",
      " 2/1:\n",
      "%matplotlib inline\n",
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      " 2/2:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "print(zip(data))\n",
      " 2/3:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "print(list(zip(data)))\n",
      " 2/4:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "print(list(zip(data[0], data[1], data[2])))\n",
      " 2/5:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "print(list(map(list, list(zip(data[0], data[1], data[2])))))\n",
      " 2/6:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "print(list(map(list, list(zip(data[:])))))\n",
      " 2/7:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "print(list(map(list, list(zip(data[0], data[1], data[2])))))\n",
      " 2/8: import numpy as np\n",
      " 2/9:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "features = (list(map(list, list(zip(data[0], data[1]))))\n",
      "labels = data[2]\n",
      "2/10:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "features = (list(map(list, list(zip(data[0], data[1])))))\n",
      "labels = data[2]\n",
      "2/11:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "features = (list(map(list, list(zip(data[0], data[1])))))\n",
      "labels = data[2]\n",
      "print(features)\n",
      "2/12:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "features = np.array(list(map(list, list(zip(data[0], data[1])))))\n",
      "labels = np.array(data[2])\n",
      "features\n",
      "2/13:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([2, 1])\n",
      "2/14:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[2, 1]])\n",
      "2/15:\n",
      "data = [[3, 2, 4, 3, 3.5, 2, 5.5, 1], \n",
      "       [1.5, 1, 1.5, 1, .5, .5, 1, 1], \n",
      "       [1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "features = np.array(list(map(list, list(zip(data[0], data[1])))))\n",
      "labels = np.array(data[2])\n",
      "np.array(data)\n",
      "2/16:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[2, 1]])\n",
      "2/17:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3.5, 0.5]])\n",
      "2/18:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[0, 1]])\n",
      "2/19:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[0, 0]])\n",
      "2/20:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[2, 0]])\n",
      "2/21:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3, 0]])\n",
      "2/22:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3, 1]])\n",
      "2/23:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3, 1.5]])\n",
      "2/24:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3, 1.5]])\n",
      "2/25:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3, 1.5]])\n",
      "2/26:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3, 1.5]])\n",
      "2/27:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3, 1.5]])\n",
      "2/28:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3, 1.5]])\n",
      "2/29:\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier()\n",
      "clf.fit(features, labels)\n",
      "clf.predict([[3, 1.5]])\n",
      " 4/1:\n",
      "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
      "%reload_ext autoreload\n",
      "%autoreload 2\n",
      "%matplotlib inline\n",
      " 4/2:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      " 4/3:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      " 4/4:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      " 4/5:\n",
      "PATH = \"../../../data/dogscats/\"\n",
      "sz=224\n",
      " 4/6: torch.cuda.is_available()\n",
      " 4/7:\n",
      "import torch\n",
      "import torchvision\n",
      "import fastai\n",
      " 4/8:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      " 4/9:\n",
      "import torch\n",
      "import torchvision\n",
      "import fastai\n",
      "import bcolz\n",
      "4/10:\n",
      "import torch\n",
      "import torchvision\n",
      "import fastai\n",
      "import bcolz\n",
      "4/11:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      "4/12:\n",
      "import torch\n",
      "import torchvision\n",
      "import fastai\n",
      "import bcolz\n",
      "4/13:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      "4/14:\n",
      "import torch\n",
      "import torchvision\n",
      "import fastai\n",
      "4/15:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      "4/16:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "4/17:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      "4/18:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      "4/19:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      "4/20:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "4/21:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "4/22:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "4/23:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "4/24:\n",
      "PATH = \"../../../data/dogscats/\"\n",
      "sz=224\n",
      "4/25: torch.cuda.is_available()\n",
      "4/26: torch.backends.cudnn.enabled\n",
      "4/27: os.listdir(PATH)\n",
      "4/28:\n",
      "PATH = \"../../data/dogscats/\"\n",
      "sz=224\n",
      "4/29: torch.cuda.is_available()\n",
      "4/30: torch.backends.cudnn.enabled\n",
      "4/31: os.listdir(PATH)\n",
      "4/32: os.listdir(f'{PATH}valid')\n",
      "4/33:\n",
      "files = os.listdir(f'{PATH}valid/cats')[:5]\n",
      "files\n",
      "4/34:\n",
      "img = plt.imread(f'{PATH}valid/cats/{files[0]}')\n",
      "plt.imshow(img);\n",
      "4/35: img.shape\n",
      "4/36: img[:4,:4]\n",
      "4/37:\n",
      "arch=resnet34\n",
      "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 2)\n",
      "4/38:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "4/39:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "4/40:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "4/41:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "4/42:\n",
      "PATH = \"../../data/dogscats/\"\n",
      "sz=224\n",
      "4/43: torch.cuda.is_available()\n",
      "4/44: torch.backends.cudnn.enabled\n",
      "4/45:\n",
      "arch=resnet34\n",
      "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 2)\n",
      "4/46:\n",
      "# This is the label for a val data\n",
      "data.val_y\n",
      "4/47:\n",
      "# from here we know that 'cats' is label 0 and 'dogs' is label 1.\n",
      "data.classes\n",
      "4/48:\n",
      "# this gives prediction for validation set. Predictions are in log scale\n",
      "log_preds = learn.predict()\n",
      "log_preds.shape\n",
      " 5/1:\n",
      "arch=resnet34\n",
      "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 2)\n",
      " 5/2:\n",
      "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
      "%reload_ext autoreload\n",
      "%autoreload 2\n",
      "%matplotlib inline\n",
      " 5/3:\n",
      "import torch\n",
      "import torchvision\n",
      "import fastai\n",
      " 5/4:\n",
      "# This file contains all the main external libs we'll use\n",
      "from fastai.imports import *\n",
      " 5/5:\n",
      "from fastai.transforms import *\n",
      "from fastai.conv_learner import *\n",
      "from fastai.model import *\n",
      "from fastai.dataset import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      " 5/6:\n",
      "PATH = \"../../data/dogscats/\"\n",
      "sz=224\n",
      " 5/7: torch.cuda.is_available()\n",
      " 5/8: torch.backends.cudnn.enabled\n",
      " 5/9:\n",
      "# os.makedirs('data/dogscats/models', exist_ok=True)\n",
      "\n",
      "# !ln -s /datasets/fast.ai/dogscats/train {PATH}\n",
      "# !ln -s /datasets/fast.ai/dogscats/test {PATH}\n",
      "# !ln -s /datasets/fast.ai/dogscats/valid {PATH}\n",
      "\n",
      "# os.makedirs('/cache/tmp', exist_ok=True)\n",
      "# !ln -fs /cache/tmp {PATH}\n",
      "5/10:\n",
      "# os.makedirs('/cache/tmp', exist_ok=True)\n",
      "# !ln -fs /cache/tmp {PATH}\n",
      "5/11: os.listdir(PATH)\n",
      "5/12: os.listdir(f'{PATH}valid')\n",
      "5/13:\n",
      "files = os.listdir(f'{PATH}valid/cats')[:5]\n",
      "files\n",
      "5/14:\n",
      "img = plt.imread(f'{PATH}valid/cats/{files[0]}')\n",
      "plt.imshow(img);\n",
      "5/15: img.shape\n",
      "5/16: img[:4,:4]\n",
      "5/17:\n",
      "# Uncomment the below if you need to reset your precomputed activations\n",
      "# shutil.rmtree(f'{PATH}tmp', ignore_errors=True)\n",
      "5/18:\n",
      "arch=resnet34\n",
      "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 2)\n",
      "5/19:\n",
      "img = plt.imread(f'{PATH}valid/cats/{files[0]}')\n",
      "plt.imshow(img);\n",
      "5/20:\n",
      "arch=resnet34\n",
      "data = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn = ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 2)\n",
      " 6/1:\n",
      "from IPython.display import YouTubeVideo\n",
      "YouTubeVideo('pHMzNW8Agq4')\n",
      " 6/2:\n",
      "%pylab inline\n",
      "#Import Code from previous videos:\n",
      "from partFour import *\n",
      " 6/3:\n",
      "def f(x):\n",
      "    return x**2\n",
      " 6/4:\n",
      "epsilon = 1e-4\n",
      "x = 1.5\n",
      " 6/5: numericalGradient = (f(x+epsilon)- f(x-epsilon))/(2*epsilon)\n",
      " 6/6: numericalGradient, 2*x\n",
      " 6/7:\n",
      "class Neural_Network(object):\n",
      "    def __init__(self):        \n",
      "        #Define Hyperparameters\n",
      "        self.inputLayerSize = 2\n",
      "        self.outputLayerSize = 1\n",
      "        self.hiddenLayerSize = 3\n",
      "        \n",
      "        #Weights (parameters)\n",
      "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
      "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
      "        \n",
      "    def forward(self, X):\n",
      "        #Propogate inputs though network\n",
      "        self.z2 = np.dot(X, self.W1)\n",
      "        self.a2 = self.sigmoid(self.z2)\n",
      "        self.z3 = np.dot(self.a2, self.W2)\n",
      "        yHat = self.sigmoid(self.z3) \n",
      "        return yHat\n",
      "        \n",
      "    def sigmoid(self, z):\n",
      "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
      "        return 1/(1+np.exp(-z))\n",
      "    \n",
      "    def sigmoidPrime(self,z):\n",
      "        #Gradient of sigmoid\n",
      "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
      "    \n",
      "    def costFunction(self, X, y):\n",
      "        #Compute cost for given X,y, use weights already stored in class.\n",
      "        self.yHat = self.forward(X)\n",
      "        J = 0.5*sum((y-self.yHat)**2)\n",
      "        return J\n",
      "        \n",
      "    def costFunctionPrime(self, X, y):\n",
      "        #Compute derivative with respect to W and W2 for a given X and y:\n",
      "        self.yHat = self.forward(X)\n",
      "        \n",
      "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
      "        dJdW2 = np.dot(self.a2.T, delta3)\n",
      "        \n",
      "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
      "        dJdW1 = np.dot(X.T, delta2)  \n",
      "        \n",
      "        return dJdW1, dJdW2\n",
      "    \n",
      "    #Helper Functions for interacting with other classes:\n",
      "    def getParams(self):\n",
      "        #Get W1 and W2 unrolled into vector:\n",
      "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
      "        return params\n",
      "    \n",
      "    def setParams(self, params):\n",
      "        #Set W1 and W2 using single paramater vector.\n",
      "        W1_start = 0\n",
      "        W1_end = self.hiddenLayerSize * self.inputLayerSize\n",
      "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n",
      "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
      "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n",
      "        \n",
      "    def computeGradients(self, X, y):\n",
      "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
      "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n",
      " 6/8:\n",
      "def computeNumericalGradient(N, X, y):\n",
      "        paramsInitial = N.getParams()\n",
      "        numgrad = np.zeros(paramsInitial.shape)\n",
      "        perturb = np.zeros(paramsInitial.shape)\n",
      "        e = 1e-4\n",
      "\n",
      "        for p in range(len(paramsInitial)):\n",
      "            #Set perturbation vector\n",
      "            perturb[p] = e\n",
      "            N.setParams(paramsInitial + perturb)\n",
      "            loss2 = N.costFunction(X, y)\n",
      "            \n",
      "            N.setParams(paramsInitial - perturb)\n",
      "            loss1 = N.costFunction(X, y)\n",
      "\n",
      "            #Compute Numerical Gradient\n",
      "            numgrad[p] = (loss2 - loss1) / (2*e)\n",
      "\n",
      "            #Return the value we changed to zero:\n",
      "            perturb[p] = 0\n",
      "            \n",
      "        #Return Params to original value:\n",
      "        N.setParams(paramsInitial)\n",
      "\n",
      "        return numgrad\n",
      " 6/9: NN = Neural_Network()\n",
      "6/10:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/11:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/12: norm(grad-numgrad)/norm(grad+numgrad)\n",
      "6/13: X\n",
      "6/14: X\n",
      "6/15: NN = Neural_Network()\n",
      "6/16: y\n",
      "6/17:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/18:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/19:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/20:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/21:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/22:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/23:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/24:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/25:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/26:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/27:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/28:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/29:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/30:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/31:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/32:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/33:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/34:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/35:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/36:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/37:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/38:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/39:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      "6/40: w1\n",
      "6/41: W1\n",
      "6/42: NN.W1\n",
      "6/43: NN.W2\n",
      "6/44: NN.W1\n",
      "6/45:\n",
      "numgrad = computeNumericalGradient(NN, X, y)\n",
      "numgrad\n",
      "6/46:\n",
      "grad = NN.computeGradients(X,y)\n",
      "grad\n",
      " 7/1:\n",
      "# First, import PyTorch\n",
      "import torch\n",
      " 7/2:\n",
      "def activation(x):\n",
      "    \"\"\" Sigmoid activation function \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        x: torch.Tensor\n",
      "    \"\"\"\n",
      "    return 1/(1+torch.exp(-x))\n",
      " 7/3:\n",
      "### Generate some data\n",
      "torch.manual_seed(7) # Set the random seed so things are predictable\n",
      "\n",
      "# Features are 3 random normal variables\n",
      "features = torch.randn((1, 5))\n",
      "# True weights for our data, random normal variables again\n",
      "weights = torch.randn_like(features)\n",
      "# and a true bias term\n",
      "bias = torch.randn((1, 1))\n",
      " 7/4:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "weights.shape\n",
      " 7/5:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "bias.shape\n",
      " 7/6:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "features.shape\n",
      " 7/7:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.dot(features, weights)\n",
      " 7/8:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "features\n",
      " 7/9:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "features\n",
      "weights\n",
      "7/10:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.t(weights)\n",
      "7/11:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.dot(features, torch.t(weights))\n",
      "7/12:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.sum([features[i] * weights[i] for i in range(len(features)), bias])\n",
      "7/13:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.sum([features[i] * weights[i] for i in range(len(features))])\n",
      "7/14:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.sum(torch.tensor([features[i] * weights[i] for i in range(len(features))]))\n",
      "7/15:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.sum([features[i] * weights[i] for i in range(len(features))])\n",
      "7/16:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.sum(torch.tensor([features[i] * weights[i] for i in range(len(features))]))\n",
      "7/17:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.tensor([features[i] * weights[i] for i in range(len(features))])\n",
      "7/18:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "[features[i] * weights[i] for i in range(len(features))]\n",
      "7/19:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "features[i] * weights[i] for i in range(len(features))\n",
      "7/20:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "[features[i] * weights[i] for i in range(len(features))]\n",
      "7/21:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "unlist([features[i] * weights[i] for i in range(len(features))])\n",
      "7/22:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "[features[i] * weights[i] for i in range(len(features))][0]\n",
      "7/23:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.sum([features[i] * weights[i] for i in range(len(features))][0], bias)\n",
      "7/24:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.sum([features[i] * weights[i] for i in range(len(features))][0])\n",
      "7/25:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.sum([features[i] * weights[i] for i in range(len(features))][0]) + bias\n",
      "7/26:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "sigmoid(torch.sum([features[i] * weights[i] for i in range(len(features))][0]) + bias)\n",
      "7/27:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "activation(torch.sum([features[i] * weights[i] for i in range(len(features))][0]) + bias)\n",
      "7/28:\n",
      "## Calculate the output of this network using matrix multiplication\n",
      "\n",
      "torch.mm(features, weights)\n",
      "7/29:\n",
      "## Calculate the output of this network using matrix multiplication\n",
      "\n",
      "torch.mm(features, torch.t(weights))\n",
      "7/30:\n",
      "## Calculate the output of this network using matrix multiplication\n",
      "\n",
      "activation(torch.mm(features, torch.t(weights)) + bias)\n",
      "7/31:\n",
      "## Your solution here\n",
      "torch.mm(features, torch.t(W1))\n",
      "7/32:\n",
      "### Generate some data\n",
      "torch.manual_seed(7) # Set the random seed so things are predictable\n",
      "\n",
      "# Features are 3 random normal variables\n",
      "features = torch.randn((1, 3))\n",
      "\n",
      "# Define the size of each layer in our network\n",
      "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
      "n_hidden = 2                    # Number of hidden units \n",
      "n_output = 1                    # Number of output units\n",
      "\n",
      "# Weights for inputs to hidden layer\n",
      "W1 = torch.randn(n_input, n_hidden)\n",
      "# Weights for hidden layer to output layer\n",
      "W2 = torch.randn(n_hidden, n_output)\n",
      "\n",
      "# and bias terms for hidden and output layers\n",
      "B1 = torch.randn((1, n_hidden))\n",
      "B2 = torch.randn((1, n_output))\n",
      "7/33:\n",
      "## Your solution here\n",
      "torch.mm(features, torch.t(W1))\n",
      "7/34:\n",
      "## Your solution here\n",
      "torch.mm(features, W1)\n",
      "7/35:\n",
      "## Your solution here\n",
      "activation(torch.mm(features, W1) + B1).shape\n",
      "7/36:\n",
      "## Your solution here\n",
      "features.shape\n",
      "7/37:\n",
      "## Your solution here\n",
      "features.shape\n",
      "W1.shape?\n",
      "7/38:\n",
      "## Your solution here\n",
      "features.shape\n",
      "W1.shape\n",
      "7/39:\n",
      "## Your solution here\n",
      "features\n",
      "7/40:\n",
      "## Your solution here\n",
      "features\n",
      "W2\n",
      "7/41:\n",
      "## Your solution here\n",
      "features\n",
      "7/42:\n",
      "## Your solution here\n",
      "features\n",
      "W1\n",
      "7/43:\n",
      "## Your solution here\n",
      "features\n",
      "W2\n",
      "7/44:\n",
      "## Your solution here\n",
      "features\n",
      "7/45:\n",
      "## Your solution here\n",
      "features\n",
      "W1\n",
      "7/46:\n",
      "## Your solution here\n",
      "features\n",
      "7/47:\n",
      "## Your solution here\n",
      "features + bias\n",
      "7/48:\n",
      "## Your solution here\n",
      "features\n",
      "7/49:\n",
      "## Your solution here\n",
      "activation(torch.mm(features, W1) + bias)\n",
      "7/50:\n",
      "## Your solution here\n",
      "torch.mm(activation(torch.mm(features, W1) + B1) + B2)\n",
      "7/51:\n",
      "## Your solution here\n",
      "torch.mm(activation(torch.mm(features, W1) + B1), W2) + B2\n",
      "7/52:\n",
      "## Your solution here\n",
      "activation(torch.mm(activation(torch.mm(features, W1) + B1), W2) + B2)\n",
      "7/53:\n",
      "a = np.random.rand(4,3)\n",
      "a\n",
      "7/54:\n",
      "import numpy as np\n",
      "\n",
      "a = np.random.rand(4,3)\n",
      "a\n",
      "7/55:\n",
      "b = torch.from_numpy(a)\n",
      "b\n",
      "7/56: b.numpy()\n",
      "7/57:\n",
      "# Multiply PyTorch Tensor by 2, in place\n",
      "b.mul_(2)\n",
      "7/58:\n",
      "# Numpy array matches new values from Tensor\n",
      "a\n",
      "7/59:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "features * weights\n",
      "7/60:\n",
      "### Generate some data\n",
      "torch.manual_seed(7) # Set the random seed so things are predictable\n",
      "\n",
      "# Features are 3 random normal variables\n",
      "features = torch.randn((1, 5))\n",
      "# True weights for our data, random normal variables again\n",
      "weights = torch.randn_like(features)\n",
      "# and a true bias term\n",
      "bias = torch.randn((1, 1))\n",
      "7/61:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "features * weights\n",
      "7/62:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "torch.sum(features * weights) + bias\n",
      "7/63:\n",
      "## Calculate the output of this network using the weights and bias tensors\n",
      "\n",
      "activation(torch.sum(features * weights) + bias)\n",
      " 9/1:\n",
      "# Import necessary packages\n",
      "\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import numpy as np\n",
      "import torch\n",
      "\n",
      "import helper\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      " 9/2:\n",
      "### Run this cell\n",
      "\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "# Define a transform to normalize the data\n",
      "transform = transforms.Compose([transforms.ToTensor(),\n",
      "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
      "                              ])\n",
      "\n",
      "# Download and load the training data\n",
      "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
      " 9/3:\n",
      "dataiter = iter(trainloader)\n",
      "images, labels = dataiter.next()\n",
      "print(type(images))\n",
      "print(images.shape)\n",
      "print(labels.shape)\n",
      " 9/4: plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');\n",
      " 9/5:\n",
      "## Your solution\n",
      "\n",
      "images\n",
      "\n",
      "out = # output of your network, should have shape (64,10)\n",
      " 9/6:\n",
      "## Your solution\n",
      "\n",
      "print(images)\n",
      "\n",
      "#out = # output of your network, should have shape (64,10)\n",
      " 9/7:\n",
      "## Your solution\n",
      "\n",
      "images.shape\n",
      "#out = # output of your network, should have shape (64,10)\n",
      " 9/8:\n",
      "## Your solution\n",
      "\n",
      "images.view(64, 784)\n",
      "\n",
      "#out = # output of your network, should have shape (64,10)\n",
      " 9/9:\n",
      "## Your solution\n",
      "\n",
      "images.view(64, 784).shape\n",
      "\n",
      "#out = # output of your network, should have shape (64,10)\n",
      "9/10:\n",
      "## Your solution\n",
      "\n",
      "flattened = images.view(64, 784)\n",
      "weights = torch.randn_like(flattened)\n",
      "weight.shape\n",
      "#out = # output of your network, should have shape (64,10)\n",
      "9/11:\n",
      "## Your solution\n",
      "\n",
      "flattened = images.view(64, 784)\n",
      "weights = torch.randn_like(flattened)\n",
      "weights.shape\n",
      "#out = # output of your network, should have shape (64,10)\n",
      "9/12:\n",
      "## Your solution\n",
      "\n",
      "flattened = images.view(64, 784)\n",
      "W1 = torch.randn((784, 256))\n",
      "B1 = torch.randn((1,1))\n",
      "W2 = torch.randn((256, 10))\n",
      "B2 = torch.randn((1,1))\n",
      "\n",
      "def sigmoid(x):\n",
      "    return (1 / (1+torch.exp(-x)))\n",
      "\n",
      "out = torch.mm(sigmoid(torch.mm(flattened, W1) + B1), W2)\n",
      "9/13:\n",
      "## Your solution\n",
      "\n",
      "flattened = images.view(64, 784)\n",
      "W1 = torch.randn((784, 256))\n",
      "B1 = torch.randn((1,1))\n",
      "W2 = torch.randn((256, 10))\n",
      "B2 = torch.randn((1,1))\n",
      "\n",
      "def sigmoid(x):\n",
      "    return (1 / (1+torch.exp(-x)))\n",
      "\n",
      "out = torch.mm(sigmoid(torch.mm(flattened, W1) + B1), W2)\n",
      "out.shape\n",
      "9/14:\n",
      "## Your solution\n",
      "\n",
      "flattened = images.view(64, 784)\n",
      "w1 = torch.randn((784, 256))\n",
      "b1 = torch.randn(256)\n",
      "w2 = torch.randn((256, 10))\n",
      "b2 = torch.randn(10)\n",
      "\n",
      "def sigmoid(x):\n",
      "    return (1 / (1+torch.exp(-x)))\n",
      "\n",
      "out = torch.mm(sigmoid(torch.mm(flattened, w1) + b1), w2)\n",
      "9/15:\n",
      "## Your solution\n",
      "\n",
      "flattened = images.view(64, 784)\n",
      "w1 = torch.randn((784, 256))\n",
      "b1 = torch.randn(256)\n",
      "w2 = torch.randn((256, 10))\n",
      "b2 = torch.randn(10)\n",
      "\n",
      "def sigmoid(x):\n",
      "    return (1 / (1+torch.exp(-x)))\n",
      "\n",
      "out = torch.mm(sigmoid(torch.mm(flattened, w1) + b1), w2) + b2\n",
      "9/16:\n",
      "def softmax(x):\n",
      "    return torch.exp(x) / torch.exp(x).sum()\n",
      "\n",
      "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
      "probabilities = softmax(out)\n",
      "\n",
      "# Does it have the right shape? Should be (64, 10)\n",
      "print(probabilities.shape)\n",
      "# Does it sum to 1?\n",
      "print(probabilities.sum(dim=1))\n",
      "9/17:\n",
      "def softmax(x):\n",
      "    denom = x.exp().sum(dim=1).view(-1, 1)\n",
      "    num = x.exp()\n",
      "    return num / denom\n",
      "\n",
      "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
      "probabilities = softmax(out)\n",
      "\n",
      "# Does it have the right shape? Should be (64, 10)\n",
      "print(probabilities.shape)\n",
      "# Does it sum to 1?\n",
      "print(probabilities.sum(dim=1))\n",
      "9/18:\n",
      "# Create the network and look at it's text representation\n",
      "model = Network()\n",
      "model\n",
      "9/19: from torch import nn\n",
      "9/20:\n",
      "class Network(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        # Inputs to hidden layer linear transformation\n",
      "        self.hidden = nn.Linear(784, 256)\n",
      "        # Output layer, 10 units - one for each digit\n",
      "        self.output = nn.Linear(256, 10)\n",
      "        \n",
      "        # Define sigmoid activation and softmax output \n",
      "        self.sigmoid = nn.Sigmoid()\n",
      "        self.softmax = nn.Softmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # Pass the input tensor through each of our operations\n",
      "        x = self.hidden(x)\n",
      "        x = self.sigmoid(x)\n",
      "        x = self.output(x)\n",
      "        x = self.softmax(x)\n",
      "        \n",
      "        return x\n",
      "9/21:\n",
      "# Create the network and look at it's text representation\n",
      "model = Network()\n",
      "model\n",
      "9/22:\n",
      "## Your solution here\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.hidden1 = nn.Linear((784, 128))\n",
      "        self.hidden2 = nn.Linear((128, 64))\n",
      "        self.output = nn.Linear((64, 10))\n",
      "        \n",
      "        self.relu = nn.ReLU()\n",
      "        self.softmax = nn.softmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = self.hidden1(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.hidden2(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.output(x)\n",
      "        x = self.softmax(x)\n",
      "        return(x)\n",
      "9/23:\n",
      "test = NN()\n",
      "test\n",
      "9/24:\n",
      "class Network(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        # Inputs to hidden layer linear transformation\n",
      "        self.hidden = nn.Linear(784, 256)\n",
      "        # Output layer, 10 units - one for each digit\n",
      "        self.output = nn.Linear(256, 10)\n",
      "        \n",
      "        # Define sigmoid activation and softmax output \n",
      "        self.sigmoid = nn.Sigmoid()\n",
      "        self.softmax = nn.Softmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # Pass the input tensor through each of our operations\n",
      "        x = self.hidden(x)\n",
      "        x = self.sigmoid(x)\n",
      "        x = self.output(x)\n",
      "        x = self.softmax(x)\n",
      "        \n",
      "        return x\n",
      "9/25:\n",
      "# Create the network and look at it's text representation\n",
      "model = Network()\n",
      "model\n",
      "9/26:\n",
      "## Your solution here\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.hidden1 = nn.Linear((784, 128))\n",
      "        self.hidden2 = nn.Linear((128, 64))\n",
      "        self.output = nn.Linear((64, 10))\n",
      "        \n",
      "        self.relu = nn.ReLU()\n",
      "        self.softmax = nn.softmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = self.hidden1(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.hidden2(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.output(x)\n",
      "        x = self.softmax(x)\n",
      "        return(x)\n",
      "9/27:\n",
      "test = NN()\n",
      "test\n",
      "9/28:\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class Network(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        # Inputs to hidden layer linear transformation\n",
      "        self.hidden = nn.Linear(784, 256)\n",
      "        # Output layer, 10 units - one for each digit\n",
      "        self.output = nn.Linear(256, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # Hidden layer with sigmoid activation\n",
      "        x = F.sigmoid(self.hidden(x))\n",
      "        # Output layer with softmax activation\n",
      "        x = F.softmax(self.output(x), dim=1)\n",
      "        \n",
      "        return x\n",
      "9/29:\n",
      "## Your solution here\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.hidden1 = nn.Linear((784, 128))\n",
      "        self.hidden2 = nn.Linear((128, 64))\n",
      "        self.output = nn.Linear((64, 10))\n",
      "        \n",
      "        self.relu = nn.ReLU()\n",
      "        self.softmax = nn.softmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = self.hidden1(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.hidden2(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.output(x)\n",
      "        x = self.softmax(x)\n",
      "        return(x)\n",
      "9/30:\n",
      "test = NN()\n",
      "test\n",
      "9/31:\n",
      "## Your solution here\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.hidden1 = nn.Linear(784, 128)\n",
      "        self.hidden2 = nn.Linear(128, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.relu = nn.ReLU()\n",
      "        self.softmax = nn.softmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = self.hidden1(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.hidden2(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.output(x)\n",
      "        x = self.softmax(x)\n",
      "        return(x)\n",
      "9/32:\n",
      "test = NN()\n",
      "test\n",
      "9/33:\n",
      "## Your solution here\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.hidden1 = nn.Linear(784, 128)\n",
      "        self.hidden2 = nn.Linear(128, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.relu = nn.ReLU()\n",
      "        self.softmax = nn.Softmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = self.hidden1(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.hidden2(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.output(x)\n",
      "        x = self.softmax(x)\n",
      "        return(x)\n",
      "9/34:\n",
      "test = NN()\n",
      "test\n",
      "9/35:\n",
      "print(model.fc1.weight)\n",
      "print(model.fc1.bias)\n",
      "9/36:\n",
      "# Create the network and look at it's text representation\n",
      "model = Network()\n",
      "model\n",
      "9/37:\n",
      "class Network(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        # Inputs to hidden layer linear transformation\n",
      "        self.hidden = nn.Linear(784, 256)\n",
      "        # Output layer, 10 units - one for each digit\n",
      "        self.output = nn.Linear(256, 10)\n",
      "        \n",
      "        # Define sigmoid activation and softmax output \n",
      "        self.sigmoid = nn.Sigmoid()\n",
      "        self.softmax = nn.Softmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # Pass the input tensor through each of our operations\n",
      "        x = self.hidden(x)\n",
      "        x = self.sigmoid(x)\n",
      "        x = self.output(x)\n",
      "        x = self.softmax(x)\n",
      "        \n",
      "        return x\n",
      "9/38:\n",
      "# Create the network and look at it's text representation\n",
      "model = Network()\n",
      "model\n",
      "9/39:\n",
      "print(model.fc1.weight)\n",
      "print(model.fc1.bias)\n",
      "9/40:\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class Network(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        # Inputs to hidden layer linear transformation\n",
      "        self.hidden = nn.Linear(784, 256)\n",
      "        # Output layer, 10 units - one for each digit\n",
      "        self.output = nn.Linear(256, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # Hidden layer with sigmoid activation\n",
      "        x = F.sigmoid(self.hidden(x))\n",
      "        # Output layer with softmax activation\n",
      "        x = F.softmax(self.output(x), dim=1)\n",
      "        \n",
      "        return x\n",
      "9/41:\n",
      "print(model.fc1.weight)\n",
      "print(model.fc1.bias)\n",
      "9/42:\n",
      "print(model.fc1.weight)\n",
      "print(model.fc1.bias)\n",
      "9/43:\n",
      "print(model.hidden.weight)\n",
      "print(model.hidden.bias)\n",
      "9/44:\n",
      "# Set biases to all zeros\n",
      "model.fc1.bias.data.fill_(0)\n",
      "9/45:\n",
      "# Set biases to all zeros\n",
      "model.hidden.bias.data.fill_(0)\n",
      "9/46:\n",
      "# sample from random normal with standard dev = 0.01\n",
      "model.hidden.weight.data.normal_(std=0.01)\n",
      "9/47:\n",
      "# Grab some data \n",
      "dataiter = iter(trainloader)\n",
      "images, labels = dataiter.next()\n",
      "\n",
      "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
      "images.resize_(64, 1, 784)\n",
      "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
      "\n",
      "# Forward pass through the network\n",
      "img_idx = 0\n",
      "ps = model.forward(images[img_idx,:])\n",
      "\n",
      "img = images[img_idx]\n",
      "helper.view_classify(img.view(1, 28, 28), ps)\n",
      "9/48:\n",
      "# Hyperparameters for our network\n",
      "input_size = 784\n",
      "hidden_sizes = [128, 64]\n",
      "output_size = 10\n",
      "\n",
      "# Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(hidden_sizes[1], output_size),\n",
      "                      nn.Softmax(dim=1))\n",
      "print(model)\n",
      "\n",
      "# Forward pass through the network and display output\n",
      "images, labels = next(iter(trainloader))\n",
      "images.resize_(images.shape[0], 1, 784)\n",
      "ps = model.forward(images[0,:])\n",
      "helper.view_classify(images[0].view(1, 28, 28), ps)\n",
      "9/49:\n",
      "print(model[0])\n",
      "model[0].weight\n",
      "9/50:\n",
      "from collections import OrderedDict\n",
      "model = nn.Sequential(OrderedDict([\n",
      "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
      "                      ('relu1', nn.ReLU()),\n",
      "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
      "                      ('relu2', nn.ReLU()),\n",
      "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
      "                      ('softmax', nn.Softmax(dim=1))]))\n",
      "model\n",
      "9/51:\n",
      "print(model[0])\n",
      "print(model.fc1)\n",
      "10/1:\n",
      "# TODO: Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(128, 64), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(64, 10),\n",
      "                     nn.LogSoftmax(dim=1))\n",
      "\n",
      "# TODO: Define the loss\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "### Run this to check your work\n",
      "# Get our data\n",
      "images, labels = next(iter(trainloader))\n",
      "# Flatten images\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "# Forward pass, get our logits\n",
      "logits = model(images)\n",
      "# Calculate the loss with the logits and the labels\n",
      "loss = criterion(logits, labels)\n",
      "\n",
      "print(loss)\n",
      "10/2:\n",
      "import torch\n",
      "from torch import nn\n",
      "import torch.nn.functional as F\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "# Define a transform to normalize the data\n",
      "transform = transforms.Compose([transforms.ToTensor(),\n",
      "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
      "                              ])\n",
      "# Download and load the training data\n",
      "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
      "10/3:\n",
      "# Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(128, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10))\n",
      "\n",
      "# Define the loss\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "# Get our data\n",
      "images, labels = next(iter(trainloader))\n",
      "# Flatten images\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "# Forward pass, get our logits\n",
      "logits = model(images)\n",
      "# Calculate the loss with the logits and the labels\n",
      "loss = criterion(logits, labels)\n",
      "\n",
      "print(loss)\n",
      "10/4:\n",
      "# TODO: Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(128, 64), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(64, 10),\n",
      "                     nn.LogSoftmax(dim=1))\n",
      "\n",
      "# TODO: Define the loss\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "### Run this to check your work\n",
      "# Get our data\n",
      "images, labels = next(iter(trainloader))\n",
      "# Flatten images\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "# Forward pass, get our logits\n",
      "logits = model(images)\n",
      "# Calculate the loss with the logits and the labels\n",
      "loss = criterion(logits, labels)\n",
      "\n",
      "print(loss)\n",
      "10/5:\n",
      "# Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(128, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10))\n",
      "\n",
      "# Define the loss\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "# Get our data\n",
      "images, labels = next(iter(trainloader))\n",
      "# Flatten images\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "# Forward pass, get our logits\n",
      "logits = model(images)\n",
      "# Calculate the loss with the logits and the labels\n",
      "loss = criterion(logits, labels)\n",
      "\n",
      "print(loss)\n",
      "10/6:\n",
      "# TODO: Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(128, 64), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(64, 10),\n",
      "                     nn.LogSoftmax(dim=1))\n",
      "\n",
      "# TODO: Define the loss\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "### Run this to check your work\n",
      "# Get our data\n",
      "images, labels = next(iter(trainloader))\n",
      "# Flatten images\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "# Forward pass, get our logits\n",
      "logits = model(images)\n",
      "# Calculate the loss with the logits and the labels\n",
      "loss = criterion(logits, labels)\n",
      "\n",
      "print(loss)\n",
      "10/7:\n",
      "# TODO: Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(128, 64), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(64, 10),\n",
      "                     nn.LogSoftmax(dim=1))\n",
      "\n",
      "# TODO: Define the loss\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "### Run this to check your work\n",
      "# Get our data\n",
      "images, labels = next(iter(trainloader))\n",
      "# Flatten images\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "# Forward pass, get our logits\n",
      "logits = model(images)\n",
      "# Calculate the loss with the logits and the labels\n",
      "loss = criterion(logits, labels)\n",
      "\n",
      "print(loss)\n",
      "print(torch.exp(logits))\n",
      "10/8:\n",
      "# TODO: Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(128, 64), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(64, 10),\n",
      "                     nn.LogSoftmax(dim=1))\n",
      "\n",
      "# TODO: Define the loss\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "### Run this to check your work\n",
      "# Get our data\n",
      "images, labels = next(iter(trainloader))\n",
      "# Flatten images\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "# Forward pass, get our logits\n",
      "logits = model(images)\n",
      "# Calculate the loss with the logits and the labels\n",
      "loss = criterion(logits, labels)\n",
      "\n",
      "print(loss)\n",
      "print(torch.exp(logits).sum())\n",
      "10/9:\n",
      "# TODO: Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(128, 64), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(64, 10),\n",
      "                     nn.LogSoftmax(dim=1))\n",
      "\n",
      "# TODO: Define the loss\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "### Run this to check your work\n",
      "# Get our data\n",
      "images, labels = next(iter(trainloader))\n",
      "# Flatten images\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "# Forward pass, get our logits\n",
      "logits = model(images)\n",
      "# Calculate the loss with the logits and the labels\n",
      "loss = criterion(logits, labels)\n",
      "\n",
      "print(loss)\n",
      "print(torch.exp(logits).sum(dim=1))\n",
      "10/10:\n",
      "# TODO: Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(128, 64), \n",
      "                     nn.ReLU(),\n",
      "                     nn.Linear(64, 10),\n",
      "                     nn.LogSoftmax(dim=1))\n",
      "\n",
      "# TODO: Define the loss\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "### Run this to check your work\n",
      "# Get our data\n",
      "images, labels = next(iter(trainloader))\n",
      "# Flatten images\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "# Forward pass, get our logits\n",
      "logits = model(images)\n",
      "# Calculate the loss with the logits and the labels\n",
      "loss = criterion(logits, labels)\n",
      "\n",
      "print(loss)\n",
      "10/11:\n",
      "x = torch.randn(2,2, requires_grad=True)\n",
      "print(x)\n",
      "10/12:\n",
      "y = x**2\n",
      "print(y)\n",
      "10/13:\n",
      "## grad_fn shows the function that generated this variable\n",
      "print(y.grad_fn)\n",
      "10/14:\n",
      "z = y.mean()\n",
      "print(z)\n",
      "10/15: print(x.grad)\n",
      "10/16:\n",
      "z.backward()\n",
      "print(x.grad)\n",
      "print(x/2)\n",
      "10/17:\n",
      "# Build a feed-forward network\n",
      "model = nn.Sequential(nn.Linear(784, 128),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(128, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10),\n",
      "                      nn.LogSoftmax(dim=1))\n",
      "\n",
      "criterion = nn.NLLLoss()\n",
      "images, labels = next(iter(trainloader))\n",
      "images = images.view(images.shape[0], -1)\n",
      "\n",
      "logits = model(images)\n",
      "loss = criterion(logits, labels)\n",
      "10/18:\n",
      "print('Before backward pass: \\n', model[0].weight.grad)\n",
      "\n",
      "loss.backward()\n",
      "\n",
      "print('After backward pass: \\n', model[0].weight.grad)\n",
      "10/19:\n",
      "from torch import optim\n",
      "\n",
      "# Optimizers require the parameters to optimize and a learning rate\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
      "10/20:\n",
      "print('Initial weights - ', model[0].weight)\n",
      "\n",
      "images, labels = next(iter(trainloader))\n",
      "images.resize_(64, 784)\n",
      "\n",
      "# Clear the gradients, do this because gradients are accumulated\n",
      "optimizer.zero_grad()\n",
      "\n",
      "# Forward pass, then backward pass, then update weights\n",
      "output = model.forward(images)\n",
      "loss = criterion(output, labels)\n",
      "loss.backward()\n",
      "print('Gradient -', model[0].weight.grad)\n",
      "10/21:\n",
      "# Take an update step and few the new weights\n",
      "optimizer.step()\n",
      "print('Updated weights - ', model[0].weight)\n",
      "10/22:\n",
      "## Your solution here\n",
      "\n",
      "model = nn.Sequential(nn.Linear(784, 128),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(128, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10),\n",
      "                      nn.LogSoftmax(dim=1))\n",
      "\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        # Flatten MNIST images into a 784 long vector\n",
      "        images = images.view(images.shape[0], -1)\n",
      "    \n",
      "        # TODO: Training pass\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(images)\n",
      "        loss = criterion(output, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        running_loss += loss.item()\n",
      "    else:\n",
      "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
      "10/23:\n",
      "## Your solution here\n",
      "\n",
      "model = nn.Sequential(nn.Linear(784, 128),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(128, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10),\n",
      "                      nn.LogSoftmax(dim=1))\n",
      "\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        # Flatten MNIST images into a 784 long vector\n",
      "        images = images.view(images.shape[0], -1)\n",
      "    \n",
      "        # TODO: Training pass\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(images)\n",
      "        loss = criterion(output, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        running_loss += loss.item()\n",
      "    else:\n",
      "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
      "10/24:\n",
      "%matplotlib inline\n",
      "import helper\n",
      "\n",
      "images, labels = next(iter(trainloader))\n",
      "\n",
      "img = images[0].view(1, 784)\n",
      "# Turn off gradients to speed up this part\n",
      "with torch.no_grad():\n",
      "    logits = model.forward(img)\n",
      "\n",
      "# Output of the network are logits, need to take softmax for probabilities\n",
      "ps = F.softmax(logits, dim=1)\n",
      "helper.view_classify(img.view(1, 28, 28), ps)\n",
      "10/25:\n",
      "## Your solution here\n",
      "\n",
      "model = nn.Sequential(nn.Linear(784, 128),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(128, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10),\n",
      "                      nn.LogSoftmax(dim=1))\n",
      "\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        # Flatten MNIST images into a 784 long vector\n",
      "        images = images.view(images.shape[0], -1)\n",
      "    \n",
      "        # TODO: Training pass\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(images)\n",
      "        loss = criterion(output, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        running_loss += loss.item()\n",
      "    else:\n",
      "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
      "10/26:\n",
      "%matplotlib inline\n",
      "import helper\n",
      "\n",
      "images, labels = next(iter(trainloader))\n",
      "\n",
      "img = images[0].view(1, 784)\n",
      "# Turn off gradients to speed up this part\n",
      "with torch.no_grad():\n",
      "    logits = model.forward(img)\n",
      "\n",
      "# Output of the network are logits, need to take softmax for probabilities\n",
      "ps = F.softmax(logits, dim=1)\n",
      "helper.view_classify(img.view(1, 28, 28), ps)\n",
      "10/27:\n",
      "%matplotlib inline\n",
      "import helper\n",
      "\n",
      "images, labels = next(iter(trainloader))\n",
      "\n",
      "img = images[0].view(1, 784)\n",
      "# Turn off gradients to speed up this part\n",
      "with torch.no_grad():\n",
      "    logits = model.forward(img)\n",
      "\n",
      "# Output of the network are logits, need to take softmax for probabilities\n",
      "ps = F.softmax(logits, dim=1)\n",
      "helper.view_classify(img.view(1, 28, 28), ps)\n",
      "11/1:\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "import helper\n",
      "\n",
      "# Define a transform to normalize the data\n",
      "transform = transforms.Compose([transforms.ToTensor(),\n",
      "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
      "# Download and load the training data\n",
      "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
      "\n",
      "# Download and load the test data\n",
      "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
      "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
      "11/2:\n",
      "image, label = next(iter(trainloader))\n",
      "helper.imshow(image[0,:]);\n",
      "11/3: # TODO: Define your network architecture here\n",
      "11/4: # TODO: Create the network, define the criterion and optimizer\n",
      "11/5: # TODO: Train the network here\n",
      "11/6:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = \n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/7:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "from torch import optim\n",
      "11/8:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "from torch import optim\n",
      "\n",
      "model = nn.Sequential(nn.Linear(784, 256), \n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(256, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10),\n",
      "                      nn.LogSoftmax(dim=1))\n",
      "11/9:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.KLDivLoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer)\n",
      "11/10:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.KLDivLoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 5)\n",
      "11/11:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.KLDivLoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
      "11/12:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for image, target in trainloader:\n",
      "    optimizer.zero_grad()\n",
      "    output = model(image)\n",
      "    loss = loss_fn(output, target)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "11/13:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "model = nn.Sequential(nn.Linear(784, 256), \n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(256, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10),\n",
      "                      nn.LogSoftmax(dim=1))\n",
      "11/14:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.KLDivLoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
      "11/15:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for image, target in trainloader:\n",
      "    optimizer.zero_grad()\n",
      "    output = model(image)\n",
      "    loss = loss_fn(output, target)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "11/16:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for image, target in trainloader:\n",
      "    optimizer.zero_grad()\n",
      "    output = model.forward(image)\n",
      "    loss = loss_fn(output, target)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "11/17:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "model = nn.Sequential(nn.Linear(784, 256), \n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(256, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10),\n",
      "                      nn.LogSoftmax(dim=1))\n",
      "\n",
      "model\n",
      "11/18:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.CrossEntropyLoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
      "11/19:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for image, target in trainloader:\n",
      "    optimizer.zero_grad()\n",
      "    output = model.forward(image)\n",
      "    loss = loss_fn(output, target)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "11/20:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/21:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = \n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/22:\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "import helper\n",
      "\n",
      "# Define a transform to normalize the data\n",
      "transform = transforms.Compose([transforms.ToTensor(),\n",
      "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
      "# Download and load the training data\n",
      "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
      "\n",
      "# Download and load the test data\n",
      "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
      "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
      "11/23:\n",
      "image, label = next(iter(trainloader))\n",
      "helper.imshow(image[0,:]);\n",
      "11/24:\n",
      "image, label = next(iter(trainloader))\n",
      "helper.imshow(image[0,:]);\n",
      "print(image[0,:].shape)\n",
      "11/25:\n",
      "image, label = next(iter(trainloader))\n",
      "helper.imshow(image[0,:]);\n",
      "print(image.shape)\n",
      "11/26:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/27:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(-1,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/28:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.CrossEntropyLoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
      "\n",
      "print(trainloader.shape)\n",
      "11/29:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        print(image.shape)\n",
      "#         optimizer.zero_grad()\n",
      "#         output = model.forward(image)\n",
      "#         loss = loss_fn(output, target)\n",
      "#         loss.backward()\n",
      "#         optimizer.step()\n",
      "11/30:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64, 784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/31:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = model(img)\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/32:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = model(img)\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/33:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/34:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/35:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/36:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/37:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/38:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.KLDivLoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
      "11/39:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64, 784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/40:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.CrossEntropyLoss()\n",
      "optimizer = optim.Adamax(model.parameters(), lr=0.01)\n",
      "11/41:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64, 784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/42:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.CrossEntropyLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
      "11/43:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64, 784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/44:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(32, 784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/45:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64, 784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/46:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
      "11/47:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64, 784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/48:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64, -1)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/49:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(-1, 784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/50:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/51:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(784,-1)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/52:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(32,-1)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/53:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(63,-1)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/54:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,-1)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/55:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/56:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
      "11/57:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/58:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
      "11/59:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/60:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/61:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/62:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        print(image.shape)\n",
      "#         image.resize_(64,784)\n",
      "#         optimizer.zero_grad()\n",
      "#         output = model.forward(image)\n",
      "#         loss = loss_fn(output, target)\n",
      "#         loss.backward()\n",
      "#         optimizer.step()\n",
      "11/63:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        print(output.shape)\n",
      "#         loss = loss_fn(output, target)\n",
      "#         loss.backward()\n",
      "#         optimizer.step()\n",
      "11/64:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        print(target.shape)\n",
      "#         loss.backward()\n",
      "#         optimizer.step()\n",
      "11/65:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        print(loss.shape)\n",
      "#         loss.backward()\n",
      "#         optimizer.step()\n",
      "11/66:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.resize_(64,1)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/67:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        target.resize_(64,1)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/68:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/69:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/70:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        print(target.shape)\n",
      "#         image.resize_(64,784)\n",
      "#         optimizer.zero_grad()\n",
      "#         output = model.forward(image)\n",
      "#         loss = loss_fn(output, target)\n",
      "#         loss.backward()\n",
      "#         optimizer.step()\n",
      "11/71:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        target.resize_(64)\n",
      "        image.resize_(64,784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/72:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        target.resize_(64)\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/73:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize(64, -1)\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/74:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        image.resize(64, 784)\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/75:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "model = nn.Sequential(lambda x: x.view(x.shape[0], -1),\n",
      "                      nn.Linear(784, 256), \n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(256, 64),\n",
      "                      nn.ReLU(),\n",
      "                      nn.Linear(64, 10),\n",
      "                      nn.LogSoftmax(dim=1))\n",
      "\n",
      "model\n",
      "11/76:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(x):\n",
      "        x.resize_(64, -1)\n",
      "        x = nn.ReLU(self.hidden1(x))\n",
      "        x = nn.ReLU(self.hidden2(x))\n",
      "        x = nn.LogSoftmax(self.output(x), dim=1)\n",
      "        return(x)\n",
      "11/77:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/78:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/79:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for images, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(images)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/80:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for images, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(images)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/81:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x.resize_(64, -1)\n",
      "        x = nn.ReLU(self.hidden1(x))\n",
      "        x = nn.ReLU(self.hidden2(x))\n",
      "        x = nn.LogSoftmax(self.output(x), dim=1)\n",
      "        return(x)\n",
      "11/82:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/83:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/84:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x.resize_(64, 784)\n",
      "        x = nn.ReLU(self.hidden1(x))\n",
      "        x = nn.ReLU(self.hidden2(x))\n",
      "        x = nn.LogSoftmax(self.output(x), dim=1)\n",
      "        return(x)\n",
      "11/85:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/86:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/87:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(64, 784)\n",
      "        x = nn.ReLU(self.hidden1(x))\n",
      "        x = nn.ReLU(self.hidden2(x))\n",
      "        x = nn.LogSoftmax(self.output(x), dim=1)\n",
      "        return(x)\n",
      "11/88:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/89:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/90:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(64, 784)\n",
      "        x = nn.ReLU(self.hidden1(x))\n",
      "        x = nn.ReLU(self.hidden2(x))\n",
      "        x = nn.LogSoftmax(self.output(x))\n",
      "        return(x)\n",
      "11/91:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/92:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/93:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(64, 784)\n",
      "        x = self.hidden1(x)\n",
      "        x = nn.ReLU(x)\n",
      "        x = self.hidden2(x)\n",
      "        x = nn.ReLU(x)\n",
      "        x = self.output(x)\n",
      "        x = nn.LogSoftmax(x, dim=1)\n",
      "        return(x)\n",
      "11/94:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/95:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/96:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        self.relu = nn.ReLU()\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(64, 784)\n",
      "        x = self.hidden1(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.hidden2(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.output(x)\n",
      "        x = nn.LogSoftmax(x, dim=1)\n",
      "        return(x)\n",
      "11/97:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/98:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "12/1:\n",
      "# TODO: Define your network architecture here\n",
      "class Classifier(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 128)\n",
      "        self.fc3 = nn.Linear(128, 64)\n",
      "        self.fc4 = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # make sure input tensor is flattened\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        \n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = F.relu(self.fc3(x))\n",
      "        x = F.log_softmax(self.fc4(x), dim=1)\n",
      "        \n",
      "        return x\n",
      "12/2:\n",
      "from torch import nn, optim\n",
      "import torch.nn.functional as F\n",
      "12/3:\n",
      "# TODO: Define your network architecture here\n",
      "class Classifier(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 128)\n",
      "        self.fc3 = nn.Linear(128, 64)\n",
      "        self.fc4 = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # make sure input tensor is flattened\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        \n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = F.relu(self.fc3(x))\n",
      "        x = F.log_softmax(self.fc4(x), dim=1)\n",
      "        \n",
      "        return x\n",
      "12/4:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "model = Classifier()\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
      "12/5:\n",
      "# TODO: Train the network here\n",
      "epochs = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        log_ps = model(images)\n",
      "        loss = criterion(log_ps, labels)\n",
      "        \n",
      "        optimizer.zero_grad()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "        running_loss += loss.item()\n",
      "    else:\n",
      "        print(f\"Training loss: {running_loss}\")\n",
      "12/6:\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "import helper\n",
      "\n",
      "# Define a transform to normalize the data\n",
      "transform = transforms.Compose([transforms.ToTensor(),\n",
      "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
      "# Download and load the training data\n",
      "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
      "\n",
      "# Download and load the test data\n",
      "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
      "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
      "12/7:\n",
      "image, label = next(iter(trainloader))\n",
      "helper.imshow(image[0,:]);\n",
      "12/8:\n",
      "from torch import nn, optim\n",
      "import torch.nn.functional as F\n",
      "12/9:\n",
      "# TODO: Define your network architecture here\n",
      "class Classifier(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 128)\n",
      "        self.fc3 = nn.Linear(128, 64)\n",
      "        self.fc4 = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # make sure input tensor is flattened\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        \n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = F.relu(self.fc3(x))\n",
      "        x = F.log_softmax(self.fc4(x), dim=1)\n",
      "        \n",
      "        return x\n",
      "12/10:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "model = Classifier()\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
      "12/11:\n",
      "# TODO: Train the network here\n",
      "epochs = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        log_ps = model(images)\n",
      "        loss = criterion(log_ps, labels)\n",
      "        \n",
      "        optimizer.zero_grad()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "        running_loss += loss.item()\n",
      "    else:\n",
      "        print(f\"Training loss: {running_loss}\")\n",
      "11/99:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "12/12:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[1]\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img, ps, version='Fashion')\n",
      "11/100:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        self.relu = nn.ReLU()\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        x = self.hidden1(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.hidden2(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.output(x)\n",
      "        x = nn.LogSoftmax(x, dim=1)\n",
      "        return(x)\n",
      "11/101:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/102:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/103:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        self.relu = nn.ReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        x = self.hidden1(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.hidden2(x)\n",
      "        x = self.relu(x)\n",
      "        x = self.output(x)\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "11/104:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "11/105:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "11/106:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "12/13:\n",
      "# TODO: Train the network here\n",
      "epochs = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        log_ps = model(images)\n",
      "        loss = criterion(log_ps, labels)\n",
      "        \n",
      "        optimizer.zero_grad()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "        running_loss += loss.item()\n",
      "    else:\n",
      "        print(f\"Training loss: {running_loss}\")\n",
      "11/107:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/108:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        self.relu = nn.ReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        x = self.relu(self.hidden1(x))\n",
      "        x = self.relu(self.hidden2(x))\n",
      "        x = self.lsm(self.output(x))\n",
      "        return(x)\n",
      "11/109:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.KLDivLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.09)\n",
      "11/110:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "11/111:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        self.relu = nn.ReLU()\n",
      "        self.lsm = nn.Softmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        x = self.relu(self.hidden1(x))\n",
      "        x = self.relu(self.hidden2(x))\n",
      "        x = self.lsm(self.output(x))\n",
      "        return(x)\n",
      "11/112:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.KLDivLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.09)\n",
      "11/113:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "11/114:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.KLDivLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.09)\n",
      "11/115:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        self.relu = nn.ReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        x = self.relu(self.hidden1(x))\n",
      "        x = self.relu(self.hidden2(x))\n",
      "        x = self.lsm(self.output(x))\n",
      "        return(x.float())\n",
      "11/116:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.KLDivLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.09)\n",
      "11/117:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "11/118:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "11/119:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        self.relu = nn.ReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        x = self.relu(self.hidden1(x))\n",
      "        x = self.relu(self.hidden2(x))\n",
      "        x = self.lsm(self.output(x))\n",
      "        return(x)\n",
      "11/120:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.09)\n",
      "11/121:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "11/122:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/123:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/124:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/125:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/126:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/127:\n",
      "# TODO: Define your network architecture here\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        \n",
      "        self.hidden1 = nn.Linear(784, 256)\n",
      "        self.hidden2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        x = self.lrelu(self.hidden1(x))\n",
      "        x = self.lrelu(self.hidden2(x))\n",
      "        x = self.lsm(self.output(x))\n",
      "        return(x)\n",
      "11/128:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=1e-3)\n",
      "11/129:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "11/130:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=1e-2)\n",
      "11/131:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "11/132:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adamax(model.parameters())\n",
      "11/133:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "11/134:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "11/135:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/136:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/137:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/138:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/139:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/140:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/141:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/142:\n",
      "# TODO: Create the network, define the criterion and optimizer\n",
      "\n",
      "from torch import optim\n",
      "\n",
      "model = NN()\n",
      "loss_fn = torch.nn.NLLLoss()\n",
      "optimizer = optim.Adamax(model.parameters(), lr=0.001)\n",
      "11/143:\n",
      "# TODO: Train the network here\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    epoch_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        epoch_loss += loss.item()\n",
      "    else:\n",
      "        print(epoch_loss)\n",
      "11/144:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/145:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/146:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/147:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "11/148:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.resize_(1, 784)\n",
      "\n",
      "# TODO: Calculate the class probabilities (softmax) for img\n",
      "ps = torch.exp(model(img))\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
      "\n",
      "test_guesses = model(images)\n",
      "test_loss = loss_fn(test_guesses, labels)\n",
      "\n",
      "print(test_loss)\n",
      "13/1:\n",
      "top_p, top_class = ps.topk(1, dim=1)\n",
      "# Look at the most likely classes for the first 10 examples\n",
      "print(top_class[:10,:])\n",
      "13/2:\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "# Define a transform to normalize the data\n",
      "transform = transforms.Compose([transforms.ToTensor(),\n",
      "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
      "# Download and load the training data\n",
      "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
      "\n",
      "# Download and load the test data\n",
      "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
      "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
      "13/3:\n",
      "from torch import nn, optim\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class Classifier(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 128)\n",
      "        self.fc3 = nn.Linear(128, 64)\n",
      "        self.fc4 = nn.Linear(64, 10)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # make sure input tensor is flattened\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        \n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = F.relu(self.fc3(x))\n",
      "        x = F.log_softmax(self.fc4(x), dim=1)\n",
      "        \n",
      "        return x\n",
      "13/4:\n",
      "model = Classifier()\n",
      "\n",
      "images, labels = next(iter(testloader))\n",
      "# Get the class probabilities\n",
      "ps = torch.exp(model(images))\n",
      "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
      "print(ps.shape)\n",
      "13/5:\n",
      "top_p, top_class = ps.topk(1, dim=1)\n",
      "# Look at the most likely classes for the first 10 examples\n",
      "print(top_class[:10,:])\n",
      "13/6: equals = top_class == labels.view(*top_class.shape)\n",
      "13/7:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "labels.shape\n",
      "13/8:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "top_class.shape\n",
      "13/9:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "top_class\n",
      "13/10:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "labels.class\n",
      "13/11:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "labels.shape\n",
      "13/12:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "labels\n",
      "13/13:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "top_class.view(-1)\n",
      "13/14:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "top_class.view(-1) == labels\n",
      "13/15:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "top_class.view(-1) == labels\n",
      "13/16:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "(top_class.view(-1) == labels).sum() / len(top_class.view(-1) == labels)\n",
      "13/17:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "(top_class.view(-1) == labels).sum()\n",
      "13/18:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "(top_class.view(-1) == labels).sum() \n",
      "/ len(top_class.view(-1) == labels)\n",
      "13/19:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "(top_class.view(-1) == labels).sum() \n",
      "len(top_class.view(-1) == labels)\n",
      "13/20:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "(top_class.view(-1) == labels).sum() / float(len(top_class.view(-1) == labels))\n",
      "13/21:\n",
      "equals = top_class == labels.view(*top_class.shape)\n",
      "float((top_class.view(-1) == labels).sum()) / float(len(top_class.view(-1) == labels))\n",
      "13/22:\n",
      "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
      "print(f'Accuracy: {accuracy.item()*100}%')\n",
      "13/23: equals = top_class == labels.view(*top_class.shape)\n",
      "13/24:\n",
      "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
      "print(f'Accuracy: {accuracy.item()*100}%')\n",
      "13/25:\n",
      "model = Classifier()\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
      "\n",
      "epochs = 30\n",
      "steps = 0\n",
      "\n",
      "train_losses, test_losses = [], []\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        \n",
      "        optimizer.zero_grad()\n",
      "        \n",
      "        log_ps = model(images)\n",
      "        loss = criterion(log_ps, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "        running_loss += loss.item()\n",
      "        \n",
      "    else:\n",
      "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
      "        with torch.no_grad():\n",
      "            for images, labels in testloader:\n",
      "                probs = torch.exp(model(images))\n",
      "                guesses = probs.topk(1).view(-1)\n",
      "                equals = guesses == labels\n",
      "                print(equals)\n",
      "        print(f'Accuracy: {accuracy.item()*100}%')\n",
      "13/26:\n",
      "model = Classifier()\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
      "\n",
      "epochs = 30\n",
      "steps = 0\n",
      "\n",
      "train_losses, test_losses = [], []\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        \n",
      "        optimizer.zero_grad()\n",
      "        \n",
      "        log_ps = model(images)\n",
      "        loss = criterion(log_ps, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "        running_loss += loss.item()\n",
      "        \n",
      "    else:\n",
      "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
      "        with torch.no_grad():\n",
      "            for images, labels in testloader:\n",
      "                probs = torch.exp(model(images))\n",
      "                print(probs)\n",
      "#                 guesses = probs.topk(1).view(-1)\n",
      "#                 equals = guesses == labels\n",
      "#                 print(equals)\n",
      "        print(f'Accuracy: {accuracy.item()*100}%')\n",
      "13/27:\n",
      "model = Classifier()\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
      "\n",
      "epochs = 30\n",
      "steps = 0\n",
      "\n",
      "train_losses, test_losses = [], []\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        \n",
      "        optimizer.zero_grad()\n",
      "        \n",
      "        log_ps = model(images)\n",
      "        loss = criterion(log_ps, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "        running_loss += loss.item()\n",
      "        \n",
      "    else:\n",
      "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
      "        with torch.no_grad():\n",
      "            for images, labels in testloader:\n",
      "                probs = torch.exp(model(images))\n",
      "                guesses = probs.topk(1)\n",
      "                print(guesses)\n",
      "#                 equals = guesses == labels\n",
      "#                 print(equals)\n",
      "        print(f'Accuracy: {accuracy.item()*100}%')\n",
      "13/28:\n",
      "model = Classifier()\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
      "\n",
      "epochs = 30\n",
      "steps = 0\n",
      "\n",
      "train_losses, test_losses = [], []\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        \n",
      "        optimizer.zero_grad()\n",
      "        \n",
      "        log_ps = model(images)\n",
      "        loss = criterion(log_ps, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "        running_loss += loss.item()\n",
      "        \n",
      "    else:\n",
      "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
      "        with torch.no_grad():\n",
      "            for images, labels in testloader:\n",
      "                probs = torch.exp(model(images))\n",
      "                guesses = probs.topk(1)[1]\n",
      "                print(guesses)\n",
      "#                 equals = guesses == labels\n",
      "#                 print(equals)\n",
      "        print(f'Accuracy: {accuracy.item()*100}%')\n",
      "13/29:\n",
      "model = Classifier()\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
      "\n",
      "epochs = 30\n",
      "steps = 0\n",
      "\n",
      "train_losses, test_losses = [], []\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        \n",
      "        optimizer.zero_grad()\n",
      "        \n",
      "        log_ps = model(images)\n",
      "        loss = criterion(log_ps, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "        running_loss += loss.item()\n",
      "        \n",
      "    else:\n",
      "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
      "        with torch.no_grad():\n",
      "            for images, labels in testloader:\n",
      "                probs = torch.exp(model(images))\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == labels\n",
      "                print(equals)\n",
      "        print(f'Accuracy: {accuracy.item()*100}%')\n",
      "13/30:\n",
      "model = Classifier()\n",
      "criterion = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
      "\n",
      "epochs = 30\n",
      "steps = 0\n",
      "\n",
      "train_losses, test_losses = [], []\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for images, labels in trainloader:\n",
      "        \n",
      "        optimizer.zero_grad()\n",
      "        \n",
      "        log_ps = model(images)\n",
      "        loss = criterion(log_ps, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "        running_loss += loss.item()\n",
      "        \n",
      "    else:\n",
      "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
      "        with torch.no_grad():\n",
      "            for images, labels in testloader:\n",
      "                probs = torch.exp(model(images))\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == labels\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "        print(f'Accuracy: {accuracy.item()*100}%')\n",
      "13/31:\n",
      "## TODO: Define your model with dropout added\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.dropout = nn.Dropout()\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax()\n",
      "        \n",
      "    def forward(x)\n",
      "        x = x.view(64, 784)\n",
      "        x = self.dropout(self.relu(self.fc1(x)))\n",
      "        x = self.dropout(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "13/32:\n",
      "## TODO: Define your model with dropout added\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.dropout = nn.Dropout()\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax()\n",
      "        \n",
      "    def forward(x):\n",
      "        x = x.view(64, 784)\n",
      "        x = self.dropout(self.relu(self.fc1(x)))\n",
      "        x = self.dropout(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "13/33:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "13/34:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "model\n",
      "13/35:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    else:\n",
      "        with torch.no_grad():\n",
      "            model.eval()\n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "13/36:\n",
      "## TODO: Define your model with dropout added\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.dropout = nn.Dropout()\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax()\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(64, 784)\n",
      "        x = self.dropout(self.relu(self.fc1(x)))\n",
      "        x = self.dropout(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "13/37:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    else:\n",
      "        with torch.no_grad():\n",
      "            model.eval()\n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "13/38:\n",
      "## TODO: Define your model with dropout added\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.dropout = nn.Dropout()\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(64, 784)\n",
      "        x = self.dropout(self.relu(self.fc1(x)))\n",
      "        x = self.dropout(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "13/39:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    else:\n",
      "        with torch.no_grad():\n",
      "            model.eval()\n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "13/40:\n",
      "## TODO: Define your model with dropout added\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.dropout = nn.Dropout()\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(32, 784)\n",
      "        x = self.dropout(self.relu(self.fc1(x)))\n",
      "        x = self.dropout(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "13/41:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    else:\n",
      "        with torch.no_grad():\n",
      "            model.eval()\n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "13/42:\n",
      "## TODO: Define your model with dropout added\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.dropout = nn.Dropout()\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(64, 784)\n",
      "        x = self.dropout(self.relu(self.fc1(x)))\n",
      "        x = self.dropout(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "13/43:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    else:\n",
      "        with torch.no_grad():\n",
      "            model.eval()\n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "13/44:\n",
      "## TODO: Define your model with dropout added\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.dropout = nn.Dropout()\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(64, -1)\n",
      "        x = self.dropout(self.relu(self.fc1(x)))\n",
      "        x = self.dropout(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "13/45:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    else:\n",
      "        with torch.no_grad():\n",
      "            model.eval()\n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "13/46:\n",
      "## TODO: Define your model with dropout added\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.dropout = nn.Dropout()\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        x = self.dropout(self.relu(self.fc1(x)))\n",
      "        x = self.dropout(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "13/47:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    else:\n",
      "        with torch.no_grad():\n",
      "            model.eval()\n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "13/48:\n",
      "# Import helper module (should be in the repo)\n",
      "import helper\n",
      "\n",
      "# Test out your network!\n",
      "\n",
      "model.eval()\n",
      "\n",
      "dataiter = iter(testloader)\n",
      "images, labels = dataiter.next()\n",
      "img = images[0]\n",
      "# Convert 2D image to 1D vector\n",
      "img = img.view(1, 784)\n",
      "\n",
      "# Calculate the class probabilities (softmax) for img\n",
      "with torch.no_grad():\n",
      "    output = model.forward(img)\n",
      "\n",
      "ps = torch.exp(output)\n",
      "\n",
      "# Plot the image and probabilities\n",
      "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')\n",
      "13/49:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "13/50:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    else:\n",
      "        with torch.no_grad():\n",
      "            \n",
      "            model.eval()\n",
      "            \n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "                \n",
      "        model.train()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "13/51:\n",
      "## TODO: Define your model with dropout added\n",
      "\n",
      "class NN(nn.Module):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(784, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        \n",
      "        self.dropout = nn.Dropout(p=0.2)\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        x = x.view(x.shape[0], -1)\n",
      "        x = self.dropout(self.relu(self.fc1(x)))\n",
      "        x = self.dropout(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "13/52:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    else:\n",
      "        with torch.no_grad():\n",
      "            \n",
      "            model.eval()\n",
      "            \n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "                \n",
      "        model.train()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "13/53:\n",
      "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
      "\n",
      "model = NN()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "epochs = 5\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    for image, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(image)\n",
      "        loss = loss_fn(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    else:\n",
      "        test_loss = 0\n",
      "        with torch.no_grad():\n",
      "            \n",
      "            model.eval()\n",
      "            \n",
      "            for image, target in testloader:\n",
      "                output = model(image)\n",
      "                probs = torch.exp(output)\n",
      "                guesses = probs.topk(1)[1].view(-1)\n",
      "                equals = guesses == target\n",
      "                accuracy = equals.type(torch.FloatTensor).mean()\n",
      "                test_loss += loss_fn(output, target).item()\n",
      "                \n",
      "        model.train()\n",
      "        print(f'Accuracy: {accuracy.item() * 100}%')\n",
      "        print(f'Training loss: {train_loss/len(trainloader)}%')\n",
      "        print(f'Testing loss: {test_loss/len(testloader)}%')\n",
      "13/54: model.state_dict\n",
      "13/55: model\n",
      "13/56: model.state_dict.keys()\n",
      "13/57: model.state_dict().keys()\n",
      "13/58: model\n",
      "13/59: model.fc1\n",
      "13/60: model\n",
      "14/1:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torch import nn\n",
      "from torch import optim\n",
      "import torch.nn.functional as F\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "import fc_model\n",
      "14/2:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torch import nn\n",
      "from torch import optim\n",
      "import torch.nn.functional as F\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "import fc_model\n",
      "15/1:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/2:\n",
      "data_dir = 'Cat_Dog_data/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/3:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/4:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/5:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/6:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/7:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/8:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/9:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/10:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/11:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/12:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/13:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    transforms.Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/14:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/15:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/16:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/17:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/18:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/19:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/20:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.TenCrop(255),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/21:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/22:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/23:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/24:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/25:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.Resize(255),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomCrop(224),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/26:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/27:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.Resize(255),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomCrop(224),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/28:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/29:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomCrop(224),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/30:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/31:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomCrop(224),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/32:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/33:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/34:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/35:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/36:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/37:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomResizedCrop(224),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/38:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/39:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomResizedCrop(224),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/40:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/41:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/42:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/43:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/44:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/45:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/46:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/47:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/48:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/49:\n",
      "data_dir = '/Users/js/Desktop/all/train'\n",
      "\n",
      "transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "dataset = datasets.ImageFolder(data_dir, transform=transforms)\n",
      "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
      "15/50:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/51:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/52:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/53:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/54:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/55:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/56:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/57:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/58:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/59:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/60:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/61:\n",
      "data_dir = '/Users/js/Desktop/all/'\n",
      "\n",
      "train_transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "test_transforms = transforms.Compose([\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "train_dataset = datasets.ImageFolder(data_dir + 'train', transform=train_transforms)\n",
      "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
      "test_dataset = datasets.ImageFolder(data_dir + 'test1', transform=test_transforms)\n",
      "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
      "15/62:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/63:\n",
      "data_dir = '/Users/js/Desktop/all/'\n",
      "\n",
      "train_transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "test_transforms = transforms.Compose([\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "train_dataset = datasets.ImageFolder(data_dir + 'train', transform=train_transforms)\n",
      "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
      "test_dataset = datasets.ImageFolder(data_dir + 'test1', transform=test_transforms)\n",
      "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
      "15/64:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "import helper\n",
      "15/65:\n",
      "data_dir = '/Users/js/Desktop/all/'\n",
      "\n",
      "train_transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "test_transforms = transforms.Compose([\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "train_dataset = datasets.ImageFolder(data_dir + 'train', transform=train_transforms)\n",
      "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
      "test_dataset = datasets.ImageFolder(data_dir + 'test1', transform=test_transforms)\n",
      "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
      "15/66:\n",
      "# Run this to test your data loader\n",
      "images, labels = next(iter(dataloader))\n",
      "helper.imshow(images[0], normalize=False)\n",
      "15/67:\n",
      "# TODO: Define transforms for the training data and testing data\n",
      "data_dir = '/Users/js/Desktop/all/'\n",
      "\n",
      "train_transforms = transforms.Compose([\n",
      "    transforms.RandomRotation(30),\n",
      "    transforms.RandomHorizontalFlip(),\n",
      "    transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "\n",
      "test_transforms = transforms.Compose([\n",
      "    transforms.RandomResizedCrop(250),\n",
      "    transforms.ToTensor()\n",
      "])\n",
      "\n",
      "train_dataset = datasets.ImageFolder(data_dir + 'train', transform=train_transforms)\n",
      "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
      "\n",
      "test_dataset = datasets.ImageFolder(data_dir + 'test1', transform=test_transforms)\n",
      "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
      "15/68:\n",
      "# change this to the trainloader or testloader \n",
      "data_iter = iter(testloader)\n",
      "\n",
      "images, labels = next(data_iter)\n",
      "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
      "for ii in range(4):\n",
      "    ax = axes[ii]\n",
      "    helper.imshow(images[ii], ax=ax)\n",
      "15/69:\n",
      "# change this to the trainloader or testloader \n",
      "data_iter = iter(testloader)\n",
      "\n",
      "images, labels = next(data_iter)\n",
      "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
      "for ii in range(4):\n",
      "    ax = axes[ii]\n",
      "    helper.imshow(images[ii], ax=ax)\n",
      "15/70:\n",
      "# change this to the trainloader or testloader \n",
      "data_iter = iter(testloader)\n",
      "\n",
      "images, labels = next(data_iter)\n",
      "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
      "for ii in range(4):\n",
      "    ax = axes[ii]\n",
      "    helper.imshow(images[ii], ax=ax)\n",
      "15/71:\n",
      "# change this to the trainloader or testloader \n",
      "data_iter = iter(testloader)\n",
      "\n",
      "images, labels = next(data_iter)\n",
      "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
      "for ii in range(4):\n",
      "    ax = axes[ii]\n",
      "    helper.imshow(images[ii], ax=ax)\n",
      "15/72:\n",
      "# change this to the trainloader or testloader \n",
      "data_iter = iter(testloader)\n",
      "\n",
      "images, labels = next(data_iter)\n",
      "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
      "for ii in range(4):\n",
      "    ax = axes[ii]\n",
      "    helper.imshow(images[ii], ax=ax)\n",
      "15/73:\n",
      "# change this to the trainloader or testloader \n",
      "data_iter = iter(trainloader)\n",
      "\n",
      "images, labels = next(data_iter)\n",
      "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
      "for ii in range(4):\n",
      "    ax = axes[ii]\n",
      "    helper.imshow(images[ii], ax=ax)\n",
      "16/1:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torch import nn\n",
      "from torch import optim\n",
      "import torch.nn.functional as F\n",
      "from torchvision import datasets, transforms, models\n",
      "16/2:\n",
      "data_dir = '/Users/js/Desktop/all/'\n",
      "\n",
      "# TODO: Define transforms for the training data and testing data\n",
      "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
      "                                       transforms.RandomResizedCrop(224),\n",
      "                                       transforms.RandomHorizontalFlip(),\n",
      "                                       transforms.ToTensor(),\n",
      "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
      "                                                            [0.229, 0.224, 0.225])])\n",
      "\n",
      "test_transforms = transforms.Compose([transforms.Resize(255),\n",
      "                                      transforms.CenterCrop(224),\n",
      "                                      transforms.ToTensor(),\n",
      "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
      "                                                           [0.229, 0.224, 0.225])])\n",
      "\n",
      "# Pass transforms in here, then run the next cell to see how the transforms look\n",
      "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
      "test_data = datasets.ImageFolder(data_dir + '/test1', transform=test_transforms)\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
      "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
      "16/3:\n",
      "model = models.densenet121(pretrained=True)\n",
      "model\n",
      "16/4:\n",
      "# Freeze parameters so we don't backprop through them\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "\n",
      "from collections import OrderedDict\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "                          ('fc1', nn.Linear(1024, 500)),\n",
      "                          ('relu', nn.ReLU()),\n",
      "                          ('fc2', nn.Linear(500, 2)),\n",
      "                          ('output', nn.LogSoftmax(dim=1))\n",
      "                          ]))\n",
      "    \n",
      "model.classifier = classifier\n",
      "16/5: import time\n",
      "16/6:\n",
      "for device in ['cpu', 'cuda']:\n",
      "\n",
      "    criterion = nn.NLLLoss()\n",
      "    # Only train the classifier parameters, feature parameters are frozen\n",
      "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
      "\n",
      "    model.to(device)\n",
      "\n",
      "    for ii, (inputs, labels) in enumerate(trainloader):\n",
      "\n",
      "        # Move input and label tensors to the GPU\n",
      "        inputs, labels = inputs.to(device), labels.to(device)\n",
      "\n",
      "        start = time.time()\n",
      "\n",
      "        outputs = model.forward(inputs)\n",
      "        loss = criterion(outputs, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "\n",
      "        if ii==3:\n",
      "            break\n",
      "        \n",
      "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")\n",
      "16/7:\n",
      "## TODO: Use a pretrained model to classify the cat and dog images\n",
      "\n",
      "model = models.Inception3(pretrained=True)\n",
      "model\n",
      "16/8:\n",
      "## TODO: Use a pretrained model to classify the cat and dog images\n",
      "\n",
      "model = models.Inception3(pretrained=True)\n",
      "model\n",
      "16/9:\n",
      "## TODO: Use a pretrained model to classify the cat and dog images\n",
      "\n",
      "model = models.Inception_v3(pretrained=True)\n",
      "model\n",
      "16/10:\n",
      "## TODO: Use a pretrained model to classify the cat and dog images\n",
      "\n",
      "model = models.nception_v3(pretrained=True)\n",
      "model\n",
      "16/11:\n",
      "## TODO: Use a pretrained model to classify the cat and dog images\n",
      "\n",
      "model = models.inception_v3(pretrained=True)\n",
      "model\n",
      "16/12:\n",
      "for param in model.parameters():\n",
      "    param.require_grad = False\n",
      "    \n",
      "from collections import OrderedDict\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu', nn.LeakyReLU()),\n",
      "    ('fc2', nn.Linear(1024, 256)),\n",
      "    ('lrelu', nn.LeakyReLU()),\n",
      "    ('fc3', nn.Linear(256, 64)), \n",
      "    ('lrelu', nn.LeakyReLU()),\n",
      "    ('output', nn.Linear(64, 2)),\n",
      "    ('lsm', nn.LogSoftmax(dim=1))\n",
      "]))\n",
      "16/13:\n",
      "for param in model.parameters():\n",
      "    param.require_grad = False\n",
      "    \n",
      "from collections import OrderedDict\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu', nn.LeakyReLU()),\n",
      "    ('fc2', nn.Linear(1024, 256)),\n",
      "    ('lrelu', nn.LeakyReLU()),\n",
      "    ('fc3', nn.Linear(256, 64)), \n",
      "    ('lrelu', nn.LeakyReLU()),\n",
      "    ('output', nn.Linear(64, 2)),\n",
      "    ('lsm', nn.LogSoftmax(dim=1))\n",
      "]))\n",
      "\n",
      "model.classifier = classifier\n",
      "16/14:\n",
      "for param in model.parameters():\n",
      "    param.require_grad = False\n",
      "    \n",
      "from collections import OrderedDict\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu', nn.LeakyReLU()),\n",
      "    ('fc2', nn.Linear(1024, 256)),\n",
      "    ('lrelu', nn.LeakyReLU()),\n",
      "    ('fc3', nn.Linear(256, 64)), \n",
      "    ('lrelu', nn.LeakyReLU()),\n",
      "    ('output', nn.Linear(64, 2)),\n",
      "    ('lsm', nn.LogSoftmax(dim=1))\n",
      "]))\n",
      "\n",
      "model.classifier = classifier\n",
      "model\n",
      "16/15:\n",
      "for param in model.parameters():\n",
      "    param.require_grad = False\n",
      "    \n",
      "classifier = nn.Sequential(\n",
      "    nn.Linear(2048, 512),\n",
      "    nn.LeakyReLU(),\n",
      "    nn.Dropout(0.2),\n",
      "    nn.Linear(512, 64),\n",
      "    nn.LeakyReLU(),\n",
      "    nn.Dropout(0.2),\n",
      "    nn.Linear(64, 2),\n",
      "    nn.LogSoftmax(dim=1)\n",
      ")\n",
      "\n",
      "model.classifier = classifier\n",
      "model\n",
      "16/16: device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "16/17:\n",
      "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "device\n",
      "16/18:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adamax(model.classifier.parameters(), lr=0.001)\n",
      "model.to(device)\n",
      "16/19:\n",
      "epochs = 1\n",
      "running_loss = 0\n",
      "\n",
      "for epoch in range(epochs):\n",
      "    for image, label in trainloader:\n",
      "        image, label = image.to(device), label.to(device)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        running_loss += loss.item()\n",
      "17/1:\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "from torch import nn\n",
      "from torch import optim\n",
      "import torch.nn.functional as F\n",
      "from torchvision import datasets, transforms, models\n",
      "17/2:\n",
      "data_dir = '/Users/js/Desktop/all/'\n",
      "\n",
      "# TODO: Define transforms for the training data and testing data\n",
      "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
      "                                       transforms.RandomResizedCrop(224),\n",
      "                                       transforms.RandomHorizontalFlip(),\n",
      "                                       transforms.ToTensor(),\n",
      "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
      "                                                            [0.229, 0.224, 0.225])])\n",
      "\n",
      "test_transforms = transforms.Compose([transforms.Resize(255),\n",
      "                                      transforms.CenterCrop(224),\n",
      "                                      transforms.ToTensor(),\n",
      "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
      "                                                           [0.229, 0.224, 0.225])])\n",
      "\n",
      "# Pass transforms in here, then run the next cell to see how the transforms look\n",
      "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
      "test_data = datasets.ImageFolder(data_dir + '/test1', transform=test_transforms)\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
      "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
      "17/3:\n",
      "## TODO: Use a pretrained model to classify the cat and dog images\n",
      "\n",
      "model = models.inception_v3(pretrained=True)\n",
      "model\n",
      "17/4:\n",
      "for param in model.parameters():\n",
      "    param.require_grad = False\n",
      "    \n",
      "classifier = nn.Sequential(\n",
      "    nn.Linear(2048, 512),\n",
      "    nn.LeakyReLU(),\n",
      "    nn.Dropout(0.2),\n",
      "    nn.Linear(512, 64),\n",
      "    nn.LeakyReLU(),\n",
      "    nn.Dropout(0.2),\n",
      "    nn.Linear(64, 2),\n",
      "    nn.LogSoftmax(dim=1)\n",
      ")\n",
      "\n",
      "model.classifier = classifier\n",
      "model\n",
      "17/5:\n",
      "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "device\n",
      "17/6:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adamax(model.classifier.parameters(), lr=0.001)\n",
      "model.to(device)\n",
      "17/7:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "for epoch in range(epochs):\n",
      "    \n",
      "    train_loss = 0\n",
      "    \n",
      "    for image, label in trainloader:\n",
      "        image, label = image.to(device), label.to(device)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "\n",
      "    else:\n",
      "        \n",
      "        test_loss = 0 \n",
      "        \n",
      "        with torch.no_grad():\n",
      "            model.eval()\n",
      "            for image, label in testloader:\n",
      "                image, label = image.to(device), label.to(device)\n",
      "                output = model.forward(image)\n",
      "                test_loss += loss_fn(outupt, label).item()\n",
      "                \n",
      "                \n",
      "    print(train_loss)\n",
      "17/8:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "for epoch in range(epochs):\n",
      "    \n",
      "    train_loss = 0\n",
      "    \n",
      "    for image, label in trainloader:\n",
      "        image, label = image.to(device), label.to(device)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "\n",
      "    else:\n",
      "        \n",
      "        test_loss = 0 \n",
      "        \n",
      "        with torch.no_grad():\n",
      "            model.eval()\n",
      "            for image, label in testloader:\n",
      "                image, label = image.to(device), label.to(device)\n",
      "                output = model.forward(image)\n",
      "                test_loss += loss_fn(outupt, label).item()\n",
      "                \n",
      "                \n",
      "    print(train_loss)\n",
      "    print(test_loss)\n",
      "17/9:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "for epoch in range(epochs):\n",
      "    \n",
      "    train_loss = 0\n",
      "    \n",
      "    for image, label in trainloader:\n",
      "        image, label = image.to(device), label.to(device)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    print(train_loss)\n",
      "17/10:\n",
      "## TODO: Use a pretrained model to classify the cat and dog images\n",
      "\n",
      "model = models.resnet50(pretrained=True)\n",
      "model\n",
      "17/11:\n",
      "## TODO: Use a pretrained model to classify the cat and dog images\n",
      "\n",
      "model = models.inception_v3(pretrained=True)\n",
      "model\n",
      "17/12:\n",
      "for param in model.parameters():\n",
      "    param.require_grad = False\n",
      "    \n",
      "classifier = nn.Sequential(\n",
      "    nn.Linear(2048, 512),\n",
      "    nn.LeakyReLU(),\n",
      "    nn.Dropout(0.2),\n",
      "    nn.Linear(512, 64),\n",
      "    nn.LeakyReLU(),\n",
      "    nn.Dropout(0.2),\n",
      "    nn.Linear(64, 2),\n",
      "    nn.LogSoftmax(dim=1)\n",
      ")\n",
      "\n",
      "model.fc = classifier\n",
      "model\n",
      "17/13:\n",
      "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "device\n",
      "17/14:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adamax(model.classifier.parameters(), lr=0.001)\n",
      "model.to(device)\n",
      "17/15:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "for epoch in range(epochs):\n",
      "    \n",
      "    train_loss = 0\n",
      "    \n",
      "    for image, label in trainloader:\n",
      "        image, label = image.to(device), label.to(device)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    print(train_loss)\n",
      "17/16:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adamax(model.fc.parameters(), lr=0.001)\n",
      "model.to(device)\n",
      "17/17:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "for epoch in range(epochs):\n",
      "    \n",
      "    train_loss = 0\n",
      "    \n",
      "    for image, label in trainloader:\n",
      "        image, label = image.to(device), label.to(device)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    print(train_loss)\n",
      "17/18:\n",
      "## TODO: Use a pretrained model to classify the cat and dog images\n",
      "\n",
      "model = models.resnet50(pretrained=True)\n",
      "model\n",
      "17/19:\n",
      "for param in model.parameters():\n",
      "    param.require_grad = False\n",
      "    \n",
      "classifier = nn.Sequential(\n",
      "    nn.Linear(2048, 512),\n",
      "    nn.LeakyReLU(),\n",
      "    nn.Dropout(0.2),\n",
      "    nn.Linear(512, 64),\n",
      "    nn.LeakyReLU(),\n",
      "    nn.Dropout(0.2),\n",
      "    nn.Linear(64, 2),\n",
      "    nn.LogSoftmax(dim=1)\n",
      ")\n",
      "\n",
      "model.fc = classifier\n",
      "model\n",
      "17/20:\n",
      "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "device\n",
      "17/21:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adamax(model.fc.parameters(), lr=0.001)\n",
      "model.to(device)\n",
      "17/22:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "for epoch in range(epochs):\n",
      "    \n",
      "    train_loss = 0\n",
      "    \n",
      "    for image, label in trainloader:\n",
      "        image, label = image.to(device), label.to(device)\n",
      "        optimizer.zero_grad()\n",
      "        output = model.forward(image)\n",
      "        loss = loss_fn(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    print(train_loss)\n",
      "18/1:\n",
      "# import libraries\n",
      "import torch\n",
      "import numpy as np\n",
      "18/2:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/3:\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "    \n",
      "# obtain one batch of training images\n",
      "dataiter = iter(train_loader)\n",
      "images, labels = dataiter.next()\n",
      "images = images.numpy()\n",
      "\n",
      "# plot the images in the batch, along with the corresponding labels\n",
      "fig = plt.figure(figsize=(25, 4))\n",
      "for idx in np.arange(20):\n",
      "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
      "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
      "    # print out the correct label for each image\n",
      "    # .item() gets the value contained in a Tensor\n",
      "    ax.set_title(str(labels[idx].item()))\n",
      "18/4:\n",
      "img = np.squeeze(images[1])\n",
      "\n",
      "fig = plt.figure(figsize = (12,12)) \n",
      "ax = fig.add_subplot(111)\n",
      "ax.imshow(img, cmap='gray')\n",
      "width, height = img.shape\n",
      "thresh = img.max()/2.5\n",
      "for x in range(width):\n",
      "    for y in range(height):\n",
      "        val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
      "        ax.annotate(str(val), xy=(y,x),\n",
      "                    horizontalalignment='center',\n",
      "                    verticalalignment='center',\n",
      "                    color='white' if img[x][y]<thresh else 'black')\n",
      "18/5:\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "## TODO: Define the NN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # linear layer (784 -> 1 hidden node)\n",
      "        self.fc1 = nn.Linear(28 * 28, 128)\n",
      "        self.fc2 = nn.Linear(128, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 28 * 28)\n",
      "        # add hidden layer, with relu activation function\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = F.log\n",
      "        return x\n",
      "\n",
      "# initialize the NN\n",
      "model = Net()\n",
      "print(model)\n",
      "18/6:\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "## TODO: Define the NN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # linear layer (784 -> 1 hidden node)\n",
      "        self.fc1 = nn.Linear(28 * 28, 128)\n",
      "        self.fc2 = nn.Linear(128, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 28 * 28)\n",
      "        # add hidden layer, with relu activation function\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = F.log_softmax(x)\n",
      "        return x\n",
      "\n",
      "# initialize the NN\n",
      "model = Net()\n",
      "print(model)\n",
      "18/7:\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "## TODO: Define the NN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # linear layer (784 -> 1 hidden node)\n",
      "        self.fc1 = nn.Linear(28 * 28, 128)\n",
      "        self.fc2 = nn.Linear(128, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 28 * 28)\n",
      "        # add hidden layer, with relu activation function\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = F.log_softmax(x)\n",
      "        return x\n",
      "\n",
      "# initialize the NN\n",
      "model = Net()\n",
      "print(model)\n",
      "18/8:\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "## TODO: Define the NN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # linear layer (784 -> 1 hidden node)\n",
      "        self.fc1 = nn.Linear(28 * 28, 128)\n",
      "        self.fc2 = nn.Linear(128, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 28 * 28)\n",
      "        # add hidden layer, with relu activation function\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = F.log_softmax(x)\n",
      "        return x\n",
      "\n",
      "# initialize the NN\n",
      "model = Net()\n",
      "print(model)\n",
      "18/9:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from nn import optim\n",
      "optimizer = optim.Ad\n",
      "18/10:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.Ad\n",
      "18/11:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
      "18/12:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.RMSprop(model.parameters(), lr=1e-3, momentum=0.2)\n",
      "18/13:\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "## TODO: Define the NN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # linear layer (784 -> 1 hidden node)\n",
      "        self.fc1 = nn.Linear(28 * 28, 128)\n",
      "        self.fc2 = nn.Linear(128, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 28 * 28)\n",
      "        # add hidden layer, with relu activation function\n",
      "        x = F.relu(F.dropout(self.fc1(x), p=0.2))\n",
      "        x = F.relu(F.dropout(self.fc2(x), p=0.2))\n",
      "        x = F.log_softmax(x, dim=1)\n",
      "        return x\n",
      "\n",
      "# initialize the NN\n",
      "model = Net()\n",
      "print(model)\n",
      "18/14:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.RMSprop(model.parameters(), lr=1e-3, momentum=0.2)\n",
      "18/15:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 30  # suggest training between 20-50 epochs\n",
      "\n",
      "model.train() # prep model for training\n",
      "\n",
      "for epoch in range(n_epochs):\n",
      "    # monitor training loss\n",
      "    train_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    for data, target in train_loader:\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update running training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    # print training statistics \n",
      "    # calculate average loss over an epoch\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "\n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
      "        epoch+1, \n",
      "        train_loss\n",
      "        ))\n",
      "18/16:\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "## TODO: Define the NN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # linear layer (784 -> 1 hidden node)\n",
      "        self.fc1 = nn.Linear(28 * 28, 512)\n",
      "        self.fc2 = nn.Linear(512, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 28 * 28)\n",
      "        # add hidden layer, with relu activation function\n",
      "        x = F.relu(F.dropout(self.fc1(x), p=0.2))\n",
      "        x = F.relu(F.dropout(self.fc2(x), p=0.2))\n",
      "        x = self.output(x)\n",
      "        x = F.log_softmax(x, dim=1)\n",
      "        return x\n",
      "\n",
      "# initialize the NN\n",
      "model = Net()\n",
      "print(model)\n",
      "18/17:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.RMSprop(model.parameters(), momentum=0.2)\n",
      "18/18:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 10  # suggest training between 20-50 epochs\n",
      "\n",
      "model.train() # prep model for training\n",
      "\n",
      "for epoch in range(n_epochs):\n",
      "    # monitor training loss\n",
      "    train_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    for data, target in train_loader:\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update running training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    # print training statistics \n",
      "    # calculate average loss over an epoch\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "\n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
      "        epoch+1, \n",
      "        train_loss\n",
      "        ))\n",
      "18/19:\n",
      "import torch.nn as nn\n",
      "\n",
      "## TODO: Define the NN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # linear layer (784 -> 1 hidden node)\n",
      "        self.fc1 = nn.Linear(28 * 28, 512)\n",
      "        self.fc2 = nn.Linear(512, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=0.2)\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 28 * 28)\n",
      "        x = self.drop(self.relu(self.fc1(x)))\n",
      "        x = self.drop(self.relu(self.fc2(x)))\n",
      "        x = self.output(x)\n",
      "        x = self.lsm(x)\n",
      "        return x\n",
      "\n",
      "# initialize the NN\n",
      "model = Net()\n",
      "print(model)\n",
      "18/20:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.RMSprop(model.parameters(), momentum=0.2)\n",
      "18/21:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 10  # suggest training between 20-50 epochs\n",
      "\n",
      "model.train() # prep model for training\n",
      "\n",
      "for epoch in range(n_epochs):\n",
      "    # monitor training loss\n",
      "    train_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    for data, target in train_loader:\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update running training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    # print training statistics \n",
      "    # calculate average loss over an epoch\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "\n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
      "        epoch+1, \n",
      "        train_loss\n",
      "        ))\n",
      "18/22:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.RMSprop(model.parameters(), lr=0.005, momentum=0.2)\n",
      "18/23:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 20  # suggest training between 20-50 epochs\n",
      "\n",
      "model.train() # prep model for training\n",
      "\n",
      "for epoch in range(n_epochs):\n",
      "    # monitor training loss\n",
      "    train_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    for data, target in train_loader:\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update running training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    # print training statistics \n",
      "    # calculate average loss over an epoch\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "\n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
      "        epoch+1, \n",
      "        train_loss\n",
      "        ))\n",
      "18/24:\n",
      "# initialize lists to monitor test loss and accuracy\n",
      "test_loss = 0.0\n",
      "class_correct = list(0. for i in range(10))\n",
      "class_total = list(0. for i in range(10))\n",
      "\n",
      "model.eval() # prep model for *evaluation*\n",
      "\n",
      "for data, target in test_loader:\n",
      "    # forward pass: compute predicted outputs by passing inputs to the model\n",
      "    output = model(data)\n",
      "    # calculate the loss\n",
      "    loss = criterion(output, target)\n",
      "    # update test loss \n",
      "    test_loss += loss.item()*data.size(0)\n",
      "    # convert output probabilities to predicted class\n",
      "    _, pred = torch.max(output, 1)\n",
      "    # compare predictions to true label\n",
      "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
      "    # calculate test accuracy for each object class\n",
      "    for i in range(batch_size):\n",
      "        label = target.data[i]\n",
      "        class_correct[label] += correct[i].item()\n",
      "        class_total[label] += 1\n",
      "\n",
      "# calculate and print avg test loss\n",
      "test_loss = test_loss/len(test_loader.dataset)\n",
      "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
      "\n",
      "for i in range(10):\n",
      "    if class_total[i] > 0:\n",
      "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
      "            str(i), 100 * class_correct[i] / class_total[i],\n",
      "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
      "    else:\n",
      "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
      "\n",
      "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
      "    100. * np.sum(class_correct) / np.sum(class_total),\n",
      "    np.sum(class_correct), np.sum(class_total)))\n",
      "18/25:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.2)\n",
      "18/26:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 5  # suggest training between 20-50 epochs\n",
      "\n",
      "model.train() # prep model for training\n",
      "\n",
      "for epoch in range(n_epochs):\n",
      "    # monitor training loss\n",
      "    train_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    for data, target in train_loader:\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update running training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    # print training statistics \n",
      "    # calculate average loss over an epoch\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "\n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
      "        epoch+1, \n",
      "        train_loss\n",
      "        ))\n",
      "18/27:\n",
      "# initialize lists to monitor test loss and accuracy\n",
      "test_loss = 0.0\n",
      "class_correct = list(0. for i in range(10))\n",
      "class_total = list(0. for i in range(10))\n",
      "\n",
      "model.eval() # prep model for *evaluation*\n",
      "\n",
      "for data, target in test_loader:\n",
      "    # forward pass: compute predicted outputs by passing inputs to the model\n",
      "    output = model(data)\n",
      "    # calculate the loss\n",
      "    loss = criterion(output, target)\n",
      "    # update test loss \n",
      "    test_loss += loss.item()*data.size(0)\n",
      "    # convert output probabilities to predicted class\n",
      "    _, pred = torch.max(output, 1)\n",
      "    # compare predictions to true label\n",
      "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
      "    # calculate test accuracy for each object class\n",
      "    for i in range(batch_size):\n",
      "        label = target.data[i]\n",
      "        class_correct[label] += correct[i].item()\n",
      "        class_total[label] += 1\n",
      "\n",
      "# calculate and print avg test loss\n",
      "test_loss = test_loss/len(test_loader.dataset)\n",
      "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
      "\n",
      "for i in range(10):\n",
      "    if class_total[i] > 0:\n",
      "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
      "            str(i), 100 * class_correct[i] / class_total[i],\n",
      "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
      "    else:\n",
      "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
      "\n",
      "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
      "    100. * np.sum(class_correct) / np.sum(class_total),\n",
      "    np.sum(class_correct), np.sum(class_total)))\n",
      "18/28:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
      "18/29:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
      "18/30:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 5  # suggest training between 20-50 epochs\n",
      "\n",
      "model.train() # prep model for training\n",
      "\n",
      "for epoch in range(n_epochs):\n",
      "    # monitor training loss\n",
      "    train_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    for data, target in train_loader:\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update running training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    # print training statistics \n",
      "    # calculate average loss over an epoch\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "\n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
      "        epoch+1, \n",
      "        train_loss\n",
      "        ))\n",
      "18/31:\n",
      "## TODO: Specify loss and optimization functions\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "from torch import optim\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.1)\n",
      "18/32:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 5  # suggest training between 20-50 epochs\n",
      "\n",
      "model.train() # prep model for training\n",
      "\n",
      "for epoch in range(n_epochs):\n",
      "    # monitor training loss\n",
      "    train_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    for data, target in train_loader:\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update running training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    # print training statistics \n",
      "    # calculate average loss over an epoch\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "\n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
      "        epoch+1, \n",
      "        train_loss\n",
      "        ))\n",
      "18/33:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(type(train_data))\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/34:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(np.array(train_data))\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/35:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(train_data.shape)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/36:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform).numpy()\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform).numpy()\n",
      "\n",
      "print(type(train_data))\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/37:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform).numpy()\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform).numpy()\n",
      "\n",
      "print(type(train_data))\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/38:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(train_data.train.numpy())\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/39:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(train_data.train())\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/40:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(train_data.train\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/41:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(train_data.train)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/42:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(train_data)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/43:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True, transform=transform)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(test_data)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/44:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(train_data)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/45:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "print(type(train_data))\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/46:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "18/47:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "train_loader\n",
      "18/48:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "train_loader[0]\n",
      "18/49:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "a, b = train_loader\n",
      "18/50:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "train_loader\n",
      "18/51:\n",
      "# import libraries\n",
      "import torch\n",
      "import numpy as np\n",
      "import skorch\n",
      "18/52:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data, batch_size=batch_size)\n",
      "skorch.dataset.CVSplit(trainloader)\n",
      "18/53:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data)\n",
      "skorch.dataset.CVSplit(trainloader)\n",
      "18/54:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data)\n",
      "skorch.dataset.CVSplit(trainloader)[0]\n",
      "18/55:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data)\n",
      "skorch.dataset.CVSplit(trainloader)\n",
      "18/56:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data)\n",
      "18/57:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data)\n",
      "trainloader\n",
      "18/58:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data)\n",
      "np.array(trainloader)?\n",
      "18/59:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data)\n",
      "np.array(trainloader)\n",
      "18/60:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data)\n",
      "trainloader.shape/\n",
      "18/61:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "\n",
      "# convert data to torch.FloatTensor\n",
      "transform = transforms.ToTensor()\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.MNIST(root='data', train=True,\n",
      "                                   download=True)\n",
      "test_data = datasets.MNIST(root='data', train=False,\n",
      "                                  download=True, transform=transform)\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "trainloader = skorch.dataset.Dataset(train_data)\n",
      "trainloader.shape\n",
      "19/1:\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "# Read in the image\n",
      "image = mpimg.imread('data/curved_lane.jpg')\n",
      "\n",
      "plt.imshow(image)\n",
      "19/2:\n",
      "# Convert to grayscale for filtering\n",
      "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
      "\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/3:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, sobel_y)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/4:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.matrix('-1 0 1; -2 0 2; -1 0 1')\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, sobel_x)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/5:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.matrix('-1 0 1; -2 0 2; -1 0 1')\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, sobel_y)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/6:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.matrix('-1 0 1; -2 0 2; -1 0 1')\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, sobel_x)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/7:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.matrix('-1 0 1; -2 0 2; -1 0 1')\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, sobel_y)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/8:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.matrix('-1 0 1; -2 0 2; -1 0 1')\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, sobel_y)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "filtered_image\n",
      "19/9:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1 0 1],\n",
      "                    [-2 0 2],\n",
      "                    [-1 0 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, sobel_y)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/10:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, sobel_y)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/11:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, sobel_x)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/12:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = np.array([[1, 2, 1],\n",
      "                       [2, 4, 2],\n",
      "                       [1, 2, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/13:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/16 * np.array([[1, 2, 1],\n",
      "                            [2, 4, 2],\n",
      "                             [1, 2, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/14:\n",
      "# Convert to grayscale for filtering\n",
      "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
      "\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/15:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/16:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "for i in range(20):\n",
      "    filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/17:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/18:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "print(type(filtered_image))\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/19:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "print(gray[:10])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "print(filtered_image[:10])\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/20:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "print(gray[:10])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "for i in range(100):\n",
      "    filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "print(filtered_image[:10])\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/21:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "print(gray[:10])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "for i in range(10):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "\n",
      "print(filtered_image[:10])\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/22:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "print(gray[:10])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "for i in range(100):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "\n",
      "print(filtered_image[:10])\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/23:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "print(gray[:10])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "for i in range(500):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "\n",
      "print(filtered_image[:10])\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/24:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "print(gray[:10])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "\n",
      "for i in range(5000):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "\n",
      "print(filtered_image[:10])\n",
      "\n",
      "plt.imshow(filtered_image, cmap='gray')\n",
      "19/25:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = [np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/26:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))])\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/27:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))])\n",
      "\n",
      "print(type(final_image))\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/28:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))])\n",
      "\n",
      "print(x_edges[:1])\n",
      "print(y_edges[:1])\n",
      "print(final_image[:1])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "19/29:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([int(np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2)) for i in range(len(x_edges))])\n",
      "\n",
      "print(x_edges[:1])\n",
      "print(y_edges[:1])\n",
      "print(final_image[:1])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "19/30:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([(np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))])\n",
      "\n",
      "print(x_edges[:1])\n",
      "print(y_edges[:1])\n",
      "print(final_image[:1])\n",
      "\n",
      "plt.imagesc(final_image, cmap='gray')\n",
      "19/31:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "print(x_edges[:1])\n",
      "print(y_edges[:1])\n",
      "print(final_image[:1])\n",
      "\n",
      "plt.imagesc(final_image, cmap='gray')\n",
      "19/32:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "print(final_image[:1])\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/33:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "print(max(final_image))\n",
      "19/34:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "print(max(final_image))\n",
      "19/35:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "print([max(i) for i in final_image])\n",
      "19/36:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "print(max([max(i) for i in final_image])\n",
      "19/37:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "print(max([max(i) for i in final_image]))\n",
      "19/38:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "print([max(i) for i in final_image])\n",
      "19/39:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "plt.imshow(np.array([[1]]), cmap='gray')\n",
      "19/40:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "plt.imshow(np.array([[1.]]), cmap='gray')\n",
      "19/41:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "plt.imshow(np.array([[1.2]]), cmap='gray')\n",
      "19/42:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "plt.imshow(np.array([[42.2]]), cmap='gray')\n",
      "19/43:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "plt.imshow(np.array([[256.2]]), cmap='gray')\n",
      "19/44:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "plt.imshow(np.array([[253.2]]), cmap='gray')\n",
      "19/45:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "plt.imshow(np.array([[253.2, 124.2], [4.62, 1.35]]), cmap='gray')\n",
      "19/46:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "print(final_image.shape)\n",
      "19/47:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "print(final_image.shape)\n",
      "print(x_edges.shape)\n",
      "print(y_edges.shape)\n",
      "19/48:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "print(final_image.shape)\n",
      "print(type(y_edges))\n",
      "19/49:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "#plt.imshow(final_image, cmap='gray')\n",
      "print(type(final_image))\n",
      "print(type(y_edges))\n",
      "19/50:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/51:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/52:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "19/53:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/54:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/55:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "unchanged = np.array([[1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "final = cv2.filter2D(final_image, -1, unchanged)\n",
      "\n",
      "plt.imshow(final, cmap='gray')\n",
      "19/56:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "unchanged = np.array([[1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x, cv2.CV_8U)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y, cv2.CV_8U)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "final = cv2.filter2D(final_image, -1, unchanged)\n",
      "\n",
      "plt.imshow(final, cmap='gray')\n",
      "19/57:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "unchanged = np.array([[1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x, cv2.CV_8U)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y, cv2.CV_8U)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "final = cv2.filter2D(final_image, -1, unchanged, cv2.CV_8U)\n",
      "\n",
      "plt.imshow(final, cmap='gray')\n",
      "19/58:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "unchanged = np.array([[1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "final = cv2.filter2D(final_image, -1, unchanged)\n",
      "\n",
      "plt.imshow(final)\n",
      "19/59:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))])\n",
      "\n",
      "plt.imshow(final_image)\n",
      "19/60:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i]) ** 2 for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image)\n",
      "19/61:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image)\n",
      "19/62:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = cv2.filter2D(gray, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/63:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/64:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = gray\n",
      "for i in range(10):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/65:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/28 * np.array([[1, 4, 1],\n",
      "                              [4, 8, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = gray\n",
      "for i in range(20):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/66:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = gray\n",
      "for i in range(20):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/67:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/68:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/69:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/70:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel)  \n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/71:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "laplace = cv2.filter2D(gray, -1, laplacian)\n",
      "plt.imshow(laplace, cmap='gray')\n",
      "19/72:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "laplace = cv2.Laplacian(gray)\n",
      "plt.imshow(laplace, cmap='gray')\n",
      "19/73:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "laplace = cv2.Laplacian(gray, cv2.CV_64F)\n",
      "plt.imshow(laplace, cmap='gray')\n",
      "19/74:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "laplace = cv2.Laplacian(gray, cv2.CV_64F)\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/75:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/76:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/77:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/78:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "mean = np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "meanblur = cv2.filter2D(gray, -1, mean)\n",
      "\n",
      "plt.imshow(meanblur, cmap='gray')\n",
      "19/79:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(200):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "meanblur = cv2.filter2D(gray, -1, mean)\n",
      "\n",
      "plt.imshow(meanblur, cmap='gray')\n",
      "19/80:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(20):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/81:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(50):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/82:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(1):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/83:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(2):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/84:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "laplacian = np.array([[0, 1, 0],\n",
      "                      [1, -4, 1],\n",
      "                      [0, 1, 0]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(1):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/85:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_3 = 1/36 * np.array([[1, 4, 1],\n",
      "                              [4, 16, 4],\n",
      "                              [1, 4, 1]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(5):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_3)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/86:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(5):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/87:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/25 * np.ones((5,5))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(5):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/88:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(5):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/89:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/64 * np.ones((8,8))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(5):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/90:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/25 * np.ones((5,5))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(5):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/91:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/25 * np.ones((5,5))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(1):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/92:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/25 * np.ones((5,5))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "for i in range(3):\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "    filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/93:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/25 * np.ones((5,5))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/94:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/95:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/96:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/97:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/98:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/99:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/100:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/101:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/102:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/103:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/104:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/105:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/106:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/107:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/108:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/109:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/110:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5')\n",
      "\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/111:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/112:\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "# Read in the image\n",
      "image = mpimg.imread('/Users/js/Desktop/Screen Shot 2018-11-12 at 6.19.37 PM.png')\n",
      "\n",
      "plt.imshow(image)\n",
      "19/113:\n",
      "# Convert to grayscale for filtering\n",
      "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
      "\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/114:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(blurred, cmap='gray')\n",
      "19/115:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/116:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "19/117:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/118:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/119:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "print(wiki_gaussian)\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "    \n",
      "blurred = filtered_image\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "19/120:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -1, -2, -1], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 1, 2, 1]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-1, 0, 1],\n",
      "                    [-2, 0, 2],\n",
      "                    [-1, 0, 1]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "19/121:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-2, 0, 2],\n",
      "                    [-4, 0, 4],\n",
      "                    [-2, 0, 2]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "19/122:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "19/123:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "19/124:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, gaussian_5)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/125:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/126:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/127:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/128:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(5*np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/129:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/130:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "19/131:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/25 * np.ones((5,5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "19/132:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/9 * np.ones((3,3))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "19/133:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/25 * np.ones((5,5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "19/134:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "19/135:\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "# Read in the image\n",
      "image = mpimg.imread('/Users/js/Desktop/23621568_2261964924029998_373406371621137953_n.jpg')\n",
      "\n",
      "plt.imshow(image)\n",
      "19/136:\n",
      "# Convert to grayscale for filtering\n",
      "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
      "\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/137:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = 1/49 * np.ones((7,7))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "19/138:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "19/139:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_and(final_image), cmap='gray')\n",
      "19/140:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "19/141:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(final_image, cmap='gray')\n",
      "19/142:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "19/143:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/144:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/145:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/146:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/147:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/148:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/149:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/150:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/151:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/152:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/153:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/154:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/155:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "#plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/156:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "#plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/157:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "#plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/158:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "#plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/159:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/160:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/161:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/162:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/163:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/164:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "#plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/165:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/166:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/167:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/168:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/15)**2 * np.ones((15, 15))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/169:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/170:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/171:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "#plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/172:\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "# Read in the image\n",
      "image = mpimg.imread('/Users/js/Desktop/Screen Shot 2018-11-12 at 6.34.56 PM.png')\n",
      "\n",
      "plt.imshow(image)\n",
      "19/173:\n",
      "# Convert to grayscale for filtering\n",
      "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
      "\n",
      "plt.imshow(gray, cmap='gray')\n",
      "19/174:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "#plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/175:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/176:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/177:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(x_edges), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(y_edges), cmap='gray')\n",
      "19/178:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(x_edges), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(y_edges), cmap='gray')\n",
      "19/179:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(x_edges), cmap='gray')\n",
      "#plt.imshow(cv2.bitwise_not(y_edges), cmap='gray')\n",
      "19/180:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "#plt.imshow(cv2.bitwise_not(x_edges), cmap='gray')\n",
      "#plt.imshow(cv2.bitwise_not(y_edges), cmap='gray')\n",
      "19/181:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(x_edges), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(y_edges), cmap='gray')\n",
      "19/182:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(x_edges), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(y_edges), cmap='gray')\n",
      "19/183:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(cv2.bitwise_not(x_edges), cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/184:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/185:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "plt.imshow(y_edges, cmap='gray')\n",
      "19/186:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "#filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "19/187:\n",
      "# Create a custom kernel\n",
      "\n",
      "# 3x3 array for edge detection\n",
      "sobel_y = np.array([[ -2, -4, -2], \n",
      "                   [ 0, 0, 0], \n",
      "                   [ 2, 4, 2]])\n",
      "\n",
      "## TODO: Create and apply a Sobel x operator\n",
      "sobel_x = np.array([[-20, 0, 20],\n",
      "                    [-40, 0, 40],\n",
      "                    [-20, 0, 20]])\n",
      "\n",
      "gaussian_5 = 1/314 * np.array([[1, 4, 8, 4, 1],\n",
      "                              [4, 8, 32,8, 2],\n",
      "                              [8, 32,64,32,8],\n",
      "                              [4, 8, 32,32,4],\n",
      "                              [1, 4, 8, 4, 1]])\n",
      "\n",
      "mean = (1/5)**2 * np.ones((5, 5))\n",
      "\n",
      "wiki_gaussian = np.matrix('0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00038771 0.01330373 0.11098164 0.22508352 0.11098164 0.01330373 0.00038771 0.00019117 0.00655965 0.05472157 0.11098164 0.05472157 0.00655965 0.00019117 0.00002292 0.00078633 0.00655965 0.01330373 0.00655965 0.00078633 0.00002292 0.00000067 0.00002292 0.00019117 0.00038771 0.00019117 0.00002292 0.00000067')\n",
      "wiki_gaussian = np.resize(wiki_gaussian, (7,7))\n",
      "\n",
      "# Filter the image using filter2D, which has inputs: (grayscale image, bit-depth, kernel) \n",
      "\n",
      "filtered_image = gray\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, wiki_gaussian)\n",
      "filtered_image = cv2.filter2D(filtered_image, -1, mean)\n",
      "\n",
      "x_edges = cv2.filter2D(filtered_image, -1, sobel_x)\n",
      "y_edges = cv2.filter2D(filtered_image, -1, sobel_y)\n",
      "final_image = np.int8(np.array([np.sqrt(x_edges[i] ** 2 + y_edges[i] ** 2) for i in range(len(x_edges))]))\n",
      "\n",
      "\n",
      "plt.imshow(cv2.bitwise_not(final_image), cmap='gray')\n",
      "plt.imshow(x_edges, cmap='gray')\n",
      "#plt.imshow(y_edges, cmap='gray')\n",
      "20/1:\n",
      "import torch\n",
      "import numpy as np\n",
      "\n",
      "# check if CUDA is available\n",
      "train_on_gpu = torch.cuda.is_available()\n",
      "\n",
      "if not train_on_gpu:\n",
      "    print('CUDA is not available.  Training on CPU ...')\n",
      "else:\n",
      "    print('CUDA is available!  Training on GPU ...')\n",
      "20/2:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "from torch.utils.data.sampler import SubsetRandomSampler\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "# percentage of training set to use as validation\n",
      "valid_size = 0.2\n",
      "\n",
      "# convert data to a normalized torch.FloatTensor\n",
      "transform = transforms.Compose([\n",
      "    transforms.ToTensor(),\n",
      "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
      "    ])\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.CIFAR10('data', train=True,\n",
      "                              download=True, transform=transform)\n",
      "test_data = datasets.CIFAR10('data', train=False,\n",
      "                             download=True, transform=transform)\n",
      "\n",
      "# obtain training indices that will be used for validation\n",
      "num_train = len(train_data)\n",
      "indices = list(range(num_train))\n",
      "np.random.shuffle(indices)\n",
      "split = int(np.floor(valid_size * num_train))\n",
      "train_idx, valid_idx = indices[split:], indices[:split]\n",
      "\n",
      "# define samplers for obtaining training and validation batches\n",
      "train_sampler = SubsetRandomSampler(train_idx)\n",
      "valid_sampler = SubsetRandomSampler(valid_idx)\n",
      "\n",
      "# prepare data loaders (combine dataset and sampler)\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    sampler=train_sampler, num_workers=num_workers)\n",
      "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
      "    sampler=valid_sampler, num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "# specify the image classes\n",
      "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
      "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "20/3:\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "# helper function to un-normalize and display an image\n",
      "def imshow(img):\n",
      "    img = img / 2 + 0.5  # unnormalize\n",
      "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
      "20/4:\n",
      "# obtain one batch of training images\n",
      "dataiter = iter(train_loader)\n",
      "images, labels = dataiter.next()\n",
      "images = images.numpy() # convert images to numpy for display\n",
      "\n",
      "# plot the images in the batch, along with the corresponding labels\n",
      "fig = plt.figure(figsize=(25, 4))\n",
      "# display 20 images\n",
      "for idx in np.arange(20):\n",
      "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
      "    imshow(images[idx])\n",
      "    ax.set_title(classes[labels[idx]])\n",
      "20/5:\n",
      "rgb_img = np.squeeze(images[3])\n",
      "channels = ['red channel', 'green channel', 'blue channel']\n",
      "\n",
      "fig = plt.figure(figsize = (36, 36)) \n",
      "for idx in np.arange(rgb_img.shape[0]):\n",
      "    ax = fig.add_subplot(1, 3, idx + 1)\n",
      "    img = rgb_img[idx]\n",
      "    ax.imshow(img, cmap='gray')\n",
      "    ax.set_title(channels[idx])\n",
      "    width, height = img.shape\n",
      "    thresh = img.max()/2.5\n",
      "    for x in range(width):\n",
      "        for y in range(height):\n",
      "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
      "            ax.annotate(str(val), xy=(y,x),\n",
      "                    horizontalalignment='center',\n",
      "                    verticalalignment='center', size=8,\n",
      "                    color='white' if img[x][y]<thresh else 'black')\n",
      "20/6:\n",
      "import torch.nn as nn\n",
      "\n",
      "# define the CNN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # convolutional layer\n",
      "        self.conv1 = nn.Conv2d(3, 16, 5, padding=1)\n",
      "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
      "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
      "        # max pooling layer \n",
      "        self.pool = nn.MaxPool2d(2, 2)\n",
      "        # fully connected layers\n",
      "        self.fc1 = nn.Linear()\n",
      "        # relu\n",
      "        self.relu = nn.LeakyReLU()\n",
      "\n",
      "    def forward(self, x):\n",
      "        # add sequence of convolutional and max pooling layers\n",
      "        x = self.pool(self.relu(self.conv1(x)))\n",
      "        return x\n",
      "\n",
      "# create a complete CNN\n",
      "model = Net()\n",
      "print(model)\n",
      "\n",
      "# move tensors to GPU if CUDA is available\n",
      "if train_on_gpu:\n",
      "    model.cuda()\n",
      "20/7:\n",
      "rgb_img = np.squeeze(images[3])\n",
      "channels = ['red channel', 'green channel', 'blue channel']\n",
      "\n",
      "fig = plt.figure(figsize = (36, 36)) \n",
      "for idx in np.arange(rgb_img.shape[0]):\n",
      "    ax = fig.add_subplot(1, 3, idx + 1)\n",
      "    img = rgb_img[idx]\n",
      "    ax.imshow(img, cmap='gray')\n",
      "    ax.set_title(channels[idx])\n",
      "    width, height = img.shape\n",
      "    thresh = img.max()/2.5\n",
      "    for x in range(width):\n",
      "        for y in range(height):\n",
      "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
      "            ax.annotate(str(val), xy=(y,x),\n",
      "                    horizontalalignment='center',\n",
      "                    verticalalignment='center', size=8,\n",
      "                    color='white' if img[x][y]<thresh else 'black')\n",
      "20/8:\n",
      "# obtain one batch of training images\n",
      "dataiter = iter(train_loader)\n",
      "images, labels = dataiter.next()\n",
      "images = images.numpy() # convert images to numpy for display\n",
      "\n",
      "# plot the images in the batch, along with the corresponding labels\n",
      "fig = plt.figure(figsize=(25, 4))\n",
      "# display 20 images\n",
      "for idx in np.arange(20):\n",
      "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
      "    imshow(images[idx])\n",
      "    ax.set_title(classes[labels[idx]])\n",
      "20/9:\n",
      "import torch.nn as nn\n",
      "\n",
      "# define the CNN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # convolutional layer\n",
      "        self.conv1 = nn.Conv2d(3, 16, 5, padding=1)\n",
      "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
      "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
      "        # max pooling layer \n",
      "        self.pool = nn.MaxPool2d(2, 2)\n",
      "        # fully connected layers\n",
      "        self.fc1 = nn.Linear(4, 16)\n",
      "        self.output = nn.Linear(16, 10)\n",
      "        # relu\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        # output softmax\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        # dropout \n",
      "        self.drop = nn.Dropout(p=0.2)\n",
      "    def forward(self, x):\n",
      "        # add sequence of convolutional and max pooling layers\n",
      "        x = self.pool(self.relu(self.conv1(x)))\n",
      "        x = self.pool(self.relu(self.conv2(x)))\n",
      "        x = self.drop(self.pool(self.relu(self.conv3(x))))\n",
      "        x = self.drop(self.relu(self.fc1(x)))\n",
      "        x = self.lsm(self.output(x))\n",
      "        return x\n",
      "\n",
      "# create a complete CNN\n",
      "model = Net()\n",
      "print(model)\n",
      "\n",
      "# move tensors to GPU if CUDA is available\n",
      "if train_on_gpu:\n",
      "    model.cuda()\n",
      "20/10:\n",
      "import torch.optim as optim\n",
      "\n",
      "# specify loss function\n",
      "criterion =\n",
      "\n",
      "# specify optimizer\n",
      "optimizer = None\n",
      "20/11:\n",
      "import torch.optim as optim\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "optimizer = optim.A\n",
      "20/12:\n",
      "import torch.optim as optim\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
      "20/13:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 5 # you may increase this number to train a final model\n",
      "\n",
      "valid_loss_min = np.Inf # track change in validation loss\n",
      "\n",
      "for epoch in range(1, n_epochs+1):\n",
      "\n",
      "    # keep track of training and validation loss\n",
      "    train_loss = 0.0\n",
      "    valid_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    model.train()\n",
      "    for data, target in train_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    ######################    \n",
      "    # validate the model #\n",
      "    ######################\n",
      "    model.eval()\n",
      "    for data, target in valid_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # update average validation loss \n",
      "        valid_loss += loss.item()*data.size(0)\n",
      "    \n",
      "    # calculate average losses\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
      "        \n",
      "    # print training/validation statistics \n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
      "        epoch, train_loss, valid_loss))\n",
      "    \n",
      "    # save model if validation loss has decreased\n",
      "    if valid_loss <= valid_loss_min:\n",
      "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
      "        valid_loss_min,\n",
      "        valid_loss))\n",
      "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
      "        valid_loss_min = valid_loss\n",
      "20/14:\n",
      "import torch.nn as nn\n",
      "\n",
      "# define the CNN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # convolutional layer\n",
      "        \n",
      "        self.conv1 = nn.Conv2d(3, 16, 5, padding=1) # 32x32x3 -> 16x16x16 with pooling\n",
      "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1) # -> 8x8x32 with pooling\n",
      "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1) # -> 4x4x64 with pooling\n",
      "        # max pooling layer \n",
      "        self.pool = nn.MaxPool2d(2, 2)\n",
      "        # fully connected layers\n",
      "        self.fc1 = nn.Linear(1024, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        # relu\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        # output softmax\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        # dropout \n",
      "        self.drop = nn.Dropout(p=0.2)\n",
      "    def forward(self, x):\n",
      "        # add sequence of convolutional and max pooling layers\n",
      "        x = self.pool(self.relu(self.conv1(x)))\n",
      "        x = self.pool(self.relu(self.conv2(x)))\n",
      "        x = self.pool(self.relu(self.conv3(x)))\n",
      "        \n",
      "        x = x.view(-1, 4*4*64) #flatten\n",
      "        \n",
      "        x = self.drop(self.relu(self.fc1(x)))\n",
      "        x = self.drop(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(self.output(x))\n",
      "        return x\n",
      "\n",
      "# create a complete CNN\n",
      "model = Net()\n",
      "print(model)\n",
      "\n",
      "# move tensors to GPU if CUDA is available\n",
      "if train_on_gpu:\n",
      "    model.cuda()\n",
      "20/15:\n",
      "import torch.optim as optim\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
      "20/16:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 5 # you may increase this number to train a final model\n",
      "\n",
      "valid_loss_min = np.Inf # track change in validation loss\n",
      "\n",
      "for epoch in range(1, n_epochs+1):\n",
      "\n",
      "    # keep track of training and validation loss\n",
      "    train_loss = 0.0\n",
      "    valid_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    model.train()\n",
      "    for data, target in train_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    ######################    \n",
      "    # validate the model #\n",
      "    ######################\n",
      "    model.eval()\n",
      "    for data, target in valid_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # update average validation loss \n",
      "        valid_loss += loss.item()*data.size(0)\n",
      "    \n",
      "    # calculate average losses\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
      "        \n",
      "    # print training/validation statistics \n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
      "        epoch, train_loss, valid_loss))\n",
      "    \n",
      "    # save model if validation loss has decreased\n",
      "    if valid_loss <= valid_loss_min:\n",
      "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
      "        valid_loss_min,\n",
      "        valid_loss))\n",
      "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
      "        valid_loss_min = valid_loss\n",
      "21/1:\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "# define the CNN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # convolutional layer (sees 32x32x3 image tensor)\n",
      "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
      "        # convolutional layer (sees 16x16x16 tensor)\n",
      "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
      "        # convolutional layer (sees 8x8x32 tensor)\n",
      "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
      "        # max pooling layer\n",
      "        self.pool = nn.MaxPool2d(2, 2)\n",
      "        # linear layer (64 * 4 * 4 -> 500)\n",
      "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
      "        # linear layer (500 -> 10)\n",
      "        self.fc2 = nn.Linear(500, 10)\n",
      "        # dropout layer (p=0.25)\n",
      "        self.dropout = nn.Dropout(0.25)\n",
      "\n",
      "    def forward(self, x):\n",
      "        # add sequence of convolutional and max pooling layers\n",
      "        x = self.pool(F.relu(self.conv1(x)))\n",
      "        x = self.pool(F.relu(self.conv2(x)))\n",
      "        x = self.pool(F.relu(self.conv3(x)))\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 64 * 4 * 4)\n",
      "        # add dropout layer\n",
      "        x = self.dropout(x)\n",
      "        # add 1st hidden layer, with relu activation function\n",
      "        x = F.relu(self.fc1(x))\n",
      "        # add dropout layer\n",
      "        x = self.dropout(x)\n",
      "        # add 2nd hidden layer, with relu activation function\n",
      "        x = self.fc2(x)\n",
      "        return x\n",
      "\n",
      "# create a complete CNN\n",
      "model = Net()\n",
      "print(model)\n",
      "\n",
      "# move tensors to GPU if CUDA is available\n",
      "if train_on_gpu:\n",
      "    model.cuda()\n",
      "21/2:\n",
      "import torch.optim as optim\n",
      "\n",
      "# specify loss function (categorical cross-entropy)\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "# specify optimizer\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
      "21/3:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 30\n",
      "\n",
      "valid_loss_min = np.Inf # track change in validation loss\n",
      "\n",
      "for epoch in range(1, n_epochs+1):\n",
      "\n",
      "    # keep track of training and validation loss\n",
      "    train_loss = 0.0\n",
      "    valid_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    model.train()\n",
      "    for data, target in train_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    ######################    \n",
      "    # validate the model #\n",
      "    ######################\n",
      "    model.eval()\n",
      "    for data, target in valid_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # update average validation loss \n",
      "        valid_loss += loss.item()*data.size(0)\n",
      "    \n",
      "    # calculate average losses\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
      "        \n",
      "    # print training/validation statistics \n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
      "        epoch, train_loss, valid_loss))\n",
      "    \n",
      "    # save model if validation loss has decreased\n",
      "    if valid_loss <= valid_loss_min:\n",
      "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
      "        valid_loss_min,\n",
      "        valid_loss))\n",
      "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
      "        valid_loss_min = valid_loss\n",
      "21/4:\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "# define the CNN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # convolutional layer (sees 32x32x3 image tensor)\n",
      "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
      "        # convolutional layer (sees 16x16x16 tensor)\n",
      "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
      "        # convolutional layer (sees 8x8x32 tensor)\n",
      "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
      "        # max pooling layer\n",
      "        self.pool = nn.MaxPool2d(2, 2)\n",
      "        # linear layer (64 * 4 * 4 -> 500)\n",
      "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
      "        # linear layer (500 -> 10)\n",
      "        self.fc2 = nn.Linear(500, 10)\n",
      "        # dropout layer (p=0.25)\n",
      "        self.dropout = nn.Dropout(0.25)\n",
      "\n",
      "    def forward(self, x):\n",
      "        # add sequence of convolutional and max pooling layers\n",
      "        x = self.pool(F.relu(self.conv1(x)))\n",
      "        x = self.pool(F.relu(self.conv2(x)))\n",
      "        x = self.pool(F.relu(self.conv3(x)))\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 64 * 4 * 4)\n",
      "        # add dropout layer\n",
      "        x = self.dropout(x)\n",
      "        # add 1st hidden layer, with relu activation function\n",
      "        x = F.relu(self.fc1(x))\n",
      "        # add dropout layer\n",
      "        x = self.dropout(x)\n",
      "        # add 2nd hidden layer, with relu activation function\n",
      "        x = self.fc2(x)\n",
      "        return x\n",
      "\n",
      "# create a complete CNN\n",
      "model = Net()\n",
      "print(model)\n",
      "\n",
      "# move tensors to GPU if CUDA is available\n",
      "if train_on_gpu:\n",
      "    model.cuda()\n",
      "21/5:\n",
      "import torch\n",
      "import numpy as np\n",
      "\n",
      "# check if CUDA is available\n",
      "train_on_gpu = torch.cuda.is_available()\n",
      "\n",
      "if not train_on_gpu:\n",
      "    print('CUDA is not available.  Training on CPU ...')\n",
      "else:\n",
      "    print('CUDA is available!  Training on GPU ...')\n",
      "21/6:\n",
      "from torchvision import datasets\n",
      "import torchvision.transforms as transforms\n",
      "from torch.utils.data.sampler import SubsetRandomSampler\n",
      "\n",
      "# number of subprocesses to use for data loading\n",
      "num_workers = 0\n",
      "# how many samples per batch to load\n",
      "batch_size = 20\n",
      "# percentage of training set to use as validation\n",
      "valid_size = 0.2\n",
      "\n",
      "# convert data to a normalized torch.FloatTensor\n",
      "transform = transforms.Compose([\n",
      "    transforms.ToTensor(),\n",
      "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
      "    ])\n",
      "\n",
      "# choose the training and test datasets\n",
      "train_data = datasets.CIFAR10('data', train=True,\n",
      "                              download=True, transform=transform)\n",
      "test_data = datasets.CIFAR10('data', train=False,\n",
      "                             download=True, transform=transform)\n",
      "\n",
      "# obtain training indices that will be used for validation\n",
      "num_train = len(train_data)\n",
      "indices = list(range(num_train))\n",
      "np.random.shuffle(indices)\n",
      "split = int(np.floor(valid_size * num_train))\n",
      "train_idx, valid_idx = indices[split:], indices[:split]\n",
      "\n",
      "# define samplers for obtaining training and validation batches\n",
      "train_sampler = SubsetRandomSampler(train_idx)\n",
      "valid_sampler = SubsetRandomSampler(valid_idx)\n",
      "\n",
      "# prepare data loaders (combine dataset and sampler)\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
      "    sampler=train_sampler, num_workers=num_workers)\n",
      "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
      "    sampler=valid_sampler, num_workers=num_workers)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "    num_workers=num_workers)\n",
      "\n",
      "# specify the image classes\n",
      "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
      "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "21/7:\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "# helper function to un-normalize and display an image\n",
      "def imshow(img):\n",
      "    img = img / 2 + 0.5  # unnormalize\n",
      "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
      "21/8:\n",
      "# obtain one batch of training images\n",
      "dataiter = iter(train_loader)\n",
      "images, labels = dataiter.next()\n",
      "images = images.numpy() # convert images to numpy for display\n",
      "\n",
      "# plot the images in the batch, along with the corresponding labels\n",
      "fig = plt.figure(figsize=(25, 4))\n",
      "# display 20 images\n",
      "for idx in np.arange(20):\n",
      "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
      "    imshow(images[idx])\n",
      "    ax.set_title(classes[labels[idx]])\n",
      "21/9:\n",
      "rgb_img = np.squeeze(images[3])\n",
      "channels = ['red channel', 'green channel', 'blue channel']\n",
      "\n",
      "fig = plt.figure(figsize = (36, 36)) \n",
      "for idx in np.arange(rgb_img.shape[0]):\n",
      "    ax = fig.add_subplot(1, 3, idx + 1)\n",
      "    img = rgb_img[idx]\n",
      "    ax.imshow(img, cmap='gray')\n",
      "    ax.set_title(channels[idx])\n",
      "    width, height = img.shape\n",
      "    thresh = img.max()/2.5\n",
      "    for x in range(width):\n",
      "        for y in range(height):\n",
      "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
      "            ax.annotate(str(val), xy=(y,x),\n",
      "                    horizontalalignment='center',\n",
      "                    verticalalignment='center', size=8,\n",
      "                    color='white' if img[x][y]<thresh else 'black')\n",
      "21/10:\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "# define the CNN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # convolutional layer (sees 32x32x3 image tensor)\n",
      "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
      "        # convolutional layer (sees 16x16x16 tensor)\n",
      "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
      "        # convolutional layer (sees 8x8x32 tensor)\n",
      "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
      "        # max pooling layer\n",
      "        self.pool = nn.MaxPool2d(2, 2)\n",
      "        # linear layer (64 * 4 * 4 -> 500)\n",
      "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
      "        # linear layer (500 -> 10)\n",
      "        self.fc2 = nn.Linear(500, 10)\n",
      "        # dropout layer (p=0.25)\n",
      "        self.dropout = nn.Dropout(0.25)\n",
      "\n",
      "    def forward(self, x):\n",
      "        # add sequence of convolutional and max pooling layers\n",
      "        x = self.pool(F.relu(self.conv1(x)))\n",
      "        x = self.pool(F.relu(self.conv2(x)))\n",
      "        x = self.pool(F.relu(self.conv3(x)))\n",
      "        # flatten image input\n",
      "        x = x.view(-1, 64 * 4 * 4)\n",
      "        # add dropout layer\n",
      "        x = self.dropout(x)\n",
      "        # add 1st hidden layer, with relu activation function\n",
      "        x = F.relu(self.fc1(x))\n",
      "        # add dropout layer\n",
      "        x = self.dropout(x)\n",
      "        # add 2nd hidden layer, with relu activation function\n",
      "        x = self.fc2(x)\n",
      "        return x\n",
      "\n",
      "# create a complete CNN\n",
      "model = Net()\n",
      "print(model)\n",
      "\n",
      "# move tensors to GPU if CUDA is available\n",
      "if train_on_gpu:\n",
      "    model.cuda()\n",
      "21/11:\n",
      "import torch.optim as optim\n",
      "\n",
      "# specify loss function (categorical cross-entropy)\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "# specify optimizer\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
      "21/12:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 30\n",
      "\n",
      "valid_loss_min = np.Inf # track change in validation loss\n",
      "\n",
      "for epoch in range(1, n_epochs+1):\n",
      "\n",
      "    # keep track of training and validation loss\n",
      "    train_loss = 0.0\n",
      "    valid_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    model.train()\n",
      "    for data, target in train_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    ######################    \n",
      "    # validate the model #\n",
      "    ######################\n",
      "    model.eval()\n",
      "    for data, target in valid_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # update average validation loss \n",
      "        valid_loss += loss.item()*data.size(0)\n",
      "    \n",
      "    # calculate average losses\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
      "        \n",
      "    # print training/validation statistics \n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
      "        epoch, train_loss, valid_loss))\n",
      "    \n",
      "    # save model if validation loss has decreased\n",
      "    if valid_loss <= valid_loss_min:\n",
      "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
      "        valid_loss_min,\n",
      "        valid_loss))\n",
      "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
      "        valid_loss_min = valid_loss\n",
      "20/17:\n",
      "import torch.nn as nn\n",
      "\n",
      "# define the CNN architecture\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        # convolutional layer\n",
      "        \n",
      "        self.conv1 = nn.Conv2d(3, 16, 5, padding=2) # 32x32x3 -> 16x16x16 with pooling\n",
      "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1) # -> 8x8x32 with pooling\n",
      "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1) # -> 4x4x64 with pooling\n",
      "        # max pooling layer \n",
      "        self.pool = nn.MaxPool2d(2, 2)\n",
      "        # fully connected layers\n",
      "        self.fc1 = nn.Linear(1024, 256)\n",
      "        self.fc2 = nn.Linear(256, 64)\n",
      "        self.output = nn.Linear(64, 10)\n",
      "        # relu\n",
      "        self.relu = nn.LeakyReLU()\n",
      "        # output softmax\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        # dropout \n",
      "        self.drop = nn.Dropout(p=0.2)\n",
      "    def forward(self, x):\n",
      "        # add sequence of convolutional and max pooling layers\n",
      "        x = self.pool(self.relu(self.conv1(x)))\n",
      "        x = self.pool(self.relu(self.conv2(x)))\n",
      "        x = self.pool(self.relu(self.conv3(x)))\n",
      "        \n",
      "        x = x.view(-1, 4*4*64) #flatten\n",
      "        \n",
      "        x = self.drop(self.relu(self.fc1(x)))\n",
      "        x = self.drop(self.relu(self.fc2(x)))\n",
      "        x = self.lsm(self.output(x))\n",
      "        return x\n",
      "\n",
      "# create a complete CNN\n",
      "model = Net()\n",
      "print(model)\n",
      "\n",
      "# move tensors to GPU if CUDA is available\n",
      "if train_on_gpu:\n",
      "    model.cuda()\n",
      "20/18:\n",
      "import torch.optim as optim\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
      "20/19:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 5 # you may increase this number to train a final model\n",
      "\n",
      "valid_loss_min = np.Inf # track change in validation loss\n",
      "\n",
      "for epoch in range(1, n_epochs+1):\n",
      "\n",
      "    # keep track of training and validation loss\n",
      "    train_loss = 0.0\n",
      "    valid_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    model.train()\n",
      "    for data, target in train_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    ######################    \n",
      "    # validate the model #\n",
      "    ######################\n",
      "    model.eval()\n",
      "    for data, target in valid_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # update average validation loss \n",
      "        valid_loss += loss.item()*data.size(0)\n",
      "    \n",
      "    # calculate average losses\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
      "        \n",
      "    # print training/validation statistics \n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
      "        epoch, train_loss, valid_loss))\n",
      "    \n",
      "    # save model if validation loss has decreased\n",
      "    if valid_loss <= valid_loss_min:\n",
      "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
      "        valid_loss_min,\n",
      "        valid_loss))\n",
      "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
      "        valid_loss_min = valid_loss\n",
      "20/20: model.load_state_dict(torch.load('model_cifar.pt'))\n",
      "20/21:\n",
      "# track test loss\n",
      "test_loss = 0.0\n",
      "class_correct = list(0. for i in range(10))\n",
      "class_total = list(0. for i in range(10))\n",
      "\n",
      "model.eval()\n",
      "# iterate over test data\n",
      "for data, target in test_loader:\n",
      "    # move tensors to GPU if CUDA is available\n",
      "    if train_on_gpu:\n",
      "        data, target = data.cuda(), target.cuda()\n",
      "    # forward pass: compute predicted outputs by passing inputs to the model\n",
      "    output = model(data)\n",
      "    # calculate the batch loss\n",
      "    loss = criterion(output, target)\n",
      "    # update test loss \n",
      "    test_loss += loss.item()*data.size(0)\n",
      "    # convert output probabilities to predicted class\n",
      "    _, pred = torch.max(output, 1)    \n",
      "    # compare predictions to true label\n",
      "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
      "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
      "    # calculate test accuracy for each object class\n",
      "    for i in range(batch_size):\n",
      "        label = target.data[i]\n",
      "        class_correct[label] += correct[i].item()\n",
      "        class_total[label] += 1\n",
      "\n",
      "# average test loss\n",
      "test_loss = test_loss/len(test_loader.dataset)\n",
      "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
      "\n",
      "for i in range(10):\n",
      "    if class_total[i] > 0:\n",
      "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
      "            classes[i], 100 * class_correct[i] / class_total[i],\n",
      "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
      "    else:\n",
      "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
      "\n",
      "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
      "    100. * np.sum(class_correct) / np.sum(class_total),\n",
      "    np.sum(class_correct), np.sum(class_total)))\n",
      "20/22:\n",
      "import torch.optim as optim\n",
      "\n",
      "# specify loss function\n",
      "criterion = nn.NLLLoss()\n",
      "\n",
      "# specify optimizer\n",
      "optimizer = optim.Adam(model.parameters())\n",
      "20/23:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 5 # you may increase this number to train a final model\n",
      "\n",
      "valid_loss_min = np.Inf # track change in validation loss\n",
      "\n",
      "for epoch in range(1, n_epochs+1):\n",
      "\n",
      "    # keep track of training and validation loss\n",
      "    train_loss = 0.0\n",
      "    valid_loss = 0.0\n",
      "    \n",
      "    ###################\n",
      "    # train the model #\n",
      "    ###################\n",
      "    model.train()\n",
      "    for data, target in train_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # clear the gradients of all optimized variables\n",
      "        optimizer.zero_grad()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # backward pass: compute gradient of the loss with respect to model parameters\n",
      "        loss.backward()\n",
      "        # perform a single optimization step (parameter update)\n",
      "        optimizer.step()\n",
      "        # update training loss\n",
      "        train_loss += loss.item()*data.size(0)\n",
      "        \n",
      "    ######################    \n",
      "    # validate the model #\n",
      "    ######################\n",
      "    model.eval()\n",
      "    for data, target in valid_loader:\n",
      "        # move tensors to GPU if CUDA is available\n",
      "        if train_on_gpu:\n",
      "            data, target = data.cuda(), target.cuda()\n",
      "        # forward pass: compute predicted outputs by passing inputs to the model\n",
      "        output = model(data)\n",
      "        # calculate the batch loss\n",
      "        loss = criterion(output, target)\n",
      "        # update average validation loss \n",
      "        valid_loss += loss.item()*data.size(0)\n",
      "    \n",
      "    # calculate average losses\n",
      "    train_loss = train_loss/len(train_loader.dataset)\n",
      "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
      "        \n",
      "    # print training/validation statistics \n",
      "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
      "        epoch, train_loss, valid_loss))\n",
      "    \n",
      "    # save model if validation loss has decreased\n",
      "    if valid_loss <= valid_loss_min:\n",
      "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
      "        valid_loss_min,\n",
      "        valid_loss))\n",
      "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
      "        valid_loss_min = valid_loss\n",
      "22/1:\n",
      "import os\n",
      "import numpy as np\n",
      "import torch\n",
      "\n",
      "import torchvision\n",
      "from torchvision import datasets, models, transforms\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "%matplotlib inline\n",
      "22/2:\n",
      "# check if CUDA is available\n",
      "train_on_gpu = torch.cuda.is_available()\n",
      "\n",
      "if not train_on_gpu:\n",
      "    print('CUDA is not available.  Training on CPU ...')\n",
      "else:\n",
      "    print('CUDA is available!  Training on GPU ...')\n",
      "22/3:\n",
      "# define training and test data directories\n",
      "data_dir = '/Users/js/Desktop/flower_photos/'\n",
      "train_dir = os.path.join(data_dir, 'train/')\n",
      "test_dir = os.path.join(data_dir, 'test/')\n",
      "\n",
      "# classes are folders in each directory with these names\n",
      "classes = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
      "22/4:\n",
      "# load and transform data using ImageFolder\n",
      "\n",
      "# VGG-16 Takes 224x224 images as input, so we resize all of them\n",
      "data_transform = transforms.Compose([transforms.RandomResizedCrop(224), \n",
      "                                      transforms.ToTensor()])\n",
      "\n",
      "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
      "test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
      "\n",
      "# print out some data stats\n",
      "print('Num training images: ', len(train_data))\n",
      "print('Num test images: ', len(test_data))\n",
      "22/5:\n",
      "# define dataloader parameters\n",
      "batch_size = 20\n",
      "num_workers=0\n",
      "\n",
      "# prepare data loaders\n",
      "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
      "                                           num_workers=num_workers, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
      "                                          num_workers=num_workers, shuffle=True)\n",
      "22/6:\n",
      "# Visualize some sample data\n",
      "\n",
      "# obtain one batch of training images\n",
      "dataiter = iter(train_loader)\n",
      "images, labels = dataiter.next()\n",
      "images = images.numpy() # convert images to numpy for display\n",
      "\n",
      "# plot the images in the batch, along with the corresponding labels\n",
      "fig = plt.figure(figsize=(25, 4))\n",
      "for idx in np.arange(20):\n",
      "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
      "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
      "    ax.set_title(classes[labels[idx]])\n",
      "22/7:\n",
      "# Load the pretrained model from pytorch\n",
      "vgg16 = models.vgg16(pretrained=True)\n",
      "\n",
      "# print out the model structure\n",
      "print(vgg16)\n",
      "22/8:\n",
      "print(vgg16.classifier[6].in_features) \n",
      "print(vgg16.classifier[6].out_features)\n",
      "22/9:\n",
      "# Freeze training for all \"features\" layers\n",
      "for param in vgg16.features.parameters():\n",
      "    param.requires_grad = False\n",
      "22/10:\n",
      "## TODO: add a last linear layer  that maps n_inputs -> 5 flower classes\n",
      "## new layers automatically have requires_grad = True\n",
      "\n",
      "from torch import nn\n",
      "\n",
      "\n",
      "# after completing your model, if GPU is available, move the model to GPU\n",
      "if train_on_gpu:\n",
      "    vgg16.cuda()\n",
      "22/11:\n",
      "## TODO: add a last linear layer  that maps n_inputs -> 5 flower classes\n",
      "## new layers automatically have requires_grad = True\n",
      "\n",
      "from torch import nn\n",
      "vgg16.classifier[7] = nn.LeakyReLU()\n",
      "vgg16.classifier[8] = nn.Dropout(p=0.3)\n",
      "vgg16.classifier[9] = nn.Linear(1000, 5)\n",
      "\n",
      "# after completing your model, if GPU is available, move the model to GPU\n",
      "if train_on_gpu:\n",
      "    vgg16.cuda()\n",
      "22/12:\n",
      "## TODO: add a last linear layer  that maps n_inputs -> 5 flower classes\n",
      "## new layers automatically have requires_grad = True\n",
      "\n",
      "from torch import nn\n",
      "vgg16.classifier[6] = nn.Linear(4096, 5)\n",
      "\n",
      "# after completing your model, if GPU is available, move the model to GPU\n",
      "if train_on_gpu:\n",
      "    vgg16.cuda()\n",
      "22/13:\n",
      "## TODO: add a last linear layer  that maps n_inputs -> 5 flower classes\n",
      "## new layers automatically have requires_grad = True\n",
      "\n",
      "from torch import nn\n",
      "vgg16.classifier[6] = nn.Linear(4096, 5)\n",
      "\n",
      "# after completing your model, if GPU is available, move the model to GPU\n",
      "if train_on_gpu:\n",
      "    vgg16.cuda()\n",
      "    \n",
      "model\n",
      "22/14:\n",
      "## TODO: add a last linear layer  that maps n_inputs -> 5 flower classes\n",
      "## new layers automatically have requires_grad = True\n",
      "\n",
      "from torch import nn\n",
      "vgg16.classifier[6] = nn.Linear(4096, 5)\n",
      "\n",
      "# after completing your model, if GPU is available, move the model to GPU\n",
      "if train_on_gpu:\n",
      "    vgg16.cuda()\n",
      "    \n",
      "vgg16\n",
      "22/15:\n",
      "import torch.optim as optim\n",
      "\n",
      "# specify loss function (categorical cross-entropy)\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "# specify optimizer (stochastic gradient descent) and learning rate = 0.001\n",
      "optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)\n",
      "22/16:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 2\n",
      "\n",
      "## TODO complete epoch and training batch loops\n",
      "## These loops should update the classifier-weights of this model\n",
      "## And track (and print out) the training loss over time\n",
      "\n",
      "for e in range(n_epochs):\n",
      "    train_loss = 0\n",
      "    for image, label in train_loader:\n",
      "        if train_on_gpu:\n",
      "            image, label = image.cuda(), label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        output = vgg16.forward(image)\n",
      "        loss = criterion(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "    print(train_loss)\n",
      "22/17:\n",
      "# number of epochs to train the model\n",
      "n_epochs = 1\n",
      "\n",
      "## TODO complete epoch and training batch loops\n",
      "## These loops should update the classifier-weights of this model\n",
      "## And track (and print out) the training loss over time\n",
      "\n",
      "for e in range(n_epochs):\n",
      "    train_loss = 0\n",
      "    for image, label in train_loader:\n",
      "        if train_on_gpu:\n",
      "            image, label = image.cuda(), label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        output = vgg16.forward(image)\n",
      "        loss = criterion(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        print(train_loss)\n",
      "    print(train_loss)\n",
      "22/18:\n",
      "# track test loss \n",
      "# over 5 flower classes\n",
      "test_loss = 0.0\n",
      "class_correct = list(0. for i in range(5))\n",
      "class_total = list(0. for i in range(5))\n",
      "\n",
      "vgg16.eval() # eval mode\n",
      "\n",
      "# iterate over test data\n",
      "for data, target in test_loader:\n",
      "    # move tensors to GPU if CUDA is available\n",
      "    if train_on_gpu:\n",
      "        data, target = data.cuda(), target.cuda()\n",
      "    # forward pass: compute predicted outputs by passing inputs to the model\n",
      "    output = vgg16(data)\n",
      "    # calculate the batch loss\n",
      "    loss = criterion(output, target)\n",
      "    # update  test loss \n",
      "    test_loss += loss.item()*data.size(0)\n",
      "    # convert output probabilities to predicted class\n",
      "    _, pred = torch.max(output, 1)    \n",
      "    # compare predictions to true label\n",
      "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
      "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
      "    # calculate test accuracy for each object class\n",
      "    for i in range(batch_size):\n",
      "        label = target.data[i]\n",
      "        class_correct[label] += correct[i].item()\n",
      "        class_total[label] += 1\n",
      "\n",
      "# calculate avg test loss\n",
      "test_loss = test_loss/len(test_loader.dataset)\n",
      "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
      "\n",
      "for i in range(5):\n",
      "    if class_total[i] > 0:\n",
      "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
      "            classes[i], 100 * class_correct[i] / class_total[i],\n",
      "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
      "    else:\n",
      "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
      "\n",
      "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
      "    100. * np.sum(class_correct) / np.sum(class_total),\n",
      "    np.sum(class_correct), np.sum(class_total)))\n",
      "23/1:\n",
      "import torch\n",
      "from torch import nn\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "23/2:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "23/3:\n",
      "class RNN(nn.Module):\n",
      "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
      "        super(RNN, self).__init__()\n",
      "        \n",
      "        self.hidden_dim=hidden_dim\n",
      "\n",
      "        # define an RNN with specified parameters\n",
      "        # batch_first means that the first dim of the input and output will be the batch_size\n",
      "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
      "        \n",
      "        # last, fully-connected layer\n",
      "        self.fc = nn.Linear(hidden_dim, output_size)\n",
      "\n",
      "    def forward(self, x, hidden):\n",
      "        # x (batch_size, seq_length, input_size)\n",
      "        # hidden (n_layers, batch_size, hidden_dim)\n",
      "        # r_out (batch_size, time_step, hidden_size)\n",
      "        batch_size = x.size(0)\n",
      "        \n",
      "        # get RNN outputs\n",
      "        r_out, hidden = self.rnn(x, hidden)\n",
      "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
      "        r_out = r_out.view(-1, self.hidden_dim)  \n",
      "        \n",
      "        # get final output \n",
      "        output = self.fc(r_out)\n",
      "        \n",
      "        return output, hidden\n",
      "23/4:\n",
      "# test that dimensions are as expected\n",
      "test_rnn = RNN(input_size=1, output_size=1, hidden_dim=10, n_layers=2)\n",
      "\n",
      "# generate evenly spaced, test data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length, 1))\n",
      "\n",
      "test_input = torch.Tensor(data).unsqueeze(0) # give it a batch_size of 1 as first dimension\n",
      "print('Input size: ', test_input.size())\n",
      "\n",
      "# test out rnn sizes\n",
      "test_out, test_h = test_rnn(test_input, None)\n",
      "print('Output size: ', test_out.size())\n",
      "print('Hidden state size: ', test_h.size())\n",
      "23/5:\n",
      "# decide on hyperparameters\n",
      "input_size=1 \n",
      "output_size=1\n",
      "hidden_dim=32\n",
      "n_layers=1\n",
      "\n",
      "# instantiate an RNN\n",
      "rnn = RNN(input_size, output_size, hidden_dim, n_layers)\n",
      "print(rnn)\n",
      "23/6:\n",
      "# MSE loss and Adam optimizer with a learning rate of 0.01\n",
      "criterion = nn.MSELoss()\n",
      "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)\n",
      "23/7:\n",
      "# train the RNN\n",
      "def train(rnn, n_steps, print_every):\n",
      "    \n",
      "    # initialize the hidden state\n",
      "    hidden = None      \n",
      "    \n",
      "    for batch_i, step in enumerate(range(n_steps)):\n",
      "        # defining the training data \n",
      "        time_steps = np.linspace(step * np.pi, (step+1)*np.pi, seq_length + 1)\n",
      "        data = np.sin(time_steps)\n",
      "        data.resize((seq_length + 1, 1)) # input_size=1\n",
      "\n",
      "        x = data[:-1]\n",
      "        y = data[1:]\n",
      "        \n",
      "        # convert data into Tensors\n",
      "        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension\n",
      "        y_tensor = torch.Tensor(y)\n",
      "\n",
      "        # outputs from the rnn\n",
      "        prediction, hidden = rnn(x_tensor, hidden)\n",
      "\n",
      "        ## Representing Memory ##\n",
      "        # make a new variable for hidden and detach the hidden state from its history\n",
      "        # this way, we don't backpropagate through the entire history\n",
      "        hidden = hidden.data\n",
      "\n",
      "        # calculate the loss\n",
      "        loss = criterion(prediction, y_tensor)\n",
      "        # zero gradients\n",
      "        optimizer.zero_grad()\n",
      "        # perform backprop and update weights\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "\n",
      "        # display loss and predictions\n",
      "        if batch_i%print_every == 0:        \n",
      "            print('Loss: ', loss.item())\n",
      "            plt.plot(time_steps[1:], x, 'r.') # input\n",
      "            plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.') # predictions\n",
      "            plt.show()\n",
      "    \n",
      "    return rnn\n",
      "23/8:\n",
      "# train the rnn and monitor results\n",
      "n_steps = 75\n",
      "print_every = 15\n",
      "\n",
      "trained_rnn = train(rnn, n_steps, print_every)\n",
      "24/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn\n",
      "import torch.nn.functional as F\n",
      "24/2:\n",
      "# open text file and read in data as `text`\n",
      "with open('data/anna.txt', 'r') as f:\n",
      "    text = f.read()\n",
      "24/3: text[:100]\n",
      "24/4:\n",
      "# encode the text and map each character to an integer and vice versa\n",
      "\n",
      "# we create two dictionaries:\n",
      "# 1. int2char, which maps integers to characters\n",
      "# 2. char2int, which maps characters to unique integers\n",
      "chars = tuple(set(text))\n",
      "int2char = dict(enumerate(chars))\n",
      "char2int = {ch: ii for ii, ch in int2char.items()}\n",
      "\n",
      "# encode the text\n",
      "encoded = np.array([char2int[ch] for ch in text])\n",
      "24/5: encoded[:100]\n",
      "24/6:\n",
      "# encode the text and map each character to an integer and vice versa\n",
      "\n",
      "# we create two dictionaries:\n",
      "# 1. int2char, which maps integers to characters\n",
      "# 2. char2int, which maps characters to unique integers\n",
      "chars = tuple(set(text))\n",
      "int2char = dict(enumerate(chars))\n",
      "char2int = {ch: ii for ii, ch in int2char.items()}\n",
      "\n",
      "# encode the text\n",
      "encoded = np.array([char2int[ch] for ch in text])\n",
      "24/7:\n",
      "def one_hot_encode(arr, n_labels):\n",
      "    \n",
      "    # Initialize the the encoded array\n",
      "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
      "    \n",
      "    # Fill the appropriate elements with ones\n",
      "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
      "    \n",
      "    # Finally reshape it to get back to the original array\n",
      "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
      "    \n",
      "    return one_hot\n",
      "24/8:\n",
      "# check that the function works as expected\n",
      "test_seq = np.array([[3, 5, 1]])\n",
      "one_hot = one_hot_encode(test_seq, 8)\n",
      "\n",
      "print(one_hot)\n",
      "24/9:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, seq_length))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:n, n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[1:] + [x[0]]\n",
      "        yield x, y\n",
      "24/10:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/11:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:n, n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[1:] + [x[0]]\n",
      "        yield x, y\n",
      "24/12:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/13:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:n, n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[1:]\n",
      "        yield x, y\n",
      "24/14:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/15:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:n, n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[:, 1:] + np.array[:, 0]\n",
      "        yield x, y\n",
      "24/16:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/17:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:n, n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[:, 1:] + x[:, 0]\n",
      "        yield x, y\n",
      "24/18:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "25/1:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    batch_size_total = batch_size * seq_length\n",
      "    # total number of batches we can make\n",
      "    n_batches = len(arr)//batch_size_total\n",
      "    \n",
      "    # Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * batch_size_total]\n",
      "    # Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    # iterate through the array, one sequence at a time\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = np.zeros_like(x)\n",
      "        try:\n",
      "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
      "        except IndexError:\n",
      "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
      "        yield x, y\n",
      "25/2:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "25/3:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn\n",
      "import torch.nn.functional as F\n",
      "25/4:\n",
      "# open text file and read in data as `text`\n",
      "with open('data/anna.txt', 'r') as f:\n",
      "    text = f.read()\n",
      "25/5: text[:100]\n",
      "25/6:\n",
      "# encode the text and map each character to an integer and vice versa\n",
      "\n",
      "# we create two dictionaries:\n",
      "# 1. int2char, which maps integers to characters\n",
      "# 2. char2int, which maps characters to unique integers\n",
      "chars = tuple(set(text))\n",
      "int2char = dict(enumerate(chars))\n",
      "char2int = {ch: ii for ii, ch in int2char.items()}\n",
      "\n",
      "# encode the text\n",
      "encoded = np.array([char2int[ch] for ch in text])\n",
      "25/7: encoded[:100]\n",
      "25/8:\n",
      "def one_hot_encode(arr, n_labels):\n",
      "    \n",
      "    # Initialize the the encoded array\n",
      "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
      "    \n",
      "    # Fill the appropriate elements with ones\n",
      "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
      "    \n",
      "    # Finally reshape it to get back to the original array\n",
      "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
      "    \n",
      "    return one_hot\n",
      "25/9:\n",
      "# check that the function works as expected\n",
      "test_seq = np.array([[3, 5, 1]])\n",
      "one_hot = one_hot_encode(test_seq, 8)\n",
      "\n",
      "print(one_hot)\n",
      "25/10:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    batch_size_total = batch_size * seq_length\n",
      "    # total number of batches we can make\n",
      "    n_batches = len(arr)//batch_size_total\n",
      "    \n",
      "    # Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * batch_size_total]\n",
      "    # Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    # iterate through the array, one sequence at a time\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = np.zeros_like(x)\n",
      "        try:\n",
      "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
      "        except IndexError:\n",
      "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
      "        yield x, y\n",
      "25/11:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/19:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[:, 1:] + x[:, 0]\n",
      "        yield x, y\n",
      "24/20:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/21:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[:, 1:] + x[:, 0].view(x[:,0].shape[0], -1)\n",
      "        yield x, y\n",
      "24/22:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/23:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[:, 1:] + x[:, 0].unsqueeze(0)\n",
      "        yield x, y\n",
      "24/24:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/25:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[:, 1:] + x[:, 0].expand_dims(axis=1)\n",
      "        yield x, y\n",
      "24/26:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/27:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = x[:, 1:] + np.expand_dims(x[:, 0], axis=1)\n",
      "        yield x, y\n",
      "24/28:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/29:\n",
      "# printing out the first 10 items in a sequence\n",
      "print('x\\n', x[:10, :10])\n",
      "print('\\ny\\n', y[:10, :10])\n",
      "24/30:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/31:\n",
      "# printing out the first 10 items in a sequence\n",
      "print('x\\n', x[:10, :10])\n",
      "print('\\ny\\n', y[:10, :10])\n",
      "24/32:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    target_arr = arr[1:] + [arr[0]]\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    \n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = target_arr[:, n:n+seq_length]\n",
      "        yield x, y\n",
      "24/33:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/34:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    target_arr = arr[1:] + [arr[0]]\n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    target_arr = target_arr[:n_batches * (batch_size * seq_length)]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    target_arr = target_arr.reshape((batch_size, -1))\n",
      "\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = target_arr[:, n:n+seq_length]\n",
      "        yield x, y\n",
      "24/35:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/36:\n",
      "# printing out the first 10 items in a sequence\n",
      "print('x\\n', x[:10, :10])\n",
      "print('\\ny\\n', y[:10, :10])\n",
      "24/37:\n",
      "# printing out the first 10 items in a sequence\n",
      "print('x\\n', x[:10, :10])\n",
      "print('\\ny\\n', y[:10, :10])\n",
      "24/38:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    target_arr = arr[1:] + [arr[0]]\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    target_arr = target_arr.reshape((batch_size, -1))\n",
      "\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = target_arr[:, n:n+seq_length]\n",
      "        yield x, y\n",
      "24/39:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/40: encoded.shape\n",
      "24/41:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "len(encoded)\n",
      "24/42:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "len(encoded) // (batch_size * seq_length)\n",
      "24/43:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "24/44:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "encoded[:n_batches * (batch_size * seq_length)]\n",
      "24/45:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "len(encoded[:n_batches * (batch_size * seq_length)])\n",
      "24/46:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "24/47:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "len(trimmed)\n",
      "24/48:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "len(trimmed[1:])\n",
      "24/49:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "len(trimmed[0])\n",
      "24/50:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0]\n",
      "24/51:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "[[trimmed[0]]\n",
      "24/52:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "[trimmed[0]]\n",
      "24/53:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "[trimmed[0]] + np.array([1,2,3])\n",
      "24/54:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.array([trimmed[0]]) + np.array([1,2,3])\n",
      "24/55:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.array(trimmed[0]) + np.array([1,2,3])\n",
      "24/56:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.array([1,2,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/57:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(np.array([1,2,3]), np.array([4])\n",
      "24/58:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(np.array([1,2,3]), np.array([4]))\n",
      "24/59:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(np.array([1,2,3]), np.array([4]), axis=0)\n",
      "24/60:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(np.array([1,2,3]), np.array([4]), axis=1)\n",
      "24/61:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(np.array([1,2,3]), np.expand_dims(np.array([4])))\n",
      "24/62:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(np.array([1,2,3]), np.expand_dims(np.array([4]), axis=0))\n",
      "24/63:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed\n",
      "24/64:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed.shape\n",
      "24/65:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].shape\n",
      "24/66:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "[trimmed[0]].shape\n",
      "24/67:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.array(trimmed[0]).shape\n",
      "24/68:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].view(1, 1).shape\n",
      "24/69:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.array(trimmed[0]).view(1, 1).shape\n",
      "24/70:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0]\n",
      "24/71:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.asarray(trimmed[0])\n",
      "24/72:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.asarray(trimmed[0]).shape\n",
      "24/73:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.asarray(trimmed[0]).reshape((1,1))\n",
      "24/74:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.asarray(trimmed[0]).reshape((1,1)).shape\n",
      "24/75:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.asarray(trimmed[0]).reshape((1))\n",
      "24/76:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.asarray(trimmed[0]).reshape((1)).shape\n",
      "24/77:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape((1)).shape\n",
      "24/78:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape((1))\n",
      "24/79:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape((1)) + np.array([0])\n",
      "24/80:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape((1)) + np.array([1])\n",
      "24/81:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(trimmed[0].reshape((1)), np.array([2]))\n",
      "24/82:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(trimmed[0].reshape((1)), np.array([2,3]))\n",
      "24/83:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(trimmed[0].reshape((1)), np.asarray(2))\n",
      "24/84:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate(trimmed[0].reshape((1)), np.asarray(2).reshape((1)))\n",
      "24/85:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "a = np.random.randn((1, 5))\n",
      "print(a)\n",
      "np.concatenate(trimmed[0].reshape((1)), np.asarray(2).reshape((1)))\n",
      "24/86:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "a = np.random.randn(1, 5)\n",
      "print(a)\n",
      "np.concatenate(trimmed[0].reshape((1)), np.asarray(2).reshape((1)))\n",
      "24/87:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "a = np.random.randn(1, 5)\n",
      "print(a)\n",
      "np.concatenate(trimmed[0].reshape((1)), a)\n",
      "24/88:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "a = np.random.randn(1, 5)\n",
      "print(a)\n",
      "np.concatenate(trimmed[0].reshape((1)))\n",
      "24/89:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "a = np.random.randn(1, 5)\n",
      "print(a)\n",
      "trimmed[0].reshape((1))\n",
      "24/90:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "a = np.random.randn(1, 5)\n",
      "print(a)\n",
      "trimmed[0].reshape((1)).shape\n",
      "24/91:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "a = np.random.randn(1, 5)\n",
      "print(a)\n",
      "trimmed[0].reshape((1, 1)).shape\n",
      "24/92:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "a = np.random.randn(1, 5)\n",
      "print(a)\n",
      "np.concatenate(trimmed[0].reshape((1, 1)), a)\n",
      "24/93:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[1:]\n",
      "24/94:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[1:]\n",
      "trimmed\n",
      "24/95:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[1:]\n",
      "trimmed[0]\n",
      "24/96:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate([trimmed[1:], trimmed[0]])\n",
      "24/97:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate([trimmed[1:], trimmed[0]], axis=1)\n",
      "24/98:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate([trimmed[1:], trimmed[0]], axis=0)\n",
      "24/99:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "np.concatenate([trimmed[1:], trimmed[0]], axis=0)\n",
      "trimmed[0].shape\n",
      "24/100:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].shape\n",
      "24/101:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape(1,1)\n",
      "24/102:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape(1,1)\n",
      "len(trimmed)\n",
      "24/103:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape(1,1)\n",
      "len(trimmed-1)\n",
      "24/104:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape(1,1)\n",
      "len(trimmed-1)\n",
      "24/105:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape(1,1)\n",
      "len(trimmed)-1\n",
      "24/106:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape(1,1)\n",
      "24/107:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "trimmed[0].reshape(1,1)\n",
      "trimmed[1:].reshape(-1, len(trimmed)-1)\n",
      "24/108:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "\n",
      "np.concatenate([trimmed[1:].reshape(-1, len(trimmed)-1), trimmed[0].reshape(1,1)], axis=1)\n",
      "24/109:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "\n",
      "np.concatenate([trimmed[1:].reshape(-1, len(trimmed)-1), trimmed[0].reshape(1,1)], axis=1).shape\n",
      "24/110:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "\n",
      "np.concatenate([trimmed[1:].reshape(-1, len(trimmed)-1), trimmed[0].reshape(1,1)], axis=1).shape\n",
      "encoded.shape\n",
      "24/111:\n",
      "batch_size = 8\n",
      "seq_length = 50\n",
      "n_batches = len(encoded) // (batch_size * seq_length)\n",
      "trimmed = encoded[:n_batches * (batch_size * seq_length)]\n",
      "\n",
      "np.concatenate([trimmed[1:].reshape(-1, len(trimmed)-1), trimmed[0].reshape(1,1)], axis=1).shape\n",
      "trimmed.shape\n",
      "24/112:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    target_arr = np.concatenate([arr[1:].reshape(-1, len(arr)-1), arr[0].reshape(1,1)], axis=1)\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    target_arr = target_arr.reshape((batch_size, -1))\n",
      "\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = target_arr[:, n:n+seq_length]\n",
      "        yield x, y\n",
      "24/113:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/114:\n",
      "# printing out the first 10 items in a sequence\n",
      "print('x\\n', x[:10, :10])\n",
      "print('\\ny\\n', y[:10, :10])\n",
      "24/115:\n",
      "def get_batches(arr, batch_size, seq_length):\n",
      "    '''Create a generator that returns batches of size\n",
      "       batch_size x seq_length from arr.\n",
      "       \n",
      "       Arguments\n",
      "       ---------\n",
      "       arr: Array you want to make batches from\n",
      "       batch_size: Batch size, the number of sequences per batch\n",
      "       seq_length: Number of encoded chars in a sequence\n",
      "    '''\n",
      "    \n",
      "    \n",
      "    ## TODO: Get the number of batches we can make\n",
      "    n_batches = len(arr) // (batch_size * seq_length)\n",
      "    \n",
      "    ## TODO: Keep only enough characters to make full batches\n",
      "    arr = arr[:n_batches * (batch_size * seq_length)]\n",
      "    target_arr = np.concatenate([arr[1:].reshape(-1, len(arr)-1), arr[0].reshape(1,1)], axis=1)\n",
      "    \n",
      "    ## TODO: Reshape into batch_size rows\n",
      "    arr = arr.reshape((batch_size, -1))\n",
      "    target_arr = target_arr.reshape((batch_size, -1))\n",
      "\n",
      "    \n",
      "    ## TODO: Iterate over the batches using a window of size seq_length\n",
      "    for n in range(0, arr.shape[1], seq_length):\n",
      "        # The features\n",
      "        x = arr[:, n:n+seq_length]\n",
      "        # The targets, shifted by one\n",
      "        y = target_arr[:, n:n+seq_length]\n",
      "        yield x, y\n",
      "24/116:\n",
      "batches = get_batches(encoded, 8, 50)\n",
      "x, y = next(batches)\n",
      "24/117:\n",
      "# printing out the first 10 items in a sequence\n",
      "print('x\\n', x[:10, :10])\n",
      "print('\\ny\\n', y[:10, :10])\n",
      "24/118:\n",
      "encoded[:100]\n",
      "char2int\n",
      "24/119:\n",
      "encoded[:100]\n",
      "chars\n",
      "24/120:\n",
      "encoded[:100]\n",
      "len(chars)\n",
      "24/121:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "        self.init_hidden()\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = self.fc(x)\n",
      "        out = self.lsm(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/122:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "        self.init_hidden()\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = x.contiguous().view(-1, self.n_hidden)\n",
      "        x = self.drop(x)\n",
      "        x = self.fc(x)\n",
      "        out = self.lsm(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/123:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        \n",
      "        self.init_hidden()\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = x.contiguous().view(-1, self.n_hidden)\n",
      "        x = self.drop(x)\n",
      "        x = self.fc(x)\n",
      "        out = self.lsm(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/124:\n",
      "def train(net, data, epochs=2, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/125:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/126:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = x.contiguous().view(-1, self.n_hidden)\n",
      "        x = self.drop(x)\n",
      "        x = self.fc(x)\n",
      "        out = self.lsm(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/127:\n",
      "def train(net, data, epochs=2, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/128:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/129:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 2# start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/130:\n",
      "# check if GPU is available\n",
      "train_on_gpu = torch.cuda.is_available()\n",
      "if(train_on_gpu):\n",
      "    print('Training on GPU!')\n",
      "else: \n",
      "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
      "24/131:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = x.contiguous().view(-1, self.n_hidden)\n",
      "        x = self.drop(x)\n",
      "        x = self.fc(x)\n",
      "        out = self.lsm(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/132:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/133:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/134:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 2 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/135:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        #x = x.contiguous().view(-1, self.n_hidden)\n",
      "        x = self.drop(x)\n",
      "        x = self.fc(x)\n",
      "        out = self.lsm(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/136:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/137:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous().view(-1, self.n_hidden)\n",
      "        x = self.fc(x)\n",
      "        out = self.lsm(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/138:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/139:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/140:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 2 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "25/12:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the LSTM\n",
      "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
      "                            dropout=drop_prob, batch_first=True)\n",
      "        \n",
      "        ## TODO: define a dropout layer\n",
      "        self.dropout = nn.Dropout(drop_prob)\n",
      "        \n",
      "        ## TODO: define the final, fully-connected output layer\n",
      "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
      "      \n",
      "    \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        r_output, hidden = self.lstm(x, hidden)\n",
      "        \n",
      "        ## TODO: pass through a dropout layer\n",
      "        out = self.dropout(r_output)\n",
      "        \n",
      "        # Stack up LSTM outputs using view\n",
      "        # you may need to use contiguous to reshape the output\n",
      "        out = out.contiguous().view(-1, self.n_hidden)\n",
      "        \n",
      "        ## TODO: put x through the fully-connected layer\n",
      "        out = self.fc(out)\n",
      "        \n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "25/13:\n",
      "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "25/14:\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "25/15:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 20 # start smaller if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "25/16:\n",
      "# check if GPU is available\n",
      "train_on_gpu = torch.cuda.is_available()\n",
      "if(train_on_gpu):\n",
      "    print('Training on GPU!')\n",
      "else: \n",
      "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
      "25/17:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the LSTM\n",
      "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
      "                            dropout=drop_prob, batch_first=True)\n",
      "        \n",
      "        ## TODO: define a dropout layer\n",
      "        self.dropout = nn.Dropout(drop_prob)\n",
      "        \n",
      "        ## TODO: define the final, fully-connected output layer\n",
      "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
      "      \n",
      "    \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        r_output, hidden = self.lstm(x, hidden)\n",
      "        \n",
      "        ## TODO: pass through a dropout layer\n",
      "        out = self.dropout(r_output)\n",
      "        \n",
      "        # Stack up LSTM outputs using view\n",
      "        # you may need to use contiguous to reshape the output\n",
      "        out = out.contiguous().view(-1, self.n_hidden)\n",
      "        \n",
      "        ## TODO: put x through the fully-connected layer\n",
      "        out = self.fc(out)\n",
      "        \n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "25/18:\n",
      "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "25/19:\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "25/20:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start smaller if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/141:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous().view(-1, self.n_hidden)\n",
      "        x = self.fc(x)\n",
      "        out = self.lsm(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/142:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous().view(-1, self.n_hidden)\n",
      "        x = self.fc(x)\n",
      "        out = self.lsm(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/143:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/144:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/145:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 2 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/146:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous().view(-1, self.n_hidden)\n",
      "        out = self.fc(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/147:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/148:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/149:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 2 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "25/21:\n",
      "# change the name, for saving multiple files\n",
      "model_name = 'rnn_20_epoch.net'\n",
      "\n",
      "checkpoint = {'n_hidden': net.n_hidden,\n",
      "              'n_layers': net.n_layers,\n",
      "              'state_dict': net.state_dict(),\n",
      "              'tokens': net.chars}\n",
      "\n",
      "with open(model_name, 'wb') as f:\n",
      "    torch.save(checkpoint, f)\n",
      "25/22:\n",
      "def predict(net, char, h=None, top_k=None):\n",
      "        ''' Given a character, predict the next character.\n",
      "            Returns the predicted character and the hidden state.\n",
      "        '''\n",
      "        \n",
      "        # tensor inputs\n",
      "        x = np.array([[net.char2int[char]]])\n",
      "        x = one_hot_encode(x, len(net.chars))\n",
      "        inputs = torch.from_numpy(x)\n",
      "        \n",
      "        if(train_on_gpu):\n",
      "            inputs = inputs.cuda()\n",
      "        \n",
      "        # detach hidden state from history\n",
      "        h = tuple([each.data for each in h])\n",
      "        # get the output of the model\n",
      "        out, h = net(inputs, h)\n",
      "\n",
      "        # get the character probabilities\n",
      "        p = F.softmax(out, dim=1).data\n",
      "        if(train_on_gpu):\n",
      "            p = p.cpu() # move to cpu\n",
      "        \n",
      "        # get top characters\n",
      "        if top_k is None:\n",
      "            top_ch = np.arange(len(net.chars))\n",
      "        else:\n",
      "            p, top_ch = p.topk(top_k)\n",
      "            top_ch = top_ch.numpy().squeeze()\n",
      "        \n",
      "        # select the likely next character with some element of randomness\n",
      "        p = p.numpy().squeeze()\n",
      "        char = np.random.choice(top_ch, p=p/p.sum())\n",
      "        \n",
      "        # return the encoded value of the predicted char and the hidden state\n",
      "        return net.int2char[char], h\n",
      "25/23:\n",
      "def sample(net, size, prime='The', top_k=None):\n",
      "        \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    else:\n",
      "        net.cpu()\n",
      "    \n",
      "    net.eval() # eval mode\n",
      "    \n",
      "    # First off, run through the prime characters\n",
      "    chars = [ch for ch in prime]\n",
      "    h = net.init_hidden(1)\n",
      "    for ch in prime:\n",
      "        char, h = predict(net, ch, h, top_k=top_k)\n",
      "\n",
      "    chars.append(char)\n",
      "    \n",
      "    # Now pass in the previous character and get a new one\n",
      "    for ii in range(size):\n",
      "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
      "        chars.append(char)\n",
      "\n",
      "    return ''.join(chars)\n",
      "25/24: print(sample(net, 1000, prime='Anna', top_k=5))\n",
      "24/150:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 2 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/151:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous()\n",
      "        x = x.view(-1, self.n_hidden)\n",
      "        out = self.fc(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/152:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/153:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/154:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 2 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/155:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/156:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/157:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous()\n",
      "        x = x.resize(-1, self.n_hidden)\n",
      "        out = self.fc(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/158:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/159:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/160:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/161:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous()\n",
      "        x = x.view(-1, self.n_hidden)\n",
      "        out = self.fc(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/162:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/163:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/164:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous()\n",
      "        x = x.view(-1, self.n_hidden)\n",
      "        out = self.fc(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/165:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous()\n",
      "        x = x.view(-1, self.n_hidden)\n",
      "        out = self.fc(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/166:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/167:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/168:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/169:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous()\n",
      "        x = x.view(torch.tensor(x.shape).prod() / self.n_hidden, self.n_hidden)\n",
      "        out = self.fc(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/170:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/171:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/172:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/173:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous()\n",
      "        x = x.resize(torch.tensor(x.shape).prod() / self.n_hidden, self.n_hidden)\n",
      "        out = self.fc(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/174:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/175:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/176:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/177:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "25/25:\n",
      "# Here we have loaded in a model that trained over 20 epochs `rnn_20_epoch.net`\n",
      "with open('rnn_20_epoch.net', 'rb') as f:\n",
      "    checkpoint = torch.load(f)\n",
      "    \n",
      "loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
      "loaded.load_state_dict(checkpoint['state_dict'])\n",
      "25/26:\n",
      "# Sample using a loaded model\n",
      "print(sample(loaded, 2000, top_k=5, prime=\"And Levin said\"))\n",
      "24/178:\n",
      "class CharRNN(nn.Module):\n",
      "    \n",
      "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
      "                               drop_prob=0.5, lr=0.001):\n",
      "        super().__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "        self.n_layers = n_layers\n",
      "        self.n_hidden = n_hidden\n",
      "        self.lr = lr\n",
      "        \n",
      "        # creating character dictionaries\n",
      "        self.chars = tokens\n",
      "        self.int2char = dict(enumerate(self.chars))\n",
      "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
      "        \n",
      "        ## TODO: define the layers of the model\n",
      "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers, dropout=self.drop_prob, batch_first=True)\n",
      "        self.drop = nn.Dropout(p=self.drop_prob)\n",
      "        self.fc = nn.Linear(self.n_hidden, len(self.chars))\n",
      "                \n",
      "    def forward(self, x, hidden):\n",
      "        ''' Forward pass through the network. \n",
      "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
      "                \n",
      "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
      "        x , hidden = self.lstm(x, hidden)\n",
      "        x = self.drop(x)\n",
      "        x = x.contiguous().view(-1, self.n_hidden)\n",
      "        out = self.fc(x)\n",
      "        # return the final output and the hidden state\n",
      "        return out, hidden\n",
      "    \n",
      "    \n",
      "    def init_hidden(self, batch_size):\n",
      "        ''' Initializes hidden state '''\n",
      "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
      "        # initialized to zero, for hidden state and cell state of LSTM\n",
      "        weight = next(self.parameters()).data\n",
      "        \n",
      "        if (train_on_gpu):\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
      "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
      "        else:\n",
      "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
      "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
      "        \n",
      "        return hidden\n",
      "24/179:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/180:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/181:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/182:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.contiguous().view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/183:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/184:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/185:\n",
      "def train(net, data, epochs=5, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
      "    ''' Training a network \n",
      "    \n",
      "        Arguments\n",
      "        ---------\n",
      "        \n",
      "        net: CharRNN network\n",
      "        data: text data to train the network\n",
      "        epochs: Number of epochs to train\n",
      "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
      "        seq_length: Number of character steps per mini-batch\n",
      "        lr: learning rate\n",
      "        clip: gradient clipping\n",
      "        val_frac: Fraction of data to hold out for validation\n",
      "        print_every: Number of steps for printing training and validation loss\n",
      "    \n",
      "    '''\n",
      "    net.train()\n",
      "    \n",
      "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "    \n",
      "    # create training and validation data\n",
      "    val_idx = int(len(data)*(1-val_frac))\n",
      "    data, val_data = data[:val_idx], data[val_idx:]\n",
      "    \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    \n",
      "    counter = 0\n",
      "    n_chars = len(net.chars)\n",
      "    for e in range(epochs):\n",
      "        # initialize hidden state\n",
      "        h = net.init_hidden(batch_size)\n",
      "        \n",
      "        for x, y in get_batches(data, batch_size, seq_length):\n",
      "            counter += 1\n",
      "            \n",
      "            # One-hot encode our data and make them Torch tensors\n",
      "            x = one_hot_encode(x, n_chars)\n",
      "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
      "            \n",
      "            if(train_on_gpu):\n",
      "                inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "            # Creating new variables for the hidden state, otherwise\n",
      "            # we'd backprop through the entire training history\n",
      "            h = tuple([each.data for each in h])\n",
      "\n",
      "            # zero accumulated gradients\n",
      "            net.zero_grad()\n",
      "            \n",
      "            # get the output from the model\n",
      "            output, h = net(inputs, h)\n",
      "            \n",
      "            # calculate the loss and perform backprop\n",
      "            loss = criterion(output, targets.contiguous().view(batch_size*seq_length))\n",
      "            loss.backward()\n",
      "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
      "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "            opt.step()\n",
      "            \n",
      "            # loss stats\n",
      "            if counter % print_every == 0:\n",
      "                # Get validation loss\n",
      "                val_h = net.init_hidden(batch_size)\n",
      "                val_losses = []\n",
      "                net.eval()\n",
      "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
      "                    # One-hot encode our data and make them Torch tensors\n",
      "                    x = one_hot_encode(x, n_chars)\n",
      "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
      "                    \n",
      "                    # Creating new variables for the hidden state, otherwise\n",
      "                    # we'd backprop through the entire training history\n",
      "                    val_h = tuple([each.data for each in val_h])\n",
      "                    \n",
      "                    inputs, targets = x, y\n",
      "                    if(train_on_gpu):\n",
      "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
      "\n",
      "                    output, val_h = net(inputs, val_h)\n",
      "                    val_loss = criterion(output, targets.contiguous().view(batch_size*seq_length))\n",
      "                \n",
      "                    val_losses.append(val_loss.item())\n",
      "                \n",
      "                net.train() # reset to train mode after iterationg through validation data\n",
      "                \n",
      "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "                      \"Step: {}...\".format(counter),\n",
      "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
      "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
      "24/186:\n",
      "## TODO: set you model hyperparameters\n",
      "# define and print the net\n",
      "n_hidden=512\n",
      "n_layers=2\n",
      "\n",
      "net = CharRNN(chars, n_hidden, n_layers)\n",
      "print(net)\n",
      "24/187:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)\n",
      "24/188:\n",
      "batch_size = 128\n",
      "seq_length = 100\n",
      "n_epochs = 1 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.01, print_every=10)\n",
      "24/189:\n",
      "batch_size = 32\n",
      "seq_length = 20\n",
      "n_epochs = 3 # start small if you are just testing initial behavior\n",
      "\n",
      "# train the model\n",
      "train(net, encoded, n_epochs, batch_size, seq_length, 0.01, 10)\n",
      "24/190:\n",
      "# change the name, for saving multiple files\n",
      "model_name = 'rnn_x_epoch.net'\n",
      "\n",
      "checkpoint = {'n_hidden': net.n_hidden,\n",
      "              'n_layers': net.n_layers,\n",
      "              'state_dict': net.state_dict(),\n",
      "              'tokens': net.chars}\n",
      "\n",
      "with open(model_name, 'wb') as f:\n",
      "    torch.save(checkpoint, f)\n",
      "24/191:\n",
      "def predict(net, char, h=None, top_k=None):\n",
      "        ''' Given a character, predict the next character.\n",
      "            Returns the predicted character and the hidden state.\n",
      "        '''\n",
      "        \n",
      "        # tensor inputs\n",
      "        x = np.array([[net.char2int[char]]])\n",
      "        x = one_hot_encode(x, len(net.chars))\n",
      "        inputs = torch.from_numpy(x)\n",
      "        \n",
      "        if(train_on_gpu):\n",
      "            inputs = inputs.cuda()\n",
      "        \n",
      "        # detach hidden state from history\n",
      "        h = tuple([each.data for each in h])\n",
      "        # get the output of the model\n",
      "        out, h = net(inputs, h)\n",
      "\n",
      "        # get the character probabilities\n",
      "        p = F.softmax(out, dim=1).data\n",
      "        if(train_on_gpu):\n",
      "            p = p.cpu() # move to cpu\n",
      "        \n",
      "        # get top characters\n",
      "        if top_k is None:\n",
      "            top_ch = np.arange(len(net.chars))\n",
      "        else:\n",
      "            p, top_ch = p.topk(top_k)\n",
      "            top_ch = top_ch.numpy().squeeze()\n",
      "        \n",
      "        # select the likely next character with some element of randomness\n",
      "        p = p.numpy().squeeze()\n",
      "        char = np.random.choice(top_ch, p=p/p.sum())\n",
      "        \n",
      "        # return the encoded value of the predicted char and the hidden state\n",
      "        return net.int2char[char], h\n",
      "24/192:\n",
      "def sample(net, size, prime='The', top_k=None):\n",
      "        \n",
      "    if(train_on_gpu):\n",
      "        net.cuda()\n",
      "    else:\n",
      "        net.cpu()\n",
      "    \n",
      "    net.eval() # eval mode\n",
      "    \n",
      "    # First off, run through the prime characters\n",
      "    chars = [ch for ch in prime]\n",
      "    h = net.init_hidden(1)\n",
      "    for ch in prime:\n",
      "        char, h = predict(net, ch, h, top_k=top_k)\n",
      "\n",
      "    chars.append(char)\n",
      "    \n",
      "    # Now pass in the previous character and get a new one\n",
      "    for ii in range(size):\n",
      "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
      "        chars.append(char)\n",
      "\n",
      "    return ''.join(chars)\n",
      "24/193: print(sample(net, 1000, prime='Anna', top_k=5))\n",
      "28/1:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "\n",
      "torch.manual_seed(1)\n",
      "28/2:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "28/3:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "28/4:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "28/5: labels\n",
      "28/6:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [list(map(float, i)) for i in labels]\n",
      "28/7: features\n",
      "28/8:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "28/9: labels\n",
      "28/10:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "28/11:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "28/12: features\n",
      "28/13: features.shape\n",
      "28/14:\n",
      "features.shape\n",
      "labels.shape\n",
      "28/15: features.shape\n",
      "28/16:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "28/17:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = range(len(x))\n",
      "28/18:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = range(len(x))\n",
      "times\n",
      "28/19:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = range(1, len(x)+1)?\n",
      "28/20:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = range(1, len(x)+1)\n",
      "28/21:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = range(1, len(x)+1)\n",
      "times\n",
      "28/22:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = list(range(1, len(x)+1))\n",
      "28/23:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = list(range(1, len(x)+1))\n",
      "times\n",
      "28/24:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = torch.tensor(list(range(1, len(x)+1)))\n",
      "28/25:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = torch.range(1, len(x)+1)\n",
      "28/26:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = torch.arange(1, len(x)+1)\n",
      "28/27:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = torch.arange(1, len(x)+1)\n",
      "times\n",
      "28/28:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "x.shape\n",
      "29/1:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "x\n",
      "29/2:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "x\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "29/3:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "print(x)\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "29/4:\n",
      "import torch\n",
      "from torch import nn\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "29/5:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "29/6:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "x\n",
      "29/7:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "x.shape\n",
      "29/8:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "x.size()\n",
      "29/9:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "x.size\n",
      "29/10:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "# how many time steps/data pts are in one batch of data\n",
      "seq_length = 20\n",
      "\n",
      "# generate evenly spaced data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
      "\n",
      "x = data[:-1] # all but the last piece of data\n",
      "y = data[1:] # all but the first\n",
      "\n",
      "# display the data\n",
      "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
      "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
      "\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "x.size(0)\n",
      "29/11:\n",
      "class RNN(nn.Module):\n",
      "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
      "        super(RNN, self).__init__()\n",
      "        \n",
      "        self.hidden_dim=hidden_dim\n",
      "\n",
      "        # define an RNN with specified parameters\n",
      "        # batch_first means that the first dim of the input and output will be the batch_size\n",
      "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
      "        \n",
      "        # last, fully-connected layer\n",
      "        self.fc = nn.Linear(hidden_dim, output_size)\n",
      "\n",
      "    def forward(self, x, hidden):\n",
      "        # x (batch_size, seq_length, input_size)\n",
      "        # hidden (n_layers, batch_size, hidden_dim)\n",
      "        # r_out (batch_size, time_step, hidden_size)\n",
      "        batch_size = x.size(0)\n",
      "        \n",
      "        # get RNN outputs\n",
      "        r_out, hidden = self.rnn(x, hidden)\n",
      "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
      "        r_out = r_out.view(-1, self.hidden_dim)  \n",
      "        \n",
      "        # get final output \n",
      "        output = self.fc(r_out)\n",
      "        \n",
      "        return output, hidden\n",
      "29/12:\n",
      "# test that dimensions are as expected\n",
      "test_rnn = RNN(input_size=1, output_size=1, hidden_dim=10, n_layers=2)\n",
      "\n",
      "# generate evenly spaced, test data pts\n",
      "time_steps = np.linspace(0, np.pi, seq_length)\n",
      "data = np.sin(time_steps)\n",
      "data.resize((seq_length, 1))\n",
      "\n",
      "test_input = torch.Tensor(data).unsqueeze(0) # give it a batch_size of 1 as first dimension\n",
      "print('Input size: ', test_input.size())\n",
      "\n",
      "# test out rnn sizes\n",
      "test_out, test_h = test_rnn(test_input, None)\n",
      "print('Output size: ', test_out.size())\n",
      "print('Hidden state size: ', test_h.size())\n",
      "28/29:\n",
      "x = labels[:-1]\n",
      "y = labels[1:]\n",
      "times = torch.arange(1, len(x)+1)\n",
      "28/30:\n",
      "x = labels[:-1].unsqueeze(0)\n",
      "y = labels[1:]\n",
      "times = torch.arange(1, len(x)+1)\n",
      "x\n",
      "28/31:\n",
      "x = labels[:-1].unsqueeze(0)\n",
      "y = labels[1:]\n",
      "times = torch.arange(1, len(x)+1)\n",
      "x.shape\n",
      "28/32:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:]\n",
      "times = torch.arange(1, len(x)+1)\n",
      "x.shape\n",
      "28/33:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:]\n",
      "times = torch.arange(1, len(x)+1)\n",
      "x\n",
      "28/34:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "28/35:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "y.shape\n",
      "28/36:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "x.reshape\n",
      "28/37:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "28/38:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "\n",
      "        \n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x), self.batch_size, -1)\n",
      "28/39:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "\n",
      "        \n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x), self.batch_size, -1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "28/40: testing = lstm(input_dim=1, output_dim=1, hidden_dim=10, n_layers=2)\n",
      "28/41: testing = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2)\n",
      "28/42: testing = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1)\n",
      "28/43:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x), self.batch_size, -1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "28/44: testing = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1)\n",
      "28/45: testing\n",
      "28/46:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(lstm.parameters(), lr=1e-3)\n",
      "28/47: model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1)\n",
      "28/48:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "28/49:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x), self.batch_size, -1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "28/50: model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1, dropout=0.3)\n",
      "28/51:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "28/52:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1, dropout=0.3)\n",
      "mode\n",
      "28/53:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1, dropout=0.3)\n",
      "model\n",
      "28/54:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def init_hidden(self):\n",
      "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
      "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
      "    \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x), self.batch_size, -1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "28/55:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1, dropout=0.3)\n",
      "model\n",
      "28/56:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x), self.batch_size, -1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "28/57:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1, dropout=0.3)\n",
      "model\n",
      "28/58:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "lstm(x)\n",
      "28/59:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "model(x)\n",
      "28/60:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "model(x, hidden)\n",
      "28/61:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/62:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/63:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "28/64:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "prediction.shape()\n",
      "28/65:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "prediction\n",
      "28/66:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "prediction.shape\n",
      "28/67:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "y.shape\n",
      "28/68:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "y.unsqueeze(1)\n",
      "28/69:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "y.unsqueeze(1).shape\n",
      "28/70:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction - y.unsqueeze(1).shape)\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/71:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction - y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/72:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x)\n",
      "loss = loss_fn(prediction - y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/73:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction - y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/74:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden, None)\n",
      "loss = loss_fn(prediction - y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/75:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction - y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/76:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden, y.unsqueeze(1))\n",
      "loss = loss_fn(prediction - y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/77:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction - y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/78:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/79:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "\n",
      "loss\n",
      "28/80:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/81:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/82:\n",
      "epochs = 3\n",
      "\n",
      "model.zero_grad()\n",
      "hidden = None\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "loss\n",
      "28/83:\n",
      "epochs = 3\n",
      "\n",
      "for e in epochs:\n",
      "    model.zero_grad()\n",
      "    hidden = None\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/84:\n",
      "epochs = 3\n",
      "hidden = None\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/85:\n",
      "epochs = 3\n",
      "hidden = None\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    \n",
      "loss\n",
      "28/86:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "hidden = None\n",
      "28/87:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/88: loss\n",
      "28/89:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/90: loss\n",
      "28/91:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/92: loss\n",
      "28/93:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/94: loss\n",
      "28/95:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/96: loss\n",
      "28/97:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "hidden = None\n",
      "28/98:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/99: loss\n",
      "28/100:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/101: loss\n",
      "28/102:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/103: loss\n",
      "28/104:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/105: loss\n",
      "28/106:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/107: loss\n",
      "28/108:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/109: loss\n",
      "28/110:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/111: loss\n",
      "28/112:\n",
      "epochs = 30\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/113: loss\n",
      "28/114:\n",
      "epochs = 30\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/115: loss\n",
      "28/116:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/117: loss\n",
      "28/118:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/119: loss\n",
      "28/120:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/121: loss\n",
      "28/122:\n",
      "epochs = 1000\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/123: loss\n",
      "28/124:\n",
      "epochs = 1000\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/125: loss\n",
      "28/126:\n",
      "epochs = 1000\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/127: loss\n",
      "28/128:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction[:5])\n",
      "28/129:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction[:5], y[:5])\n",
      "28/130:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction)\n",
      "28/131:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(y)\n",
      "28/132:\n",
      "epochs = 1000\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/133: loss\n",
      "28/134:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(y)\n",
      "28/135:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction)\n",
      "print(y)\n",
      "28/136:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "hidden = None\n",
      "28/137:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i])\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/138:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/139:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/140: loss\n",
      "28/141:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction)\n",
      "print(y)\n",
      "28/142:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/143: loss\n",
      "28/144:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/145: loss\n",
      "28/146:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/147: loss\n",
      "28/148:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/149: loss\n",
      "28/150:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/151: loss\n",
      "28/152:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/153: loss\n",
      "28/154:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "28/155:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/156: loss\n",
      "28/157:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/158: loss\n",
      "28/159:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/160: loss\n",
      "28/161:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/162: loss\n",
      "28/163:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for i in range(len(x)):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x[i], hidden)\n",
      "        loss = loss_fn(prediction, y[i].unsqueeze(1).unsqueeze(1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "28/164: loss\n",
      "28/165:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "model.zero_grad()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/166: loss\n",
      "28/167:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "model.zero_grad()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/168: loss\n",
      "28/169:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "model.zero_grad()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/170: loss\n",
      "28/171:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "model.zero_grad()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/172: loss\n",
      "28/173:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "model.zero_grad()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/174: loss\n",
      "28/175:\n",
      "epochs = 1\n",
      "\n",
      "\n",
      "model.zero_grad()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "loss.backward()\n",
      "optimizer.step()\n",
      "28/176: loss\n",
      "28/177:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/178: loss\n",
      "28/179:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/180: loss\n",
      "28/181:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "hidden = None\n",
      "28/182:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/183: loss\n",
      "28/184:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/185: loss\n",
      "28/186:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/187: loss\n",
      "28/188:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/189: loss\n",
      "28/190:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "28/191: loss\n",
      "28/192:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction)\n",
      "print(y)\n",
      "28/193:\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "28/194:\n",
      "plt.figure(figsize=(8,5))\n",
      "plt.plot(times, x, 'r.')\n",
      "28/195:\n",
      "plt.figure(figsize=(8,5))\n",
      "x.numpy()\n",
      "plt.plot(times, x, 'r.')\n",
      "28/196:\n",
      "plt.figure(figsize=(8,5))\n",
      "x.numpy()\n",
      "plt.plot(times, y, 'r.')\n",
      "28/197:\n",
      "plt.figure(figsize=(8,5))\n",
      "\n",
      "plt.plot(times, prediction.data.numpy().flatten(), 'r.')\n",
      "30/1:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "\n",
      "torch.manual_seed(1)\n",
      "30/2:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "30/3:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "30/4:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x), self.batch_size, -1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "30/5:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1, dropout=0.3)\n",
      "model\n",
      "30/6:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "hidden = None\n",
      "30/7:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/8: x.shape\n",
      "30/9: x.view(0)\n",
      "30/10:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "hidden = None\n",
      "30/11: x.view(1, -1, 1)\n",
      "30/12: x.view(1, -1, 1).shape\n",
      "30/13: len(x)\n",
      "30/14:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, len(x), -1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "30/15:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1, dropout=0.3)\n",
      "model\n",
      "30/16: x.shape\n",
      "30/17: x.reshape(self.batch_size, len(x), -1)\n",
      "30/18: x.reshape(1, len(x), -1)\n",
      "30/19: x.reshape(1, len(x), -1).shape\n",
      "30/20: x.shape\n",
      "30/21:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, len(x), -1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "30/22:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=1, dropout=0.3)\n",
      "model\n",
      "30/23:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "hidden = None\n",
      "30/24:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.unsqueeze(1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/25: y.shape\n",
      "30/26:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "hidden = None\n",
      "30/27:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(1, len(y), 1)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/28:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(1, len(y), 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/29: loss\n",
      "30/30:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(1, len(y), 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/31: loss\n",
      "30/32:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(1, len(y), 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/33: loss\n",
      "30/34:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "30/35:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "hidden = None\n",
      "30/36:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, len(y), 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/37:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/38:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "30/39:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "30/40:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "hidden = None\n",
      "30/41:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/42: loss\n",
      "30/43:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/44: loss\n",
      "30/45:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/46: loss\n",
      "30/47:\n",
      "epochs = 1000\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/48: loss\n",
      "30/49:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "30/50:\n",
      "epochs = 1000\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/51: loss\n",
      "30/52:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/53: loss\n",
      "30/54:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/55: loss\n",
      "30/56:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/57: loss\n",
      "30/58:\n",
      "epochs = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/59: loss\n",
      "30/60:\n",
      "epochs = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/61: loss\n",
      "30/62:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction)\n",
      "print(y)\n",
      "30/63: loss.item()\n",
      "30/64:\n",
      "epochs = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/65: loss.item()\n",
      "30/66:\n",
      "epochs = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/67: loss.item()\n",
      "30/68:\n",
      "epochs = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/69: loss.item()\n",
      "30/70:\n",
      "epochs = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/71: loss.item()\n",
      "30/72:\n",
      "epochs = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/73: loss.item()\n",
      "30/74:\n",
      "epochs = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/75: loss.item()\n",
      "30/76:\n",
      "epochs = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/77: loss.item()\n",
      "30/78:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
      "30/79:\n",
      "epochs = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/80: loss.item()\n",
      "30/81:\n",
      "epochs = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/82: loss.item()\n",
      "30/83:\n",
      "epochs = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/84: loss.item()\n",
      "30/85:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction)\n",
      "print(y)\n",
      "30/86:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction[:5])\n",
      "print(y[:5])\n",
      "30/87:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction.shape)\n",
      "print(y.shape)\n",
      "30/88:\n",
      "prediction, hidden = model(x, hidden)\n",
      "prediction.reshape(-1, 1)\n",
      "print(prediction[:-5])\n",
      "print(y[:-5])\n",
      "30/89:\n",
      "prediction, hidden = model(x, hidden)\n",
      "prediction.reshape(-1, 1)\n",
      "print(prediction[-5:-1])\n",
      "print(y[-5:-1])\n",
      "30/90:\n",
      "prediction, hidden = model(x, hidden)\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "print(prediction[-5:-1])\n",
      "print(y[-5:-1])\n",
      "30/91:\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "30/92:\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(times, y)\n",
      "plt.show()\n",
      "30/93:\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(times, y, 'b')\n",
      "plt.show()\n",
      "30/94:\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(times, y, 'b.')\n",
      "plt.show()\n",
      "30/95:\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(times, y, color='b')\n",
      "plt.show()\n",
      "30/96:\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(times, y, color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "30/97:\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(times, y, color='b')\n",
      "\n",
      "prediction.detach().numpy()\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "30/98:\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(times, y, color='b')\n",
      "\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "30/99:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "30/100: hidden = None\n",
      "30/101:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
      "30/102: loss.item()\n",
      "30/103:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/104: loss.item()\n",
      "30/105:\n",
      "prediction, hidden = model(x, hidden)\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "print(prediction[-5:-1])\n",
      "print(y[-5:-1])\n",
      "30/106:\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(times, y, color='b')\n",
      "\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "30/107:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "30/108:\n",
      "epochs = 5000\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "30/109: loss.item()\n",
      "30/110:\n",
      "prediction, hidden = model(x, hidden)\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "print(prediction[-5:-1])\n",
      "print(y[-5:-1])\n",
      "30/111:\n",
      "plt.figure(figsize=(8, 8))\n",
      "plt.scatter(times, y, color='b')\n",
      "\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "30/112:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "torch.manual_seed(1)\n",
      "30/113:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "30/114:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "30/115:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "30/116:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "30/117: hidden = None\n",
      "30/118:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "30/119:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item)\n",
      "        plt.figure(figsize=(8, 8))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "30/120: loss.item()\n",
      "30/121:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(8, 8))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "30/122:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
      "30/123:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(8, 8))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "30/124:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
      "30/125:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "30/126:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "30/127: hidden = None\n",
      "30/128:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
      "30/129:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "30/130:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/1:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "torch.manual_seed(1)\n",
      "31/2:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "31/3:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "31/4:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "31/5:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "31/6: hidden = None\n",
      "31/7:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "31/8:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/9:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/10:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/11:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "31/12:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/13:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
      "31/14:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/15:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
      "31/16:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/17:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
      "31/18:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/19: loss.item()\n",
      "31/20:\n",
      "prediction, hidden = model(x, hidden)\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "print(prediction[-5:-1])\n",
      "print(y[-5:-1])\n",
      "31/21:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/IBM_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "31/22:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "31/23:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "31/24:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "31/25:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "print(x.shape)\n",
      "31/26:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "31/27:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "31/28: hidden = None\n",
      "31/29:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
      "31/30:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/31:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "31/32:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/33:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/34:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "31/35:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/36:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/37:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/38:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
      "31/39:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/40:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/CAT_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "31/41:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "31/42:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "31/43: hidden = None\n",
      "31/44:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "31/45:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/46:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "31/47:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/48:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
      "31/49:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/50:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
      "31/51:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/52:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
      "31/53:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/54:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
      "31/55:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/56:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-6, momentum=0.2, nesterov=True)\n",
      "31/57:\n",
      "epochs = 3000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/58:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/BRK.B_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "31/59:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "31/60:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "31/61:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "31/62: hidden = None\n",
      "31/63:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-6, momentum=0.2, nesterov=True)\n",
      "31/64:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.2, nesterov=True)\n",
      "31/65:\n",
      "epochs = 3000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/66:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "31/67:\n",
      "epochs = 3000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/68:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "31/69:\n",
      "epochs = 3000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/70:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/71:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/72:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "31/73:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "31/74:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/75:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import glob, os\n",
      "\n",
      "torch.manual_seed(1)\n",
      "31/76:\n",
      "os.chdir(\"/Users/js/Desktop/datasets/sp500/individual_stocks_5yr\")\n",
      "for file in glob.glob(\"*.csv\"):\n",
      "    print(file)\n",
      "31/77:\n",
      "master_dir = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr'\n",
      "os.chdir(master_dir)\n",
      "\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for file in glob.glob(\"*.csv\"):\n",
      "    filepath = f'{masterdir}/{file}'\n",
      "\n",
      "    features = []\n",
      "    labels = []\n",
      "\n",
      "    with open(filepath, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        next(reader)\n",
      "        for row in reader:\n",
      "            features.append(row[1:4] + [row[5]])\n",
      "            labels.append(row[4])\n",
      "\n",
      "    features = [list(map(float, i)) for i in features]\n",
      "    labels = [float(j) for j in labels]\n",
      "\n",
      "    features = torch.tensor(features)\n",
      "    labels = torch.tensor(labels)\n",
      "\n",
      "    x = labels[:-1].unsqueeze(1)\n",
      "    y = labels[1:].unsqueeze(1)\n",
      "    \n",
      "    all_features.append(features)\n",
      "    all_labels.append(labels)\n",
      "31/78:\n",
      "master_dir = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr'\n",
      "os.chdir(master_dir)\n",
      "\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for file in glob.glob(\"*.csv\"):\n",
      "    filepath = f'{master_dir}/{file}'\n",
      "\n",
      "    features = []\n",
      "    labels = []\n",
      "\n",
      "    with open(filepath, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        next(reader)\n",
      "        for row in reader:\n",
      "            features.append(row[1:4] + [row[5]])\n",
      "            labels.append(row[4])\n",
      "\n",
      "    features = [list(map(float, i)) for i in features]\n",
      "    labels = [float(j) for j in labels]\n",
      "\n",
      "    features = torch.tensor(features)\n",
      "    labels = torch.tensor(labels)\n",
      "\n",
      "    x = labels[:-1].unsqueeze(1)\n",
      "    y = labels[1:].unsqueeze(1)\n",
      "    \n",
      "    all_features.append(features)\n",
      "    all_labels.append(labels)\n",
      "31/79:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "torch.manual_seed(1)\n",
      "31/80:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/BRK.B_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "31/81:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "31/82:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/83:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "31/84:\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "31/85:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "31/86:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "31/87:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/1:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "torch.manual_seed(1)\n",
      "32/2:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/3:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/4:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "32/5: hidden = None\n",
      "32/6:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "32/7:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/8:\n",
      "epochs = 300\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/9:\n",
      "epochs = 3000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/10:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "\n",
      "torch.manual_seed(1)\n",
      "32/11:\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(filename, 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                all_features.append(row[1:4] + [row[5]])\n",
      "                all_labels.append(row[4])\n",
      "                \n",
      "all_features\n",
      "32/12:\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(filename, 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                all_features.append(row[1:4] + [row[5]])\n",
      "                all_labels.append(row[4])\n",
      "                \n",
      "all_features\n",
      "32/13:\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                all_features.append(row[1:4] + [row[5]])\n",
      "                all_labels.append(row[4])\n",
      "                \n",
      "all_features\n",
      "32/14:\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                all_features.append(row[1:4] + [row[5]])\n",
      "                all_labels.append(row[4])\n",
      "                \n",
      "all_features.shape\n",
      "32/15:\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                all_features.append(row[1:4] + [row[5]])\n",
      "                all_labels.append(row[4])\n",
      "                \n",
      "all_features = [list(map(float, i)) for i in all_features]\n",
      "all_labels = [float(j) for j in all_labels]\n",
      "32/16:\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                all_features.append(row[1:4] + [row[5]])\n",
      "                all_labels.append(row[4])\n",
      "                \n",
      "print(all_features[0])\n",
      "32/17:\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                all_features.append(row[1:4] + [row[5]])\n",
      "                all_labels.append(row[4])\n",
      "                \n",
      "all_features = np.array(all_features)\n",
      "all_labels = np.array(all_labels)\n",
      "print(all_features[0])\n",
      "32/18:\n",
      "all_features = []\n",
      "all_labels = []\n",
      "\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                all_features.append(row[1:4] + [row[5]])\n",
      "                all_labels.append(row[4])\n",
      "                \n",
      "all_features = np.array(all_features)\n",
      "all_labels = np.array(all_labels)\n",
      "print(all_features.shape)\n",
      "32/19:\n",
      "def train(epochs, show_every)\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if e % show_every == 0:\n",
      "            print(loss.item())\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y, color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/20:\n",
      "def train(epochs, show_every):\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if e % show_every == 0:\n",
      "            print(loss.item())\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y, color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/21:\n",
      "def train(epochs, show_every):\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if e % show_every == 0:\n",
      "            print(loss.item())\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y, color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/22:\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/23:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/24:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    all_features = []\n",
      "    all_labels = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                all_features.append(row[1:4] + [row[5]])\n",
      "                all_labels.append(row[4])\n",
      "                \n",
      "\n",
      "    all_features = [list(map(float, i)) for i in all_features]\n",
      "    all_labels = [float(j) for j in all_labels]\n",
      "\n",
      "    all_features = torch.tensor(all_features)\n",
      "    all_labels = torch.tensor(all_labels)\n",
      "\n",
      "    x = all_labels[:-1].unsqueeze(1)\n",
      "    y = all_labels[1:].unsqueeze(1)\n",
      "    xtimes = torch.arange(1, len(x)+1)\n",
      "\n",
      "    epochs = 500\n",
      "    show_every = 500\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if e % show_every == 0:\n",
      "            print(loss.item())\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(xtimes, y, color='b')\n",
      "            plt.scatter(xtimes, prediction, color='r')\n",
      "            plt.show()\n",
      "32/25:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "\n",
      "torch.manual_seed(1)\n",
      "32/26:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:4] + [row[5]])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(features.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/27:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:5])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(features.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/28:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:6])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(features.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/29:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:6])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(features[0])\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/30:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:6])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "\n",
      "x = labels[:-1].unsqueeze(1)\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(features[0])\n",
      "print(x[0])\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/31:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:6])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "\n",
      "x = features[:-1]\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(features[0])\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/32:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.batch_size = batch_size\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/33:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x)/2, -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/34:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, dropout=0.3)\n",
      "model\n",
      "32/35: hidden = None\n",
      "32/36:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/37:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/38:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x), -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/39:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, dropout=0.3)\n",
      "model\n",
      "32/40: hidden = None\n",
      "32/41:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/42:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/43:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(len(x), -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/44:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(len(x), -1, 1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/45:\n",
      "model = lstm(input_dim=5, output_dim=1, hidden_dim=10, num_layers=2, dropout=0.3)\n",
      "model\n",
      "32/46: hidden = None\n",
      "32/47:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/48:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(len(x), -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/49:\n",
      "model = lstm(input_dim=5, output_dim=1, hidden_dim=10, num_layers=2, dropout=0.3)\n",
      "model\n",
      "32/50: hidden = None\n",
      "32/51:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/52: x\n",
      "32/53: x.shape\n",
      "32/54:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(len(x), -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/55: x.shape\n",
      "32/56:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, dropout=0.3)\n",
      "model\n",
      "32/57: hidden = None\n",
      "32/58:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/59: x.shape\n",
      "32/60:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(len(x), -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/61:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(1, len(x), -1)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/62:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, dropout=0.3)\n",
      "model\n",
      "32/63: hidden = None\n",
      "32/64:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/65: x.shape\n",
      "32/66:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(1, len(x), -1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/67:\n",
      "model = lstm(input_dim=5, output_dim=1, hidden_dim=10, num_layers=2, dropout=0.3)\n",
      "model\n",
      "32/68: hidden = None\n",
      "32/69:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/70: x.shape\n",
      "32/71:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(1, len(x), -1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/72: x.shape\n",
      "32/73:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/74:\n",
      "model = lstm(input_dim=5, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "32/75: hidden = None\n",
      "32/76:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/77: x.shape\n",
      "32/78:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(1, len(x), -1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/79: x\n",
      "32/80: x.batch_size\n",
      "32/81:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/82:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/83:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/84:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/85:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "32/86:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/87:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/88:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "\n",
      "torch.manual_seed(1)\n",
      "32/89:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "features = []\n",
      "labels = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        features.append(row[1:6])\n",
      "        labels.append(row[4])\n",
      "\n",
      "features = [list(map(float, i)) for i in features]\n",
      "labels = [float(j) for j in labels]\n",
      "\n",
      "features = torch.tensor(features)\n",
      "labels = torch.tensor(labels)\n",
      "\n",
      "x = features[:-1]\n",
      "y = labels[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/90:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/91:\n",
      "model = lstm(input_dim=5, output_dim=1, hidden_dim=10, num_layers=2, batch_size=74, dropout=0.3)\n",
      "model\n",
      "32/92: hidden = None\n",
      "32/93:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/94:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/95:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/96:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "32/97:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/98:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/99:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(74, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/100:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/101:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "print(x.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/102:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x.reshape(batch_size, -1, 1)\n",
      "print(x.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/103:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "print(len(x) // 64)\n",
      "#x.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/104:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "print(len(x) // 64)\n",
      "x = x[:19*64+1]\n",
      "x.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/105:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "print(len(x) // 64)\n",
      "x = x[:19*64]\n",
      "x.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/106:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "print(len(x) // 64)\n",
      "x = x[:19*64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/107:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/108:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/109:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=64, dropout=0.3)\n",
      "model\n",
      "32/110: hidden = None\n",
      "32/111:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/112:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.3)\n",
      "model\n",
      "32/113: hidden = None\n",
      "32/114:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/115:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y.reshape(batch_size, -1, 1))\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/116:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/117:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/118:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.3)\n",
      "model\n",
      "32/119: hidden = None\n",
      "32/120:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/121:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/122:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/123:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "\n",
      "print(x.size)\n",
      "32/124:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "\n",
      "print(x.size())\n",
      "32/125:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "\n",
      "print(x.size())\n",
      "print(y.size())\n",
      "32/126:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "\n",
      "print(x.size == y.size)\n",
      "32/127:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "\n",
      "print(x.size() == y.size())\n",
      "32/128:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "\n",
      "print(x.size == y.size\n",
      "32/129:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "\n",
      "print(x.size == y.size)\n",
      "32/130:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "\n",
      "x.size()\n",
      "32/131:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "\n",
      "len(x)\n",
      "32/132:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(x[0])\n",
      "32/133:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(y) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "print(x[0])\n",
      "print(y[0])\n",
      "32/134:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "\n",
      "x = x[:(len(x) // 64) *64]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:(len(x) // 64) *64]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/135:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "32/136:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/137:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.3)\n",
      "model\n",
      "32/138: hidden = None\n",
      "32/139:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/140:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/141:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        y = y.reshape(-1, 1)\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.show()\n",
      "32/142:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "32/143:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/144:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.3)\n",
      "model\n",
      "32/145: hidden = None\n",
      "32/146:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/147:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        y = y.reshape(-1, 1)\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.show()\n",
      "32/148:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times)\n",
      "32/149:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, len(x)+1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "32/150:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "32/151:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "32/152:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/153:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.3)\n",
      "model\n",
      "32/154: hidden = None\n",
      "32/155:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/156:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        y = y.reshape(-1, 1)\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.scatter(times, y, color='b')\n",
      "        plt.show()\n",
      "32/157:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.show()\n",
      "32/158:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "32/159:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "32/160:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.3)\n",
      "model\n",
      "32/161: hidden = None\n",
      "32/162:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/163:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if e % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.show()\n",
      "32/164:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.show()\n",
      "32/165:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.show()\n",
      "32/166:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
      "32/167:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/168:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    values = []\n",
      "\n",
      "    with open(filepath, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        next(reader)\n",
      "        for row in reader:\n",
      "            values.append(row[4])\n",
      "\n",
      "    values = [float(j) for j in labels]\n",
      "\n",
      "    values = torch.tensor(values)\n",
      "\n",
      "    x = values[:-1].unsqueeze(1)\n",
      "    y = values[1:].unsqueeze(1)\n",
      "\n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "    \n",
      "    epochs = 250\n",
      "    show_every = 250\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/169:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals= []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(all_labels)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    xtimes = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "    \n",
      "\n",
      "    epochs = 500\n",
      "    show_every = 500\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/170:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals= []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(all_labels)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "    \n",
      "\n",
      "    epochs = 500\n",
      "    show_every = 500\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/171:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "    \n",
      "\n",
      "    epochs = 500\n",
      "    show_every = 500\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/172:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 500\n",
      "    show_every = 500\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/173:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/174:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 500\n",
      "    show_every = 500\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/175:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/176:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=3, batch_size=batch_size, dropout=0.3)\n",
      "model\n",
      "32/177: hidden = None\n",
      "32/178:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "32/179:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/180:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 1000\n",
      "    show_every = 1000\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/181:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/182:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/183:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/184:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=1, batch_size=batch_size, dropout=0.3)\n",
      "model\n",
      "32/185:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.3)\n",
      "model\n",
      "32/186: hidden = None\n",
      "32/187:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/188:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/189:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/190:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/191:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/192:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "32/193:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/194: hidden = None\n",
      "32/195:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/196:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/197:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.5)\n",
      "model\n",
      "32/198: hidden = None\n",
      "32/199:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "32/200:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "32/201:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/1:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "\n",
      "torch.manual_seed(1)\n",
      "33/2:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in labels]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "33/3:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "\n",
      "torch.manual_seed(1)\n",
      "33/4:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "33/5:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "33/6:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.5)\n",
      "model\n",
      "33/7: hidden = None\n",
      "33/8:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/9:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/10:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/11:\n",
      "epochs = 1500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/12:\n",
      "epochs = 400\n",
      "show_every = 200\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/13:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/14:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/GS_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "33/15:\n",
      "epochs = 400\n",
      "show_every = 200\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/16:\n",
      "epochs = 1000\n",
      "show_every = 200\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/17:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "33/18:\n",
      "epochs = 1000\n",
      "show_every = 200\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/19: hidden = None\n",
      "33/20:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "33/21:\n",
      "epochs = 1000\n",
      "show_every = 200\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/22:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/23:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.5, nesterov=True)\n",
      "33/24:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/25: hidden = None\n",
      "33/26:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.5, nesterov=True)\n",
      "33/27:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/28:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "33/29:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "33/30:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.5)\n",
      "model\n",
      "33/31: hidden = None\n",
      "33/32:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.5, nesterov=True)\n",
      "33/33:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/34:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2, momentum=0.5, nesterov=True)\n",
      "33/35:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/36:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/37:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/38: hidden = None\n",
      "33/39:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/40:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/41: hidden = None\n",
      "33/42:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/43:\n",
      "epochs = 500\n",
      "show_every = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/44: hidden = None\n",
      "33/45:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/46:\n",
      "epochs = 100\n",
      "show_every = 20\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/47: hidden = None\n",
      "33/48:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "33/49:\n",
      "epochs = 100\n",
      "show_every = 20\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/50: hidden = None\n",
      "33/51:\n",
      "epochs = 1\n",
      "show_every = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/52:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.5)\n",
      "model\n",
      "33/53: hidden = None\n",
      "33/54:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "33/55:\n",
      "epochs = 1\n",
      "show_every = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/56:\n",
      "epochs = 100\n",
      "show_every = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/57:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/58:\n",
      "epochs = 100\n",
      "show_every = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/59:\n",
      "epochs = 1000\n",
      "show_every = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/60:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/GS_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "33/61:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/62:\n",
      "epochs = 1000\n",
      "show_every = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/63:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-1)\n",
      "33/64:\n",
      "epochs = 1000\n",
      "show_every = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/65:\n",
      "loss_fn = nn.CrossEntropyLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-1)\n",
      "33/66:\n",
      "epochs = 1000\n",
      "show_every = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/67:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-1)\n",
      "33/68:\n",
      "epochs = 1000\n",
      "show_every = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/69:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-1)\n",
      "33/70:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "33/71:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.5)\n",
      "model\n",
      "33/72: hidden = None\n",
      "33/73:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-1)\n",
      "33/74:\n",
      "epochs = 1000\n",
      "show_every = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/75:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/76:\n",
      "epochs = 1000\n",
      "show_every = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/77:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/SPGI_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "33/78:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "33/79:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.5)\n",
      "model\n",
      "33/80: hidden = None\n",
      "33/81:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/82:\n",
      "epochs = 1000\n",
      "show_every = 100\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/83:\n",
      "epochs = 2000\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/84:\n",
      "epochs = 2000\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/85:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "33/86:\n",
      "epochs = 2000\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/87:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/88:\n",
      "epochs = 750\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/89:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/90:\n",
      "epochs = 750\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/91:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/92:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3.5)\n",
      "33/93:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
      "33/94:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/95:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/96:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=2, batch_size=batch_size, dropout=0.5)\n",
      "model\n",
      "33/97: hidden = None\n",
      "33/98:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "33/99:\n",
      "epochs = 1500\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/100:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/101:\n",
      "epochs = 1500\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/102:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-1)\n",
      "33/103:\n",
      "epochs = 1500\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/104:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/105:\n",
      "epochs = 1500\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/106:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/SPGI_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x[0])\n",
      "print(y[0])\n",
      "33/107:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "33/108: hidden = None\n",
      "33/109:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/110:\n",
      "epochs = 1500\n",
      "show_every = 250\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/111:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/112:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/113:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.5, nesterov=True)\n",
      "33/114:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/115:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/116:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adagrad(model.parameters(), lr=1e-2)\n",
      "33/117:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/118:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=1e-2)\n",
      "33/119:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/120:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "33/121: hidden = None\n",
      "33/122:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), lr=1e-2)\n",
      "33/123:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/124:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), rho=0.95, eps=1e-6)\n",
      "33/125:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/126:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), rho=0.95, eps=1e-5)\n",
      "33/127:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/128:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/129:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "33/130: hidden = None\n",
      "33/131:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.RMSprop(model.parameters(), lr=1e-2, momentum=0.9, eps=1e-6)\n",
      "33/132:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/133:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/134:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/135:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=10, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "33/136:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=16, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "33/137: hidden = None\n",
      "33/138:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "33/139:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/140:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/REGN_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x[0])\n",
      "print(y[0])\n",
      "33/141:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/142:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95)\n",
      "33/143:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/144:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/145:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "33/146:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/147:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-3)\n",
      "33/148:\n",
      "epochs = 5000\n",
      "show_every = 500\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/149:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "33/150:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/151: filename\n",
      "33/152:\n",
      "for filename in os.listdir('/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/'):\n",
      "    vals = []\n",
      "    if filename.endswith(\".csv\"): \n",
      "        with open(f'/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/{filename}', 'r') as f:\n",
      "            reader = csv.reader(f)\n",
      "            next(reader)\n",
      "            for row in reader:\n",
      "                vals.append(row[4])\n",
      "                \n",
      "    vals = [float(j) for j in vals]\n",
      "    vals = torch.tensor(vals)\n",
      "\n",
      "    x = vals[:-1].unsqueeze(1)\n",
      "    y = vals[1:].unsqueeze(1)\n",
      "    \n",
      "    batch_size = 64\n",
      "    chunks = len(x) // 64\n",
      "\n",
      "    times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "    x = x[:chunks * batch_size]\n",
      "    x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "    y = y[:chunks * batch_size]\n",
      "    y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "    epochs = 300\n",
      "    show_every = 300\n",
      "\n",
      "    for e in range(epochs):\n",
      "        model.zero_grad()\n",
      "        prediction, hidden = model(x, hidden)\n",
      "        loss = loss_fn(prediction, y)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if (e+1) % show_every == 0:\n",
      "            print(loss.item())\n",
      "            print(filename)\n",
      "            plt.figure(figsize=(5, 5))\n",
      "            prediction = prediction.reshape(-1, 1)\n",
      "            prediction = prediction.detach().numpy()\n",
      "            plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "            plt.scatter(times, prediction, color='r')\n",
      "            plt.show()\n",
      "33/153: filename\n",
      "33/154: x\n",
      "33/155:\n",
      "epochs = 1\n",
      "show_every = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/156:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/REGN_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x[0])\n",
      "print(y[0])\n",
      "33/157:\n",
      "epochs = 1\n",
      "show_every = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/158:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/EBAY_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x[0])\n",
      "print(y[0])\n",
      "33/159:\n",
      "epochs = 1\n",
      "show_every = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/160: x\n",
      "33/161: x.shape\n",
      "33/162: hidden\n",
      "33/163: hidden.shape\n",
      "33/164: hidden\n",
      "33/165:\n",
      "f = open('/Users/js/Desktop/hidden.py', 'w' )\n",
      "f.write(hidden)\n",
      "f.close()\n",
      "33/166: hidden\n",
      "33/167: str(hidden)\n",
      "33/168: (str(hidden))\n",
      "33/169: (str(hidden),)\n",
      "33/170: a = str(hidden)\n",
      "33/171:\n",
      "a = str(hidden)\n",
      "a\n",
      "33/172:\n",
      "a = str(hidden)\n",
      "(a,)\n",
      "33/173:\n",
      "a = str(hidden)\n",
      "tuple(a)\n",
      "33/174:\n",
      "a = str(hidden)\n",
      "tuple([a])\n",
      "33/175: hidden[0]\n",
      "33/176: hidden[0].shape\n",
      "33/177: hidden.shape\n",
      "33/178: hidden.size\n",
      "33/179: hidden[0].shape\n",
      "33/180: hidden[0].view(-1)\n",
      "33/181: hidden[0].view(-1).shape\n",
      "33/182: hidden[0].view(-1)\n",
      "33/183: hidden[0].view(-1).numpy()\n",
      "33/184: hidden[0].view(-1).detach().numpy()\n",
      "33/185: hidden\n",
      "33/186: hidden.shape\n",
      "33/187: hidden[0].shape\n",
      "33/188:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "import pickle\n",
      "\n",
      "torch.manual_seed(1)\n",
      "33/189:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'wb')\n",
      "pickle.dump(hidden, f)\n",
      "f.close()\n",
      "33/190:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'rb')\n",
      "hidden = pickle.load(f)\n",
      "f.close()\n",
      "33/191:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/EBAY_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "33/192:\n",
      "epochs = 1\n",
      "show_every = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/193: hidden = None\n",
      "33/194:\n",
      "epochs = 1\n",
      "show_every = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "33/195: hidden\n",
      "33/196:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'rb')\n",
      "hidden = pickle.load(f)\n",
      "f.close()\n",
      "33/197: hidden\n",
      "33/198:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'wb')\n",
      "pickle.dump(hidden, f)\n",
      "f.close()\n",
      "\n",
      "torch.save(model, 'Users/js/programs/lstm-stock-time-series.pt')\n",
      "33/199:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'wb')\n",
      "pickle.dump(hidden, f)\n",
      "f.close()\n",
      "\n",
      "torch.save(model, '/Users/js/programs/lstm-stock-time-series.pt')\n",
      "33/200:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/201:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/202:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/203:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/204:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/V_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "33/205:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/206:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/207:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/REGN_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "33/208:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/209:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/NVDA_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "33/210:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/211:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/VRSK_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "33/212:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/213:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/TIF_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "33/214:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "33/215:\n",
      "f = open('/Users/js/Desktop/hidden.py', 'w' )\n",
      "f.write(hidden)\n",
      "f.close()\n",
      "33/216:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'wb')\n",
      "pickle.dump(hidden, f)\n",
      "f.close()\n",
      "\n",
      "torch.save(model, '/Users/js/programs/lstm-stock-time-series.pt')\n",
      "34/1:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "import pickle\n",
      "\n",
      "torch.manual_seed(1)\n",
      "34/2:\n",
      "times = torch.arange(1, 100.1, 0.1)\n",
      "values = torch.sin(times)\n",
      "34/3:\n",
      "times = torch.arange(1, 100.1, 0.1)\n",
      "values = torch.sin(times)\n",
      "values.shape\n",
      "34/4:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "values.shape\n",
      "34/5:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "34/6:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "34/7:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "34/8:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times.reshape(batch_size * chunks)\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "34/9:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times.view(batch_size * chunks)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "34/10:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks + 1]\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "34/11:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print(times.shape)\n",
      "34/12:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(x[1])\n",
      "print(y[1])\n",
      "print(times[:5]\n",
      "34/13:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(x[1])\n",
      "print(y[1])\n",
      "print(times[:5])\n",
      "34/14:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(x[1])\n",
      "print(y[2])\n",
      "print(times[:5])\n",
      "34/15:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(x[1])\n",
      "print(y[0])\n",
      "print(times[:5])\n",
      "34/16:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(x[1])\n",
      "print(y[1])\n",
      "print(times[:5])\n",
      "34/17:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "34/18:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "34/19:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "34/20:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "34/21: hidden = None\n",
      "34/22:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "34/23:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(5, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "34/24:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(10, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "34/25:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "34/26:\n",
      "epochs = 500\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "34/27:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "34/28:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(5, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "34/29:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "torch.manual_seed(1)\n",
      "35/2:\n",
      "times = torch.arange(1, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "35/3:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/4:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/5: hidden = None\n",
      "35/6:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "35/7:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/8:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/9:\n",
      "prediction, hidden = model(x, hidden)\n",
      "print(prediction)\n",
      "35/10:\n",
      "times = torch.arange(0, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "35/11:\n",
      "times = torch.arange(0, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/12:\n",
      "times = torch.arange(0, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/13:\n",
      "times = torch.arange(0, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/14:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/15:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/16:\n",
      "prediction = x\n",
      "model.eval()\n",
      "for i in range(100):\n",
      "    prediction, hidden = model(prediction, hidden)\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/17:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/18:\n",
      "prediction, hidden = model(x, hidden)\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/19:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/20:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat(x2, prediction[-1])\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/21:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1]))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/22:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1]), dim=1)\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/23:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1]), dim=0)\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/24:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1]), dim=1)\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/25: prediction\n",
      "35/26: prediction.shape\n",
      "35/27: x2\n",
      "35/28: x2.shape\n",
      "35/29: prediction[-1].shape\n",
      "35/30: prediction[-1].shape.unsqueeze(0)\n",
      "35/31: prediction[-1].unsqueeze(0).shape\n",
      "35/32: prediction[-1].unsqueeze(1).shape\n",
      "35/33:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/34:\n",
      "times = torch.arange(0, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 1\n",
      "chunks = len(x) // 64\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/35:\n",
      "times = torch.arange(0, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 1\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/36: hidden = None\n",
      "35/37:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "35/38:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/39:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/40:\n",
      "times = torch.arange(0, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 1\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/41:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/42:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/43: hidden = None\n",
      "35/44:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "35/45:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/46:\n",
      "times = torch.arange(0, 100, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 128\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/47:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/48:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/49: hidden = None\n",
      "35/50:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "35/51:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/52:\n",
      "times = torch.arange(0, 10, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/53:\n",
      "times = torch.arange(0, 10, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 1\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/54:\n",
      "times = torch.arange(0, 10, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 1\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/55:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/56:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/57: hidden = None\n",
      "35/58:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "35/59:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/60:\n",
      "epochs = 100\n",
      "show_every = 25\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/61:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "35/62:\n",
      "epochs = 100\n",
      "show_every = 25\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/63:\n",
      "epochs = 100\n",
      "show_every = 25\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/64:\n",
      "epochs = 300\n",
      "show_every = 100\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/65:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "35/66:\n",
      "epochs = 300\n",
      "show_every = 100\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/67:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/68:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/69:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/70:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(torch.arange(0, 10.5, 0.1, prediction, color='r')\n",
      "plt.show()\n",
      "35/71:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(torch.arange(0, 10.5, 0.1), prediction, color='r')\n",
      "plt.show()\n",
      "35/72:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(torch.arange(0, 10.1, 0.1), prediction, color='r')\n",
      "plt.show()\n",
      "35/73:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(torch.arange(0, 10.1, 0.1), prediction, color='r')\n",
      "plt.show()\n",
      "\n",
      "prediction.size\n",
      "35/74:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(torch.arange(0, 10.1, 0.1), prediction, color='r')\n",
      "plt.show()\n",
      "\n",
      "print(prediction.size)\n",
      "35/75:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "print(prediction.size)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(torch.arange(0, 10.1, 0.1), prediction, color='r')\n",
      "plt.show()\n",
      "35/76:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "print(prediction.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(torch.arange(0, 10.1, 0.1), prediction, color='r')\n",
      "plt.show()\n",
      "35/77:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "print(times.shape)\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(torch.arange(0, 10.1, 0.1), prediction, color='r')\n",
      "plt.show()\n",
      "35/78:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "35/79:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "print(x2.shape)\n",
      "35/80:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "print(x.shape)\n",
      "35/81:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.plot(times, y.reshape(-1, 1), color='b')\n",
      "plt.plot(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/82:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.resha?pe(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/83:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/84:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(y.reshape(-1, 1), color='b')\n",
      "plt.scatter(prediction, color='r')\n",
      "plt.show()\n",
      "35/85:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/86:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.plot(y.reshape(-1, 1), color='b')\n",
      "plt.plot(prediction, color='r')\n",
      "plt.show()\n",
      "35/87:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/88:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "\n",
      "print(prediction.shape)\n",
      "35/89:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "\n",
      "print(y.shape)\n",
      "35/90:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "\n",
      "print(y.squeeze(0).shape)\n",
      "35/91:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "\n",
      "print(y.squeeze(0).shape)\n",
      "print(prediction.shape)\n",
      "35/92:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.plot(y.squeeze(0), color='b')\n",
      "plt.plot(prediction, color='r')\n",
      "plt.show()\n",
      "\n",
      "print(y.squeeze(0).shape)\n",
      "print(prediction.shape)\n",
      "35/93:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.plot(y.squeeze(0).squeeze(1), color='b')\n",
      "plt.plot(prediction, color='r')\n",
      "plt.show()\n",
      "\n",
      "print(y.squeeze(0).shape)\n",
      "print(prediction.shape)\n",
      "35/94:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "\n",
      "print(y.squeeze(0).shape)\n",
      "print(prediction.shape)\n",
      "35/95:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "prediction.shape\n",
      "35/96:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "x2.shape\n",
      "35/97:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "x.shape\n",
      "35/98:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "plt.plot(x, color='r')\n",
      "plt.show()\n",
      "35/99:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy()\n",
      "plt.plot(x3, color='r')\n",
      "plt.show()\n",
      "35/100:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy()\n",
      "print(x3.shape)\n",
      "plt.plot(x3, color='r')\n",
      "plt.show()\n",
      "35/101:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy()\n",
      "print(x3.reshape(-1))\n",
      "plt.plot(x3, color='r')\n",
      "plt.show()\n",
      "35/102:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "plt.plot(x3, color='r')\n",
      "plt.show()\n",
      "35/103:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/104:\n",
      "x2 = x\n",
      "prediction, hidden = model(x2, hidden)\n",
      "x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "prediction, hidden = model(x2, hidden)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/105:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)))\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/106: prediction[-1].shape\n",
      "35/107: prediction[-1].shape.unsqueeze(0)\n",
      "35/108: prediction[-1].unsqueeze(0)\n",
      "35/109: prediction[-1].unsqueeze(0).shape\n",
      "35/110:\n",
      "prediction[-1].unsqueeze(0).shape\n",
      "x2.shape\n",
      "35/111:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/112:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=1)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/113:\n",
      "epochs = 300\n",
      "show_every = 100\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/114:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/115:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=1)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/116:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=1)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/117:\n",
      "prediction[-1].unsqueeze(0).shape\n",
      "x2.shape\n",
      "35/118: prediction.shape\n",
      "35/119:\n",
      "times = torch.arange(0, 10, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "35/120:\n",
      "times = torch.arange(0, 10, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/121:\n",
      "times = torch.arange(0, 10, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/122:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/123: hidden = None\n",
      "35/124:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "35/125:\n",
      "epochs = 300\n",
      "show_every = 100\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/126:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "35/127:\n",
      "epochs = 300\n",
      "show_every = 100\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/128:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/129:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/130:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/131: hidden = None\n",
      "35/132:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "35/133:\n",
      "epochs = 300\n",
      "show_every = 100\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/134:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 16\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/135:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/136:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/137: hidden = None\n",
      "35/138:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/139:\n",
      "loss_fn = nn.MSELoss()\n",
      "#optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "35/140:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/141:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/142:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/143:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/144: hidden = None\n",
      "35/145:\n",
      "loss_fn = nn.MSELoss()\n",
      "#optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "35/146:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/147:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/148:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=1)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/149: print(x2.shape)\n",
      "35/150: prediction.shape\n",
      "35/151: prediction.shape\n",
      "35/152: x.shape\n",
      "35/153: x2.shape\n",
      "35/154: x2.shape\n",
      "35/155:\n",
      "print(x2.shape)\n",
      "print(prediction.shape)\n",
      "35/156:\n",
      "print(x2.shape)\n",
      "print(prediction[-1].shape)\n",
      "35/157:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/158:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=1)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/159:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=2)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/160:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/161:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "        y = y[:chunks * batch_size]\n",
      "        y = y.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/162:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/163: hidden = None\n",
      "35/164:\n",
      "loss_fn = nn.MSELoss()\n",
      "#optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "35/165:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/166:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/167:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/168: hidden = None\n",
      "35/169:\n",
      "loss_fn = nn.MSELoss()\n",
      "#optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "35/170:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/171:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/172:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/173:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/174:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "chunks\n",
      "35/175:\n",
      "print(x2.shape)\n",
      "print(prediction[-1].shape)\n",
      "35/176:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "print(x.shape)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "chunks\n",
      "35/177:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "chunks\n",
      "35/178:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/179:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape.squeeze(0))\n",
      "35/180:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.squeeze(0).shape)\n",
      "35/181:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.squeeze(1).shape)\n",
      "35/182:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.reshape(-1, 1).shape)\n",
      "35/183:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/184:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "35/185:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "35/186: hidden = None\n",
      "35/187:\n",
      "loss_fn = nn.MSELoss()\n",
      "#optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "35/188:\n",
      "epochs = 1000\n",
      "show_every = 250\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "35/189:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "35/190:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/191:\n",
      "x2 = x\n",
      "for i in range(50):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/192: print(x2.shape)\n",
      "35/193:\n",
      "x2 = x\n",
      "for i in range(50):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x2 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/194:\n",
      "print(x2.shape)\n",
      "prediction.shape\n",
      "35/195:\n",
      "x2 = x\n",
      "for i in range(50):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "prediction = prediction.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(prediction, color='b')\n",
      "plt.show()\n",
      "35/196: x.shape\n",
      "35/197: x3.shape\n",
      "35/198: prediction.shape\n",
      "35/199: x2.shape\n",
      "35/200:\n",
      "x2 = x\n",
      "for i in range(50):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(x2, color='b')\n",
      "plt.show()\n",
      "35/201:\n",
      "x2 = x\n",
      "for i in range(20):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(x2, color='b')\n",
      "plt.show()\n",
      "35/202:\n",
      "x2 = x\n",
      "for i in range(10):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(x2, color='b')\n",
      "plt.show()\n",
      "35/203:\n",
      "x2 = x\n",
      "for i in range(10):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "plt.show()\n",
      "35/204:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "plt.show()\n",
      "35/205:\n",
      "times = torch.arange(0, 25, 0.1)\n",
      "values = torch.sin(times)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/206:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "plt.show()\n",
      "35/207:\n",
      "x2 = x\n",
      "for i in range(0):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "plt.show()\n",
      "35/208:\n",
      "x2 = x\n",
      "for i in range(0):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(x2, color='b')\n",
      "\n",
      "plt.show()\n",
      "35/209: import os\n",
      "35/210:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "35/211:\n",
      "import os \n",
      "import csv\n",
      "35/212:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "35/213:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "print(values)\n",
      "35/214:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "print(values.shape)\n",
      "35/215:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "35/216:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 4\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/1:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/2:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "import csv\n",
      "\n",
      "torch.manual_seed(1)\n",
      "36/3:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/4:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/5:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "36/6:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/7: hidden = None\n",
      "36/8:\n",
      "loss_fn = nn.MSELoss()\n",
      "#optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/9:\n",
      "epochs = 50\n",
      "show_every = 10\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/10:\n",
      "epochs = 500\n",
      "show_every = 250\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/11:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/12:\n",
      "epochs = 500\n",
      "show_every = 250\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/13:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/14:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/15:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/16:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x3, color='r')\n",
      "plt.plot(x2, color='b')\n",
      "\n",
      "plt.show()\n",
      "36/17:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/18:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/19:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/REGN.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/20:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "36/21:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/22: hidden = None\n",
      "36/23:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/24:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/25:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/26:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e2)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/27:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/28:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/29:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/30:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/31:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/REGN.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/32:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/REGN.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "print(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/33:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/REGN.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "print(max(values))\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/34:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/REGN.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "print(values / max(values))\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/35:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/REGN.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "values = values / max(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/36:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "36/37:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/38: hidden = None\n",
      "36/39:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/40:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/41:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/42:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/43:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/44:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/45:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/46:\n",
      "x2 = x\n",
      "for i in range(2):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/47:\n",
      "x2 = x\n",
      "for i in range(10):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/48:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/49:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "values = values / max(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/50:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "36/51:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/52: hidden = None\n",
      "36/53:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/54:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/55:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/56:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/57:\n",
      "loss_fn = nn.MSELoss()\n",
      "#optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/58:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/59:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/BBT.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "values = values / max(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/60:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "36/61:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/62: hidden = None\n",
      "36/63:\n",
      "loss_fn = nn.MSELoss()\n",
      "#optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/64:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/65:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/66:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/67:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/68:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/69:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/70:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/71:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/72:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/73:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/GS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "values = values / max(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 32\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/74:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "36/75:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/76: hidden = None\n",
      "36/77:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/78:\n",
      "epochs = 1000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/79:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/80:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/81:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/82:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/83:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=16, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/84: hidden = None\n",
      "36/85:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/86:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/87:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/88:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/89:\n",
      "x2 = x\n",
      "for i in range(2):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/90:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/91:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/GS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "values = values / max(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 8\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/92:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "36/93:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=16, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/94:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=8, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/95: hidden = None\n",
      "36/96:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/97:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/98:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/99:\n",
      "x2 = x\n",
      "for i in range(5):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/100:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/101:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/MAC.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "values = values / max(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 8\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/102:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "36/103:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=8, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/104: hidden = None\n",
      "36/105:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/106:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/107:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/108:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/109:\n",
      "x2 = x\n",
      "for i in range(3):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/110:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "36/111:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "values = values / max(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 8\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "36/112:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "36/113:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=8, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "36/114: hidden = None\n",
      "36/115:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "36/116:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "36/117:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.squeeze(0), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "36/118:\n",
      "x2 = x\n",
      "for i in range(1):\n",
      "    prediction, hidden = model(x2, hidden)\n",
      "    x2 = torch.cat((x2, prediction[-1].unsqueeze(0)), dim=0)\n",
      "\n",
      "print(x.shape)\n",
      "print(x2.shape)\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "x3 = x.detach().numpy().reshape(-1)\n",
      "x2 = x2.detach().numpy().reshape(-1)\n",
      "\n",
      "plt.plot(x2, color='b')\n",
      "plt.plot(x3, color='r')\n",
      "\n",
      "plt.show()\n",
      "38/1:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "38/2:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=8, num_layers=2, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "38/3:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "import csv\n",
      "\n",
      "torch.manual_seed(1)\n",
      "38/4:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/CMS.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "values = values / max(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 8\n",
      "chunks = len(x) // batch_size\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "times = times[:batch_size * chunks]\n",
      "\n",
      "print(times.shape)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "38/5:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(-1, 1)\n",
      "        x = x[:chunks * batch_size]\n",
      "        x = x.reshape(batch_size, -1, 1)\n",
      "        \n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "38/6:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=8, num_layers=2, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "38/7: hidden = None\n",
      "38/8:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-1)\n",
      "#optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "38/9:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "39/1:\n",
      "import numpy as np\n",
      "\n",
      "# read data from text files\n",
      "with open('data/reviews.txt', 'r') as f:\n",
      "    reviews = f.read()\n",
      "with open('data/labels.txt', 'r') as f:\n",
      "    labels = f.read()\n",
      "39/2:\n",
      "print(reviews[:2000])\n",
      "print()\n",
      "print(labels[:20])\n",
      "39/3:\n",
      "from string import punctuation\n",
      "\n",
      "print(punctuation)\n",
      "\n",
      "# get rid of punctuation\n",
      "reviews = reviews.lower() # lowercase, standardize\n",
      "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
      "39/4:\n",
      "# split by new lines and spaces\n",
      "reviews_split = all_text.split('\\n')\n",
      "all_text = ' '.join(reviews_split)\n",
      "\n",
      "# create a list of words\n",
      "words = all_text.split()\n",
      "39/5: words[:30]\n",
      "39/6:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "vocab_to_int = None\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "reviews_ints = []\n",
      "39/7: w = Counter(words)\n",
      "39/8:\n",
      "w = Counter(words)\n",
      "w\n",
      "39/9:\n",
      "w = Counter(words)\n",
      "w.sort()\n",
      "39/10:\n",
      "w = Counter(words)\n",
      "w.most_common()\n",
      "39/11:\n",
      "w = Counter(words)\n",
      "w.most_common()[:-2]\n",
      "39/12:\n",
      "w = Counter(words)\n",
      "w.most_common()[::-1]\n",
      "39/13:\n",
      "w = Counter(words)\n",
      "w.most_common()\n",
      "39/14:\n",
      "w = Counter(words)\n",
      "w.most_common()[1]\n",
      "39/15:\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "39/16:\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "39/17:\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "w\n",
      "39/18:\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "w1 = [x[0] for x in w]\n",
      "39/19:\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "w1 = [x[0] for x in w]\n",
      "w1\n",
      "39/20:\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "w1 = {x[0]:w.index(x) for x in w}\n",
      "w1\n",
      "39/21:\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "w1 = {x[0]:w.index(x)+1 for x in w}\n",
      "w1\n",
      "39/22:\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "w1 = {x[0]:w.index(x)+1 for x in w}\n",
      "len(w1)\n",
      "39/23:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {x[0]:w.index(x)+1 for x in w}\n",
      "print(w)\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "reviews_ints = []\n",
      "39/24: Counter(words).most_common()\n",
      "39/25:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = [x[0] for x in w]\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "reviews_ints = []\n",
      "39/26: print(vocab_to_int)\n",
      "39/27: w\n",
      "39/28: enumerate(w)\n",
      "39/29: list(enumerate(w))[:5]\n",
      "39/30: {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "39/31:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "reviews_ints = []\n",
      "39/32:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "reviews_ints = [vocab_to_int.get(word) for word in words]\n",
      "39/33:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/34:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "reviews_ints = [vocab_to_int.get(word) for word in reviews_split]\n",
      "39/35:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/36:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "reviews_ints = [vocab_to_int.get(word) for review in reviews_split for word in review]\n",
      "39/37:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/38: reviews_split\n",
      "39/39:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review] for review in reviews_split]\n",
      "39/40:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/41: vocab_to_int.get('at')\n",
      "39/42:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/43:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/44:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/45:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/46:\n",
      "# 1=positive, 0=negative label conversion\n",
      "print(labels)\n",
      "encoded_labels = None\n",
      "39/47:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 for label in labels if label=='positive' else 0]\n",
      "39/48:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels]\n",
      "39/49:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels]\n",
      "encoded_labels\n",
      "39/50:\n",
      "# 1=positive, 0=negative label conversion\n",
      "labels\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels]\n",
      "encoded_labels\n",
      "39/51:\n",
      "# 1=positive, 0=negative label conversion\n",
      "print(labels)\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels]\n",
      "encoded_labels\n",
      "39/52:\n",
      "# 1=positive, 0=negative label conversion\n",
      "print(type(labels))\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels]\n",
      "encoded_labels\n",
      "39/53:\n",
      "# 1=positive, 0=negative label conversion\n",
      "print(labels[:2])\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels]\n",
      "encoded_labels\n",
      "39/54:\n",
      "# 1=positive, 0=negative label conversion\n",
      "\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "encoded_labels\n",
      "39/55:\n",
      "# outlier review stats\n",
      "review_lens = Counter([len(x) for x in reviews_ints])\n",
      "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
      "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
      "39/56:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "print(whichOne)\n",
      "reviews_ints = ''\n",
      "encoded_labels =''\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/57:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "reviews_ints = reviews_ints.pop(whichOne[0])\n",
      "encoded_labels = labels.pop(whichOne[0])\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/58:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "reviews_ints = reviews_ints.pop(whichOne[0])\n",
      "encoded_labels = encoded_labels.pop(whichOne[0])\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/59:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/60:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/61:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/62:\n",
      "from string import punctuation\n",
      "\n",
      "print(punctuation)\n",
      "\n",
      "# get rid of punctuation\n",
      "reviews = reviews.lower() # lowercase, standardize\n",
      "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
      "39/63:\n",
      "# split by new lines and spaces\n",
      "reviews_split = all_text.split('\\n')\n",
      "all_text = ' '.join(reviews_split)\n",
      "\n",
      "# create a list of words\n",
      "words = all_text.split()\n",
      "39/64: words[:30]\n",
      "39/65:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/66:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/67:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/68:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "encoded_labels\n",
      "39/69:\n",
      "# outlier review stats\n",
      "review_lens = Counter([len(x) for x in reviews_ints])\n",
      "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
      "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
      "39/70:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "reviews_ints = reviews_ints.pop(whichOne[0])\n",
      "encoded_labels = encoded_labels.pop(whichOne[0])\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/71:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/72:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/73:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "encoded_labels\n",
      "39/74:\n",
      "# outlier review stats\n",
      "review_lens = Counter([len(x) for x in reviews_ints])\n",
      "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
      "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
      "39/75:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "reviews_ints.pop(whichOne[0])\n",
      "encoded_labels.pop(whichOne[0])\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/76:\n",
      "def pad_features(reviews_ints, seq_length):\n",
      "    ''' Return features of review_ints, where each review is padded with 0's \n",
      "        or truncated to the input seq_length.\n",
      "    '''\n",
      "    ## implement function\n",
      "    for review in reviews_ints:\n",
      "        if len(review) > 200:\n",
      "            review = review[:200]\n",
      "        while len(review) < 200:\n",
      "            review.insert(0, [0])\n",
      "    features=reviews_ints\n",
      "    \n",
      "    return features\n",
      "39/77:\n",
      "# Test your implementation!\n",
      "\n",
      "seq_length = 200\n",
      "\n",
      "features = pad_features(reviews_ints, seq_length=seq_length)\n",
      "\n",
      "## test statements - do not change - ##\n",
      "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
      "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
      "\n",
      "# print first 10 values of the first 30 batches \n",
      "print(features[:30,:10])\n",
      "39/78:\n",
      "for review in reviews_ints:\n",
      "    if len(review) > 200:\n",
      "        review = review[:200]\n",
      "    while len(review) < 200:\n",
      "        review.insert(0, [0])\n",
      "39/79:\n",
      "for review in reviews_ints:\n",
      "    if len(review) > 200:\n",
      "        review = review[:200]\n",
      "    while len(review) < 200:\n",
      "        review.insert(0, [0])\n",
      "reviews_ints[:5]\n",
      "39/80:\n",
      "for review in reviews_ints:\n",
      "    if len(review) > 200:\n",
      "        review = review[:200]\n",
      "    while len(review) < 200:\n",
      "        review.insert(0, [0])\n",
      "reviews_ints[1]\n",
      "39/81:\n",
      "for review in reviews_ints:\n",
      "    if len(review) > 200:\n",
      "        review = review[:200]\n",
      "    while len(review) < 200:\n",
      "        review.insert(0, [0])\n",
      "len(reviews_ints[1])\n",
      "39/82:\n",
      "for i in reviews_ints:\n",
      "    if len(i) != 200:\n",
      "        print(i)\n",
      "39/83: print(reviews_ints.shape)\n",
      "39/84: print(reviews_ints.size)\n",
      "39/85: print(len(reviews_ints))\n",
      "39/86: print(reviews_ints[0])\n",
      "39/87:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/88:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/89:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "encoded_labels\n",
      "39/90:\n",
      "# outlier review stats\n",
      "review_lens = Counter([len(x) for x in reviews_ints])\n",
      "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
      "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
      "39/91:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "reviews_ints.pop(whichOne[0])\n",
      "encoded_labels.pop(whichOne[0])\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/92:\n",
      "def pad_features(reviews_ints, seq_length):\n",
      "    ''' Return features of review_ints, where each review is padded with 0's \n",
      "        or truncated to the input seq_length.\n",
      "    '''\n",
      "    ## implement function\n",
      "    for review in reviews_ints:\n",
      "        if len(review) > 200:\n",
      "            review = review[:200]\n",
      "        while len(review) < 200:\n",
      "            review.insert(0, 0)\n",
      "    features=reviews_ints\n",
      "    \n",
      "    return features\n",
      "39/93: print(reviews_ints[0])\n",
      "39/94: print(reviews_ints[1])\n",
      "39/95: print(reviews_ints[3])\n",
      "39/96:\n",
      "for review in reviews_ints:\n",
      "        if len(review) > 200:\n",
      "            review = review[:200]\n",
      "        while len(review) < 200:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "print(reviews_ints)\n",
      "39/97:\n",
      "for review in reviews_ints:\n",
      "        if len(review) > 200:\n",
      "            review = review[:200]\n",
      "        while len(review) < 200:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "print(reviews_ints[0])\n",
      "39/98:\n",
      "for review in reviews_ints:\n",
      "        if len(review) > 200:\n",
      "            review = review[:200]\n",
      "        while len(review) < 200:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "print(len(reviews_ints[0]))\n",
      "39/99:\n",
      "# Test your implementation!\n",
      "\n",
      "seq_length = 200\n",
      "\n",
      "features = pad_features(reviews_ints, seq_length=seq_length)\n",
      "\n",
      "## test statements - do not change - ##\n",
      "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
      "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
      "\n",
      "# print first 10 values of the first 30 batches \n",
      "print(features[:30,:10])\n",
      "39/100:\n",
      "def pad_features(reviews_ints, seq_length):\n",
      "    ''' Return features of review_ints, where each review is padded with 0's \n",
      "        or truncated to the input seq_length.\n",
      "    '''\n",
      "    ## implement function\n",
      "    for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "    features=reviews_ints\n",
      "    \n",
      "    return features\n",
      "39/101:\n",
      "# Test your implementation!\n",
      "\n",
      "seq_length = 200\n",
      "\n",
      "features = pad_features(reviews_ints, seq_length=seq_length)\n",
      "\n",
      "## test statements - do not change - ##\n",
      "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
      "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
      "\n",
      "# print first 10 values of the first 30 batches \n",
      "print(features[:30,:10])\n",
      "39/102:\n",
      "def pad_features(reviews_ints, seq_length):\n",
      "    ''' Return features of review_ints, where each review is padded with 0's \n",
      "        or truncated to the input seq_length.\n",
      "    '''\n",
      "    ## implement function\n",
      "    for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "    features=reviews_ints.reshape(-1, seq_length)\n",
      "    \n",
      "    return features\n",
      "39/103:\n",
      "# Test your implementation!\n",
      "\n",
      "seq_length = 200\n",
      "\n",
      "features = pad_features(reviews_ints, seq_length=seq_length)\n",
      "\n",
      "## test statements - do not change - ##\n",
      "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
      "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
      "\n",
      "# print first 10 values of the first 30 batches \n",
      "print(features[:30,:10])\n",
      "39/104:\n",
      "def pad_features(reviews_ints, seq_length):\n",
      "    ''' Return features of review_ints, where each review is padded with 0's \n",
      "        or truncated to the input seq_length.\n",
      "    '''\n",
      "    ## implement function\n",
      "    for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "    features=np.reshape(reviews_ints, (-1, seq_length))\n",
      "    \n",
      "    return features\n",
      "39/105:\n",
      "# Test your implementation!\n",
      "\n",
      "seq_length = 200\n",
      "\n",
      "features = pad_features(reviews_ints, seq_length=seq_length)\n",
      "\n",
      "## test statements - do not change - ##\n",
      "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
      "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
      "\n",
      "# print first 10 values of the first 30 batches \n",
      "print(features[:30,:10])\n",
      "39/106: reviews_ints\n",
      "39/107: len(reviews_ints)\n",
      "39/108: reviews_ints = np.array(reviews_ints)\n",
      "39/109:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "reviews_ints\n",
      "39/110:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "reviews_ints.shape\n",
      "39/111:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "reviews_ints.unsqueeze(0)\n",
      "39/112:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "reviews_ints..expand_dims(0)\n",
      "39/113:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "reviews_ints.expand_dims(0)\n",
      "39/114:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "np.expand_dims(reviews_ints, 0)\n",
      "39/115:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "np.expand_dims(reviews_ints, 0).shape'\n",
      "39/116:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "np.expand_dims(reviews_ints, 0).shape\n",
      "39/117:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "np.expand_dims(reviews_ints, 1).shape\n",
      "39/118:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "np.expand_dims(reviews_ints, 1).shape\n",
      "39/119:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "np.expand_dims(reviews_ints, 1)[0]\n",
      "39/120:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "np.expand_dims(reviews_ints, 1)[0].shape\n",
      "39/121:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "np.expand_dims(reviews_ints, 1).shape\n",
      "39/122:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "reviews_ints[0].shape\n",
      "39/123:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "reviews_ints[0].shape\n",
      "39/124:\n",
      "reviews_ints = np.array(reviews_ints)\n",
      "reviews_ints[0]\n",
      "39/125:\n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "reviews_ints[0]\n",
      "39/126:\n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "reviews_ints[0].shape\n",
      "39/127:\n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "reviews_ints.shape\n",
      "39/128:\n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "reviews_ints.reshape(-1, 200).shape/\n",
      "39/129:\n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "reviews_ints.reshape(-1, 200).shape\n",
      "39/130:\n",
      "def pad_features(reviews_ints, seq_length):\n",
      "    ''' Return features of review_ints, where each review is padded with 0's \n",
      "        or truncated to the input seq_length.\n",
      "    '''\n",
      "    ## implement function\n",
      "    for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "    reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "    features = reviews_ints.reshape(-1, seq_length)\n",
      "    \n",
      "    return features\n",
      "39/131:\n",
      "# Test your implementation!\n",
      "\n",
      "seq_length = 200\n",
      "\n",
      "features = pad_features(reviews_ints, seq_length=seq_length)\n",
      "\n",
      "## test statements - do not change - ##\n",
      "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
      "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
      "\n",
      "# print first 10 values of the first 30 batches \n",
      "print(features[:30,:10])\n",
      "39/132:\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "    reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "    features = reviews_ints.reshape(-1, seq_length)\n",
      "39/133:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "39/134:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "features\n",
      "39/135:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "features.shape\n",
      "39/136:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "features.shape\n",
      "len(reviews_ints)\n",
      "39/137:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "features.shape\n",
      "reviews_ints[0]\n",
      "39/138:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "features.shape\n",
      "features\n",
      "39/139:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "features.shape\n",
      "features[0]\n",
      "39/140:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "features.shape\n",
      "39/141:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "reviews_ints\n",
      "39/142:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "reviews_ints/shape\n",
      "39/143:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "reviews_ints.shape\n",
      "39/144:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "reviews_ints[0]\n",
      "39/145:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "reviews_ints[0].shape\n",
      "39/146:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints])\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "reviews_ints.flatten().shape\n",
      "39/147:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints]).flatten()\n",
      "features = reviews_ints.reshape(-1, seq_length)\n",
      "\n",
      "reviews_ints.shape\n",
      "39/148:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints]).flatten()\n",
      "\n",
      "reviews_ints.shape\n",
      "39/149:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints]).flatten()\n",
      "\n",
      "reviews_ints[0]\n",
      "39/150:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = np.array([np.array(review) for review in reviews_ints]).flatten()\n",
      "\n",
      "reviews_ints[:2]\n",
      "39/151:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = [np.array(review) for review in reviews_ints]\n",
      "\n",
      "reviews_ints\n",
      "39/152:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = [np.array(review) for review in reviews_ints]\n",
      "\n",
      "np.array(reviews_ints).flatten()\n",
      "39/153:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = [np.array(review) for review in reviews_ints]\n",
      "\n",
      "np.array(reviews_ints).flatten().shape\n",
      "39/154:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "            \n",
      "reviews_ints = [np.array(review) for review in reviews_ints]\n",
      "\n",
      "reviews_ints[0]\n",
      "39/155:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "type(reviews_ints)\n",
      "39/156:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "type(reviews_ints[0])\n",
      "39/157:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "\n",
      "np.array(reviews_ints).shape\n",
      "39/158:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "\n",
      "np.array(reviews_ints).flatten()\n",
      "39/159:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "\n",
      "np.ravel(reviews_ints)?\n",
      "39/160:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "\n",
      "np.ravel(reviews_ints)\n",
      "39/161:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "\n",
      "np.ravel(reviews_ints).shape\n",
      "39/162:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "reviews_ints = [np.array(review) for review in reviews_ints]\n",
      "39/163:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "reviews_ints = [np.array(review) for review in reviews_ints]\n",
      "np.ravel(reviews_ints)\n",
      "39/164:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "39/165:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "reviews_ints\n",
      "39/166:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "np.ravel(reviews_ints)\n",
      "39/167:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "np.ravel(reviews_ints).flatten()\n",
      "39/168:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "np.reshape(reviews_ints, (-1, 200))\n",
      "39/169:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "np.reshape(reviews_ints, (-1, 200)).shape\n",
      "39/170:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "np.reshape(reviews_ints, (25000, 200)).shape\n",
      "39/171:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "np.concatenate( LIST, axis=0 )\n",
      "39/172:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "np.concatenate( reviews_ints, axis=0 )\n",
      "39/173:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "np.concatenate( reviews_ints, axis=0 ).shape\n",
      "39/174:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "np.concatenate( reviews_ints, axis=1 ).shape\n",
      "39/175:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "out = np.concatenate(input_list).ravel()\n",
      "out\n",
      "39/176:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "out = np.concatenate(reviews_ints).ravel()\n",
      "out\n",
      "39/177:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    review = np.array(review)\n",
      "out = np.concatenate(reviews_ints).ravel()\n",
      "out.shape\n",
      "39/178:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    if len(review != 200):\n",
      "        print(review)\n",
      "39/179:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    if len(review != 200):\n",
      "        print(len(review))\n",
      "39/180:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    if len(review) != 200:\n",
      "        print(len(review))\n",
      "39/181:\n",
      "seq_length = 200\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    if len(review) != 200:\n",
      "        print(len(review))\n",
      "39/182:\n",
      "seq_length = 200\n",
      "features = []\n",
      "\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    features.append(review)\n",
      "    \n",
      "print(features)\n",
      "39/183:\n",
      "seq_length = 200\n",
      "features = []\n",
      "\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    features.append(review)\n",
      "    \n",
      "features = np.array(features)\n",
      "print(features.shape)\n",
      "39/184:\n",
      "seq_length = 200\n",
      "features = []\n",
      "\n",
      "for review in reviews_ints:\n",
      "    if len(review) > seq_length:\n",
      "        review = review[:seq_length]\n",
      "    while len(review) < seq_length:\n",
      "        review.insert(0, 0)\n",
      "    features.append(review)\n",
      "    \n",
      "features = np.array(features)\n",
      "print(features.shape)\n",
      "39/185:\n",
      "def pad_features(reviews_ints, seq_length):\n",
      "    ''' Return features of review_ints, where each review is padded with 0's \n",
      "        or truncated to the input seq_length.\n",
      "    '''\n",
      "    ## implement function\n",
      "    features = []\n",
      "    \n",
      "    for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "        features.append(review)\n",
      "    \n",
      "    features = np.array(features)\n",
      "    \n",
      "    return features\n",
      "39/186:\n",
      "# Test your implementation!\n",
      "\n",
      "seq_length = 200\n",
      "\n",
      "features = pad_features(reviews_ints, seq_length=seq_length)\n",
      "\n",
      "## test statements - do not change - ##\n",
      "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
      "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
      "\n",
      "# print first 10 values of the first 30 batches \n",
      "print(features[:30,:10])\n",
      "39/187:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "\n",
      "len(features)\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "39/188:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "\n",
      "len(features) * split_frac\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "39/189:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = len(features) * split_frac\n",
      "split_2 = split_1 + len(features) * (1 - split_frac) / 2\n",
      "print(split_2)\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "39/190:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = len(features) * split_frac\n",
      "split_2 = split_1 + len(features) * (1 - split_frac) / 2\n",
      "\n",
      "train_x = x[:split_1]\n",
      "val_x = x[:split_2]\n",
      "test_x = x[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "39/191:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = len(features) * split_frac\n",
      "split_2 = split_1 + len(features) * (1 - split_frac) / 2\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "39/192:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = len(features) * split_frac\n",
      "split_2 = split_1 + len(features) * (1 - split_frac) / 2\n",
      "\n",
      "print(split_1)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "39/193:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "39/194:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "39/195:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "train_y = labels[:split_1]\n",
      "val_y = labels[split_1:split_2]\n",
      "test_y = labels[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "\n",
      "print(train_y.shape)\n",
      "print(val_y.shape)\n",
      "print(test_y.shape)\n",
      "39/196:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "train_y = encoded_labels[:split_1]\n",
      "val_y = encoded_labels[split_1:split_2]\n",
      "test_y = encoded_labels[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "\n",
      "print(train_y.shape)\n",
      "print(val_y.shape)\n",
      "print(test_y.shape)\n",
      "39/197:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "encoded_labels = np.array(encoded_labels)\n",
      "39/198:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "encoded_labels = np.array(encoded_labels)\n",
      "39/199:\n",
      "# outlier review stats\n",
      "review_lens = Counter([len(x) for x in reviews_ints])\n",
      "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
      "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
      "39/200:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "reviews_ints.pop(whichOne[0])\n",
      "encoded_labels.pop(whichOne[0])\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/201:\n",
      "import numpy as np\n",
      "\n",
      "# read data from text files\n",
      "with open('data/reviews.txt', 'r') as f:\n",
      "    reviews = f.read()\n",
      "with open('data/labels.txt', 'r') as f:\n",
      "    labels = f.read()\n",
      "39/202:\n",
      "print(reviews[:2000])\n",
      "print()\n",
      "print(labels[:20])\n",
      "39/203:\n",
      "from string import punctuation\n",
      "\n",
      "print(punctuation)\n",
      "\n",
      "# get rid of punctuation\n",
      "reviews = reviews.lower() # lowercase, standardize\n",
      "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
      "39/204:\n",
      "# split by new lines and spaces\n",
      "reviews_split = all_text.split('\\n')\n",
      "all_text = ' '.join(reviews_split)\n",
      "\n",
      "# create a list of words\n",
      "words = all_text.split()\n",
      "39/205: words[:30]\n",
      "39/206:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/207:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/208:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "encoded_labels = np.array(encoded_labels)\n",
      "39/209:\n",
      "# outlier review stats\n",
      "review_lens = Counter([len(x) for x in reviews_ints])\n",
      "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
      "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
      "39/210:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "reviews_ints.pop(whichOne[0])\n",
      "encoded_labels.pop(whichOne[0])\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/211:\n",
      "def pad_features(reviews_ints, seq_length):\n",
      "    ''' Return features of review_ints, where each review is padded with 0's \n",
      "        or truncated to the input seq_length.\n",
      "    '''\n",
      "    ## implement function\n",
      "    features = []\n",
      "    \n",
      "    for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "        features.append(review)\n",
      "    \n",
      "    features = np.array(features)\n",
      "    \n",
      "    return features\n",
      "39/212:\n",
      "# Test your implementation!\n",
      "\n",
      "seq_length = 200\n",
      "\n",
      "features = pad_features(reviews_ints, seq_length=seq_length)\n",
      "\n",
      "## test statements - do not change - ##\n",
      "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
      "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
      "\n",
      "# print first 10 values of the first 30 batches \n",
      "print(features[:30,:10])\n",
      "39/213:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "train_y = encoded_labels[:split_1]\n",
      "val_y = encoded_labels[split_1:split_2]\n",
      "test_y = encoded_labels[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "\n",
      "print(train_y.shape)\n",
      "print(val_y.shape)\n",
      "print(test_y.shape)\n",
      "39/214:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "train_y = encoded_labels[:split_1]\n",
      "val_y = encoded_labels[split_1:split_2]\n",
      "test_y = encoded_labels[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "\n",
      "print(train_y.shape)\n",
      "print(val_y.shape)\n",
      "print(test_y.shape)\n",
      "\n",
      "print(val_y[:-1])\n",
      "print(test_y[0])\n",
      "39/215:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "train_y = encoded_labels[:split_1]\n",
      "val_y = encoded_labels[split_1:split_2]\n",
      "test_y = encoded_labels[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "\n",
      "print(train_y.shape)\n",
      "print(val_y.shape)\n",
      "print(test_y.shape)\n",
      "\n",
      "print(encoded_labels)\n",
      "39/216:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "train_y = encoded_labels[:split_1]\n",
      "val_y = encoded_labels[split_1:split_2]\n",
      "test_y = encoded_labels[split_2:]\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "\n",
      "print(train_y.shape)\n",
      "print(val_y.shape)\n",
      "print(test_y.shape)\n",
      "\n",
      "print(encoded_labels.shape)\n",
      "39/217:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "39/218:\n",
      "# outlier review stats\n",
      "review_lens = Counter([len(x) for x in reviews_ints])\n",
      "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
      "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
      "39/219:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "reviews_ints.pop(whichOne[0])\n",
      "encoded_labels.pop(whichOne[0])\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/220:\n",
      "import numpy as np\n",
      "\n",
      "# read data from text files\n",
      "with open('data/reviews.txt', 'r') as f:\n",
      "    reviews = f.read()\n",
      "with open('data/labels.txt', 'r') as f:\n",
      "    labels = f.read()\n",
      "39/221:\n",
      "print(reviews[:2000])\n",
      "print()\n",
      "print(labels[:20])\n",
      "39/222:\n",
      "from string import punctuation\n",
      "\n",
      "print(punctuation)\n",
      "\n",
      "# get rid of punctuation\n",
      "reviews = reviews.lower() # lowercase, standardize\n",
      "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
      "39/223:\n",
      "# split by new lines and spaces\n",
      "reviews_split = all_text.split('\\n')\n",
      "all_text = ' '.join(reviews_split)\n",
      "\n",
      "# create a list of words\n",
      "words = all_text.split()\n",
      "39/224: words[:30]\n",
      "39/225:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/226:\n",
      "# split by new lines and spaces\n",
      "reviews_split = all_text.split('\\n')\n",
      "all_text = ' '.join(reviews_split)\n",
      "\n",
      "# create a list of words\n",
      "words = all_text.split()\n",
      "39/227: words[:30]\n",
      "39/228:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/229:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/230:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "39/231:\n",
      "# outlier review stats\n",
      "review_lens = Counter([len(x) for x in reviews_ints])\n",
      "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
      "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
      "39/232:\n",
      "from string import punctuation\n",
      "\n",
      "print(punctuation)\n",
      "\n",
      "# get rid of punctuation\n",
      "reviews = reviews.lower() # lowercase, standardize\n",
      "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
      "39/233:\n",
      "# split by new lines and spaces\n",
      "reviews_split = all_text.split('\\n')\n",
      "all_text = ' '.join(reviews_split)\n",
      "\n",
      "# create a list of words\n",
      "words = all_text.split()\n",
      "39/234: words[:30]\n",
      "39/235:\n",
      "# feel free to use this import \n",
      "from collections import Counter\n",
      "\n",
      "## Build a dictionary that maps words to integers\n",
      "w = Counter(words)\n",
      "w = w.most_common()\n",
      "vocab_to_int = {j[0]:i+1 for (i, j) in enumerate(w)}\n",
      "\n",
      "## use the dict to tokenize each review in reviews_split\n",
      "## store the tokenized reviews in reviews_ints\n",
      "    \n",
      "reviews_ints = [[vocab_to_int.get(word) for word in review.split()] for review in reviews_split]\n",
      "39/236:\n",
      "# stats about vocabulary\n",
      "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
      "print()\n",
      "\n",
      "# print tokens in first review\n",
      "print('Tokenized review: \\n', reviews_ints[:1])\n",
      "39/237:\n",
      "# 1=positive, 0=negative label conversion\n",
      "encoded_labels = [1 if label=='positive' else 0 for label in labels.split('\\n')]\n",
      "encoded_labels\n",
      "39/238:\n",
      "# outlier review stats\n",
      "review_lens = Counter([len(x) for x in reviews_ints])\n",
      "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
      "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
      "39/239:\n",
      "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
      "\n",
      "## remove any reviews/labels with zero length from the reviews_ints list.\n",
      "\n",
      "whichOne = [reviews_ints.index(review) for review in reviews_ints if len(review)==0]\n",
      "reviews_ints.pop(whichOne[0])\n",
      "encoded_labels.pop(whichOne[0])\n",
      "\n",
      "print('Number of reviews after removing outliers: ', len(reviews_ints))\n",
      "39/240:\n",
      "def pad_features(reviews_ints, seq_length):\n",
      "    ''' Return features of review_ints, where each review is padded with 0's \n",
      "        or truncated to the input seq_length.\n",
      "    '''\n",
      "    ## implement function\n",
      "    features = []\n",
      "    \n",
      "    for review in reviews_ints:\n",
      "        if len(review) > seq_length:\n",
      "            review = review[:seq_length]\n",
      "        while len(review) < seq_length:\n",
      "            review.insert(0, 0)\n",
      "        features.append(review)\n",
      "    \n",
      "    features = np.array(features)\n",
      "    \n",
      "    return features\n",
      "39/241:\n",
      "# Test your implementation!\n",
      "\n",
      "seq_length = 200\n",
      "\n",
      "features = pad_features(reviews_ints, seq_length=seq_length)\n",
      "\n",
      "## test statements - do not change - ##\n",
      "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
      "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
      "\n",
      "# print first 10 values of the first 30 batches \n",
      "print(features[:30,:10])\n",
      "39/242:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "encoded_labels = np.array(encoded_labels)\n",
      "\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "\n",
      "print(train_y.shape)\n",
      "print(val_y.shape)\n",
      "print(test_y.shape)\n",
      "\n",
      "print(encoded_labels.shape)\n",
      "39/243:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "encoded_labels = np.array(encoded_labels)\n",
      "\n",
      "train_y = encoded_labels[:split_1]\n",
      "val_y = encoded_labels[split_1:split_2]\n",
      "test_y = encoded_labels[split_2:]\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "\n",
      "print(train_y.shape)\n",
      "print(val_y.shape)\n",
      "print(test_y.shape)\n",
      "\n",
      "print(encoded_labels.shape)\n",
      "39/244:\n",
      "split_frac = 0.8\n",
      "\n",
      "## split data into training, validation, and test data (features and labels, x and y)\n",
      "split_1 = int(len(features) * split_frac)\n",
      "split_2 = int(split_1 + len(features) * (1 - split_frac) / 2)\n",
      "\n",
      "train_x = features[:split_1]\n",
      "val_x = features[split_1:split_2]\n",
      "test_x = features[split_2:]\n",
      "\n",
      "encoded_labels = np.array(encoded_labels)\n",
      "\n",
      "train_y = encoded_labels[:split_1]\n",
      "val_y = encoded_labels[split_1:split_2]\n",
      "test_y = encoded_labels[split_2:]\n",
      "## print out the shapes of your resultant feature data\n",
      "\n",
      "print(train_x.shape)\n",
      "print(val_x.shape)\n",
      "print(test_x.shape)\n",
      "\n",
      "print(train_y.shape)\n",
      "print(val_y.shape)\n",
      "print(test_y.shape)\n",
      "39/245:\n",
      "import torch\n",
      "from torch.utils.data import TensorDataset, DataLoader\n",
      "\n",
      "# create Tensor datasets\n",
      "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
      "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
      "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
      "\n",
      "# dataloaders\n",
      "batch_size = 50\n",
      "\n",
      "# make sure to SHUFFLE your data\n",
      "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
      "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
      "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
      "39/246:\n",
      "# obtain one batch of training data\n",
      "dataiter = iter(train_loader)\n",
      "sample_x, sample_y = dataiter.next()\n",
      "\n",
      "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
      "print('Sample input: \\n', sample_x)\n",
      "print()\n",
      "print('Sample label size: ', sample_y.size()) # batch_size\n",
      "print('Sample label: \\n', sample_y)\n",
      "39/247:\n",
      "# First checking if GPU is available\n",
      "train_on_gpu=torch.cuda.is_available()\n",
      "\n",
      "if(train_on_gpu):\n",
      "    print('Training on GPU.')\n",
      "else:\n",
      "    print('No GPU available, training on CPU.')\n",
      "41/1:\n",
      "import csv\n",
      "import numpy as np\n",
      "41/2: !head -n2 train.csv\n",
      "41/3:\n",
      "dat = []\n",
      "with open('train.csv') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for line in reader:\n",
      "        dat.append(line)\n",
      "42/1:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "42/2: !head -n2 train.csv\n",
      "42/3:\n",
      "dat = []\n",
      "with open('trainaa') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for line in reader:\n",
      "        dat.append(line)\n",
      "42/4: dat[:2]\n",
      "42/5:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.decomposition import PCA\n",
      "42/6:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.decomposition import PCA\n",
      "42/7: !head -n2 train.csv\n",
      "42/8:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.decomposition import PCA\n",
      "42/9:\n",
      "dat = np.array(dat)\n",
      "dat.size\n",
      "42/10:\n",
      "dat = np.array(dat)\n",
      "dat.shape\n",
      "42/11:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "print(labels[:2])\n",
      "print(features[:2])\n",
      "42/12:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "labels = float(labels)\n",
      "print(labels[:2])\n",
      "print(features[:2])\n",
      "42/13:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "labels = [float(x) for x in labels]\n",
      "print(labels[:2])\n",
      "print(features[:2])\n",
      "42/14:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "labels = [float(x) for x in labels]\n",
      "print(type(labels))\n",
      "print(features[:2])\n",
      "42/15:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "labels = np.array([float(x) for x in labels])\n",
      "features = np.array([[float(x) for x in row] for row in features])\n",
      "print(labels[:2])\n",
      "print(features[:2])\n",
      "42/16:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "labels = np.array([float(x) for x in labels])\n",
      "\n",
      "print(features[:2])\n",
      "42/17:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "labels = np.array([float(x) for x in labels])\n",
      "\n",
      "print(features[:2])\n",
      "42/18:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "labels = np.array([float(a) for a in labels])\n",
      "features = np.array([[float(b) for b in row] for row in features])\n",
      "print(features[:2])\n",
      "42/19:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "\n",
      "labels = np.array([float(a) for a in labels])\n",
      "for row in features:\n",
      "    for item in row:\n",
      "        try:\n",
      "            item = float(item)\n",
      "        except:\n",
      "            print(item)\n",
      "42/20:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "\n",
      "labels = np.array([float(a) for a in labels])\n",
      "features[:2]\n",
      "42/21:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "\n",
      "labels = np.array([float(a) for a in labels])\n",
      "print(features[:2])\n",
      "42/22:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "\n",
      "labels = np.array([float(a) for a in labels])\n",
      "print(features[462:470])\n",
      "42/23:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "\n",
      "labels = np.array([float(a) for a in labels])\n",
      "for row in features:\n",
      "    if ' ' in row:\n",
      "        print(row)\n",
      "42/24:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "\n",
      "labels = np.array([float(a) for a in labels])\n",
      "for row in features:\n",
      "    if '' in row:\n",
      "        print(row)\n",
      "42/25:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "\n",
      "bads = []\n",
      "for row in features:\n",
      "    if '' in row:\n",
      "        bads.append(features.index(row))\n",
      "print(bads)\n",
      "42/26:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,3:]\n",
      "\n",
      "bads = []\n",
      "for row in features:\n",
      "    if '' in row:\n",
      "        bads.append(list(features).index(row))\n",
      "print(bads)\n",
      "42/27: dat\n",
      "42/28: list(dat)\n",
      "42/29: dat\n",
      "42/30: dat[0]\n",
      "42/31: dat[0][0]\n",
      "42/32: dat\n",
      "42/33: dat.shape\n",
      "42/34:\n",
      "for row in dat:\n",
      "    if '' in row:\n",
      "        dat.remove(row)\n",
      "dat.shape\n",
      "42/35:\n",
      "for row in dat:\n",
      "    if '' in row:\n",
      "        dat.delete(row)\n",
      "dat.shape\n",
      "42/36:\n",
      "for row in dat:\n",
      "    if '' in row:\n",
      "        np.delete(dat, row)\n",
      "dat.shape\n",
      "42/37: dat[np.all(dat != '', axis=1)]\n",
      "42/38: dat[np.all(dat != '', axis=1)].shape\n",
      "42/39:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.decomposition import PCA\n",
      "import time\n",
      "42/40:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[1]\n",
      "42/41:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[1]\n",
      "42/42:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[1][0]\n",
      "42/43:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[0,:]\n",
      "42/44:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0]\n",
      "42/45:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "for i in features[:,0]:\n",
      "    i = i[:-4]\n",
      "features[0]\n",
      "42/46:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "for i in features[:,0]:\n",
      "    print(i)\n",
      "42/47:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "for i in features[:5,0]:\n",
      "    print(i[:-4])\n",
      "42/48:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "for i in features[:5,0]:\n",
      "    i = i[:-4]\n",
      "features[:5]\n",
      "42/49:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "[a.replace(' UTC', '') for a in features[:,0]]\n",
      "42/50:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0] = [a.replace(' UTC', '') for a in features[:,0]]\n",
      "features[:5]\n",
      "42/51:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0] = [a.replace(' UTC', '') for a in features[:,0]]\n",
      "features[:5,0]\n",
      "42/52:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0] = [a.replace(' UTC', '') for a in features[:,0]]\n",
      "[time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in features[:5,0]]\n",
      "42/53:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0] = [a.replace(' UTC', '') for a in features[:,0]]\n",
      "features[:,0] = [time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in features[:,0]]\n",
      "42/54:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0] = [a.replace(' UTC', '') for a in features[:,0]]\n",
      "features[:,0] = [time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in features[:,0]]\n",
      "features[:5]\n",
      "42/55:\n",
      "dat = []\n",
      "with open('trainaa') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for line in reader:\n",
      "        dat.append(line)\n",
      "42/56:\n",
      "dat = np.array(dat)\n",
      "dat.shape\n",
      "dat = dat[np.all(dat != '', axis=1)]\n",
      "42/57:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0] = [a.replace(' UTC', '') for a in features[:,0]]\n",
      "features[:,0] = [time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in features[:,0]]\n",
      "features[:5]\n",
      "42/58:\n",
      "labels = [float(a) for a in labels]\n",
      "features = [\n",
      "    [float(b) for b in row] for row in features]\n",
      "42/59:\n",
      "fs_model = ExtraTreesClassifier(n_ensembles=100)\n",
      "fs_model.fit(features, labels)\n",
      "print(fs_model.feature_importances_)\n",
      "42/60:\n",
      "fs_model = ExtraTreesClassifier(n_estimators=100)\n",
      "fs_model.fit(features, labels)\n",
      "print(fs_model.feature_importances_)\n",
      "42/61:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.ensemble import ExtraTreesRegressor\n",
      "from sklearn.decomposition import PCA\n",
      "import time\n",
      "42/62:\n",
      "fs_model = ExtraTreesRegressor(n_estimators=100)\n",
      "fs_model.fit(features, labels)\n",
      "print(fs_model.feature_importances_)\n",
      "42/63:\n",
      "pca = PCA()\n",
      "pca.fit(features)\n",
      "print(pca.explained_variance_ratio)\n",
      "42/64:\n",
      "pca = PCA()\n",
      "pca.fit(features)\n",
      "print(pca.explained_variance_ratio_)\n",
      "42/65:\n",
      "pca = PCA(n_components=2)\n",
      "pca.fit(features)\n",
      "print(pca.explained_variance_ratio_)\n",
      "42/66:\n",
      "pca = PCA(n_components=1)\n",
      "pca.fit(features)\n",
      "print(pca.explained_variance_ratio_)\n",
      "42/67:\n",
      "pca = PCA(n_components=1)\n",
      "features = pca.fit_transform(features)\n",
      "features[:5]\n",
      "42/68: x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
      "42/69:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "42/70:\n",
      "clf = RandomForestRegressor()\n",
      "clf.fit(features, labels)\n",
      "print(clf.score)\n",
      "42/71:\n",
      "clf = RandomForestRegressor()\n",
      "clf.fit(x_train, y_train)\n",
      "print(clf.score(x_test, y_test))\n",
      "42/72:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "42/73:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn\n",
      "42/74:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn\n",
      "from torch import optimizer\n",
      "42/75:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn\n",
      "from torch import optim\n",
      "42/76:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "42/77:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "42/78:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "42/79:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0] = [a.replace(' UTC', '') for a in features[:,0]]\n",
      "features[:,0] = [time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in features[:,0]]\n",
      "42/80:\n",
      "dat = []\n",
      "with open('trainaa') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for line in reader:\n",
      "        dat.append(line)\n",
      "42/81:\n",
      "dat = np.array(dat)\n",
      "dat.shape\n",
      "dat = dat[np.all(dat != '', axis=1)]\n",
      "42/82:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0] = [a.replace(' UTC', '') for a in features[:,0]]\n",
      "features[:,0] = [time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in features[:,0]]\n",
      "42/83:\n",
      "labels = [float(a) for a in labels]\n",
      "features = [[float(b) for b in row] for row in features]\n",
      "42/84:\n",
      "pca = PCA(n_components=1)\n",
      "pca_features = pca.fit_transform(features)\n",
      "42/85: x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
      "42/86: range(labels)\n",
      "42/87: labels\n",
      "42/88: max(labels)\n",
      "42/89:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "42/90:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout):\n",
      "        super().__init__()\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "42/91:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "42/92: torch.version.__version__\n",
      "42/93: torch.__version__\n",
      "42/94: torch\n",
      "42/95: torch.zeros(1)\n",
      "43/1:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "43/2:\n",
      "dat = []\n",
      "with open('trainaa') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for line in reader:\n",
      "        dat.append(line)\n",
      "43/3:\n",
      "dat = np.array(dat)\n",
      "dat.shape\n",
      "dat = dat[np.all(dat != '', axis=1)]\n",
      "43/4:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "features[:,0] = [a.replace(' UTC', '') for a in features[:,0]]\n",
      "features[:,0] = [time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in features[:,0]]\n",
      "43/5:\n",
      "labels = [float(a) for a in labels]\n",
      "features = [[float(b) for b in row] for row in features]\n",
      "43/6:\n",
      "pca = PCA(n_components=1)\n",
      "pca_features = pca.fit_transform(features)\n",
      "43/7: x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
      "43/8:\n",
      "clf = RandomForestRegressor()\n",
      "clf.fit(x_train, y_train)\n",
      "print(clf.score(x_test, y_test))\n",
      "43/9:\n",
      "batches = 16\n",
      "in_dim = 6\n",
      "h1_dim = 64\n",
      "h2_dim = 256\n",
      "h3_dim = 32\n",
      "out_dim = 1\n",
      "43/10:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout):\n",
      "        super().__init__()\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "43/11:\n",
      "batches = 16\n",
      "in_dim = 6\n",
      "out_dim = 1\n",
      "h1_dim = 64\n",
      "h2_dim = 256\n",
      "h3_dim = 32\n",
      "43/12:\n",
      "batches = 16\n",
      "in_dim = 6\n",
      "out_dim = 1\n",
      "h1_dim = 64\n",
      "h2_dim = 256\n",
      "h3_dim = 32\n",
      "dropout = 0.3\n",
      "43/13:\n",
      "model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout)\n",
      "model\n",
      "43/14:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
      "43/15:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
      "43/16:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "43/17:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import torch.utils.data\n",
      "43/18:\n",
      "class ds(Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "43/19:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "43/20: train_ds = ds(x_train, y_train)\n",
      "43/21:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "43/22: train_ds.__getitem__(0)\n",
      "43/23:\n",
      "i, j = train_ds.__getitem__(0)\n",
      "print(i)\n",
      "print(j)\n",
      "43/24:\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=8, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=8, shuffle=True)\n",
      "train_loader\n",
      "43/25:\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=8, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=8, shuffle=True)\n",
      "43/26:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=8, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=8, shuffle=True)\n",
      "43/27: len(train_loader)\n",
      "43/28:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=True)\n",
      "43/29: len(train_loader)\n",
      "43/30:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=True)\n",
      "43/31: len(train_loader)\n",
      "43/32:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        for feature, label in test_loader:\n",
      "            pred = model.forward(feature)\n",
      "            loss = loss_fn(pred, label)\n",
      "            test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "43/33:\n",
      "batch_size = 64\n",
      "in_dim = 6\n",
      "out_dim = 1\n",
      "h1_dim = 64\n",
      "h2_dim = 256\n",
      "h3_dim = 32\n",
      "dropout = 0.3\n",
      "43/34:\n",
      "batch_size = 64\n",
      "in_dim = 6\n",
      "out_dim = 1\n",
      "h1_dim = 64\n",
      "h2_dim = 256\n",
      "h3_dim = 32\n",
      "dropout = 0.3\n",
      "43/35:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size):\n",
      "        super().__init__()\n",
      "        self.batch_size = batch_size\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = torch.tensor(x)\n",
      "        x = x.view(self.batch_size, self.in_dim)\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "43/36: model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "43/37:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
      "43/38:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "43/39:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "43/40:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        for feature, label in test_loader:\n",
      "            pred = model.forward(feature)\n",
      "            loss = loss_fn(pred, label)\n",
      "            test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "43/41: train_loader[0]\n",
      "43/42: train_loader\n",
      "43/43: iter(train_loder)\n",
      "43/44: iter(train_lodder)\n",
      "43/45: iter(train_loader)\n",
      "43/46: next(iter(train_loader))\n",
      "43/47: type(next(iter(train_loader)))\n",
      "43/48: next(iter(train_loader)).shape\n",
      "43/49: torch.tensor(next(iter(train_loader)))\n",
      "43/50: torch.stack(next(iter(train_loader)))\n",
      "43/51: np.array(next(iter(train_loader)))\n",
      "43/52: np.array(next(iter(train_loader))).shape\n",
      "43/53: np.array(next(iter(train_loader))).shape\n",
      "43/54: np.array(next(iter(train_loader)))\n",
      "43/55: torch.from_numpy(np.array(next(iter(train_loader))))\n",
      "43/56: torch.tensor(np.array(next(iter(train_loader))))\n",
      "43/57: np.array(next(iter(train_loader)))\n",
      "43/58: unlist(next(iter(train_loader)))\n",
      "43/59: next(iter(train_loader))\n",
      "43/60: len(next(iter(train_loader)))\n",
      "43/61: next(iter(train_loader))\n",
      "43/62: next(iter(train_loader))[0]\n",
      "43/63: next(iter(train_loader))[1]\n",
      "43/64: next(iter(train_loader))[0]\n",
      "43/65: next(iter(train_loader))[0].shape\n",
      "43/66: next(iter(train_loader))[0]\n",
      "43/67: len(next(iter(train_loader))[0])\n",
      "43/68: len(next(iter(train_loader))[1])\n",
      "43/69: len(next(iter(train_loader))[0])\n",
      "43/70:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "43/71: len(next(iter(train_loader))[0])\n",
      "43/72: next(iter(train_loader))\n",
      "43/73: next(iter(train_loader))[0]\n",
      "43/74: torch.cat(next(iter(train_loader))[0])\n",
      "43/75: torch.cat(next(iter(train_loader))[0], dim=1)\n",
      "43/76: torch.cat(next(iter(train_loader))[0])\n",
      "43/77: torch.cat(next(iter(train_loader))[0]).view(batch_size, -1)\n",
      "43/78: torch.cat(next(iter(train_loader))[0]).view(batch_size, -1).shape\n",
      "43/79:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size):\n",
      "        super().__init__()\n",
      "        self.batch_size = batch_size\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = torch.cat(x).view(batch_size, self.in_dim)\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "43/80: model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "43/81:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
      "43/82:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "43/83:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "43/84:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        for feature, label in test_loader:\n",
      "            pred = model.forward(feature)\n",
      "            loss = loss_fn(pred, label)\n",
      "            test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "43/85:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size):\n",
      "        super().__init__()\n",
      "        self.batch_size = batch_size\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = torch.cat(x).view(batch_size, -1)\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "43/86: model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "43/87:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
      "43/88:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "43/89:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "43/90:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        for feature, label in test_loader:\n",
      "            pred = model.forward(feature)\n",
      "            loss = loss_fn(pred, label)\n",
      "            test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "43/91: next(iter(train_loader))[0]\n",
      "43/92: torch.cat(next(iter(train_loader))[0])\n",
      "43/93: torch.cat(next(iter(train_loader))[0]).view(batch_size, -1)\n",
      "43/94: torch.cat(next(iter(train_loader))[0]).view(batch_size, -1).float()\n",
      "43/95:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size):\n",
      "        super().__init__()\n",
      "        self.batch_size = batch_size\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = torch.cat(x).view(batch_size, -1).float()\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "43/96: model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "43/97:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
      "43/98:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "43/99:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "43/100:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        for feature, label in test_loader:\n",
      "            pred = model.forward(feature)\n",
      "            loss = loss_fn(pred, label)\n",
      "            test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "43/101:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        for feature, label in test_loader:\n",
      "            pred = model.forward(feature)\n",
      "            loss = loss_fn(pred, label)\n",
      "            test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "43/102:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        print(loss.item())\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        test_loss += loss.item()\n",
      "        print(loss.item())\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "43/103:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
      "43/104:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
      "43/105:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        print(loss.item())\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        test_loss += loss.item()\n",
      "        print(loss.item())\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "43/106: f1, l1 = next(iter(train_loader))\n",
      "43/107:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "model.forward(f1)\n",
      "43/108:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1\n",
      "43/109:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "torch.cat(f1).view(batch_size, -1).float()\n",
      "43/110:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "43/111:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "fc1 = nn.Linear(6, 64)\n",
      "43/112:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc1(f1)\n",
      "43/113:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "fc1 = nn.Linear(6, 64)\n",
      "f1 = fc1(f1)\n",
      "lrelu = nn.LeakyReLU()\n",
      "lrelu(f1)\n",
      "43/114:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "fc1 = nn.Linear(6, 64)\n",
      "f1 = fc1(f1)\n",
      "lrelu = nn.LeakyReLU()\n",
      "lrelu(f1)\n",
      "drop = nn.Dropout(p=0.3)\n",
      "43/115:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "fc1 = nn.Linear(6, 64)\n",
      "f1 = fc1(f1)\n",
      "lrelu = nn.LeakyReLU()\n",
      "f1 = lrelu(f1)\n",
      "drop = nn.Dropout(p=0.3)\n",
      "f1 = drop(f1)\n",
      "43/116:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "fc1 = nn.Linear(6, 64)\n",
      "f1 = fc1(f1)\n",
      "lrelu = nn.LeakyReLU()\n",
      "f1 = lrelu(f1)\n",
      "drop = nn.Dropout(p=0.3)\n",
      "f1 = drop(f1)\n",
      "f1\n",
      "43/117:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "fc1 = nn.Linear(6, 64)\n",
      "f1 = fc1(f1)\n",
      "lrelu = nn.LeakyReLU()\n",
      "f1 = lrelu(f1)\n",
      "drop = nn.Dropout(p=0.3)\n",
      "f1 = drop(f1)\n",
      "f1\n",
      "fc2 = nn.Linear(64, 256)\n",
      "f1 = fc2(f1)\n",
      "f1\n",
      "43/118:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "print(f1)\n",
      "43/119:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "print(f1)\n",
      "43/120:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "f1 = drop(lrelu(fc2(f1)))\n",
      "print(f1)\n",
      "43/121:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "f1 = drop(lrelu(fc2(f1)))\n",
      "f1 = drop(lrelu(fc3(f1)))\n",
      "print(f1)\n",
      "43/122:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "f1 = drop(lrelu(fc2(f1)))\n",
      "f1 = drop(lrelu(fc3(f1)))\n",
      "f1 = out(f1)\n",
      "print(f1)\n",
      "43/123:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "f1 = drop(lrelu(fc2(f1)))\n",
      "f1 = drop(lrelu(fc3(f1)))\n",
      "f1 = out(f1)\n",
      "print(f1)\n",
      "\n",
      "model.forward(f1)\n",
      "43/124:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "print(model.forward(f1))\n",
      "\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "f1 = drop(lrelu(fc2(f1)))\n",
      "f1 = drop(lrelu(fc3(f1)))\n",
      "f1 = out(f1)\n",
      "print(f1)\n",
      "43/125:\n",
      "model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "model\n",
      "43/126:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "print(model(f1))\n",
      "\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "f1 = drop(lrelu(fc2(f1)))\n",
      "f1 = drop(lrelu(fc3(f1)))\n",
      "f1 = out(f1)\n",
      "print(f1)\n",
      "43/127:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "print(model.forward(f1))\n",
      "\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "f1 = drop(lrelu(fc2(f1)))\n",
      "f1 = drop(lrelu(fc3(f1)))\n",
      "f1 = out(f1)\n",
      "print(f1)\n",
      "43/128:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "print(model.forward(f1))\n",
      "\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "f1 = drop(lrelu(fc2(f1)))\n",
      "f1 = drop(lrelu(fc3(f1)))\n",
      "f1 = out(f1)\n",
      "print(f1)\n",
      "43/129:\n",
      "f1, l1 = next(iter(train_loader))\n",
      "print(model.forward(f1))\n",
      "\n",
      "f1 = torch.cat(f1).view(batch_size, -1).float()\n",
      "lrelu = nn.LeakyReLU()\n",
      "drop = nn.Dropout(p=0.3)\n",
      "\n",
      "fc1 = nn.Linear(6, 64)\n",
      "fc2 = nn.Linear(64, 256)\n",
      "fc3 = nn.Linear(256, 32)\n",
      "out = nn.Linear(32, 1)\n",
      "\n",
      "f1 = drop(lrelu(fc1(f1)))\n",
      "f1 = drop(lrelu(fc2(f1)))\n",
      "f1 = drop(lrelu(fc3(f1)))\n",
      "f1 = out(f1)\n",
      "print(f1)\n",
      "43/130:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        print(loss.item())\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        test_loss += loss.item()\n",
      "        print(loss.item())\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "43/131:\n",
      "model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "model\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "    print('Training on GPU')\n",
      "43/132:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3?)\n",
      "43/133:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "43/134:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "43/135:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "44/1:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import torch.utils.data\n",
      "44/2:\n",
      "dat = []\n",
      "with open('trainaa') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for line in reader:\n",
      "        dat.append(line)\n",
      "dat = np.array(dat)\n",
      "dat = dat[np.all(dat != '', axis=1)]\n",
      "dat[:,2] = [a.replace(' UTC', '') for a in dat[:,2]]\n",
      "dat[:,2] = [time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in dat[:,2]]\n",
      "44/3:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "44/4:\n",
      "labels = np.array([float(a) for a in labels])\n",
      "features = np.array([[float(b) for b in row] for row in features])\n",
      "44/5: x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
      "44/6: x_train\n",
      "44/7: x_train.shape\n",
      "44/8: x_train = torch.tensor(x_train)\n",
      "44/9: x_train.shape\n",
      "44/10: type(x_train)\n",
      "44/11:\n",
      "x_train = torch.tensor(x_train)\n",
      "x_test = torch.tensor(x_test)\n",
      "y_train = torch.tensor(y_train)\n",
      "y_test = torch.tensor(y_test)\n",
      "44/12: y_train.shape\n",
      "44/13: x_test.shape\n",
      "44/14:\n",
      "batch_size = 64\n",
      "in_dim = 6\n",
      "out_dim = 1\n",
      "h1_dim = 64\n",
      "h2_dim = 256\n",
      "h3_dim = 32\n",
      "dropout = 0.3\n",
      "44/15:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size):\n",
      "        super().__init__()\n",
      "        self.batch_size = batch_size\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = torch.cat(x).view(batch_size, -1).float()\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "44/16:\n",
      "model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "model\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "    print('Training on GPU')\n",
      "44/17:\n",
      "model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "print(model)\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "    print('Training on GPU')\n",
      "44/18:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "44/19:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "44/20:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "44/21:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "44/22: next(iter(train_loader))[0].shape\n",
      "44/23:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size):\n",
      "        super().__init__()\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "44/24:\n",
      "model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "print(model)\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "    print('Training on GPU')\n",
      "44/25:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "44/26:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "44/27:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "44/28:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "44/29:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature)\n",
      "        loss = loss_fn(pred, label)\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "44/30:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "44/31:\n",
      "epochs = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "44/32:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
      "44/33:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, nesterov=True)\n",
      "44/34:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "44/35:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
      "44/36:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "44/37:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "44/38:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "46/1:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import torch.utils.data\n",
      "46/2:\n",
      "dat = []\n",
      "with open('trainaa') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for line in reader:\n",
      "        dat.append(line)\n",
      "dat = np.array(dat)\n",
      "dat = dat[np.all(dat != '', axis=1)]\n",
      "dat[:,2] = [a.replace(' UTC', '') for a in dat[:,2]]\n",
      "dat[:,2] = [time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in dat[:,2]]\n",
      "46/3:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "46/4:\n",
      "labels = np.array([float(a) for a in labels])\n",
      "features = np.array([[float(b) for b in row] for row in features])\n",
      "46/5: x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
      "46/6:\n",
      "x_train = torch.tensor(x_train)\n",
      "x_test = torch.tensor(x_test)\n",
      "y_train = torch.tensor(y_train)\n",
      "y_test = torch.tensor(y_test)\n",
      "46/7:\n",
      "batch_size = 64\n",
      "in_dim = 6\n",
      "out_dim = 1\n",
      "h1_dim = 64\n",
      "h2_dim = 256\n",
      "h3_dim = 32\n",
      "dropout = 0.3\n",
      "46/8:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size):\n",
      "        super().__init__()\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "46/9:\n",
      "model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "print(model)\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "    print('Training on GPU')\n",
      "46/10:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
      "46/11:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "46/12:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "46/13:\n",
      "epochs = 3\n",
      "clip = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "46/14:\n",
      "epochs = 3\n",
      "clip = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "46/15:\n",
      "loss_fn = nn.MSELoss(reduction='sum')\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
      "46/16:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "46/17:\n",
      "epochs = 3\n",
      "clip = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "46/18:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
      "46/19:\n",
      "epochs = 3\n",
      "clip = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "47/1:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "47/2:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "47/3:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "47/4:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "47/5:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "47/6:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "47/7:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "48/1:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "48/2:\n",
      "data_dir = '/Users/js/Desktop/datasets/flower_data/'\n",
      "train_dir = data_dir + '/train'\n",
      "valid_dir = data_dir + '/valid'\n",
      "48/3:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision.transforms\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "48/4:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "import torchvision.transforms\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "48/5:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "from torchvision import transforms\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "48/6:\n",
      "import json\n",
      "\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "48/7:\n",
      "# Imports here\n",
      "import numpy as np\n",
      "import torch\n",
      "from torchvision import transforms, datasets, models\n",
      "from torch import nn, optim\n",
      "from PIL import Image\n",
      "50/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "from torchvision import transforms, datasets, models\n",
      "from PIL import Image\n",
      "import json\n",
      "50/2:\n",
      "data_dir = '/Users/js/Desktop/datasets/flower_data/'\n",
      "train_dir = data_dir + '/train'\n",
      "valid_dir = data_dir + '/valid'\n",
      "50/3:\n",
      "data_dir = '/Users/js/Desktop/datasets/flower_data/'\n",
      "train_dir = data_dir + '/train'\n",
      "val_dir = data_dir + '/valid'\n",
      "50/4:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Scale(256),\n",
      "    transforms.TenCrop(224),\n",
      "    Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "50/5:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Scale(256),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "50/6:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(256),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "50/7: train_dat\n",
      "50/8: train_dat[0]\n",
      "50/9: train_dat.__getitem__(0)\n",
      "50/10:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(256),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "50/11: train_dat.__getitem__(0)\n",
      "50/12: train_dat\n",
      "50/13:\n",
      "data_dir = '/Users/js/Desktop/datasets/flower_data'\n",
      "train_dir = data_dir + '/train'\n",
      "val_dir = data_dir + '/valid'\n",
      "50/14:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(256),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "50/15: train_dat\n",
      "50/16: val_dat\n",
      "50/17: args.nThreads\n",
      "50/18:\n",
      "import args\n",
      "args.nThreads\n",
      "50/19:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(256),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "\n",
      "train_loader = torch.utils.data.DataLoader(train_dat, batch_size=16, shuffle=True, num_workers=2)\n",
      "val_loader = torch.utils.data.DataLoader(val_dat, batch_size=16, shuffle=True, num_workers=2)\n",
      "50/20:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(256),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "\n",
      "train_loader = torch.utils.data.DataLoader(train_dat, batch_size=16, shuffle=True, num_workers=2)\n",
      "val_loader = torch.utils.data.DataLoader(val_dat, batch_size=16, shuffle=True, num_workers=2)\n",
      "50/21: next(iter(train_loader))\n",
      "50/22: next(iter(train_loader))[0].shape\n",
      "50/23: print(1)\n",
      "50/24: next(iter(train_loader)).shape\n",
      "50/25: next(iter(train_loader))[1].shape\n",
      "50/26: next(iter(train_loader))[0].shape\n",
      "50/27: next(iter(train_loader))[0][0]\n",
      "50/28: next(iter(train_loader))[0][0].shape\n",
      "50/29: next(iter(train_loader))[0][0][0].shape\n",
      "50/30: next(iter(train_loader))[0][0][0]\n",
      "50/31: im.show(next(iter(train_loader))[0][0][0])\n",
      "50/32: im = Image((next(iter(train_loader))[0][0][0])\n",
      "50/33: im = Image(next(iter(train_loader))[0][0][0])\n",
      "50/34: im = Image.open(next(iter(train_loader))[0][0][0])\n",
      "50/35: ToPILImage((next(iter(train_loader))[0][0][0])\n",
      "50/36: Image.ToPILImage((next(iter(train_loader))[0][0][0]))\n",
      "50/37: next(iter(train_loader))\n",
      "50/38: next(iter(train_loader)).shape\n",
      "50/39:\n",
      "print(next(iter(train_loader))[0].shape)\n",
      "print(next(iter(train_loader))[1].shape)\n",
      "50/40:\n",
      "print(len(train_loader))\n",
      "\n",
      "print(next(iter(train_loader))[0].shape)\n",
      "print(next(iter(train_loader))[1].shape)\n",
      "50/41:\n",
      "print(len(train_dat))\n",
      "\n",
      "print(next(iter(train_loader))[0].shape)\n",
      "print(next(iter(train_loader))[1].shape)\n",
      "50/42:\n",
      "print(len(train_dat))\n",
      "print(len(val_dat))\n",
      "\n",
      "print(next(iter(train_loader))[0].shape)\n",
      "print(next(iter(train_loader))[1].shape)\n",
      "50/43:\n",
      "print(len(train_dat))\n",
      "print(len(val_dat))\n",
      "\n",
      "print(len(train_loader))\n",
      "print(len(val_dat))\n",
      "\n",
      "print(next(iter(train_loader))[0].shape)\n",
      "print(next(iter(train_loader))[1].shape)\n",
      "50/44:\n",
      "print(len(train_dat))\n",
      "print(len(val_dat))\n",
      "\n",
      "print(len(train_loader))\n",
      "print(len(val_loader))\n",
      "\n",
      "print(next(iter(train_loader))[0].shape)\n",
      "print(next(iter(train_loader))[1].shape)\n",
      "50/45:\n",
      "print(len(train_dat))\n",
      "print(len(val_dat))\n",
      "\n",
      "print(len(train_loader))\n",
      "print(len(val_loader))\n",
      "\n",
      "print(next(iter(train_loader))[0].shape)\n",
      "print(next(iter(train_loader))[1])\n",
      "50/46:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "50/47:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "cat_to_name\n",
      "50/48:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "cat_to_name.get(34)\n",
      "50/49:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "print(cat_to_name.get(34))\n",
      "50/50:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "print(cat_to_name.get('34'))\n",
      "50/51:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "next(iter(train_loader))[1]\n",
      "50/52:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "next(iter(train_loader))[1][0]\n",
      "50/53:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "cat_to_name.get(next(iter(train_loader))[1][0])\n",
      "50/54:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "next(iter(train_loader))[1][0]\n",
      "50/55:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "next(iter(train_loader))[1][0].item()\n",
      "50/56:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "\n",
      "type(next(iter(train_loader))[1][0].item())\n",
      "50/57:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "50/58:\n",
      "print(len(train_dat))\n",
      "print(len(val_dat))\n",
      "\n",
      "print(len(train_loader))\n",
      "print(len(val_loader))\n",
      "\n",
      "print(next(iter(train_loader))[0].shape)\n",
      "print(next(iter(train_loader))[1].shape)\n",
      "50/59:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "from torchvision import transforms, datasets, models\n",
      "from PIL import Image\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "50/60:\n",
      "img = next(iter(train_loader))[0]\n",
      "img = img / 2 + 0.5  # unnormalize\n",
      "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
      "50/61:\n",
      "img = next(iter(train_loader))[0][0]\n",
      "img = img / 2 + 0.5  # unnormalize\n",
      "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
      "50/62:\n",
      "img = next(iter(train_loader))[0][0][0]\n",
      "img = img / 2 + 0.5  # unnormalize\n",
      "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
      "50/63:\n",
      "img = next(iter(train_loader))[0][0][0]\n",
      "#img = img / 2 + 0.5  # unnormalize\n",
      "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
      "50/64:\n",
      "img = next(iter(train_loader))[0][0][0]\n",
      "#img = img / 2 + 0.5  # unnormalize\n",
      "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
      "50/65:\n",
      "img, label = next(iter(train_loader))\n",
      "img = img[0][0]\n",
      "label = label[0]\n",
      "#img = img / 2 + 0.5  # unnormalize\n",
      "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
      "50/66:\n",
      "model = models.inception_v3(pretrained=True)\n",
      "model\n",
      "50/67:\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "50/68:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "from torchvision import transforms, datasets, models\n",
      "from PIL import Image\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from collections import OrderedDict\n",
      "50/69:\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1': nn.Linear(2048, 1024)),\n",
      "    ('lrelu1': nn.LeakyReLU()),\n",
      "    ('drop1': nn.Dropout(p=0.3)),\n",
      "    ('fc2': nn.Linear(1024, 512)),\n",
      "    ('lrelu2': nn.LeakyReLU()),\n",
      "    ('drop2': nn.Dropout(p=0.3)),\n",
      "    ('fc3': nn.Linear(512, 102)),\n",
      "    ('out': nn.LogSoftmax())\n",
      "]))\n",
      "\n",
      "model.fc = classifier\n",
      "model\n",
      "50/70:\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu1', nn.LeakyReLU()),\n",
      "    ('drop1', nn.Dropout(p=0.3)),\n",
      "    ('fc2', nn.Linear(1024, 512)),\n",
      "    ('lrelu2', nn.LeakyReLU()),\n",
      "    ('drop2', nn.Dropout(p=0.3)),\n",
      "    ('fc3', nn.Linear(512, 102)),\n",
      "    ('out', nn.LogSoftmax())\n",
      "]))\n",
      "\n",
      "model.fc = classifier\n",
      "model\n",
      "50/71:\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu1', nn.LeakyReLU()),\n",
      "    ('drop1', nn.Dropout(p=0.3)),\n",
      "    ('fc2', nn.Linear(1024, 512)),\n",
      "    ('lrelu2', nn.LeakyReLU()),\n",
      "    ('drop2', nn.Dropout(p=0.3)),\n",
      "    ('fc3', nn.Linear(512, 102)),\n",
      "    ('out', nn.LogSoftmax())\n",
      "]))\n",
      "\n",
      "model.classifier = classifier\n",
      "model\n",
      "50/72:\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu1', nn.LeakyReLU()),\n",
      "    ('drop1', nn.Dropout(p=0.3)),\n",
      "    ('fc2', nn.Linear(1024, 512)),\n",
      "    ('lrelu2', nn.LeakyReLU()),\n",
      "    ('drop2', nn.Dropout(p=0.3)),\n",
      "    ('fc3', nn.Linear(512, 102)),\n",
      "    ('out', nn.LogSoftmax())\n",
      "]))\n",
      "\n",
      "model.fc = classifier\n",
      "model\n",
      "50/73:\n",
      "model = models.inception_v3(pretrained=True)\n",
      "model\n",
      "50/74:\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu1', nn.LeakyReLU()),\n",
      "    ('drop1', nn.Dropout(p=0.3)),\n",
      "    ('fc2', nn.Linear(1024, 512)),\n",
      "    ('lrelu2', nn.LeakyReLU()),\n",
      "    ('drop2', nn.Dropout(p=0.3)),\n",
      "    ('fc3', nn.Linear(512, 102)),\n",
      "    ('out', nn.LogSoftmax())\n",
      "]))\n",
      "\n",
      "model.fc = OrderedDict(['classifier', classifier])\n",
      "model\n",
      "50/75:\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu1', nn.LeakyReLU()),\n",
      "    ('drop1', nn.Dropout(p=0.3)),\n",
      "    ('fc2', nn.Linear(1024, 512)),\n",
      "    ('lrelu2', nn.LeakyReLU()),\n",
      "    ('drop2', nn.Dropout(p=0.3)),\n",
      "    ('fc3', nn.Linear(512, 102)),\n",
      "    ('out', nn.LogSoftmax())\n",
      "]))\n",
      "\n",
      "model.fc = OrderedDict([('classifier', classifier)])\n",
      "model\n",
      "50/76:\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "50/77:\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu1', nn.LeakyReLU()),\n",
      "    ('drop1', nn.Dropout(p=0.3)),\n",
      "    ('fc2', nn.Linear(1024, 512)),\n",
      "    ('lrelu2', nn.LeakyReLU()),\n",
      "    ('drop2', nn.Dropout(p=0.3)),\n",
      "    ('fc3', nn.Linear(512, 102)),\n",
      "    ('out', nn.LogSoftmax())\n",
      "]))\n",
      "\n",
      "model.fc = classifier\n",
      "model\n",
      "50/78:\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu1', nn.LeakyReLU()),\n",
      "    ('drop1', nn.Dropout(p=0.3)),\n",
      "    ('fc2', nn.Linear(1024, 512)),\n",
      "    ('lrelu2', nn.LeakyReLU()),\n",
      "    ('drop2', nn.Dropout(p=0.3)),\n",
      "    ('fc3', nn.Linear(512, 102)),\n",
      "    ('out', nn.LogSoftmax())\n",
      "]))\n",
      "\n",
      "model.fc = classifier\n",
      "model\n",
      "50/79:\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "50/80:\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "    print('GPU Available')\n",
      "50/81:\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "    print('GPU Available')\n",
      "else: \n",
      "    print('Using CPU')\n",
      "50/82:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "50/83:\n",
      "a = 123124.013512\n",
      "print(f'{a:.3f}')\n",
      "50/84:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "        if torch.cuda.is_available():\n",
      "            feature, label = feature.cuda(), label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        batch_size, n_crops, channels, height, width = feature.shape\n",
      "        output = model(feature.view(-1, channels, height, width))\n",
      "        loss = loss_fn(output, label)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        if torch.cuda.is_available():\n",
      "            feature, label = feature.cuda(), label.cuda()\n",
      "        batch_size, n_crops, channels, height, width = feature.shape\n",
      "        output = model(feature.view(-1, channels, height, width))\n",
      "        loss = loss_fn(output, label)\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs}  |  Training loss: {train_loss:.6f}  |  Testing loss: {test_loss:.6f}')\n",
      "50/85:\n",
      "feature, label = next(iter(train_loader)):\n",
      "    batch_size, n_crops, channels, height, width = feature.shape\n",
      "    output = model(feature.view(-1, channels, height, width))\n",
      "    loss = loss_fn(output, label)\n",
      "    print(loss.item())\n",
      "50/86:\n",
      "feature, label = next(iter(train_loader))\n",
      "batch_size, n_crops, channels, height, width = feature.shape\n",
      "output = model(feature.view(-1, channels, height, width))\n",
      "loss = loss_fn(output, label)\n",
      "print(loss.item())\n",
      "50/87:\n",
      "feature, label = next(iter(train_loader))\n",
      "batch_size, n_crops, channels, height, width = feature.shape\n",
      "print(feature.view(-1, channels, height, width))\n",
      "50/88:\n",
      "feature, label = next(iter(train_loader))\n",
      "batch_size, n_crops, channels, height, width = feature.shape\n",
      "print(feature.view(-1, channels, height, width).shape)\n",
      "50/89:\n",
      "feature, label = next(iter(train_loader))\n",
      "batch_size, n_crops, channels, height, width = feature.shape\n",
      "flattened = feature.view(-1, channels, height, width)\n",
      "model.forward(flattened)\n",
      "50/90:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(320),\n",
      "    transforms.TenCrop(299),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "\n",
      "train_loader = torch.utils.data.DataLoader(train_dat, batch_size=16, shuffle=True, num_workers=4)\n",
      "val_loader = torch.utils.data.DataLoader(val_dat, batch_size=16, shuffle=True, num_workers=4)\n",
      "50/91:\n",
      "print(len(train_dat))\n",
      "print(len(val_dat))\n",
      "\n",
      "print(len(train_loader))\n",
      "print(len(val_loader))\n",
      "\n",
      "print(next(iter(train_loader))[0].shape)\n",
      "print(next(iter(train_loader))[1].shape)\n",
      "50/92:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "50/93:\n",
      "model = models.inception_v3(pretrained=True)\n",
      "model\n",
      "50/94:\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "50/95:\n",
      "classifier = nn.Sequential(OrderedDict([\n",
      "    ('fc1', nn.Linear(2048, 1024)),\n",
      "    ('lrelu1', nn.LeakyReLU()),\n",
      "    ('drop1', nn.Dropout(p=0.3)),\n",
      "    ('fc2', nn.Linear(1024, 512)),\n",
      "    ('lrelu2', nn.LeakyReLU()),\n",
      "    ('drop2', nn.Dropout(p=0.3)),\n",
      "    ('fc3', nn.Linear(512, 102)),\n",
      "    ('out', nn.LogSoftmax())\n",
      "]))\n",
      "\n",
      "model.fc = classifier\n",
      "model\n",
      "50/96:\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "    print('GPU Available')\n",
      "else: \n",
      "    print('Using CPU')\n",
      "50/97:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "50/98:\n",
      "feature, label = next(iter(train_loader))\n",
      "batch_size, n_crops, channels, height, width = feature.shape\n",
      "flattened = feature.view(-1, channels, height, width)\n",
      "model.forward(flattened)\n",
      "50/99:\n",
      "feature, label = next(iter(train_loader))\n",
      "batch_size, n_crops, channels, height, width = feature.shape\n",
      "flattened = feature.view(-1, channels, height, width)\n",
      "output = model.forward(flattened)\n",
      "50/100: output.shape\n",
      "50/101: output\n",
      "50/102:\n",
      "model = models.inception_v3(pretrained=True, aux_logits=False)\n",
      "model\n",
      "52/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "from torchvision import transforms, datasets, models\n",
      "from PIL import Image\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from collections import OrderedDict\n",
      "52/2:\n",
      "data_dir = '/Users/js/Desktop/datasets/flower_data'\n",
      "train_dir = data_dir + '/train'\n",
      "val_dir = data_dir + '/valid'\n",
      "52/3:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(320),\n",
      "    transforms.TenCrop(299),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "\n",
      "# train_loader = torch.utils.data.DataLoader(train_dat, batch_size=16, shuffle=True, num_workers=4)\n",
      "# val_loader = torch.utils.data.DataLoader(val_dat, batch_size=16, shuffle=True, num_workers=4)\n",
      "52/4: train_dat.shape\n",
      "52/5: len(train_dat)\n",
      "52/6: train_dat[0]\n",
      "52/7: type(train_dat)\n",
      "52/8: train_dat\n",
      "52/9:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(320),\n",
      "    transforms.TenCrop(299),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "\n",
      "train_loader = torch.utils.data.DataLoader(train_dat, batch_size=1, shuffle=True, num_workers=4)\n",
      "val_loader = torch.utils.data.DataLoader(val_dat, batch_size=1, shuffle=True, num_workers=4)\n",
      "52/10: train_loader.shape\n",
      "52/11: train_loader\n",
      "52/12: train_loader[0]\n",
      "52/13: len(train_loader)\n",
      "52/14: next(iter(train_loader))\n",
      "52/15: train_dat[0]\n",
      "52/16: a, b = train_dat\n",
      "52/17: a, b = train_dat[0]\n",
      "52/18:\n",
      "a, b = train_dat[0]\n",
      "b\n",
      "52/19:\n",
      "a, b = train_dat[0]\n",
      "a\n",
      "52/20: [a, b for a, b in train_dat]\n",
      "52/21: [a, b for (a, b) in train_dat]\n",
      "52/22: [a, b for a, b in enumerate(train_dat)]\n",
      "52/23: [(a, b) for a, b in enumerate(train_dat)]\n",
      "52/24: [(a, b) for a, b in train_dat]\n",
      "52/25: iter(train_loader)\n",
      "52/26: len(iter(train_loader))\n",
      "52/27: len(train_loader)\n",
      "52/28: a = [i for i,j in train_loader]\n",
      "53/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "from torchvision import transforms, datasets, models\n",
      "from PIL import Image\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from collections import OrderedDict\n",
      "53/2:\n",
      "data_dir = '/Users/js/Desktop/datasets/flower_data'\n",
      "train_dir = data_dir + '/train'\n",
      "val_dir = data_dir + '/valid'\n",
      "53/3:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(320),\n",
      "    transforms.TenCrop(299),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "\n",
      "train_loader = torch.utils.data.DataLoader(train_dat, batch_size=1, shuffle=True, num_workers=4)\n",
      "val_loader = torch.utils.data.DataLoader(val_dat, batch_size=1, shuffle=True, num_workers=4)\n",
      "53/4: train_dat.classes[label]\n",
      "53/5: image, label = next(iter(train_loader))\n",
      "53/6:\n",
      "image, label = next(iter(train_loader))\n",
      "label\n",
      "53/7:\n",
      "image, label = next(iter(train_loader))\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "53/8:\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "53/9:\n",
      "image, label = next(iter(train_loader))\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[image_datasets.classes[label]])\n",
      "53/10:\n",
      "image, label = next(iter(train_loader))\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/11:\n",
      "image, label = next(iter(train_loader))\n",
      "print(image.shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/12:\n",
      "image, label = next(iter(train_loader))\n",
      "print(image[0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/13:\n",
      "image, label = next(iter(train_loader))\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/14:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image.numpy()\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/15:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image.numpy()\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/16:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image.numpy()\n",
      "plt.imshow(np.transpose(image, (1,2,0)), interpolation='nearest')\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/17:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image.numpy()\n",
      "plt.imshow(image)\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/18:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "from torchvision import transforms, datasets, models\n",
      "from PIL import Image\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "%matplotlib inline\n",
      "from collections import OrderedDict\n",
      "53/19:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image.numpy()\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/20:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image.numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/21:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/22:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/23:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(image[0][0].shape)\n",
      "print(label)\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/24:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(label.item())\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/25:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[label.item()])\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/26:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[label.item()])\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/27:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/28:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(train_dat.classes[label])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/29:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/30:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/31:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/32:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/33:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/34:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/35:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/36:\n",
      "image, label = next(iter(train_loader))\n",
      "image = image[0][0].numpy().transpose((1,2,0))\n",
      "plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/37:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    image = image[i][0].numpy().transpose((1,2,0))\n",
      "    plt.imshow(image)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/38:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[i][0].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/39:\n",
      "image, label = next(iter(train_loader))\n",
      "print(image.shape)\n",
      "for i in range(10):\n",
      "    t = image[i][0].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/40:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/41:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "    plt.show()\n",
      "print(cat_to_name[str(label.item())])\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/42:\n",
      "fig,axes = plt.subplots(nrows = 2, ncols = 5, figsize=(20,50))\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "    plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/43:\n",
      "fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize=(50,20))\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "    plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/44:\n",
      "fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize=(50,20))\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    axes.imshow(t)\n",
      "    plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/45:\n",
      "fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize=(50,20))\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    fig.imshow(t)\n",
      "    plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/46:\n",
      "fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize=(50,20))\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    axes.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/47:\n",
      "fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize=(50,20))\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "    plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/48:\n",
      "fig, axes = plt.subplots(nrows = 2, ncols = 5, figsize=(50,20))\n",
      "ax=axes.ravel()\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    ax.plt.imshow(t)\n",
      "    plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/49:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "    plt.figure()\n",
      "    plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/50:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "    plt.figure()\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "53/51:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "    plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "55/1:\n",
      "import numpy as np\n",
      "import gym\n",
      "55/2:\n",
      "env = gym.make('CartPole-v0')\n",
      "env.reset()\n",
      "for _ in range(100):\n",
      "    env.render()\n",
      "    env.step(env.action_space.sample())\n",
      "env.close()\n",
      "55/3:\n",
      "env = gym.make('CartPole-v0')\n",
      "env.reset()\n",
      "for _ in range(100):\n",
      "    env.render()\n",
      "    env.step(env.action_space.sample())\n",
      "env.close()\n",
      "56/1:\n",
      "import numpy as np\n",
      "import gym\n",
      "import random\n",
      "import time\n",
      "from IPython.display import clear_output\n",
      "56/2: env = gym.make('FrozenLake-v0')\n",
      "56/3: env.render()\n",
      "56/4:\n",
      "import numpy as np\n",
      "import torch\n",
      "import gym\n",
      "import random\n",
      "import time\n",
      "from IPython.display import clear_output\n",
      "56/5: env.action_space.n\n",
      "56/6:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.\n",
      "q_tab = torch.zeros(state_size, action_size)\n",
      "56/7:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = torch.zeros(state_size, action_size)\n",
      "56/8:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = torch.zeros(state_size, action_size)\n",
      "q_tab\n",
      "56/9:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = torch.zeros(state_size, action_size)\n",
      "print(q_tab)\n",
      "56/10:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "max_exploration_rate = 1\n",
      "min_exploration_raet = 0.01\n",
      "exploration_decay_rate = 0.01\n",
      "56/11:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "max_exploration_rate = 1\n",
      "min_exploration_raet = 0.01\n",
      "exploration_decay_rate = 0.001\n",
      "56/12:\n",
      "import numpy as np\n",
      "import torch\n",
      "import gym\n",
      "import time\n",
      "from IPython.display import clear_output\n",
      "56/13: env = gym.make('FrozenLake-v0')\n",
      "56/14:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros(state_size, action_size)\n",
      "print(q_tab)\n",
      "56/15:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "print(q_tab)\n",
      "56/16:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/17:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,]\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + learning_rate * (reward + q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/18:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,]\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + learning_rate * (reward + q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/19:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + learning_rate * (reward + q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/20:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/21:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        print(new_state)\n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/22:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        print(state, action, newstate)\n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/23:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        print(state, action, new_state)\n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/24:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size), dtype=int)\n",
      "print(q_tab)\n",
      "56/25:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/26:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/27:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/28:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(chunk)\n",
      "56/29:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/30:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(chunk)\n",
      "56/31: print(q_tab)\n",
      "56/32: print(reward)\n",
      "56/33: print(state)\n",
      "56/34: print(new_state)\n",
      "56/35: print(done)\n",
      "56/36: print(exploration_rate)\n",
      "56/37:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/38: print(exploration_rate)\n",
      "56/39:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    #decay exploration\n",
      "    exploration_rate = exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/40: print(exploration_rate)\n",
      "56/41:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(chunk)\n",
      "56/42: print(state)\n",
      "56/43:\n",
      "env = gym.make('FrozenLake-v0')\n",
      "print(env)\n",
      "56/44:\n",
      "env = gym.make('FrozenLake-v0')\n",
      "env.render()\n",
      "56/45:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "init_exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/46:\n",
      "env = gym.make('FrozenLake-v0')\n",
      "env.render()\n",
      "56/47:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size), dtype=int)\n",
      "print(q_tab)\n",
      "56/48:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "init_exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/49:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = init_exploration_rate * np.exp(-exploration_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/50:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(chunk)\n",
      "56/51:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/52:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size), dtype=int)\n",
      "print(q_tab)\n",
      "56/53:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/54:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate -= exploration_decay_rate\n",
      "    all_rewards.append(current_reward)\n",
      "56/55:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/56:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size), dtype=int)\n",
      "print(q_tab)\n",
      "56/57:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/58:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = q_tab[state,].max()\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = 0.01 + 0.99 * np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/59:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/60: print(q_tab)\n",
      "56/61:\n",
      "(1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "56/62: (1 - learning_rate) * q_tab[state, action] + learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "56/63:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size), dtype=int)\n",
      "print(q_tab)\n",
      "56/64:\n",
      "episodes = 10000\n",
      "max_steps = 50\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/65:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = 0.01 + 0.99 * np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/66:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/67: print(q_tab)\n",
      "56/68: (1 - learning_rate) * q_tab[state, action] + learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "56/69: action\n",
      "56/70: state\n",
      "56/71: exploration_rate\n",
      "56/72: env.step(action)\n",
      "56/73: env.reset()\n",
      "56/74: state\n",
      "56/75: state = env.reset()\n",
      "56/76: current_reward\n",
      "56/77:\n",
      "action = env.action_space.sample()\n",
      "action\n",
      "56/78:\n",
      "action = env.action_space.sample()\n",
      "env.step(action)\n",
      "56/79:\n",
      "action = env.action_space.sample()\n",
      "env.step(action)\n",
      "56/80:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/81:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size), dtype=int)\n",
      "print(q_tab)\n",
      "56/82:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/83:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = 0.01 + 0.99 * np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/84:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/85:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "print(q_tab)\n",
      "56/86:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "print(q_tab)\n",
      "56/87:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/88:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = 0.01 + 0.99 * np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/89:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/90:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "print(q_tab)\n",
      "56/91:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/92:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/93:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/94:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "print(q_tab)\n",
      "56/95:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/96:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate -= exploration_decay_rate\n",
      "    all_rewards.append(current_reward)\n",
      "56/97:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/98:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/99:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "print(q_tab)\n",
      "56/100:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/101:\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate -= exploration_decay_rate\n",
      "    all_rewards.append(current_reward)\n",
      "56/102:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/103:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/104:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/105:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/106:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/107:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7500:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/108:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/109:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.95\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/110:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 700:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/111:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/112:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.999\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/113:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 700:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/114:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/115:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.95\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/116:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/117:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/118:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.999\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/119:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/120:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/121:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/122:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/123:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/124:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.8\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/125:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/126:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/127:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.5\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/128:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/129:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/130:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.5\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/131:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/132:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/133:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate -= exploration_decay_rate\n",
      "    all_rewards.append(current_reward)\n",
      "56/134:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/135:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.5\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/136:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate -= exploration_decay_rate\n",
      "    all_rewards.append(current_reward)\n",
      "56/137:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/138:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.5\n",
      "discount_rate = 0.97\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/139:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate -= exploration_decay_rate\n",
      "    all_rewards.append(current_reward)\n",
      "56/140:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/141:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.5\n",
      "discount_rate = 0.999\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.005\n",
      "56/142:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate -= exploration_decay_rate\n",
      "    all_rewards.append(current_reward)\n",
      "56/143:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/144:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.5\n",
      "discount_rate = 0.999\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.0001\n",
      "56/145:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate -= exploration_decay_rate\n",
      "    all_rewards.append(current_reward)\n",
      "56/146:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/147:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.999\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.0001\n",
      "56/148:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate -= exploration_decay_rate\n",
      "    all_rewards.append(current_reward)\n",
      "56/149:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/150:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.999\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.0001\n",
      "56/151:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/152:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/153:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.999\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/154:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/155:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/156:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.95\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/157:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/158:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/159:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.3\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/160:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    exploration_rate = np.exp(-exploration_decay_rate * e)\n",
      "    all_rewards.append(current_reward)\n",
      "56/161:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/162:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.3\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/163:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/164:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/165:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.3\n",
      "discount_rate = 0.99\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/166:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/167:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/168:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.3\n",
      "discount_rate = 0.97\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/169:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/170:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/171:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.4\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/172:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/173:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/174:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.2\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/175:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/176:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/177:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.1\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/178:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/179:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/180:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.9\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/181:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/182:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/183:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.7\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/184:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/185:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/186:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.5\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/187:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/188:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/189:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 1\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/190:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/191:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/192:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 95\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/193:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/194:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.95\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/195:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/196:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.95\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/197:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/198:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/199:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/200:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/201:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/202:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.3\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/203:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "56/204:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/205:\n",
      "all_rewards = np.array(all_rewards)\n",
      "\n",
      "for chunk in np.split(all_rewards, 10):\n",
      "    print(sum(chunk))\n",
      "56/206:\n",
      "vis = 3\n",
      "\n",
      "for e in range(vis):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    print(f'*********** EPISODE {e+1} ***********\\n\\n\\n')\n",
      "    time.sleep(1)\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        clear_output(wait=True)\n",
      "        env.render()\n",
      "        time.sleep(0.3)\n",
      "        action = np.argmax(q_tab[state,])\n",
      "        new_state, reward, done, info = env.step(action)\n",
      "    \n",
      "        if done:\n",
      "            clear_output(wait=True)\n",
      "            env.render()\n",
      "            \n",
      "            if reward == 1:\n",
      "                print('Success!')\n",
      "                time.sleep(3)\n",
      "            else:\n",
      "                print('You fell through a hole!')\n",
      "                time.sleep(3)\n",
      "                \n",
      "            clear_output(wait=True)\n",
      "            break\n",
      "            \n",
      "        state = new_state\n",
      "        \n",
      "env.close()\n",
      "56/207:\n",
      "vis = 3\n",
      "\n",
      "for e in range(vis):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    print(f'*********** EPISODE {e+1} ***********\\n\\n\\n')\n",
      "    time.sleep(1)\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        clear_output(wait=True)\n",
      "        env.render()\n",
      "        time.sleep(0.3)\n",
      "        action = np.argmax(q_tab[state,])\n",
      "        new_state, reward, done, info = env.step(action)\n",
      "    \n",
      "        if done:\n",
      "            clear_output(wait=True)\n",
      "            env.render()\n",
      "            \n",
      "            if reward == 1:\n",
      "                print('Success!')\n",
      "                time.sleep(3)\n",
      "            else:\n",
      "                print('You fell through a hole!')\n",
      "                time.sleep(3)\n",
      "                \n",
      "            clear_output(wait=True)\n",
      "            break\n",
      "            \n",
      "        state = new_state\n",
      "        \n",
      "env.close()\n",
      "56/208:\n",
      "vis = 3\n",
      "\n",
      "for e in range(vis):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    print(f'*********** EPISODE {e+1} ***********\\n\\n\\n')\n",
      "    time.sleep(1)\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        clear_output(wait=True)\n",
      "        env.render()\n",
      "        time.sleep(0.3)\n",
      "        action = np.argmax(q_tab[state,])\n",
      "        new_state, reward, done, info = env.step(action)\n",
      "    \n",
      "        if done:\n",
      "            clear_output(wait=True)\n",
      "            env.render()\n",
      "            \n",
      "            if reward == 1:\n",
      "                print('Success!')\n",
      "                time.sleep(3)\n",
      "            else:\n",
      "                print('You fell through a hole!')\n",
      "                time.sleep(3)\n",
      "                \n",
      "            clear_output(wait=True)\n",
      "            break\n",
      "            \n",
      "        state = new_state\n",
      "        \n",
      "env.close()\n",
      "56/209:\n",
      "env = gym.make('Breakout-v0')\n",
      "env.render()\n",
      "56/210:\n",
      "episodes = 10000\n",
      "max_steps = 100\n",
      "\n",
      "learning_rate = 0.3\n",
      "discount_rate = 0.98\n",
      "\n",
      "exploration_rate = 1\n",
      "exploration_decay_rate = 0.001\n",
      "56/211:\n",
      "action_size = env.action_space.n\n",
      "state_size = env.observation_space.n\n",
      "q_tab = np.zeros((state_size, action_size))\n",
      "\n",
      "all_rewards = []\n",
      "\n",
      "for e in range(episodes):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    current_reward = 0\n",
      "    \n",
      "    for step in range(max_steps):\n",
      "        #explore or exploit?\n",
      "        explore_threshold = np.random.rand(1)\n",
      "        if explore_threshold > exploration_rate:\n",
      "            action = np.argmax(q_tab[state,])\n",
      "        else:\n",
      "            action = env.action_space.sample()\n",
      "        \n",
      "        new_state, reward, done, info = env.step(action)\n",
      "        \n",
      "        #update q-table\n",
      "        q_tab[state, action] = (1 - learning_rate) * q_tab[state, action] + \\\n",
      "                                learning_rate * (reward + discount_rate * q_tab[new_state,].max())\n",
      "        \n",
      "        state = new_state\n",
      "        current_reward += reward\n",
      "        \n",
      "        if done:\n",
      "            break\n",
      "            \n",
      "    if e == 7000:\n",
      "        exploration_rate = 0\n",
      "    all_rewards.append(current_reward)\n",
      "57/1:\n",
      "import csv\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "import time\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import torch.utils.data\n",
      "57/2:\n",
      "dat = []\n",
      "with open('trainaa') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for line in reader:\n",
      "        dat.append(line)\n",
      "dat = np.array(dat)\n",
      "dat = dat[np.all(dat != '', axis=1)]\n",
      "dat[:,2] = [a.replace(' UTC', '') for a in dat[:,2]]\n",
      "dat[:,2] = [time.mktime(time.strptime(b, \"%Y-%m-%d %H:%M:%S\")) for b in dat[:,2]]\n",
      "57/3:\n",
      "labels = dat[:,1]\n",
      "features = dat[:,2:]\n",
      "57/4:\n",
      "labels = np.array([float(a) for a in labels])\n",
      "features = np.array([[float(b) for b in row] for row in features])\n",
      "57/5: x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
      "57/6:\n",
      "x_train = torch.tensor(x_train)\n",
      "x_test = torch.tensor(x_test)\n",
      "y_train = torch.tensor(y_train)\n",
      "y_test = torch.tensor(y_test)\n",
      "57/7:\n",
      "batch_size = 64\n",
      "in_dim = 6\n",
      "out_dim = 1\n",
      "h1_dim = 128\n",
      "h2_dim = 512\n",
      "h3_dim = 64\n",
      "dropout = 0.3\n",
      "57/8:\n",
      "class NN(nn.Module):\n",
      "    def __init__(self, in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size):\n",
      "        super().__init__()\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=dropout)\n",
      "        self.fc1 = nn.Linear(in_dim, h1_dim)\n",
      "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
      "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
      "        self.out = nn.Linear(h3_dim, out_dim)\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.out(x)\n",
      "        return(x)\n",
      "57/9:\n",
      "model = NN(in_dim, out_dim, h1_dim, h2_dim, h3_dim, dropout, batch_size)\n",
      "print(model)\n",
      "if torch.cuda.is_available():\n",
      "    model = model.cuda()\n",
      "    print('Training on GPU')\n",
      "57/10:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 100)\n",
      "57/11:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "        \n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "    \n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "57/12:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "57/13:\n",
      "epochs = 3\n",
      "clip = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "57/14:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 500)\n",
      "57/15:\n",
      "batch_size = 32\n",
      "in_dim = 6\n",
      "out_dim = 1\n",
      "h1_dim = 128\n",
      "h2_dim = 512\n",
      "h3_dim = 64\n",
      "dropout = 0.3\n",
      "57/16:\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "57/17:\n",
      "epochs = 3\n",
      "clip = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0 \n",
      "    model.train()\n",
      "    for feature, label in train_loader:\n",
      "#         feature = feature.cuda()\n",
      "#         label = label.cuda()\n",
      "        optimizer.zero_grad()\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        loss.backward()\n",
      "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
      "        optimizer.step()\n",
      "        train_loss += loss.item()\n",
      "    scheduler.step()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for feature, label in test_loader:\n",
      "        pred = model.forward(feature.float())\n",
      "        loss = loss_fn(pred, label.float())\n",
      "        test_loss += loss.item()\n",
      "    \n",
      "    print(f'Epoch: {e}/{epochs}  |  Train loss: {train_loss:.6f}  |  Test loss: {test_loss:.6f}')\n",
      "58/1:\n",
      "from fastai.imports import *\n",
      "from fastai.transforms import *\n",
      "from fastai.model import *\n",
      "from fastai.datasets import *\n",
      "from fastai.sgdr import *\n",
      "from fastai.plots import *\n",
      "from fastai.conv_learner import *\n",
      "58/2: from fastai import *\n",
      "58/3:\n",
      "PATH='/Users/js/Desktop/datasets/flower_data'\n",
      "sz=224\n",
      "58/4:\n",
      "arch=resnet34\n",
      "data=ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn=ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 3)\n",
      "58/5:\n",
      "arch=vision.models.resnet34\n",
      "data=ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn=ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 3)\n",
      "58/6: from fastai.vision import *\n",
      "58/7:\n",
      "PATH='/Users/js/Desktop/datasets/flower_data'\n",
      "sz=224\n",
      "58/8:\n",
      "arch=vision.models.resnet34\n",
      "data=ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn=ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 3)\n",
      "58/9:\n",
      "arch=vision.models.resnet34\n",
      "data=ImageDataBunch.from_paths(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn=ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 3)\n",
      "58/10:\n",
      "arch=vision.models.resnet34\n",
      "data=ImageDataBunch.from_folder(PATH, tfms=tfms_from_model(arch, sz))\n",
      "learn=ConvLearner.pretrained(arch, data, precompute=True)\n",
      "learn.fit(0.01, 3)\n",
      "59/1: import networkx as nx\n",
      "59/2: from matplotlib import pyplot as plt\n",
      "59/3: import random\n",
      "59/4: G=nx.Graph()\n",
      "59/5:\n",
      "for i in range(50):\n",
      "    G.add_edge(random.randint(1, 20),random.randint(1, 20),weight=random.randint(1, 10))\n",
      "59/6: pos = nx.circular_layout(G)\n",
      "59/7: labels = nx.get_edge_attributes(G,'weight')\n",
      "59/8: nx.draw(G,with_labels=True,pos=pos)\n",
      "59/9: nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
      "59/10: print(nx.shortest_path(G, random.randint(1, 20), random.randint(1, 20)))\n",
      "59/11: plt.show()\n",
      "59/12: plt.show()\n",
      "59/13: nx.draw(G,with_labels=True,pos=pos)\n",
      "60/1:\n",
      "import random\n",
      "\n",
      "radicand = int(input())\n",
      "\n",
      "guess = random.randint(1, 100)\n",
      "\n",
      "for i in range(10):\n",
      "    guess = (guess + radicand/guess) / 2\n",
      "\n",
      "print(guess)\n",
      "60/2:\n",
      "import random\n",
      "\n",
      "radicand = int(input())\n",
      "\n",
      "guess = random.randint(1, 100)\n",
      "\n",
      "for i in range(100):\n",
      "    guess = (guess + radicand/guess) / 2\n",
      "\n",
      "print(guess)\n",
      "61/1: import torch\n",
      "61/2:\n",
      "import torch\n",
      "from torchvision import datasets, models, transforms\n",
      "61/3:\n",
      "tfms = transforms.Compose([\n",
      "    transforms.Resize(250),\n",
      "    transforms.TenCrop(224),\n",
      "    Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "dat = torchvision.datasets.ImageFolder('./downloads', transform=tfms)\n",
      "61/4:\n",
      "tfms = transforms.Compose([\n",
      "    transforms.Resize(250),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "dat = torchvision.datasets.ImageFolder('./downloads', transform=tfms)\n",
      "61/5:\n",
      "tfms = transforms.Compose([\n",
      "    transforms.Resize(250),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "dat = datasets.ImageFolder('./downloads', transform=tfms)\n",
      "61/6: dat\n",
      "61/7: next(iter(dat))\n",
      "61/8: len(dat)\n",
      "61/9: dat[0].shape\n",
      "61/10: len(dat[0])\n",
      "61/11:\n",
      "import torch\n",
      "import numpy as np\n",
      "from torchvision import datasets, models, transforms\n",
      "61/12:\n",
      "features = np.array([img[0] for img in dat])\n",
      "labels = np.array([img[1] for img in dat])\n",
      "61/13: features\n",
      "61/14: len(dat)\n",
      "61/15: len(dat) * 0.8\n",
      "61/16: int(len(dat) * 0.8)\n",
      "61/17:\n",
      "indices = list(range(len(dat)))\n",
      "\n",
      "\n",
      "train_size = 0.8\n",
      "\n",
      "train_sampler = int(train_size * len(dat))\n",
      "indices\n",
      "61/18:\n",
      "indices = list(range(len(dat)))\n",
      "np.random.shuffle(indices)\n",
      "train_size = 0.8\n",
      "\n",
      "train_sampler = int(train_size * len(dat))\n",
      "indices\n",
      "61/19:\n",
      "indices = list(range(len(dat)))\n",
      "np.random.shuffle(indices)\n",
      "\n",
      "train_size = 0.8\n",
      "split_idx = int(train_size * len(dat))\n",
      "\n",
      "train_idx, valid_idx = indices[split:], indices[:split]\n",
      "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
      "valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
      "61/20:\n",
      "indices = list(range(len(dat)))\n",
      "np.random.shuffle(indices)\n",
      "\n",
      "train_size = 0.8\n",
      "split_idx = int(train_size * len(dat))\n",
      "\n",
      "train_idx, valid_idx = indices[split_idx:], indices[:split_idx]\n",
      "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
      "valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
      "61/21: train_sampler\n",
      "61/22:\n",
      "trainloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=train_sampler)\n",
      "testloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=valid_sampler)\n",
      "61/23:\n",
      "batch_size = 8\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=train_sampler)\n",
      "testloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=valid_sampler)\n",
      "61/24: next(iter(trainloader))\n",
      "61/25: len(next(iter(trainloader)))\n",
      "61/26: next(iter(trainloader))[1]\n",
      "61/27: resnet = models.resnet152(pretrained=True)\n",
      "61/28:\n",
      "import torch\n",
      "import numpy as np\n",
      "from torchvision import datasets, models, transforms\n",
      "from sklearn.model_selection import train_test_split\n",
      "from torch import nn, optim\n",
      "61/29:\n",
      "model = resnet\n",
      "print(model)\n",
      "61/30: next(iter(trainloader))[0].shape\n",
      "61/31:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 32)\n",
      "        self.fc4 = nn.Linear(32, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "61/32:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 32)\n",
      "        self.fc4 = nn.Linear(32, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "print(model)\n",
      "61/33:\n",
      "model = resnet\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "print(model)\n",
      "61/34: resnet = models.resnet152(pretrained=True)\n",
      "61/35:\n",
      "model = resnet\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "print(model)\n",
      "61/36:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 32)\n",
      "        self.fc4 = nn.Linear(32, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "print(model)\n",
      "61/37:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "61/38:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "61/39:\n",
      "epochs = 3\n",
      "train_loss = 0\n",
      "train_correct = 0\n",
      "test_loss = 0\n",
      "test_correct = 0\n",
      "    print(f'Epoch: {e+1}/{epochs}\\n Training loss: {train_loss} | Testing loss: {test_loss}\\n Training accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/40:\n",
      "epochs = 3\n",
      "train_loss = 0\n",
      "train_correct = 0\n",
      "test_loss = 0\n",
      "test_correct = 0\n",
      "print(f'Epoch: {e+1}/{epochs}\\n Training loss: {train_loss} | Testing loss: {test_loss}\\n Training accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/41:\n",
      "epochs = 3\n",
      "train_loss = 0\n",
      "train_correct = 0\n",
      "test_loss = 0\n",
      "test_correct = 0\n",
      "print(f'Epoch: /{epochs}\\n Training loss: {train_loss} | Testing loss: {test_loss}\\n Training accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/42:\n",
      "epochs = 3\n",
      "train_loss = 0\n",
      "train_correct = 0\n",
      "test_loss = 0\n",
      "test_correct = 0\n",
      "train_acc = train_correct / len(trainloader)\n",
      "test_acc = test_correct / len(testloader)\n",
      "print(f'Epoch: /{epochs}\\n Training loss: {train_loss} | Testing loss: {test_loss}\\n Training accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/43:\n",
      "epochs = 3\n",
      "train_loss = 0\n",
      "train_correct = 0\n",
      "test_loss = 0\n",
      "test_correct = 0\n",
      "train_acc = train_correct / len(trainloader)\n",
      "test_acc = test_correct / len(testloader)\n",
      "print(f'Epoch: /{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/44:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if torch.round(result_averaged) == label:\n",
      "            train_correct += 1\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        if torch.round(result_averaged) == label:\n",
      "            test_correct += 1\n",
      "            \n",
      "    train_acc = train_correct / len(trainloader)\n",
      "    test_acc = test_correct / len(testloader)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/45:\n",
      "feature, label = next(iter(trainloader))\n",
      "batch, ncrops, channels, height, width = feature.shape\n",
      "result = model(feature.view(-1, channels, height, width))\n",
      "result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "61/46:\n",
      "print(result_averaged.shape)\n",
      "print(label.shape)\n",
      "61/47: print(result.shape)\n",
      "61/48: print(feature.shape)\n",
      "61/49: t = model(feature)\n",
      "61/50: feature.shape\n",
      "61/51: feature[0].shape\n",
      "61/52: a = model(feature[0])\n",
      "61/53: a\n",
      "61/54: a.shape\n",
      "61/55:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "print(model)\n",
      "61/56: a = model(feature[0])\n",
      "61/57: a.shape\n",
      "61/58: a.mean(1)\n",
      "61/59: a.mean(0)\n",
      "61/60:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if torch.round(result_averaged) == label:\n",
      "            train_correct += 1\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        if torch.round(result_averaged) == label:\n",
      "            test_correct += 1\n",
      "            \n",
      "    train_acc = train_correct / len(trainloader)\n",
      "    test_acc = test_correct / len(testloader)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/61:\n",
      "feature, label = next(iter(trainloader))\n",
      "batch, ncrops, channels, height, width = feature.shape\n",
      "result = model(feature.view(-1, channels, height, width))\n",
      "result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "61/62: result_averaged.shape\n",
      "61/63:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 1)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "print(model)\n",
      "61/64:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "61/65:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if torch.round(result_averaged) == label:\n",
      "            train_correct += 1\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        if torch.round(result_averaged) == label:\n",
      "            test_correct += 1\n",
      "            \n",
      "    train_acc = train_correct / len(trainloader)\n",
      "    test_acc = test_correct / len(testloader)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/66:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "print(model)\n",
      "61/67:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "61/68:\n",
      "feature, label = next(iter(trainloader))\n",
      "batch, ncrops, channels, height, width = feature.shape\n",
      "result = model(feature.view(-1, channels, height, width))\n",
      "result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "61/69: result_averaged.shape\n",
      "61/70: result_averaged\n",
      "61/71: result_averaged.max()\n",
      "61/72: result_averaged.max(dim=1)\n",
      "61/73: result_averaged.max(dim=1).exp()\n",
      "61/74: result_averaged.max(dim=1)\n",
      "61/75: result_averaged.max(dim=1)[0]\n",
      "61/76: result_averaged.max(dim=1)[0].exp()\n",
      "61/77: result_averaged.exp()\n",
      "61/78: result_averaged.exp().max(dim=0)\n",
      "61/79: result_averaged.exp().max(dim=1)\n",
      "61/80: result_averaged.exp()\n",
      "61/81: result_averaged.exp().max(dim=1)\n",
      "61/82: result_averaged.exp().max(dim=1)[0]\n",
      "61/83: result_averaged.exp().max(dim=1)\n",
      "61/84: result_averaged.exp().max(dim=1)[1]\n",
      "61/85:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if result_averaged.exp().max(dim=1)[1] == label:\n",
      "            train_correct += 1\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        if result_averaged.exp().max(dim=1)[1] == label:\n",
      "            test_correct += 1\n",
      "            \n",
      "    train_acc = train_correct / len(trainloader)\n",
      "    test_acc = test_correct / len(testloader)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/86: label\n",
      "61/87: result_averaged.exp().max(dim=1)[1] - label\n",
      "61/88: result_averaged.exp().max(dim=1)[1]\n",
      "61/89: result_averaged.exp().max(dim=1)[1]\n",
      "61/90: torch.eq(result_averaged.exp().max(dim=1)[1], label)\n",
      "61/91: result_averaged.exp().max(dim=1)[1]\n",
      "61/92: label\n",
      "61/93: torch.eq(result_averaged.exp().max(dim=1)[1], label).sum()\n",
      "61/94: torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "61/95:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(trainloader)\n",
      "    test_acc = test_correct / len(testloader)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/96: resnet = models.resnet50(pretrained=True)\n",
      "61/97:\n",
      "model = resnet\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "print(model)\n",
      "61/98:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "print(model)\n",
      "61/99:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "61/100:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(trainloader)\n",
      "    test_acc = test_correct / len(testloader)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/101:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "for param in model.fc.parameters():\n",
      "    param.requires_grad = True\n",
      "print(model)\n",
      "61/102:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "61/103:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(trainloader)\n",
      "    test_acc = test_correct / len(testloader)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/104: le(train_sampler)\n",
      "61/105: len(train_sampler)\n",
      "61/106: trainloader\n",
      "61/107: len(trainloader)\n",
      "61/108: len(testloader)\n",
      "61/109: train_sampler\n",
      "61/110: len(train_sampler)\n",
      "61/111:\n",
      "len(train_sampler)\n",
      "len(valid_sampler)\n",
      "61/112:\n",
      "indices = list(range(len(dat)))\n",
      "np.random.shuffle(indices)\n",
      "\n",
      "train_size = 0.2\n",
      "split_idx = int(train_size * len(dat))\n",
      "\n",
      "train_idx, test_idx = indices[split_idx:], indices[:split_idx]\n",
      "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
      "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
      "61/113:\n",
      "len(train_sampler)\n",
      "len(valid_sampler)\n",
      "61/114: len(train_sampler)\n",
      "61/115:\n",
      "len(train_sampler)\n",
      "len(test_sampler)\n",
      "61/116:\n",
      "len(train_sampler)\n",
      "len(test_sampler)\n",
      "len(dat)\n",
      "61/117:\n",
      "indices = list(range(len(dat)))\n",
      "np.random.shuffle(indices)\n",
      "\n",
      "test_size = 0.2\n",
      "split_idx = int(test_size * len(dat))\n",
      "\n",
      "train_idx, test_idx = indices[split_idx:], indices[:split_idx]\n",
      "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
      "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
      "61/118:\n",
      "indices = list(range(len(dat)))\n",
      "np.random.shuffle(indices)\n",
      "\n",
      "test_size = 0.2\n",
      "split_idx = int(test_size * len(dat))\n",
      "\n",
      "train_idx, test_idx = indices[split_idx:], indices[:split_idx]\n",
      "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
      "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
      "\n",
      "print(len(train_sampler))\n",
      "print(len(test_sampler))\n",
      "61/119:\n",
      "batch_size = 8\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=train_sampler)\n",
      "testloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=test_sampler)\n",
      "61/120: next(iter(trainloader))[0].shape\n",
      "61/121: resnet = models.resnet50(pretrained=True)\n",
      "61/122:\n",
      "model = resnet\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "print(model)\n",
      "61/123:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "for param in model.fc.parameters():\n",
      "    param.requires_grad = True\n",
      "print(model)\n",
      "61/124:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "61/125:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(trainloader)\n",
      "    test_acc = test_correct / len(testloader)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/126:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "61/127:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "61/128:\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = True\n",
      "61/129:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "62/1:\n",
      "import torch\n",
      "import numpy as np\n",
      "from torchvision import datasets, models, transforms\n",
      "from sklearn.model_selection import train_test_split\n",
      "from torch import nn, optim\n",
      "62/2:\n",
      "tfms = transforms.Compose([\n",
      "    transforms.Resize(250),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "dat = datasets.ImageFolder('./downloads', transform=tfms)\n",
      "62/3:\n",
      "indices = list(range(len(dat)))\n",
      "np.random.shuffle(indices)\n",
      "\n",
      "test_size = 0.2\n",
      "split_idx = int(test_size * len(dat))\n",
      "\n",
      "train_idx, test_idx = indices[split_idx:], indices[:split_idx]\n",
      "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
      "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
      "\n",
      "print(len(train_sampler))\n",
      "print(len(test_sampler))\n",
      "62/4:\n",
      "batch_size = 8\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=train_sampler)\n",
      "testloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=test_sampler)\n",
      "62/5: next(iter(trainloader))[0].shape\n",
      "62/6: resnet = models.resnet50(pretrained=True)\n",
      "62/7:\n",
      "model = resnet\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "print(model)\n",
      "62/8:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "for param in model.fc.parameters():\n",
      "    param.requires_grad = True\n",
      "print(model)\n",
      "62/9:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "62/10:\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = True\n",
      "62/11:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "63/1:\n",
      "import torch\n",
      "import numpy as np\n",
      "from torchvision import datasets, models, transforms\n",
      "from sklearn.model_selection import train_test_split\n",
      "from torch import nn, optim\n",
      "63/2:\n",
      "tfms = transforms.Compose([\n",
      "    transforms.Resize(250),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "dat = datasets.ImageFolder('./downloads', transform=tfms)\n",
      "63/3:\n",
      "indices = list(range(len(dat)))\n",
      "np.random.shuffle(indices)\n",
      "\n",
      "test_size = 0.2\n",
      "split_idx = int(test_size * len(dat))\n",
      "\n",
      "train_idx, test_idx = indices[split_idx:], indices[:split_idx]\n",
      "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
      "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
      "\n",
      "print(len(train_sampler))\n",
      "print(len(test_sampler))\n",
      "63/4:\n",
      "batch_size = 8\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=train_sampler)\n",
      "testloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=test_sampler)\n",
      "63/5: next(iter(trainloader))[0].shape\n",
      "63/6: resnet = models.resnet50(pretrained=True)\n",
      "63/7:\n",
      "model = resnet\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "print(model)\n",
      "63/8:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "for param in model.fc.parameters():\n",
      "    param.requires_grad = True\n",
      "print(model)\n",
      "63/9:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "63/10:\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = True\n",
      "63/11:\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "64/1:\n",
      "import torch\n",
      "import numpy as np\n",
      "from torchvision import datasets, models, transforms\n",
      "from sklearn.model_selection import train_test_split\n",
      "from torch import nn, optim\n",
      "64/2:\n",
      "tfms = transforms.Compose([\n",
      "    transforms.Resize(250),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "dat = datasets.ImageFolder('./downloads', transform=tfms)\n",
      "64/3:\n",
      "indices = list(range(len(dat)))\n",
      "np.random.shuffle(indices)\n",
      "\n",
      "test_size = 0.2\n",
      "split_idx = int(test_size * len(dat))\n",
      "\n",
      "train_idx, test_idx = indices[split_idx:], indices[:split_idx]\n",
      "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
      "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
      "\n",
      "print(len(train_sampler))\n",
      "print(len(test_sampler))\n",
      "64/4:\n",
      "batch_size = 8\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=train_sampler)\n",
      "testloader = torch.utils.data.DataLoader(dat, batch_size=batch_size, sampler=test_sampler)\n",
      "64/5: next(iter(trainloader))[0].shape\n",
      "64/6: resnet = models.resnet50(pretrained=True)\n",
      "64/7:\n",
      "model = resnet\n",
      "for param in model.parameters():\n",
      "    param.requires_grad = False\n",
      "print(model)\n",
      "64/8:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.lsm = nn.LogSigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "for param in model.fc.parameters():\n",
      "    param.requires_grad = True\n",
      "print(model)\n",
      "64/9:\n",
      "loss_fn = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "64/10:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "64/11:\n",
      "model.eval()\n",
      "feature, label = next(iter(testloader)):\n",
      "batch, ncrops, channels, height, width = feature.shape\n",
      "result = model(feature.view(-1, channels, height, width))\n",
      "result_averaged = result.view(batch, ncrops, -1).mean(-1)\n",
      "loss = loss_fn(result_averaged, label)\n",
      "print(loss.item())\n",
      "print(result_averaged.exp())\n",
      "print(label)\n",
      "64/12:\n",
      "model.eval()\n",
      "feature, label = next(iter(testloader))\n",
      "batch, ncrops, channels, height, width = feature.shape\n",
      "result = model(feature.view(-1, channels, height, width))\n",
      "result_averaged = result.view(batch, ncrops, -1).mean(-1)\n",
      "loss = loss_fn(result_averaged, label)\n",
      "print(loss.item())\n",
      "print(result_averaged.exp())\n",
      "print(label)\n",
      "64/13:\n",
      "model.eval()\n",
      "feature, label = next(iter(testloader))\n",
      "batch, ncrops, channels, height, width = feature.shape\n",
      "result = model(feature.view(-1, channels, height, width))\n",
      "result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "loss = loss_fn(result_averaged, label)\n",
      "print(loss.item())\n",
      "print(result_averaged.exp())\n",
      "print(label)\n",
      "64/14: model(feature)\n",
      "64/15: model(feature.view(-1, channels, height, width))\n",
      "64/16:\n",
      "output = model(feature.view(-1, channels, height, width))\n",
      "output = output.view(batch, ncrops, -1).mean(1).exp().max(dim=1)[1]\n",
      "64/17: output\n",
      "64/18:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.sig = nn.Sigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.sig(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "for param in model.fc.parameters():\n",
      "    param.requires_grad = True\n",
      "print(model)\n",
      "64/19:\n",
      "loss_fn = nn.BCELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "64/20:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "        loss = loss_fn(result_averaged, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_averaged.exp().max(dim=1)[1], label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "64/21:\n",
      "model.eval()\n",
      "feature, label = next(iter(testloader))\n",
      "batch, ncrops, channels, height, width = feature.shape\n",
      "result = model(feature.view(-1, channels, height, width))\n",
      "result_averaged = result.view(batch, ncrops, -1).mean(1)\n",
      "loss = loss_fn(result_averaged, label)\n",
      "print(loss.item())\n",
      "print(result_averaged.exp())\n",
      "print(label)\n",
      "64/22: output = model(feature.view(-1, channels, height, width))\n",
      "64/23: output\n",
      "64/24: output.shape\n",
      "64/25: output.view(batch, ncrops, -1)\n",
      "64/26: output.view(batch, ncrops, -1).shape\n",
      "64/27: output.view(batch, ncrops, -1).mean(1)\n",
      "64/28: output.view(batch, ncrops, -1).mean(1).max(dim=1)[1]\n",
      "64/29: output.view(batch, ncrops, -1).mean(1)\n",
      "64/30: label\n",
      "64/31:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "64/32:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1]        \n",
      "        loss = loss_fn(result_finalized, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_finalized, label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1]        \n",
      "        loss = loss_fn(result_finalized, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_finalized, label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "64/33:\n",
      "loss_fn = nn.BCELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "64/34:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1]        \n",
      "        loss = loss_fn(result_finalized, label)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_finalized, label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1]        \n",
      "        loss = loss_fn(result_finalized, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_finalized, label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "64/35:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1]        \n",
      "        loss = loss_fn(result_finalized, label.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_finalized, label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1]        \n",
      "        loss = loss_fn(result_finalized, label.float())\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_finalized, label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "64/36:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float()  \n",
      "        loss = loss_fn(result_finalized, label.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_finalized, label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float()\n",
      "        loss = loss_fn(result_finalized, label.float())\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_finalized, label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "64/37:\n",
      "model.eval()\n",
      "feature, label = next(iter(testloader))\n",
      "batch, ncrops, channels, height, width = feature.shape\n",
      "result = model(feature.view(-1, channels, height, width))\n",
      "result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float()\n",
      "loss = loss_fn(result_finalized, label.float())\n",
      "print(loss.item())\n",
      "64/38: loss\n",
      "64/39: loss.backward()\n",
      "64/40:\n",
      "model.eval()\n",
      "feature, label = next(iter(testloader))\n",
      "batch, ncrops, channels, height, width = feature.shape\n",
      "result = model(feature.view(-1, channels, height, width))\n",
      "result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float()\n",
      "loss = loss_fn(result_finalized, label)\n",
      "print(loss)\n",
      "64/41:\n",
      "class net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(2048, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 256)\n",
      "        self.fc3 = nn.Linear(256, 2)\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.sig = nn.Sigmoid()\n",
      "    \n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.sig(x)\n",
      "        return(x)\n",
      "\n",
      "clf = net()\n",
      "model.fc = clf\n",
      "for param in model.fc.parameters():\n",
      "    param.requires_grad = True\n",
      "print(model)\n",
      "64/42:\n",
      "loss_fn = nn.BCELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 10)\n",
      "64/43:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float()  \n",
      "        loss = loss_fn(result_finalized, label.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_finalized, label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float()\n",
      "        loss = loss_fn(result_finalized, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_finalized, label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "64/44:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = torch.tensor(output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float(), requires_grad=True)\n",
      "        loss = loss_fn(result_finalized, label.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_finalized, label).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = torch.tensor(output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float(), requires_grad=True)\n",
      "        loss = loss_fn(result_finalized, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_finalized, label).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "64/45: result_finalized\n",
      "64/46: label\n",
      "64/47: torch.eq(result_finalized, label)\n",
      "64/48: torch.eq(result_finalized, label.float())\n",
      "64/49:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    \n",
      "    scheduler.step()\n",
      "    model.train()\n",
      "    train_loss = 0\n",
      "    train_correct = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = torch.tensor(output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float(), requires_grad=True)\n",
      "        loss = loss_fn(result_finalized, label.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        train_correct += torch.eq(result_finalized, label.float()).sum().item()\n",
      "\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    test_correct = 0\n",
      "    for feature, label in testloader:\n",
      "        batch, ncrops, channels, height, width = feature.shape\n",
      "        result = model(feature.view(-1, channels, height, width))\n",
      "        result_finalized = torch.tensor(output.view(batch, ncrops, -1).mean(1).max(dim=1)[1].float(), requires_grad=True)\n",
      "        loss = loss_fn(result_finalized, label)\n",
      "        test_loss += loss.item()\n",
      "        test_correct += torch.eq(result_finalized, label.float()).sum().item()\n",
      "            \n",
      "    train_acc = train_correct / len(train_sampler)\n",
      "    test_acc = test_correct / len(test_sampler)\n",
      "    print(f'Epoch: {e+1}/{epochs}\\nTraining loss: {train_loss} | Testing loss: {test_loss}\\nTraining accuracy: {train_acc} | Testing accuracy: {test_acc}\\n\\n')\n",
      "65/1:\n",
      "def verbosity(self, y: int) -> int:\n",
      "        \"\"\"Return the number of characters in this User's tweets in year <y>.\n",
      "\n",
      "        >>> u1 = User('Rukhsana', 'Roller coaster fanatic')\n",
      "        >>> u1.tweet('The comet!!')\n",
      "        >>> u1.tweet('Leviathan!!!!!')\n",
      "        >>> u1.verbosity(date.today().year)\n",
      "        25\n",
      "        >>> u1.verbosity(2015)\n",
      "        0\n",
      "        \"\"\"\n",
      "        # Hint: look up the attributes of date, found here:\n",
      "        # https://docs.python.org/3/library/datetime.html#date-objects\n",
      "        for t in self.tweets:\n",
      "            if i.created_at.year == y:\n",
      "                return(len(i.content))\n",
      "67/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "import csv\n",
      "67/2:\n",
      "import numpy as np\n",
      "import torch\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "67/3:\n",
      "ratings = csv.reader('./ratings.csv')\n",
      "ratings\n",
      "67/4:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "    return(reader)\n",
      "67/5: ratings = open_file('./ratings.csv')\n",
      "67/6: ratings\n",
      "67/7:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = list(csv.reader(f))\n",
      "    return(reader)\n",
      "67/8: ratings = open_file('./ratings.csv')\n",
      "67/9: ratings\n",
      "67/10:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        next(reader)\n",
      "        dat = list(reader)\n",
      "    return(reader)\n",
      "67/11: ratings = open_file('./ratings.csv')\n",
      "67/12: ratings\n",
      "67/13: ratings\n",
      "67/14:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        next(reader)\n",
      "        dat = list(reader)\n",
      "    return(reader)\n",
      "67/15: ratings = open_file('./ratings.csv')\n",
      "67/16: ratings\n",
      "67/17:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        next(reader)\n",
      "        dat = list(reader)\n",
      "    return(dat)\n",
      "67/18: ratings = open_file('./ratings.csv')\n",
      "67/19: ratings\n",
      "67/20:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        labs = next(reader)\n",
      "        dat = np.array(reader)\n",
      "    return(labs, dat)\n",
      "67/21: rating_labels, ratings = open_file('./ratings.csv')\n",
      "67/22:\n",
      "print(rating_labels)\n",
      "print(ratings)\n",
      "67/23:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        labs = next(reader)\n",
      "        dat = np.array(list(reader))\n",
      "    return(labs, dat)\n",
      "67/24: rating_labels, ratings = open_file('./ratings.csv')\n",
      "67/25:\n",
      "print(rating_labels)\n",
      "print(ratings)\n",
      "67/26:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "67/27:\n",
      "print(rating_labels)\n",
      "print(ratings[:5])\n",
      "67/28:\n",
      "print(rating_labels + '\\n')\n",
      "print(ratings[:5])\n",
      "67/29:\n",
      "print(rating_labels, '\\n')\n",
      "print(ratings[:5])\n",
      "67/30:\n",
      "print(movie_labels, '\\n')\n",
      "print(movies[:5])\n",
      "67/31: ratings[1]\n",
      "67/32: ratings[:,1]\n",
      "67/33: ratings[:,0]\n",
      "67/34: set(ratings[:,0])\n",
      "67/35: len(set(ratings[:,0]))\n",
      "67/36:\n",
      "num_users = len(set(ratings[:,0]))\n",
      "num_movies = len(set(movies[:,0]))\n",
      "67/37:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(movies[:,0])); print(num_movies)\n",
      "67/38: rate_matrix = np.zeros((num_users, num_movies))\n",
      "67/39: rate_matrix\n",
      "67/40: rate_matrix.shape\n",
      "67/41:\n",
      "for row in ratings:\n",
      "    rate_matrix[row[0], row[1]] = row[2]\n",
      "67/42:\n",
      "for row in ratings[:5]:\n",
      "    print([row[0], row[1], row[2])\n",
      "67/43:\n",
      "for row in ratings[:5]:\n",
      "    print(row[0], row[1], row[2])\n",
      "67/44:\n",
      "for row in ratings[:5]:\n",
      "    print(type(row[0]), row[1], row[2])\n",
      "67/45: ratings\n",
      "67/46: ratings.astype(float)\n",
      "67/47: ratings.astype(int)\n",
      "67/48: ratings.astype(float)\n",
      "67/49:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "\n",
      "ratings = ratings.astype(float)\n",
      "67/50:\n",
      "print(rating_labels, '\\n')\n",
      "print(ratings[:5])\n",
      "67/51:\n",
      "print(movie_labels, '\\n')\n",
      "print(movies[:5])\n",
      "67/52:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(movies[:,0])); print(num_movies)\n",
      "67/53: rate_matrix = np.zeros((num_users, num_movies))\n",
      "67/54:\n",
      "for row in ratings:\n",
      "    rate_matrix[row[0], row[1]] = row[2]\n",
      "67/55: ratings.astype(float).astype(int)\n",
      "67/56: ratings\n",
      "67/57: ratings[:,:1]\n",
      "67/58: ratings[:,(0,1)]\n",
      "67/59: ratings[:,[0,1]]\n",
      "67/60: ratings[:,[0,1]].astype(int)\n",
      "67/61:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "\n",
      "ratings[:,[0,1]] = ratings[:,[0,1]].astype(int)\n",
      "67/62:\n",
      "print(rating_labels, '\\n')\n",
      "print(ratings[:5])\n",
      "67/63:\n",
      "print(rating_labels, '\\n')\n",
      "print(ratings[:5])\n",
      "67/64: ratings[:,[0,1]].astype(int)\n",
      "67/65: ratings[:,[0,1]]\n",
      "67/66: ratings[:,[0,1]] = ratings[:,[0,1]].astype(int)\n",
      "67/67: ratings[:,[0,1]]\n",
      "67/68: ratings[:,(0,1)]\n",
      "67/69: ratings[:,(0,1)].astype(int)?\n",
      "67/70: ratings[:,(0,1)].astype(int)\n",
      "67/71: ratings[:,(0,1)] = ratings[:,(0,1)].astype(int)\n",
      "67/72: ratings\n",
      "67/73: np.concatenate(ratings[:,(0,1)].astype(int), ratings[:,(2,3)])\n",
      "67/74: np.concatenate([ratings[:,(0,1)].astype(int), ratings[:,(2,3)]])\n",
      "67/75: np.concatenate([ratings[:,(0,1)].astype(int), ratings[:,(2,3)]], axis=1)\n",
      "67/76: np.concatenate([ratings[:,(0,1)].astype(np.int), ratings[:,(2,3)]], axis=1)\n",
      "67/77: np.concatenate([ratings[:,(0,1)].astype(np.int), ratings[:,(2,3)]], axis=1, dtype='m')\n",
      "67/78: ratings\n",
      "67/79:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "\n",
      "# ratings[:,[0,1]] = ratings[:,[0,1]].astype(int) #doesnt work??? probably something to do with handling of mixed data types\n",
      "67/80:\n",
      "print(rating_labels, '\\n')\n",
      "print(ratings[:5])\n",
      "67/81:\n",
      "print(movie_labels, '\\n')\n",
      "print(movies[:5])\n",
      "67/82:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(movies[:,0])); print(num_movies)\n",
      "67/83: rate_matrix = np.zeros((num_users, num_movies))\n",
      "67/84:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0]), int(row[1])] = row[2]\n",
      "67/85: ratings[:,1]\n",
      "67/86: set(ratings[:,1])\n",
      "67/87: sorted(set(ratings[:,1]))\n",
      "67/88: sorted(set(ratings[:,1]), key=max)\n",
      "67/89: sorted(set(ratings[:,1]), key=lambda x: max(x))\n",
      "67/90: sorted(set(ratings[:,1]))\n",
      "67/91: sorted(set(ratings[:,1]), lambda x: x)\n",
      "67/92: sorted(set(ratings[:,1]), key=lambda x: x)\n",
      "67/93: sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "67/94: sorted(set(ratings[:,1]), key=lambda x: int(x), reverse=True)\n",
      "67/95: movies\n",
      "67/96: movies[:,0]\n",
      "67/97: len(movies[:,0])\n",
      "67/98: movies[0]\n",
      "67/99: movies[:,0]\n",
      "67/100: sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "67/101: print(ratings[:0])\n",
      "67/102: print(ratings[:,0])\n",
      "67/103: print(set(ratings[:,0]))\n",
      "67/104: print(sorted(set(ratings[:,0])))\n",
      "67/105: print(sorted(set(ratings[:,0]), lambda x: int(x)))\n",
      "67/106: print(sorted(set(ratings[:,0]), key=lambda x: int(x)))\n",
      "67/107: movie_ids = sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "67/108:\n",
      "movie_ids = sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "movie_ids\n",
      "67/109:\n",
      "movie_ids = sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "old_new_movie_ids = {j:i for i,j in enumerate(movie_ids)}\n",
      "old_new_movie_ids\n",
      "67/110: movies[:,0]\n",
      "67/111: old_new_movie_ids.get(movies[:,0])\n",
      "67/112: old_new_movie_ids[(movies[:,0])]\n",
      "67/113: old_new_movie_ids[movies[:,0]]\n",
      "67/114: new_ = list(map(old_new_movie_ids.get, movies[:,0]))\n",
      "67/115:\n",
      "new_ = list(map(old_new_movie_ids.get, movies[:,0]))\n",
      "new_\n",
      "67/116:\n",
      "new_ = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "new_\n",
      "67/117:\n",
      "new_ = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "len(new_)\n",
      "67/118:\n",
      "new_ = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "new_\n",
      "67/119:\n",
      "new_ = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "set(new_)\n",
      "67/120:\n",
      "new_ = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "len(set(new_))\n",
      "67/121: movies[:,0] = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "67/122: movies\n",
      "67/123: ratings\n",
      "67/124:\n",
      "import numpy as np\n",
      "import torch\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "67/125:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        labs = next(reader)\n",
      "        dat = np.array(list(reader))\n",
      "    return(labs, dat)\n",
      "67/126:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "\n",
      "# ratings[:,[0,1]] = ratings[:,[0,1]].astype(int) #doesnt work??? probably something to do with handling of mixed data types\n",
      "67/127:\n",
      "print(rating_labels, '\\n')\n",
      "print(ratings[:5])\n",
      "67/128:\n",
      "print(movie_labels, '\\n')\n",
      "print(movies[:5])\n",
      "67/129:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(movies[:,0])); print(num_movies)\n",
      "67/130:\n",
      "movie_ids = sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "old_new_movie_ids = {j:i for i,j in enumerate(movie_ids)}\n",
      "movies[:,0] = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "ratings[:,1] = np.array(list(map(old_new_movie_ids.get, ratings[:,1])))\n",
      "67/131: rate_matrix = np.zeros((num_users, num_movies))\n",
      "67/132: ratings\n",
      "67/133: movies\n",
      "67/134:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0]), int(row[1])] = row[2]\n",
      "67/135: rate_matrix.shape\n",
      "67/136: movies[:,5]\n",
      "67/137: movies\n",
      "67/138: ratings\n",
      "67/139:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0]-1), int(row[1])] = row[2]\n",
      "67/140:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0])-1, int(row[1])] = row[2]\n",
      "67/141: rate_matrix\n",
      "67/142:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "67/143:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import nn.functional as F\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "67/144:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import torch.nn.functional as F\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "67/145:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform(torch.zeros(1, num_movies, requires_grad=True))\n",
      "\n",
      "    def forward(self):\n",
      "        out = self.drop(torch.mm(user_embed, movie_embed) + user_bias + movie_bias)\n",
      "        out = F.sigmoid(out)\n",
      "        return(out * 5)\n",
      "67/146:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "t\n",
      "67/147:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "\n",
      "    def forward(self):\n",
      "        out = self.drop(torch.mm(user_embed, movie_embed) + user_bias + movie_bias)\n",
      "        out = F.sigmoid(out)\n",
      "        return(out * 5)\n",
      "67/148:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "t\n",
      "67/149:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "print(t)\n",
      "67/150: t.forward()\n",
      "67/151:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "\n",
      "        self.drop = nn.Dropout(p=0.7)\n",
      "        \n",
      "    def forward(self):\n",
      "        out = self.drop(torch.mm(user_embed, movie_embed) + user_bias + movie_bias)\n",
      "        out = F.sigmoid(out)\n",
      "        return(out * 5)\n",
      "67/152:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "print(t)\n",
      "67/153: t.forward()\n",
      "67/154:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "\n",
      "        self.drop = nn.Dropout(p=0.7)\n",
      "        \n",
      "    def forward(self):\n",
      "        out = self.drop(torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias)\n",
      "        out = F.sigmoid(out)\n",
      "        return(out * 5)\n",
      "67/155:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "print(t)\n",
      "67/156: t.forward()\n",
      "67/157:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "\n",
      "        self.drop = nn.Dropout(p=0.7)\n",
      "        \n",
      "    def forward(self):\n",
      "        out = self.drop(torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias)\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "67/158:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "print(t)\n",
      "67/159: t.forward()\n",
      "67/160:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "67/161: min(t.forward())\n",
      "67/162: t.forward().min()\n",
      "67/163: t.forward().max()\n",
      "67/164: t.forward()\n",
      "67/165: t.forward()\n",
      "67/166: t.forward()\n",
      "67/167:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "        \n",
      "    def forward(self):\n",
      "        out = torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "67/168:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "print(t)\n",
      "67/169: t.forward()\n",
      "67/170: t.forward().min()\n",
      "67/171: t.forward().max()\n",
      "67/172: t.forward()\n",
      "67/173: rate_matrix\n",
      "67/174: np.count_nonzero(rate_matrix==0)\n",
      "67/175: rate_matrix.shape\n",
      "67/176: 610*9742\n",
      "67/177: np.count_nonzero(rate_matrix!=0)\n",
      "67/178:\n",
      "class testnet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "        \n",
      "    def forward(self):\n",
      "        out = torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "67/179:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "print(t)\n",
      "67/180: t = testnet(num_users, num_movies, 50)\n",
      "67/181:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "t\n",
      "67/182:\n",
      "t = testnet(num_users, num_movies, 50).cpu()\n",
      "t\n",
      "67/183:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "        \n",
      "    def forward(self):\n",
      "        out = torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "67/184:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "t\n",
      "67/185:\n",
      "loss_fn = nn.MSELoss()\n",
      "optim = optim.Adam(t, lr=1e-2)\n",
      "67/186:\n",
      "loss_fn = nn.MSELoss()\n",
      "optim = optim.Adam([t.user_embed, t.movie_embed, t.user_bias, t.movie_bias], lr=1e-2)\n",
      "67/187: t.__dict__\n",
      "67/188: t.__dict__.keys()\n",
      "67/189: t.__dict__.vals()\n",
      "67/190: t.__dict__.values()\n",
      "67/191: t.__dict__.get()\n",
      "67/192: t.__dict__\n",
      "67/193: t.__dict__.values()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/194: list(t.__dict__.values())\n",
      "67/195: (x for x in t.__dict__.values())\n",
      "67/196: next(iter((x for x in t.__dict__.values())))\n",
      "67/197: list(x for x in t.__dict__.values())\n",
      "67/198: [list(]x for x in t.__dict__.values()]\n",
      "67/199: []x for x in t.__dict__.values()]\n",
      "67/200: [x for x in t.__dict__.values()]\n",
      "67/201:\n",
      "loss_fn = nn.MSELoss()\n",
      "optim = optim.Adam([x for x in t.__dict__.values()], lr=1e-2)\n",
      "67/202:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam([x for x in t.__dict__.values()], lr=1e-2)\n",
      "67/203:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "67/204:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam([x for x in t.__dict__.values()], lr=1e-2)\n",
      "67/205: t()\n",
      "67/206: t.forward()\n",
      "67/207: t.forward().shape\n",
      "67/208: rate_matrix.shape\n",
      "67/209:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(running_loss)\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fnn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "67/210:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(running_loss)\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "67/211: torch.tensor(rate_matrix)\n",
      "67/212: torch.tensor_(rate_matrix)\n",
      "67/213: rate_matrix = torch.tensor(rate_matrix)\n",
      "67/214: rate_matrix = torch.zeros((num_users, num_movies))\n",
      "67/215:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0])-1, int(row[1])] = row[2]\n",
      "67/216: rate_matrix = np.zeros((num_users, num_movies))\n",
      "67/217:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0])-1, int(row[1])] = row[2]\n",
      "67/218:\n",
      "rate_matrix = torch.tensor(rate_matrix)\n",
      "print(rate_matrix)\n",
      "67/219:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(running_loss)\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "67/220: rate_matrix\n",
      "67/221: rate_matrix.float()\n",
      "67/222:\n",
      "rate_matrix = torch.tensor(rate_matrix).float()\n",
      "print(rate_matrix)\n",
      "67/223:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(running_loss)\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "67/224:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(loss.item())\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "67/225: t.forward()\n",
      "67/226: t.forward().int()\n",
      "67/227: t.forward()\n",
      "67/228: t.forward().round()\n",
      "67/229: rate_matrix\n",
      "67/230: rate_matrix.int()\n",
      "67/231: rate_matrix.round()\n",
      "67/232: t.forward().round() - rate_matrix.round()\n",
      "67/233: t.forward().round() - rate_matrix.round().sum()\n",
      "67/234: t.forward().round() - rate_matrix.round()\n",
      "67/235: (t.forward().round() - rate_matrix.round()).abs()\n",
      "67/236: (t.forward().round() - rate_matrix.round()).abs().sum()\n",
      "67/237: (t.forward().round() - rate_matrix.round()).abs().sum() / (num_movies*num_users)\n",
      "67/238:\n",
      "rate_matrix = np.empty((num_users, num_movies))\n",
      "rate_matrix[:] = np.nan\n",
      "67/239:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0])-1, int(row[1])] = row[2]\n",
      "67/240: rate_matrix\n",
      "67/241:\n",
      "def c_loss(pred, label):\n",
      "    running_loss = 0\n",
      "    diff = pred - label\n",
      "    sq = diff ** 2\n",
      "    nx, ny = np.where(np.isnan(sq) == 0)\n",
      "    for i in range(len(nx)):\n",
      "        running_loss += sq[nx[i]][ny[i]]\n",
      "    return(running_loss)\n",
      "67/242:\n",
      "def c_loss(pred, label):\n",
      "    running_loss = 0\n",
      "    diff = pred - label\n",
      "    sq = diff ** 2\n",
      "    nx, ny = np.where(np.isnan(sq) == 0)\n",
      "    for i in range(len(nx)):\n",
      "        running_loss += sq[nx[i]][ny[i]]\n",
      "    return(running_loss / len(nx))\n",
      "67/243:\n",
      "loss_fn = c_loss\n",
      "optimizer = optim.Adam([x for x in t.__dict__.values()], lr=1e-2)\n",
      "67/244:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(loss.item())\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "67/245:\n",
      "print(movie_labels, '\\n')\n",
      "print(movies[:5])\n",
      "67/246:\n",
      "rate_matrix = torch.empty((num_users, num_movies))\n",
      "rate_matrix[:] = np.nan\n",
      "67/247:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0])-1, int(row[1])] = row[2]\n",
      "67/248:\n",
      "rate_matrix = np.empty((num_users, num_movies))\n",
      "rate_matrix[:] = np.nan\n",
      "67/249:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0])-1, int(row[1])] = row[2]\n",
      "67/250:\n",
      "rate_matrix = torch.tensor(rate_matrix).float()\n",
      "print(rate_matrix)\n",
      "67/251:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "        \n",
      "    def forward(self):\n",
      "        out = torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "67/252:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "t\n",
      "67/253:\n",
      "def c_loss(pred, label):\n",
      "    running_loss = 0\n",
      "    diff = pred - label\n",
      "    sq = diff ** 2\n",
      "    nx, ny = np.where(np.isnan(sq) == 0)\n",
      "    for i in range(len(nx)):\n",
      "        running_loss += sq[nx[i]][ny[i]]\n",
      "    return(running_loss / len(nx))\n",
      "67/254:\n",
      "loss_fn = c_loss\n",
      "optimizer = optim.Adam([x for x in t.__dict__.values()], lr=1e-2)\n",
      "67/255:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(loss.item())\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "67/256:\n",
      "def c_loss(pred, label):\n",
      "    running_loss = 0\n",
      "    diff = pred - label\n",
      "    sq = diff ** 2\n",
      "    nx, ny = torch.where(torch.isnan(sq) == 0)\n",
      "    for i in range(len(nx)):\n",
      "        running_loss += sq[nx[i]][ny[i]]\n",
      "    return(running_loss / len(nx))\n",
      "67/257:\n",
      "loss_fn = c_loss\n",
      "optimizer = optim.Adam([x for x in t.__dict__.values()], lr=1e-2)\n",
      "67/258:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(loss.item())\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "67/259:\n",
      "def c_loss(pred, label):\n",
      "    running_loss = 0\n",
      "    diff = pred - label\n",
      "    sq = diff ** 2\n",
      "    n = torch.nonzero(torch.isnan(sq))\n",
      "    nx, ny = n[:,0], n[:,1]\n",
      "    for i in range(len(nx)):\n",
      "        running_loss += sq[nx[i]][ny[i]]\n",
      "    return(running_loss / len(nx))\n",
      "67/260:\n",
      "loss_fn = c_loss\n",
      "optimizer = optim.Adam([x for x in t.__dict__.values()], lr=1e-2)\n",
      "67/261:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(loss.item())\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "68/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "68/2:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        labs = next(reader)\n",
      "        dat = np.array(list(reader))\n",
      "    return(labs, dat)\n",
      "68/3:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "\n",
      "# ratings[:,[0,1]] = ratings[:,[0,1]].astype(int) #doesnt work??? probably something to do with handling of mixed data types\n",
      "68/4:\n",
      "print(rating_labels, '\\n')\n",
      "print(ratings[:5])\n",
      "68/5:\n",
      "print(movie_labels, '\\n')\n",
      "print(movies[:5])\n",
      "68/6:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(movies[:,0])); print(num_movies)\n",
      "68/7:\n",
      "movie_ids = sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "old_new_movie_ids = {j:i for i,j in enumerate(movie_ids)}\n",
      "movies[:,0] = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "ratings[:,1] = np.array(list(map(old_new_movie_ids.get, ratings[:,1])))\n",
      "68/8:\n",
      "rate_matrix = np.empty((num_users, num_movies))\n",
      "rate_matrix[:] = np.nan\n",
      "68/9:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0])-1, int(row[1])] = row[2]\n",
      "68/10:\n",
      "rate_matrix = torch.tensor(rate_matrix).float()\n",
      "print(rate_matrix)\n",
      "68/11:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "        \n",
      "    def forward(self):\n",
      "        out = torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/12:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "print(testnet)\n",
      "68/13:\n",
      "def c_loss(pred, label):\n",
      "    diff = pred - label\n",
      "    sq = diff ** 2\n",
      "    mask = ~ torch.isnan(sq)\n",
      "    n_items = mask.sum()\n",
      "    loss = torch.masked_select(sq, mask).sum()\n",
      "    return(loss / n_items)\n",
      "68/14:\n",
      "loss_fn = c_loss\n",
      "optimizer = optim.Adam([x for x in t.__dict__.values()], lr=1e-2)\n",
      "68/15:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e % 100 == 0:\n",
      "        print(loss.item())\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "68/16:\n",
      "running_loss = 0\n",
      "for e in range(1000):\n",
      "    if e+1 % 100 == 0:\n",
      "        print(loss.item())\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "68/17: t.forward()\n",
      "68/18: t.movie_embed\n",
      "68/19:\n",
      "class testnet:\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        self.user_embed = nn.init.xavier_uniform_(torch.zeros(num_users, num_features, requires_grad=True))\n",
      "        self.movie_embed = nn.init.xavier_uniform_(torch.zeros(num_features, num_movies, requires_grad=True))\n",
      "        \n",
      "        self.user_bias = nn.init.xavier_uniform_(torch.zeros(num_users, 1, requires_grad=True))\n",
      "        self.movie_bias = nn.init.xavier_uniform_(torch.zeros(1, num_movies, requires_grad=True))\n",
      "        \n",
      "    def forward(self):\n",
      "        out = torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/20:\n",
      "t = testnet(num_users, num_movies, 50)\n",
      "print(testnet)\n",
      "68/21: t.movie_embed\n",
      "68/22: t.forward()\n",
      "68/23: rate_matrix\n",
      "68/24: c_loss(t.forward, rate_matrix)\n",
      "68/25: c_loss(t.forward(), rate_matrix)\n",
      "68/26: l = c_loss(t.forward(), rate_matrix)\n",
      "68/27: l.backward()\n",
      "68/28: t.movie_embed\n",
      "68/29: t.user_embed\n",
      "68/30: t.user_bias\n",
      "68/31: optimizer.step()\n",
      "68/32: t.movie_embed\n",
      "68/33: optimizer.zero_grad()\n",
      "68/34: optimizer.state\n",
      "68/35: optimizer.zero_grad()\n",
      "68/36: l = c_loss(t.forward(), rate_matrix)\n",
      "68/37: l.backward()\n",
      "68/38: t.movie_embed\n",
      "68/39:\n",
      "print(t.movie_embed)\n",
      "print(t.user_embed)\n",
      "68/40: optimizer.step()\n",
      "68/41:\n",
      "print(t.movie_embed)\n",
      "print(t.user_embed)\n",
      "68/42: optimizer.zero_grad()\n",
      "68/43:\n",
      "print(t.movie_embed)\n",
      "print(t.user_embed)\n",
      "68/44: l = c_loss(t.forward(), rate_matrix)\n",
      "68/45:\n",
      "print(t.movie_embed)\n",
      "print(t.user_embed)\n",
      "68/46: l.backward()\n",
      "68/47:\n",
      "print(t.movie_embed)\n",
      "print(t.user_embed)\n",
      "68/48:\n",
      "print(t.movie_embed)\n",
      "print(t.user_embed)\n",
      "68/49: l.item()\n",
      "68/50: optimizer.step()\n",
      "68/51: optimizer.zero_grad()\n",
      "68/52: l = c_loss(t.forward(), rate_matrix)\n",
      "68/53: l.item()\n",
      "68/54: l.backward()\n",
      "68/55: l.item()\n",
      "68/56: l.backward()\n",
      "68/57:\n",
      "print(t.movie_embed)\n",
      "print(t.user_embed)\n",
      "68/58: optimizer.step()\n",
      "68/59:\n",
      "running_loss = 0\n",
      "for e in range(100):\n",
      "    if e+1 % 10 == 0:\n",
      "        print(loss.item())\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    running_loss += loss.item()\n",
      "    optimizer.step()\n",
      "68/60: t.__dict__.values()\n",
      "68/61: t.__dict__\n",
      "68/62:\n",
      "for e in range(100):\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % 10 == 0:\n",
      "        print(loss.item())\n",
      "68/63: t.__dict__\n",
      "68/64: t.forward()\n",
      "68/65: l = c_loss(t.forward(), rate_matrix)\n",
      "68/66: l.item()\n",
      "68/67: l\n",
      "68/68:\n",
      "loss_fn = c_loss\n",
      "optimizer = optim.SparseAdam([x for x in t.__dict__.values()], lr=1e-2)\n",
      "68/69:\n",
      "for e in range(100):\n",
      "    optimizer.zero_grad()\n",
      "    output = t.forward()\n",
      "    loss = loss_fn(output, rate_matrix)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % 10 == 0:\n",
      "        print(loss.item())\n",
      "68/70:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, n_users, n_movies, n_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_features, num_movies)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(1, num_movies)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self):\n",
      "        out = torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/71:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "68/72:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_features, num_movies)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(1, num_movies)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self):\n",
      "        out = torch.mm(self.user_embed, self.movie_embed) + self.user_bias + self.movie_bias\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/73:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "68/74: model()\n",
      "68/75: model.forward()\n",
      "68/76:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_features, num_movies)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(1, num_movies)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, categoricals):\n",
      "        users, movies = categoricals[:,0], categoricals[:,1]\n",
      "        u, m, ub, um = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m) + ub + mb\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/77:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "68/78: model.forward()\n",
      "68/79: model.forward([[1, 4], [2,5]])\n",
      "68/80: t1 = np.array([[1, 4], [2,5]])\n",
      "68/81: t1\n",
      "68/82: t1[:,0]\n",
      "68/83: model.forward(np.array([[1, 4], [2,5]]))\n",
      "68/84: model.forward(torch.tensor([[1, 4], [2,5]]))\n",
      "68/85: model.user_embed\n",
      "68/86: model.user_embed(torch.tensor[[1,2]])\n",
      "68/87: model.user_embed(torch.tensor[[1]])\n",
      "68/88: model.user_embed([1])\n",
      "68/89: model.user_embed(torch.tensor())\n",
      "68/90: model.user_embed(torch.tensor([]))\n",
      "68/91: model.user_embed(torch.tensor([1]))\n",
      "68/92: model.user_embed(torch.tensor([1, 2]))\n",
      "68/93: model.user_embed(torch.tensor[[1,2]])\n",
      "68/94: model.user_embed(torch.tensor([[1,2]]))\n",
      "68/95: testing = torch.tensor([[1, 5, 6], [2,6,7]])\n",
      "68/96: ux, mx = testing[:,0], testing[:,1]\n",
      "68/97: ux\n",
      "68/98: mx\n",
      "68/99: testing\n",
      "68/100: testing = torch.tensor([[1, 5, 6], [2,6,7]]).transpose(0,1)\n",
      "68/101: ux, mx = testing[:,0], testing[:,1]\n",
      "68/102: testing\n",
      "68/103: ux\n",
      "68/104: mx\n",
      "68/105: model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "68/106: model.user_embed(ux), model.movie_embed(mx), model.user_bias(ux), model.movie_bias(mx)\n",
      "68/107: model.user_embed(ux)\n",
      "68/108: model.movie_embed(mx)\n",
      "68/109: model.movie_embed(mx).shape\n",
      "68/110: model.user_embed(ux).shape\n",
      "68/111: model.user_embed(ux), model.movie_embed(mx)\n",
      "68/112: model.user_embed(ux).shape, model.movie_embed(mx).shape\n",
      "68/113:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, categoricals):\n",
      "        users, movies = categoricals[:,0], categoricals[:,1]\n",
      "        u, m, ub, um = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m) + ub + mb\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/114:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "68/115: testing = torch.tensor([[1, 5, 6], [2,6,7]]).transpose(0,1)\n",
      "68/116: ux, mx = testing[:,0], testing[:,1]\n",
      "68/117: model.user_embed(ux).shape, model.movie_embed(mx).shape\n",
      "68/118: model.user_embed(ux).shape, model.movie_embed(mx).shape, model.user_bias(ux).shape, model.movie_bias(mx).shape\n",
      "68/119:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, categoricals):\n",
      "        users, movies = categoricals[:,0], categoricals[:,1]\n",
      "        u, m, ub, um = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m) + ub + mb\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/120: model(testing)\n",
      "68/121: ux, mx\n",
      "68/122: model.user_embed(ux).Transpose(0,1).shape, model.movie_embed(mx).shape, model.user_bias(ux).shape, model.movie_bias(mx).shape\n",
      "68/123: model.user_embed(ux).transpose(0,1).shape, model.movie_embed(mx).shape, model.user_bias(ux).shape, model.movie_bias(mx).shape\n",
      "68/124: model.user_embed.shape\n",
      "68/125: model.user_embed\n",
      "68/126: model.user_embed, model.movie_embed\n",
      "68/127:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_features, num_movies)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(1, num_movies)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, categoricals):\n",
      "        users, movies = categoricals[:,0], categoricals[:,1]\n",
      "        u, m, ub, um = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m) + ub + mb\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/128: model.user_embed, model.movie_embed\n",
      "68/129:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "68/130: model.user_embed(ux).shape, model.movie_embed(mx).shape, model.user_bias(ux).shape, model.movie_bias(mx).shape\n",
      "68/131:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, categoricals):\n",
      "        users, movies = categoricals[:,0], categoricals[:,1]\n",
      "        u, m, ub, um = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m) + ub + mb\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/132:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "68/133: testing = torch.tensor([[1, 5, 6], [2,6,7]]).transpose(0,1)\n",
      "68/134: ux, mx = testing[:,0], testing[:,1]\n",
      "68/135: ux, mx\n",
      "68/136: model.user_embed(ux).shape, model.movie_embed(mx).shape, model.user_bias(ux).shape, model.movie_bias(mx).shape\n",
      "68/137: model.user_embed(ux).shape, model.movie_embed(mx).transpose(0,1).shape, model.user_bias(ux).shape, model.movie_bias(mx).shape\n",
      "68/138: model.user_embed(ux).shape, model.movie_embed(mx).transpose(0,1).shape, model.user_bias(ux).shape, model.movie_bias(mx).transpose(0,1).shape\n",
      "68/139: torch.mm(model.user_embed(ux), model.movie_embed(mx).transpose(0,1)), model.user_bias(ux), model.movie_bias(mx).transpose(0,1)\n",
      "68/140: torch.mm(model.user_embed(ux), model.movie_embed(mx).transpose(0,1)).shape, model.user_bias(ux), model.movie_bias(mx).transpose(0,1)\n",
      "68/141: torch.mm(model.user_embed(ux), model.movie_embed(mx).transpose(0,1)) + model.user_bias(ux) + model.movie_bias(mx).transpose(0,1)\n",
      "68/142:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, categoricals):\n",
      "        users, movies = categoricals[:,0], categoricals[:,1]\n",
      "        u, m, ub, um = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m.transpose(0,1)) + ub + mb.transpose(0,1)\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/143:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "68/144: model(testing)\n",
      "68/145:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, categoricals):\n",
      "        users, movies = categoricals[:,0], categoricals[:,1]\n",
      "        u, m, ub, mb = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m.transpose(0,1)) + ub + mb.transpose(0,1)\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/146:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "68/147: testing = torch.tensor([[1, 5, 6], [2,6,7]]).transpose(0,1)\n",
      "68/148: ux, mx = testing[:,0], testing[:,1]\n",
      "68/149: ux, mx\n",
      "68/150: torch.mm(model.user_embed(ux), model.movie_embed(mx).transpose(0,1)) + model.user_bias(ux) + model.movie_bias(mx).transpose(0,1)\n",
      "68/151: model(testing)\n",
      "68/152: model(testing)\n",
      "68/153:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "68/154: model(ratings)\n",
      "68/155: type(ratings)\n",
      "68/156: model(torch.tensor(ratings))\n",
      "68/157: model(torch.tensor(ratings[:,[0,1]]))\n",
      "68/158: ratings[:,[0,1]]\n",
      "68/159: ratings[:,[0,1]].float()\n",
      "68/160: torch.tensor(ratings[:,[0,1]])\n",
      "68/161: np.asfloat(ratings[:,[0,1]])\n",
      "68/162: ratings[:,[0,1]].astype(float)\n",
      "68/163: ratings[:,[0,1]].astype(np.float)\n",
      "68/164: model(ratings[:,[0,1]].astype(np.float))\n",
      "68/165: torch.tensor(ratings[:,[0,1]].astype(np.float))\n",
      "68/166: model(torch.tensor(ratings[:,[0,1]].astype(np.float)))\n",
      "68/167: model(torch.tensor(ratings[:,[0,1]].astype(int)))\n",
      "68/168: torch.tensor(ratings[:,[0,1]].astype(int)).shape\n",
      "68/169: model(torch.tensor(ratings[:5,[0,1]].astype(int)).shape)\n",
      "68/170: torch.tensor(ratings[:5,[0,1]].astype(int))\n",
      "68/171: model(torch.tensor(ratings[:5,[0,1]].astype(int)))\n",
      "68/172: model(torch.tensor(ratings[:10,[0,1]].astype(int)))\n",
      "68/173: model(torch.tensor(ratings[:5,[0,1]].astype(int)))\n",
      "68/174: model(torch.tensor(ratings[:15,[0,1]].astype(int)))\n",
      "68/175: model(torch.tensor(ratings[:100,[0,1]].astype(int)))\n",
      "68/176: model(torch.tensor(ratings[:1000,[0,1]].astype(int)))\n",
      "68/177: model(torch.tensor(ratings[:10000,[0,1]].astype(int)))\n",
      "68/178: len(ratings)\n",
      "68/179: model(torch.tensor(ratings[:10836,[0,1]].astype(int)))\n",
      "68/180: model(torch.tensor(ratings[:,[0,1]].astype(int)))\n",
      "68/181: model(torch.tensor(ratings[:,:2].astype(int)))\n",
      "68/182: model(torch.tensor(ratings[:-1,:2].astype(int)))\n",
      "68/183: model(torch.tensor(ratings[:1,:2].astype(int)))\n",
      "68/184: model(torch.tensor(ratings[:2,:2].astype(int)))\n",
      "68/185: model(torch.tensor(ratings[:3,:2].astype(int)))\n",
      "68/186: model(torch.tensor(ratings[:100837,:2].astype(int)))\n",
      "68/187: model(torch.tensor(ratings[:100836,:2].astype(int)))\n",
      "68/188: model(torch.tensor(ratings[:10080,:2].astype(int)))\n",
      "68/189: model(torch.tensor(ratings[:100000,:2].astype(int)))\n",
      "68/190: ratings\n",
      "68/191: movies\n",
      "68/192: ratings\n",
      "68/193: ratings[:,0]\n",
      "68/194: ratings[:,0] - 1\n",
      "68/195: ratings[:,0].astype(int)\n",
      "68/196: ratings[:,0].astype(int) - 1\n",
      "68/197:\n",
      "movie_ids = sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "old_new_movie_ids = {j:i for i,j in enumerate(movie_ids)}\n",
      "movies[:,0] = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "ratings[:,1] = np.array(list(map(old_new_movie_ids.get, ratings[:,1])))\n",
      "ratings[:,0] = ratings[:,0].astype(int) - 1\n",
      "68/198: ratings\n",
      "68/199:\n",
      "rate_matrix = np.empty((num_users, num_movies))\n",
      "rate_matrix[:] = np.nan\n",
      "68/200:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0])-1, int(row[1])] = row[2]\n",
      "68/201:\n",
      "rate_matrix = torch.tensor(rate_matrix).float()\n",
      "print(rate_matrix)\n",
      "68/202: ratings\n",
      "68/203:\n",
      "rate_matrix = np.empty((num_users, num_movies))\n",
      "rate_matrix[:] = np.nan\n",
      "68/204:\n",
      "for row in ratings:\n",
      "    rate_matrix[int(row[0]), int(row[1])] = row[2]\n",
      "68/205:\n",
      "rate_matrix = torch.tensor(rate_matrix).float()\n",
      "print(rate_matrix)\n",
      "68/206:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, categoricals):\n",
      "        users, movies = categoricals[:,0], categoricals[:,1]\n",
      "        u, m, ub, mb = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m.transpose(0,1)) + ub + mb.transpose(0,1)\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "68/207:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "68/208:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "68/209: model(torch.tensor(ratings[:,:2].astype(int)))\n",
      "69/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "69/2: trainloader, testloader = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "69/3:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, categoricals):\n",
      "        users, movies = categoricals[:,0], categoricals[:,1]\n",
      "        u, m, ub, mb = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m.transpose(0,1)) + ub + mb.transpose(0,1)\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "69/4:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "69/5: next(iter(trainloader))\n",
      "69/6: next(iter(trainloader))\n",
      "69/7: type(next(iter(trainloader))[0])\n",
      "69/8: next(iter(trainloader))[0]\n",
      "69/9: next(iter(trainloader))[0].int()\n",
      "69/10: trainloader, testloader = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "69/11: next(iter(trainloader))\n",
      "69/12: trainloader, testloader = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "69/13: next(iter(trainloader))\n",
      "69/14: next(iter(trainloader))[0]\n",
      "69/15: next(iter(trainloader))[0].int()\n",
      "69/16: next(iter(trainloader))[0].int()\n",
      "69/17:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        users, movies = x[:,0].int(), x[:,1].int()\n",
      "        u, m, ub, mb = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m.transpose(0,1)) + ub + mb.transpose(0,1)\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "69/18:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "69/19: len(trainloader)\n",
      "69/20: len(testloader)\n",
      "69/21: trainloader\n",
      "69/22: print(trainloader)\n",
      "69/23: len(trainloader[0])\n",
      "69/24: len(trainloader)\n",
      "69/25:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        labs = next(reader)\n",
      "        dat = np.array(list(reader))\n",
      "    return(labs, dat)\n",
      "69/26:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "\n",
      "# ratings[:,[0,1]] = ratings[:,[0,1]].astype(int) #doesnt work??? probably something to do with handling of mixed data types\n",
      "69/27:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(movies[:,0])); print(num_movies)\n",
      "69/28:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(ratings[:,1])); print(num_movies)\n",
      "70/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "70/2: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "70/3:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "70/4: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "70/5:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "70/6: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "70/7:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "70/8: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "70/9:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "70/10: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "71/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "71/2:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        labs = next(reader)\n",
      "        dat = np.array(list(reader))\n",
      "    return(labs, dat)\n",
      "71/3:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "\n",
      "# ratings[:,[0,1]] = ratings[:,[0,1]].astype(int) #doesnt work??? probably something to do with handling of mixed data types\n",
      "71/4:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(ratings[:,1])); print(num_movies)\n",
      "71/5: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "71/6: trainloader, testloader = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "71/7:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        users, movies = x[:,0].int(), x[:,1].int()\n",
      "        u, m, ub, mb = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m.transpose(0,1)) + ub + mb.transpose(0,1)\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "71/8:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "71/9:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "71/10: model(next(iter(trainloader)))\n",
      "71/11: next(iter(trainloader))\n",
      "71/12: model(next(iter(trainloader))[0])\n",
      "71/13:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        users, movies = x[:,0].long(), x[:,1].long()\n",
      "        u, m, ub, mb = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m.transpose(0,1)) + ub + mb.transpose(0,1)\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "71/14:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "71/15:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "71/16: model(next(iter(trainloader))[0])\n",
      "71/17: next(iter(trainloader))[0]\n",
      "71/18:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "71/19: trainloader, testloader = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "72/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "72/2: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "72/3:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "72/4: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "72/5: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "72/6:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "72/7: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "72/8:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "72/9: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "72/10:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        labs = next(reader)\n",
      "        dat = np.array(list(reader))\n",
      "    return(labs, dat)\n",
      "72/11:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "\n",
      "# ratings[:,[0,1]] = ratings[:,[0,1]].astype(int) #doesnt work??? probably something to do with handling of mixed data types\n",
      "72/12:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(ratings[:,1])); print(num_movies)\n",
      "72/13:\n",
      "movie_ids = sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "old_new_movie_ids = {j:i for i,j in enumerate(movie_ids)}\n",
      "movies[:,0] = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "ratings[:,1] = np.array(list(map(old_new_movie_ids.get, ratings[:,1])))\n",
      "ratings[:,0] = ratings[:,0].astype(int) - 1\n",
      "72/14:\n",
      "print(rating_labels, '\\n')\n",
      "print(ratings[:5])\n",
      "72/15:\n",
      "print(movie_labels, '\\n')\n",
      "print(movies[:5])\n",
      "72/16: ratings\n",
      "72/17: movies\n",
      "72/18: features = ratings[:,:2].long()\n",
      "72/19: features = ratings[:,:2]\n",
      "72/20:\n",
      "features = ratings[:,:2]\n",
      "features\n",
      "72/21:\n",
      "features = ratings[:,:2]\n",
      "labels = ratings[:,2]\n",
      "labels\n",
      "72/22:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "from sklearn.model_selection import train_test_split\n",
      "72/23:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "\n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "72/24:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from process import preprocess\n",
      "from sklearn.model_selection import train_test_split\n",
      "import torch.utils.data\n",
      "72/25:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "\n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "72/26:\n",
      "split = train_test_split(features, labels, test_size=0.2)\n",
      "x_train, x_test, y_train, y_test = map(lambda x: torch.tensor(x), split)\n",
      "\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "testloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "72/27:\n",
      "features = ratings[:,:2].astype(int)\n",
      "labels = ratings[:,2].astype(float)\n",
      "72/28:\n",
      "split = train_test_split(features, labels, test_size=0.2)\n",
      "x_train, x_test, y_train, y_test = map(lambda x: torch.tensor(x), split)\n",
      "\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=8, shuffle=True)\n",
      "testloader = torch.utils.data.DataLoader(test_ds, batch_size=8, shuffle=True)\n",
      "72/29: next(iter(trainloader))[0]\n",
      "72/30:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        users, movies = x[:,0].long(), x[:,1].long()\n",
      "        u, m, ub, mb = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = torch.mm(u, m.transpose(0,1)) + ub + mb.transpose(0,1)\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "72/31:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "72/32:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "72/33: model(next(iter(trainloader))[0])\n",
      "72/34: model(next(iter(trainloader))[0])\n",
      "72/35:\n",
      "feature, label = next(iter(trainloader))\n",
      "print(model(feature))\n",
      "print(label)\n",
      "72/36:\n",
      "feature, label = next(iter(trainloader))\n",
      "print(feature)\n",
      "72/37:\n",
      "feature, label = next(iter(trainloader))\n",
      "feature[0][0]\n",
      "72/38:\n",
      "feature, label = next(iter(trainloader))\n",
      "feature\n",
      "72/39:\n",
      "feature, label = next(iter(trainloader))\n",
      "feature.shape\n",
      "72/40:\n",
      "feature, label = next(iter(trainloader))\n",
      "feature[:,0], feature[:,1]\n",
      "72/41:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "users\n",
      "72/42:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "users\n",
      "72/43:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "model.user_embed(users)\n",
      "72/44:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "model.user_embed(users).shape\n",
      "72/45:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "72/46:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "u.shape, m.shape, ub.shape, mb.shape\n",
      "72/47:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "u, m\n",
      "72/48:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "u*m\n",
      "72/49:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "u*m\n",
      "72/50:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "u*m.sum(1)\n",
      "72/51:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "torch.mm(u, m)\n",
      "72/52:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "torch.mm(u, m.transpose(0, 1))\n",
      "72/53:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "(u*m)\n",
      "72/54:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "(u*m).sum(0)\n",
      "72/55:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print((u*m).sum(0))\n",
      "print(torch.mm(u,m))\n",
      "72/56:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print((u*m).sum(0))\n",
      "print(torch.mm(u,m.transpose(0,1)))\n",
      "72/57:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print((u*m).sum(0).shape)\n",
      "print(torch.mm(u,m.transpose(0,1)).shape)\n",
      "72/58:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print((u*m).sum(0) + ub.squeeze() + mb.squeeze())\n",
      "72/59:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print(ub.squeeze())\n",
      "print((u*m).sum(0) + ub.squeeze() + mb.squeeze())\n",
      "72/60:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print(ub.squeeze()).shape\n",
      "print((u*m).sum(0) + ub.squeeze() + mb.squeeze())\n",
      "72/61:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print(ub.squeeze().shape)\n",
      "print((u*m).sum(0) + ub.squeeze() + mb.squeeze())\n",
      "72/62:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print(mb.squeeze().shape)\n",
      "print((u*m).sum(0) + ub.squeeze() + mb.squeeze())\n",
      "72/63:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print((u*m).sum(1))\n",
      "72/64:\n",
      "feature, label = next(iter(trainloader))\n",
      "users, movies = feature[:,0], feature[:,1]\n",
      "u, m, ub, mb = model.user_embed(users), model.movie_embed(movies), model.user_bias(users), model.movie_bias(movies)\n",
      "print((u*m).sum(1) + ub.squeeze() + mb.squeeze())\n",
      "72/65:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        users, movies = x[:,0].long(), x[:,1].long()\n",
      "        u, m, ub, mb = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = (u*m).sum(1) + ub.squeeze() + mb.squeeze()\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "72/66:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "72/67:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "72/68:\n",
      "feature, label = next(iter(trainloader))\n",
      "out = model(feature)\n",
      "loss = loss_fn(out, label)\n",
      "print(loss.item())\n",
      "72/69:\n",
      "feature, label = next(iter(trainloader))\n",
      "out = model(feature)\n",
      "loss = loss_fn(out, label.float())\n",
      "print(loss.item())\n",
      "72/70:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        out = model(feature)\n",
      "        loss = loss_fn(out, label.float())\n",
      "        running_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "    print(running_loss)\n",
      "72/71:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        out = model(feature)\n",
      "        loss = loss_fn(out, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        print(loss.item())\n",
      "72/72:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "72/73:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        out = model(feature)\n",
      "        loss = loss_fn(out, label.float())\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        print(loss.item())\n",
      "72/74:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "72/75: len(trainloader)\n",
      "72/76:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        out = model(feature)\n",
      "        loss = loss_fn(out, label.float())\n",
      "        running_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "    print(running_loss)\n",
      "72/77:\n",
      "epochs = 1\n",
      "\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        out = model(feature)\n",
      "        loss = loss_fn(out, label.float())\n",
      "        running_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "    print(running_loss)\n",
      "72/78:\n",
      "epochs = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        out = model(feature)\n",
      "        loss = loss_fn(out, label.float())\n",
      "        running_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "    print(running_loss)\n",
      "73/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from sklearn.model_selection import train_test_split\n",
      "import torch.utils.data\n",
      "73/2:\n",
      "def open_file(path):\n",
      "    with open(path, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        labs = next(reader)\n",
      "        dat = np.array(list(reader))\n",
      "    return(labs, dat)\n",
      "73/3:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "\n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "73/4:\n",
      "rating_labels, ratings = open_file('./ratings.csv')\n",
      "movie_labels, movies = open_file('./movies.csv')\n",
      "73/5:\n",
      "num_users = len(set(ratings[:,0])); print(num_users)\n",
      "num_movies = len(set(ratings[:,1])); print(num_movies)\n",
      "73/6:\n",
      "movie_ids = sorted(set(ratings[:,1]), key=lambda x: int(x))\n",
      "old_new_movie_ids = {j:i for i,j in enumerate(movie_ids)}\n",
      "movies[:,0] = np.array(list(map(old_new_movie_ids.get, movies[:,0])))\n",
      "ratings[:,1] = np.array(list(map(old_new_movie_ids.get, ratings[:,1])))\n",
      "ratings[:,0] = ratings[:,0].astype(int) - 1\n",
      "73/7:\n",
      "features = ratings[:,:2].astype(int)\n",
      "labels = ratings[:,2].astype(float)\n",
      "73/8:\n",
      "split = train_test_split(features, labels, test_size=0.2)\n",
      "x_train, x_test, y_train, y_test = map(lambda x: torch.tensor(x), split)\n",
      "\n",
      "train_ds = ds(x_train, y_train)\n",
      "test_ds = ds(x_test, y_test)\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=8, shuffle=True)\n",
      "testloader = torch.utils.data.DataLoader(test_ds, batch_size=8, shuffle=True)\n",
      "73/9: trainloader, testloader, num_users, num_movies = preprocess('./ratings.csv', [0,1], [2], 0.2, 8)\n",
      "73/10:\n",
      "class betternet(nn.Module):\n",
      "    def __init__(self, num_users, num_movies, num_features):\n",
      "        super().__init__()\n",
      "        self.user_embed = nn.Embedding(num_users, num_features)\n",
      "        self.movie_embed = nn.Embedding(num_movies, num_features)\n",
      "        self.user_bias = nn.Embedding(num_users, 1)\n",
      "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
      "        \n",
      "        nn.init.xavier_uniform_(self.user_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_embed.weight.data)\n",
      "        nn.init.xavier_uniform_(self.user_bias.weight.data)\n",
      "        nn.init.xavier_uniform_(self.movie_bias.weight.data)\n",
      "        \n",
      "    def forward(self, x):\n",
      "        users, movies = x[:,0].long(), x[:,1].long()\n",
      "        u, m, ub, mb = self.user_embed(users), self.movie_embed(movies), self.user_bias(users), self.movie_bias(movies)\n",
      "        out = (u*m).sum(1) + ub.squeeze() + mb.squeeze()\n",
      "        out = torch.sigmoid(out)\n",
      "        return(out * 5)\n",
      "73/11:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "73/12:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "72/79:\n",
      "model = betternet(num_users, num_movies, 50)\n",
      "print(model)\n",
      "72/80:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
      "72/81:\n",
      "epochs = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    running_loss = 0\n",
      "    for feature, label in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        out = model(feature)\n",
      "        loss = loss_fn(out, label.float())\n",
      "        running_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "    print(running_loss)\n",
      "74/1:\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "            self._results[riding][party] = 0  # initialize party in results\n",
      "74/2:         >>> e = Election(date(2000, 2, 8))\n",
      "74/3:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "            self._results[riding][party] = 0  # initialize party in results\n",
      "\n",
      "        self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/4: from datetime import date\n",
      "74/5: from typing import Dict, Tuple, List, Set, Optional, IO\n",
      "74/6:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "            self._results[riding][party] = 0  # initialize party in results\n",
      "\n",
      "        self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/7:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) \\\n",
      "            -> None:\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, \\\n",
      "        date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/8:     >>> e = Election(date(2000, 2, 8))\n",
      "74/9:     >>> e.update_results('r1', 'ndp', 1234)\n",
      "74/10:     >>> e.update_results('r1', 'lib', 1345)\n",
      "74/11:     >>> e.update_results('r1', 'pc', 1456)\n",
      "74/12:     >>> e.riding_winners('r1')\n",
      "74/13:     ['pc']\n",
      "74/14:     >>> e.update_results('r2', 'pc', 1)\n",
      "74/15:     >>> e.update_results('r2', 'pc', 1)\n",
      "74/16:     >>> e._results\n",
      "74/17:     >>> e.update_results('r2', 'pc', 1)\n",
      "74/18:         >>> e = Election(date(2000, 2, 8))\n",
      "74/19:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/20:         >>> e.results_for('r1', 'ndp')\n",
      "74/21:         1\n",
      "74/22:         >>> e.update_results('r1', 'ndp', 1000)\n",
      "74/23:         >>> e.results_for('r1', 'ndp')\n",
      "74/24:         1001\n",
      "74/25:     >>> e._ridings\n",
      "74/26:         >>> e = Election(date(2000, 2, 8))\n",
      "74/27:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/28:         >>> e._results\n",
      "74/29:         >>> e.update_results('r1', 'ndp', 5)\n",
      "74/30:         >>> e._results\n",
      "74/31:         >>> e = Election(date(2000, 2, 8))\n",
      "74/32:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/33:         >>> e._results\n",
      "74/34:         >>> e.update_results('r1', 'lib', 5)\n",
      "74/35:         >>> e._results\n",
      "74/36:         >>> e.update_results('r2', 'ndp', 6)\n",
      "74/37:         >>> e = Election(date(2000, 2, 8))\n",
      "74/38:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/39:         >>> e._results\n",
      "74/40:         >>> e.update_results('r1', 'lib', 5)\n",
      "74/41:         >>> e._results\n",
      "74/42:         >>> e.update_results('r2', 'ndp', 6)\n",
      "74/43:\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if !(self._results[riding][party]):\n",
      "            self._results[riding][party] = 0  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "74/44:\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if not self._results[riding][party]:\n",
      "            self._results[riding][party] = 0  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "74/45:         >>> e = Election(date(2000, 2, 8))\n",
      "74/46:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/47:         >>> e._results\n",
      "74/48:         >>> e.update_results('r1', 'lib', 5)\n",
      "74/49:         >>> e._results\n",
      "74/50:         >>> e.update_results('r2', 'ndp', 6)\n",
      "74/51:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if not self._results[riding][party]:\n",
      "            self._results[riding][party] = 0  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/52:         >>> e = Election(date(2000, 2, 8))\n",
      "74/53:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/54:         >>> e._results\n",
      "74/55:         >>> e._results\n",
      "74/56:         >>> e.['r1']\n",
      "74/57:         >>> e['r1']\n",
      "74/58:         >>> e.'r1'\n",
      "74/59:         >>> e._results['r1']\n",
      "74/60:         >>> e._results['r2']\n",
      "74/61:         >>> e._results['r1']\n",
      "74/62:         >>> e._results['r1'] == 1\n",
      "74/63:         >>> if e._results['r1']: print(true)\n",
      "74/64:         >>> if e._results['r1']: print(True)\n",
      "74/65:         >>> if e._results['r1']: print('a')\n",
      "74/66:         >>> if e._results['r1']: print('a')\n",
      "74/67:         'a'\n",
      "74/68:         >>> if e._results['r1']\n",
      "74/69:         >>> if not e_.results['r1']\n",
      "74/70:         >>> if not e_.results['r1']: print('a')\n",
      "74/71:         >>> if not e._results['r1']: print('a')\n",
      "74/72:         >>> e._results['r1]']\n",
      "74/73:         >>> e._results['r1']\n",
      "74/74:         >>> e._results['r1'].keys()\n",
      "74/75:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._results['r1'].keys()\n",
      "        >>> if not e._results['r1']: print('a')\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = 0  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/76:         >>> e = Election(date(2000, 2, 8))\n",
      "74/77:         >>> e._results['r1'].keys()\n",
      "74/78:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/79:         >>> e._results\n",
      "74/80:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/81:         >>> e._results\n",
      "74/82:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/83:         >>> e = Election(date(2000, 2, 8))\n",
      "74/84:         >>> e._d\n",
      "74/85:         datetime.date(2000, 2, 8)\n",
      "74/86: from datetime import date\n",
      "74/87: from typing import Dict, Tuple, List, Set, Optional, IO\n",
      "74/88:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/89:         >>> e = Election(date(2000, 2, 8))\n",
      "74/90:         >>> e._d\n",
      "74/91:         >>> e = Election(date(2000, 2, 8))\n",
      "74/92:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/93:         >>> e._results\n",
      "74/94:         >>> e.update_results('r1', 'lib', 5)\n",
      "74/95:         >>> e._results\n",
      "74/96:         >>> e.update_results('r2', 'ndp', 6)\n",
      "74/97:         >>> e._results\n",
      "74/98:         >>> e.update_results('r3', 'lib', 0)\n",
      "74/99:         >>> e._results\n",
      "74/100:         >>> e.results_for('r1', 'ndp')\n",
      "74/101:         1\n",
      "74/102:         >>> e.update_results('r1', 'ndp', 1000)\n",
      "74/103:         >>> e.results_for('r1', 'ndp')\n",
      "74/104:         1001\n",
      "74/105:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!    DONE\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/106:         >>> e = Election(date(2000, 2, 8))\n",
      "74/107:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/108:         >>> e.ridings_of()\n",
      "74/109:         >>> e.update_results('r2', 'ndp', 1)\n",
      "74/110:         >>> e.ridings_of()\n",
      "74/111:         >>> e = Election(date(2000, 2, 8))\n",
      "74/112:         >>> e.update_results('r1', 'ndp', 1234)\n",
      "74/113:         >>> e.update_results('r1', 'lib', 1345)\n",
      "74/114:         >>> e.update_results('r1', 'pc', 1456)\n",
      "74/115:         >>> e.update_results('r2', 'pc', 1)\n",
      "74/116:         >>> e.results_for('r1', 'pc')\n",
      "74/117:         >>> e.results_for('r2', 'pc')\n",
      "74/118:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/119:         >>> e = Election(date(2000, 2, 8))\n",
      "74/120:         >>> e.update_results('r1', 'ndp', 1234)\n",
      "74/121:         >>> e.update_results('r1', 'lib', 1345)\n",
      "74/122:         >>> e.update_results('r1', 'pc', 1456)\n",
      "74/123:         >>> e.update_results('r2', 'pc', 1)\n",
      "74/124:         >>> e.results_for('r1', 'pc')\n",
      "74/125:         >>> e.results_for('r2', 'pc')\n",
      "74/126:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/127:         >>> e = Election(date(2000, 2, 8))\n",
      "74/128:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/129:         >>> e.update_results('r1', 'lib', 2)\n",
      "74/130:         >>> e.update_results('r1', 'pc', 3)\n",
      "74/131:         >>> e.riding_winners('r1')\n",
      "74/132:         >>> e = Election(date(2000, 2, 8))\n",
      "74/133:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/134:         >>> e.update_results('r1', 'lib', 2)\n",
      "74/135:         >>> e.update_results('r1', 'pc', 3)\n",
      "74/136:         >>> e.update_results('r2', 'pc', 4)\n",
      "74/137:         >>> e.update_results('r2', 'lib', 5)\n",
      "74/138:         >>> e.update_results('r2', 'green', 6)\n",
      "74/139:         >>> e.update_results('r2', 'ndp', 7)\n",
      "74/140:         >>> e._results\n",
      "74/141:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.items():\n",
      "            for pt in riding:\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/142:         >>> e = Election(date(2000, 2, 8))\n",
      "74/143:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/144:         >>> e.update_results('r1', 'lib', 2)\n",
      "74/145:         >>> e.update_results('r1', 'pc', 3)\n",
      "74/146:         >>> e.update_results('r2', 'pc', 4)\n",
      "74/147:         >>> e.update_results('r2', 'lib', 5)\n",
      "74/148:         >>> e.update_results('r2', 'green', 6)\n",
      "74/149:         >>> e.update_results('r2', 'ndp', 7)\n",
      "74/150:         >>> e._results\n",
      "74/151:         >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "74/152:         >>> {i:0 for i in e._parties}\n",
      "74/153:         >>> e._results.items()\n",
      "74/154:         >>> e._results.items()[0]\n",
      "74/155:         >>> e._results.items()\n",
      "74/156:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> {i:0 for i in e._parties}\n",
      "        >>> e._results.items()\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/157:         >>> e = Election(date(2000, 2, 8))\n",
      "74/158:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/159:         >>> e.update_results('r1', 'lib', 2)\n",
      "74/160:         >>> e.update_results('r1', 'pc', 3)\n",
      "74/161:         >>> e.update_results('r2', 'pc', 4)\n",
      "74/162:         >>> e.update_results('r2', 'lib', 5)\n",
      "74/163:         >>> e.update_results('r2', 'green', 6)\n",
      "74/164:         >>> e.update_results('r2', 'ndp', 7)\n",
      "74/165:         >>> e._results\n",
      "74/166:         >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "74/167:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:      # DONE\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:          # DONE\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:              # DONE\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_seats = {i:0 for i in self._parties} # initialize dict with win counts\n",
      "        for riding in self._ridings: # for each riding\n",
      "            winner = self.riding_winners(riding) # get winner of riding\n",
      "            if len(winner) == 1: # only do stuff if no tie\n",
      "                init_seats[winner[0]] += 1\n",
      "        return init_seats\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/168:         >>> e = Election(date(2000, 2, 8))\n",
      "74/169:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/170:         >>> e.update_results('r1', 'lib', 2)\n",
      "74/171:         >>> e.update_results('r1', 'pc', 3)\n",
      "74/172:         >>> e.update_results('r2', 'pc', 4)\n",
      "74/173:         >>> e.update_results('r2', 'lib', 5)\n",
      "74/174:         >>> e.update_results('r2', 'green', 6)\n",
      "74/175:         >>> e.update_results('r2', 'ndp', 7)\n",
      "74/176:         >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "74/177:         >>> e.party_seats()\n",
      "74/178:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:      # DONE\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:          # DONE\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:              # DONE\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:                 # DON\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_seats = {i:0 for i in self._parties} # initialize dict with win counts\n",
      "        for riding in self._ridings: # for each riding\n",
      "            winner = self.riding_winners(riding) # get winner of riding\n",
      "            if len(winner) == 1: # only do stuff if no tie\n",
      "                init_seats[winner[0]] += 1\n",
      "        return init_seats\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self.party_seats())\n",
      "        winners = [pt[0] for pt in self.party_seats().items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "74/179:         >>> e = Election(date(2000, 2, 8))\n",
      "74/180:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/181:         >>> e.update_results('r1', 'lib', 2)\n",
      "74/182:         >>> e.update_results('r1', 'pc', 3)\n",
      "74/183:         >>> e.update_results('r2', 'lib', 5)\n",
      "74/184:         >>> e.update_results('r2', 'green', 6)\n",
      "74/185:         >>> e.update_results('r2', 'ndp', 7)\n",
      "74/186:         >>> e.update_results('r2', 'pc', 8)\n",
      "74/187:         >>> e.election_winners()\n",
      "74/188:         >>> e._results\n",
      "74/189:         >>> e.party_seats()\n",
      "74/190:         >>> e.election_winners()\n",
      "74/191:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:      # DONE\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:          # DONE\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:              # DONE\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:                 # DON\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_seats = {i:0 for i in self._parties} # initialize dict with win counts\n",
      "        for riding in self._ridings: # for each riding\n",
      "            winner = self.riding_winners(riding) # get winner of riding\n",
      "            if len(winner) == 1: # only do stuff if no tie\n",
      "                init_seats[winner[0]] += 1\n",
      "        return init_seats\n",
      "\n",
      "    def election_winners(self) -> List[str]:\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.party_seats()\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self.party_seats().values())\n",
      "        winners = [pt[0] for pt in self.party_seats().items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "74/192:         >>> e = Election(date(2000, 2, 8))\n",
      "74/193:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/194:         >>> e.update_results('r1', 'lib', 2)\n",
      "74/195:         >>> e.update_results('r1', 'pc', 3)\n",
      "74/196:         >>> e.update_results('r2', 'lib', 5)\n",
      "74/197:         >>> e.update_results('r2', 'green', 6)\n",
      "74/198:         >>> e.update_results('r2', 'ndp', 7)\n",
      "74/199:         >>> e.update_results('r2', 'pc', 8)\n",
      "74/200:         >>> e.party_seats()\n",
      "74/201:         >>> e.election_winners()\n",
      "74/202:     >>> e = Election(date(2000, 2, 8))\n",
      "74/203:     >>> e.update_results('r1', 'ndp', 1234)\n",
      "74/204:     >>> e.update_results('r1', 'lib', 1345)\n",
      "74/205:     >>> e.update_results('r1', 'pc', 1456)\n",
      "74/206:     >>> e.riding_winners('r1')\n",
      "74/207:     ['pc']\n",
      "74/208:     >>> e.update_results('r2', 'pc', 1)\n",
      "74/209:     >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "74/210:     True\n",
      "74/211:     >>> e.results_for('r1', 'lib')\n",
      "74/212:     1345\n",
      "74/213:     >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "74/214:     True\n",
      "74/215:         >>> country = Jurisdiction('Canada')\n",
      "74/216:         >>> country._name\n",
      "74/217:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) \\\n",
      "            -> None:\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, \\\n",
      "        date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/218:         >>> country = Jurisdiction('Canada')\n",
      "74/219:         >>> country._name\n",
      "74/220:         'Canada'\n",
      "74/221:         >>> country._history\n",
      "74/222:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        reader = instream\n",
      "        labels = next(reader)\n",
      "        dat = [line.strip().split(',') for line in reader]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for i in filtered:\n",
      "            self.update_results(i[0], i[1], i[2])\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:      # DONE\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"h\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:          # DONE\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:              # DONE\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:                 # DONE\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_seats = {i:0 for i in self._parties} # initialize dict with win counts\n",
      "        for riding in self._ridings: # for each riding\n",
      "            winner = self.riding_winners(riding) # get winner of riding\n",
      "            if len(winner) == 1: # only do stuff if no tie\n",
      "                init_seats[winner[0]] += 1\n",
      "        return init_seats\n",
      "\n",
      "    def election_winners(self) -> List[str]:          # DONE\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.party_seats()\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self.party_seats().values())\n",
      "        winners = [pt[0] for pt in self.party_seats().items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "74/223:\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        reader = instream\n",
      "        labels = next(reader)\n",
      "        dat = [line.strip().split(',') for line in reader]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for j in filtered:\n",
      "            self.update_results(j[0], j[1], j[2])\n",
      "74/224:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        reader = instream\n",
      "        labels = next(reader)\n",
      "        dat = [line.strip().split(',') for line in reader]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for j in filtered:\n",
      "            self.update_results(j[0], j[1], j[2])\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:      # DONE\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"h\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:          # DONE\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:              # DONE\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:                 # DONE\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_seats = {i:0 for i in self._parties} # initialize dict with win counts\n",
      "        for riding in self._ridings: # for each riding\n",
      "            winner = self.riding_winners(riding) # get winner of riding\n",
      "            if len(winner) == 1: # only do stuff if no tie\n",
      "                init_seats[winner[0]] += 1\n",
      "        return init_seats\n",
      "\n",
      "    def election_winners(self) -> List[str]:          # DONE\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.party_seats()\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self.party_seats().values())\n",
      "        winners = [pt[0] for pt in self.party_seats().items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "74/225:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "        \"\"\"\n",
      "        reader = instream\n",
      "        labels = next(reader)\n",
      "        dat = [line.strip().split(',') for line in reader]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for j in filtered:\n",
      "            self.update_results(j[0], j[1], j[2])\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:      # DONE\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:          # DONE\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:              # DONE\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:                 # DONE\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_seats = {i:0 for i in self._parties} # initialize dict with win counts\n",
      "        for riding in self._ridings: # for each riding\n",
      "            winner = self.riding_winners(riding) # get winner of riding\n",
      "            if len(winner) == 1: # only do stuff if no tie\n",
      "                init_seats[winner[0]] += 1\n",
      "        return init_seats\n",
      "\n",
      "    def election_winners(self) -> List[str]:          # DONE\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.party_seats()\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self.party_seats().values())\n",
      "        winners = [pt[0] for pt in self.party_seats().items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "74/226:         >>> e = Election(date(2000, 2, 8))\n",
      "74/227:         >>> e.read_results('../data/labrador.csv')\n",
      "74/228:\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.read_results(open('../data/labrador.csv'))\n",
      "        >>> e._results\n",
      "        \"\"\"\n",
      "        reader = instream\n",
      "        labels = next(reader)\n",
      "        dat = [line.strip().split(',') for line in reader]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for j in filtered:\n",
      "            self.update_results(j[0], j[1], j[2])\n",
      "74/229:         >>> e = Election(date(2000, 2, 8))\n",
      "74/230:         >>> e.read_results(open('../data/labrador.csv'))\n",
      "74/231:         >>> e._results\n",
      "74/232:\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.read_results(open('../data/labrador.csv'))\n",
      "        >>> e._results\n",
      "        >>> e.read_results(open('../'))\n",
      "        \"\"\"\n",
      "        labels = next(instream)\n",
      "        dat = [line.strip().split(',') for line in instream]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for j in filtered:\n",
      "            self.update_results(j[0], j[1], j[2])\n",
      "74/233:\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.read_results(open('../data/labrador.csv'))\n",
      "        >>> e._results\n",
      "        >>> e.read_results(open('../toronto-stpauls.csv'))\n",
      "        \"\"\"\n",
      "        labels = next(instream)\n",
      "        dat = [line.strip().split(',') for line in instream]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for j in filtered:\n",
      "            self.update_results(j[0], j[1], j[2])\n",
      "74/234:         >>> e = Election(date(2000, 2, 8))\n",
      "74/235:         >>> e.read_results(open('../data/labrador.csv'))\n",
      "74/236:         >>> e._results\n",
      "74/237:         >>> e.read_results(open('../toronto-stpauls.csv'))\n",
      "74/238:         >>> e._results\n",
      "74/239:         >>> e.read_results(open('../data/toronto-stpauls.csv'))\n",
      "74/240:         >>> e._results\n",
      "74/241:         >>> e.read_results(open('../data/toronto-stpauls.csv'))\n",
      "74/242:         >>> e._results\n",
      "74/243:         >>> country = Jurisdiction('Canada')\n",
      "74/244:         >>> country._name\n",
      "74/245:         'Canada'\n",
      "74/246:         >>> country._history\n",
      "74/247:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/248:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/249:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/250:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/251:         >>> e1.update_results('r2', 'lib', 10)\n",
      "74/252:         >>> e1.update_results('r2', 'pc', 20)\n",
      "74/253:         >>> e1.update_results('r3', 'ndp', 200)\n",
      "74/254:         >>> e1.update_results('r3', 'pc', 100)\n",
      "74/255:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/256:         >>> e2.update_results('r1', 'ndp', 10)\n",
      "74/257:         >>> e2.update_results('r1', 'lib', 20)\n",
      "74/258:         >>> e2.update_results('r2', 'lib', 50)\n",
      "74/259:         >>> e2.update_results('r2', 'pc', 5)\n",
      "74/260:         >>> e3 = Election(date(2008, 6, 1))\n",
      "74/261:         >>> e3.update_results('r1', 'ndp', 101)\n",
      "74/262:         >>> e3.update_results('r1', 'lib', 102)\n",
      "74/263:         >>> e3.update_results('r2', 'ndp', 1001)\n",
      "74/264:         >>> e3.update_results('r2', 'lib', 1002)\n",
      "74/265:         >>> j = Jurisdiction('Canada')\n",
      "74/266:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/267:         >>> j._history[date(2003, 5, 16)] = e2\n",
      "74/268:         >>> j._history[date(2003, 6, 1)] = e3\n",
      "74/269:         >>> j._history\n",
      "74/270:         >>> j._name\n",
      "74/271:         >>> j._history\n",
      "74/272:         >>> j._history[0]\n",
      "74/273:         >>> j._history\n",
      "74/274:         >>> j._history.keys()\n",
      "74/275:         >>> j._history[date(2000, 2, 8)]\n",
      "74/276:         >>> e1.election_winners\n",
      "74/277:         >>> e1.election_winners()\n",
      "74/278:         >>> e2.election_winners()\n",
      "74/279:         >>> e3.election_winners()\n",
      "74/280:         >>> e4.election_winners()\n",
      "74/281:         >>> e3.election_winners()\n",
      "74/282:         >>> e3._d\n",
      "74/283:         >>> e3._d.year\n",
      "74/284:         >>> e3._d.year()\n",
      "74/285:         >>> e3\n",
      "74/286:         >>> j._history\n",
      "74/287:         >>> j._history.items()\n",
      "74/288:         >>> next(iter(j._history.items()))\n",
      "74/289:         >>> dt, e = next(iter(j._history.items()))\n",
      "74/290:         >>> e\n",
      "74/291:         >>> j._history.items()\n",
      "74/292:         >>> j._history\n",
      "74/293:\n",
      "    def party_wins(self, party: str) -> List[date]:\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "\n",
      "        >>> j._history\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners:\n",
      "                win_dates.append(dt\n",
      "        return win_dates\n",
      "74/294:\n",
      "    def party_wins(self, party: str) -> List[date]:\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "\n",
      "        >>> j._history\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners:\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "74/295:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/296:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/297:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/298:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/299:         >>> e1.update_results('r2', 'lib', 10)\n",
      "74/300:         >>> e1.update_results('r2', 'pc', 20)\n",
      "74/301:         >>> e1.update_results('r3', 'ndp', 200)\n",
      "74/302:         >>> e1.update_results('r3', 'pc', 100)\n",
      "74/303:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/304:         >>> e2.update_results('r1', 'ndp', 10)\n",
      "74/305:         >>> e2.update_results('r1', 'lib', 20)\n",
      "74/306:         >>> e2.update_results('r2', 'lib', 50)\n",
      "74/307:         >>> e2.update_results('r2', 'pc', 5)\n",
      "74/308:         >>> e3 = Election(date(2008, 6, 1))\n",
      "74/309:         >>> e3.update_results('r1', 'ndp', 101)\n",
      "74/310:         >>> e3.update_results('r1', 'lib', 102)\n",
      "74/311:         >>> e3.update_results('r2', 'ndp', 1001)\n",
      "74/312:         >>> e3.update_results('r2', 'lib', 1002)\n",
      "74/313:         >>> j = Jurisdiction('Canada')\n",
      "74/314:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/315:         >>> j._history[date(2003, 5, 16)] = e2\n",
      "74/316:         >>> j._history[date(2003, 6, 1)] = e3\n",
      "74/317:         >>> j.party_wins('lib')\n",
      "74/318:         [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "74/319: from datetime import date\n",
      "74/320: from typing import Dict, Tuple, List, Set, Optional, IO\n",
      "74/321:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.read_results(open('../data/labrador.csv'))\n",
      "        >>> e._results\n",
      "        >>> e.read_results(open('../data/toronto-stpauls.csv'))\n",
      "        >>> e._results\n",
      "        \"\"\"\n",
      "        labels = next(instream)\n",
      "        dat = [line.strip().split(',') for line in instream]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for j in filtered:\n",
      "            self.update_results(j[0], j[1], j[2])\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:      # DONE\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:          # DONE\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:              # DONE\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:                 # DONE\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_seats = {i:0 for i in self._parties} # initialize dict with win counts\n",
      "        for riding in self._ridings: # for each riding\n",
      "            winner = self.riding_winners(riding) # get winner of riding\n",
      "            if len(winner) == 1: # only do stuff if no tie\n",
      "                init_seats[winner[0]] += 1\n",
      "        return init_seats\n",
      "\n",
      "    def election_winners(self) -> List[str]:          # DONE\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.party_seats()\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self.party_seats().values())\n",
      "        winners = [pt[0] for pt in self.party_seats().items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "74/322:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) \\\n",
      "            -> None:\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "\n",
      "        >>> j._history\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners:\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, \\\n",
      "        date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/323:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/324:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/325:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/326:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/327:         >>> e1.update_results('r2', 'lib', 10)\n",
      "74/328:         >>> e1.update_results('r2', 'pc', 20)\n",
      "74/329:         >>> e1.update_results('r3', 'ndp', 200)\n",
      "74/330:         >>> e1.update_results('r3', 'pc', 100)\n",
      "74/331:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/332:         >>> e2.update_results('r1', 'ndp', 10)\n",
      "74/333:         >>> e2.update_results('r1', 'lib', 20)\n",
      "74/334:         >>> e2.update_results('r2', 'lib', 50)\n",
      "74/335:         >>> e2.update_results('r2', 'pc', 5)\n",
      "74/336:         >>> e3 = Election(date(2008, 6, 1))\n",
      "74/337:         >>> e3.update_results('r1', 'ndp', 101)\n",
      "74/338:         >>> e3.update_results('r1', 'lib', 102)\n",
      "74/339:         >>> e3.update_results('r2', 'ndp', 1001)\n",
      "74/340:         >>> e3.update_results('r2', 'lib', 1002)\n",
      "74/341:         >>> j = Jurisdiction('Canada')\n",
      "74/342:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/343:         >>> j._history[date(2003, 5, 16)] = e2\n",
      "74/344:         >>> j._history[date(2003, 6, 1)] = e3\n",
      "74/345:         >>> j.party_wins('lib')\n",
      "74/346:\n",
      "    def party_wins(self, party: str) -> List[date]:\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "\n",
      "        >>> j._history\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "74/347:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/348:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/349:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/350:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/351:         >>> e1.update_results('r2', 'lib', 10)\n",
      "74/352:         >>> e1.update_results('r2', 'pc', 20)\n",
      "74/353:         >>> e1.update_results('r3', 'ndp', 200)\n",
      "74/354:         >>> e1.update_results('r3', 'pc', 100)\n",
      "74/355:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/356:         >>> e2.update_results('r1', 'ndp', 10)\n",
      "74/357:         >>> e2.update_results('r1', 'lib', 20)\n",
      "74/358:         >>> e2.update_results('r2', 'lib', 50)\n",
      "74/359:         >>> e2.update_results('r2', 'pc', 5)\n",
      "74/360:         >>> e3 = Election(date(2008, 6, 1))\n",
      "74/361:         >>> e3.update_results('r1', 'ndp', 101)\n",
      "74/362:         >>> e3.update_results('r1', 'lib', 102)\n",
      "74/363:         >>> e3.update_results('r2', 'ndp', 1001)\n",
      "74/364:         >>> e3.update_results('r2', 'lib', 1002)\n",
      "74/365:         >>> j = Jurisdiction('Canada')\n",
      "74/366:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/367:         >>> j._history[date(2003, 5, 16)] = e2\n",
      "74/368:         >>> j._history[date(2003, 6, 1)] = e3\n",
      "74/369:         >>> j.party_wins('lib')\n",
      "74/370:         >>> j.party_wins('lib')\n",
      "74/371:\n",
      "    def party_wins(self, party: str) -> List[date]:\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "\n",
      "        >>> j._history\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "74/372:         >>> j.party_wins('lib')\n",
      "74/373:\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "74/374:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) \\\n",
      "            -> None:\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "\n",
      "        >>> j._history\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, \\\n",
      "        date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/375:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/376:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/377:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/378:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/379:         >>> e1.update_results('r2', 'lib', 10)\n",
      "74/380:         >>> e1.update_results('r2', 'pc', 20)\n",
      "74/381:         >>> e1.update_results('r3', 'ndp', 200)\n",
      "74/382:         >>> e1.update_results('r3', 'pc', 100)\n",
      "74/383:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/384:         >>> e2.update_results('r1', 'ndp', 10)\n",
      "74/385:         >>> e2.update_results('r1', 'lib', 20)\n",
      "74/386:         >>> e2.update_results('r2', 'lib', 50)\n",
      "74/387:         >>> e2.update_results('r2', 'pc', 5)\n",
      "74/388:         >>> e3 = Election(date(2008, 6, 1))\n",
      "74/389:         >>> e3.update_results('r1', 'ndp', 101)\n",
      "74/390:         >>> e3.update_results('r1', 'lib', 102)\n",
      "74/391:         >>> e3.update_results('r2', 'ndp', 1001)\n",
      "74/392:         >>> e3.update_results('r2', 'lib', 1002)\n",
      "74/393:         >>> j = Jurisdiction('Canada')\n",
      "74/394:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/395:         >>> j._history[date(2003, 5, 16)] = e2\n",
      "74/396:         >>> j._history[date(2003, 6, 1)] = e3\n",
      "74/397:         >>> j.party_wins('lib')\n",
      "74/398:         >>> c = Jurisdiction('Canada')\n",
      "74/399:         >>>\n",
      "74/400:         >>> c\n",
      "74/401:         >>> c._history\n",
      "74/402:         >>> c._history[date(2015, 2, 3)] == True\n",
      "74/403:         >>> c._history[date(2015, 2, 3)]\n",
      "74/404:         >>> if (c._history[date(2015, 2, 3)]): print('a')\n",
      "74/405:         >>> if (date(2015, 2, 3) in c._history.keys()): print('a')\n",
      "74/406:\n",
      "            -> None:\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "\n",
      "        >>> c = Jurisdiction('Canada')\n",
      "        >>> if (date(2015, 2, 3) in c._history.keys()): print('a')\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/parkdale-highpark.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/nunavut.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/labrador.csv'))\n",
      "        \"\"\"\n",
      "        dt = date(year, month, day)\n",
      "        if dt in self._history.keys(): # if results already exist for it\n",
      "            self._history[dt].read_results(instream)\n",
      "        else:\n",
      "            self._history[dt] = Election(dt)\n",
      "            self._history[dt].read_results(instream)\n",
      "74/407:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) \\\n",
      "            -> None:\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "\n",
      "        >>> c = Jurisdiction('Canada')\n",
      "        >>> if (date(2015, 2, 3) in c._history.keys()): print('a')\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/parkdale-highpark.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/nunavut.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/labrador.csv'))\n",
      "        \"\"\"\n",
      "        dt = date(year, month, day)\n",
      "        if dt in self._history.keys(): # if results already exist for it\n",
      "            self._history[dt].read_results(instream)\n",
      "        else:\n",
      "            self._history[dt] = Election(dt)\n",
      "            self._history[dt].read_results(instream)\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:          # DONE\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, \\\n",
      "        date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/408:         >>> c = Jurisdiction('Canada')\n",
      "74/409:         >>> if (date(2015, 2, 3) in c._history.keys()): print('a')\n",
      "74/410:         >>> c.read_results(2015, 2, 3, open('../data/parkdale-highpark.csv'))\n",
      "74/411:         >>> c.read_results(2015, 2, 3, open('../data/nunavut.csv'))\n",
      "74/412:         >>> c.read_results(2015, 2, 3, open('../data/labrador.csv'))\n",
      "74/413:         >>> c._history\n",
      "74/414:         >>> c._history[date(2015, 2, 3)]\n",
      "74/415:         >>> c._history[date(2015, 2, 3)]._results\n",
      "74/416:         >>> c.party_wins('Liberal')\n",
      "74/417:         >>> c.party_wins('NDP-New Democratic Party')\n",
      "74/418:         >>> c.party_wins('NDP--New Democratic Party')\n",
      "74/419:         >>> c.party_wins()\n",
      "74/420:         >>> c.party_wins('')\n",
      "74/421:         >>> c._history[date(2015, 2, 3)]._results\n",
      "74/422:         >>> j = Jurisdiction('Canada')\n",
      "74/423:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/424:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/425:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/426:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/427:         >>> e1.update_results('r2', 'pc', 4)\n",
      "74/428:         >>> e1.update_results('r2', 'lib', 5)\n",
      "74/429:         >>> e1.update_results('r2', 'green', 6)\n",
      "74/430:         >>> e1.update_results('r2', 'ndp', 7)\n",
      "74/431:         >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "74/432:         True\n",
      "74/433:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/434:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/435:         >>> e2.update_results('r1', 'ndp', 40)\n",
      "74/436:         >>> e2.update_results('r1', 'lib', 5)\n",
      "74/437:         >>> e2.update_results('r2', 'lib', 10)\n",
      "74/438:         >>> e2.update_results('r2', 'pc', 20)\n",
      "74/439:         >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "74/440:         True\n",
      "74/441:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/442:         >>> j.party_wins('ndp')\n",
      "74/443:         >>> j.party_wins('lib')\n",
      "74/444:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/445:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/446:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/447:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/448:         >>> e1.update_results('r2', 'lib', 10)\n",
      "74/449:         >>> e1.update_results('r2', 'pc', 20)\n",
      "74/450:         >>> e1.update_results('r3', 'ndp', 200)\n",
      "74/451:         >>> e1.update_results('r3', 'pc', 100)\n",
      "74/452:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/453:         >>> e2.update_results('r1', 'ndp', 10)\n",
      "74/454:         >>> e2.update_results('r1', 'lib', 20)\n",
      "74/455:         >>> e2.update_results('r2', 'lib', 50)\n",
      "74/456:         >>> e2.update_results('r2', 'pc', 5)\n",
      "74/457:         >>> e3 = Election(date(2008, 6, 1))\n",
      "74/458:         >>> e3.update_results('r1', 'ndp', 101)\n",
      "74/459:         >>> e3.update_results('r1', 'lib', 102)\n",
      "74/460:         >>> e3.update_results('r2', 'ndp', 1001)\n",
      "74/461:         >>> e3.update_results('r2', 'lib', 1002)\n",
      "74/462:         >>> j = Jurisdiction('Canada')\n",
      "74/463:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/464:         >>> j._history[date(2003, 5, 16)] = e2\n",
      "74/465:         >>> j._history[date(2003, 6, 1)] = e3\n",
      "74/466:         >>> j.party_wins('lib')\n",
      "74/467:         >>> j._history\n",
      "74/468:         >>> j = Jurisdiction('Canada')\n",
      "74/469:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/470:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/471:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/472:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/473:         >>> e1.update_results('r2', 'pc', 4)\n",
      "74/474:         >>> e1.update_results('r2', 'lib', 5)\n",
      "74/475:         >>> e1.update_results('r2', 'green', 6)\n",
      "74/476:         >>> e1.update_results('r2', 'ndp', 7)\n",
      "74/477:         >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "74/478:         True\n",
      "74/479:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/480:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/481:         >>> e2.update_results('r1', 'ndp', 40)\n",
      "74/482:         >>> e2.update_results('r1', 'lib', 5)\n",
      "74/483:         >>> e2.update_results('r2', 'lib', 10)\n",
      "74/484:         >>> e2.update_results('r2', 'pc', 20)\n",
      "74/485:         >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "74/486:         True\n",
      "74/487:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/488:         >>> j._history\n",
      "74/489:         >>> dt, e = j._history.items()\n",
      "74/490:         >>> e\n",
      "74/491:         >>> {dt: e.popular_vote()['lib'] / sum(e.popular_vote().values()) for dt, e in j._history.items()}\n",
      "74/492:\n",
      "    def party_history(self, party: str) -> Dict[date, float]:\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, \\\n",
      "        date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        return {dt: e.popular_vote()['lib'] / sum(e.popular_vote().values()) for dt, e in self._history.items()}\n",
      "74/493:         >>> j = Jurisdiction('Canada')\n",
      "74/494:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/495:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/496:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/497:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/498:         >>> e1.update_results('r2', 'pc', 4)\n",
      "74/499:         >>> e1.update_results('r2', 'lib', 5)\n",
      "74/500:         >>> e1.update_results('r2', 'green', 6)\n",
      "74/501:         >>> e1.update_results('r2', 'ndp', 7)\n",
      "74/502:         >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "74/503:         True\n",
      "74/504:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/505:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/506:         >>> e2.update_results('r1', 'ndp', 40)\n",
      "74/507:         >>> e2.update_results('r1', 'lib', 5)\n",
      "74/508:         >>> e2.update_results('r2', 'lib', 10)\n",
      "74/509:         >>> e2.update_results('r2', 'pc', 20)\n",
      "74/510:         >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "74/511:         True\n",
      "74/512:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/513:         >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, \\\n",
      "74/514:         >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "74/515:         >>> j.party_history('lib')\n",
      "74/516:\n",
      "    def party_history(self, party: str) -> Dict[date, float]:\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.party_history('lib')\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        return {dt: e.popular_vote()[party] / sum(e.popular_vote().values()) for dt, e in self._history.items()}\n",
      "74/517:         >>> j = Jurisdiction('Canada')\n",
      "74/518:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/519:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/520:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/521:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/522:         >>> e1.update_results('r2', 'pc', 4)\n",
      "74/523:         >>> e1.update_results('r2', 'lib', 5)\n",
      "74/524:         >>> e1.update_results('r2', 'green', 6)\n",
      "74/525:         >>> e1.update_results('r2', 'ndp', 7)\n",
      "74/526:         >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "74/527:         True\n",
      "74/528:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/529:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/530:         >>> e2.update_results('r1', 'ndp', 40)\n",
      "74/531:         >>> e2.update_results('r1', 'lib', 5)\n",
      "74/532:         >>> e2.update_results('r2', 'lib', 10)\n",
      "74/533:         >>> e2.update_results('r2', 'pc', 20)\n",
      "74/534:         >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "74/535:         True\n",
      "74/536:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/537:         >>> j.party_history('lib')\n",
      "74/538:         >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "74/539:         >>> print(j.party_history('lib'))\n",
      "74/540:         >>> {dt: e.popular_vote()[party] / sum(e.popular_vote().values()) for dt, e in j._history.items()}\n",
      "74/541:         >>> {dt: e.popular_vote()['lib'] / sum(e.popular_vote().values()) for dt, e in j._history.items()}\n",
      "74/542:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:          # DONE\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) \\ # DONE\n",
      "            -> None:\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "\n",
      "        >>> c = Jurisdiction('Canada')\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/parkdale-highpark.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/nunavut.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/labrador.csv'))\n",
      "        >>> c._history[date(2015, 2, 3)]._results\n",
      "        \"\"\"\n",
      "        dt = date(year, month, day)\n",
      "        if dt in self._history.keys(): # if results already exist for it\n",
      "            self._history[dt].read_results(instream)\n",
      "        else:\n",
      "            self._history[dt] = Election(dt)\n",
      "            self._history[dt].read_results(instream)\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:          # DONE\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> print(j.party_history('lib'))\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        return {dt: e.popular_vote()[party] / sum(e.popular_vote().values()) for dt, e in self._history.items()}\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/543:         >>> j = Jurisdiction('Canada')\n",
      "74/544:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/545:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/546:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/547:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/548:         >>> e1.update_results('r2', 'pc', 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/549:         >>> e1.update_results('r2', 'lib', 5)\n",
      "74/550:         >>> e1.update_results('r2', 'green', 6)\n",
      "74/551:         >>> e1.update_results('r2', 'ndp', 7)\n",
      "74/552:         >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "74/553:         True\n",
      "74/554:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/555:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/556:         >>> e2.update_results('r1', 'ndp', 40)\n",
      "74/557:         >>> e2.update_results('r1', 'lib', 5)\n",
      "74/558:         >>> e2.update_results('r2', 'lib', 10)\n",
      "74/559:         >>> e2.update_results('r2', 'pc', 20)\n",
      "74/560:         >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "74/561:         True\n",
      "74/562:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/563:         >>> print(j.party_history('lib'))\n",
      "74/564:         >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "74/565:         >>> print(j.party_history('lib'))\n",
      "74/566:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:          # DONE\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) -> None: # DONE\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "\n",
      "        >>> c = Jurisdiction('Canada')\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/parkdale-highpark.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/nunavut.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/labrador.csv'))\n",
      "        >>> c._history[date(2015, 2, 3)]._results\n",
      "        \"\"\"\n",
      "        dt = date(year, month, day)\n",
      "        if dt in self._history.keys(): # if results already exist for it\n",
      "            self._history[dt].read_results(instream)\n",
      "        else:\n",
      "            self._history[dt] = Election(dt)\n",
      "            self._history[dt].read_results(instream)\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:          # DONE\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> print(j.party_history('lib'))\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        return {dt: e.popular_vote()[party] / sum(e.popular_vote().values()) for dt, e in self._history.items()}\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        # TODO: implement this method!\n",
      "        pass\n",
      "74/567:         >>> j = Jurisdiction('Canada')\n",
      "74/568:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/569:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/570:         >>> e1.update_results('r1', 'lib', 2)\n",
      "74/571:         >>> e1.update_results('r1', 'pc', 3)\n",
      "74/572:         >>> e1.update_results('r2', 'pc', 4)\n",
      "74/573:         >>> e1.update_results('r2', 'lib', 5)\n",
      "74/574:         >>> e1.update_results('r2', 'green', 6)\n",
      "74/575:         >>> e1.update_results('r2', 'ndp', 7)\n",
      "74/576:         >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "74/577:         True\n",
      "74/578:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/579:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/580:         >>> e2.update_results('r1', 'ndp', 40)\n",
      "74/581:         >>> e2.update_results('r1', 'lib', 5)\n",
      "74/582:         >>> e2.update_results('r2', 'lib', 10)\n",
      "74/583:         >>> e2.update_results('r2', 'pc', 20)\n",
      "74/584:         >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "74/585:         True\n",
      "74/586:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/587:         >>> print(j.party_history('lib'))\n",
      "74/588:         >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "74/589:         True\n",
      "74/590:         >>> j = Jurisdiction('Canada')\n",
      "74/591:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/592:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/593:         >>> e1.update_results('r1', 'lib', 1)\n",
      "74/594:         >>> e1.update_results('r1', 'pc', 1)\n",
      "74/595:         >>> e1.update_results('r2', 'pc', 1)\n",
      "74/596:         >>> e1.update_results('r2', 'lib', 1)\n",
      "74/597:         >>> e1.update_results('r2', 'green', 1)\n",
      "74/598:         >>> e1.update_results('r2', 'ndp', 1)\n",
      "74/599:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/600:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/601:         >>> e2.update_results('r1', 'ndp', 1)\n",
      "74/602:         >>> e2.update_results('r3', 'pc', 1)\n",
      "74/603:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/604:         >>> j._history\n",
      "74/605:         >>> j._history[0]\n",
      "74/606:         >>> j._history[date(2000, 2, 8)]\n",
      "74/607:         >>> j._history[date(2000, 2, 8)]._ridings\n",
      "74/608:         >>> j._history[date(2004, 5, 16)]._ridings\n",
      "74/609:\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j._history[date(2000, 2, 8)]._ridings\n",
      "        >>> j._history[date(2004, 5, 16)]._ridings\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        all_ridings = []\n",
      "        for i in l.items():\n",
      "            all_ridings.append(set(i[1].keys()))\n",
      "        setdiffs = []\n",
      "        for j in range(len(all_ridings)-1):\n",
      "            k = j + 1\n",
      "            setdiffs.append((all_ridings[j] - all_ridings[k], all_ridings[k] - all_ridings[j]))\n",
      "        return(setdiffs)\n",
      "74/610:         >>> j = Jurisdiction('Canada')\n",
      "74/611:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/612:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/613:         >>> e1.update_results('r1', 'lib', 1)\n",
      "74/614:         >>> e1.update_results('r1', 'pc', 1)\n",
      "74/615:         >>> e1.update_results('r2', 'pc', 1)\n",
      "74/616:         >>> e1.update_results('r2', 'lib', 1)\n",
      "74/617:         >>> e1.update_results('r2', 'green', 1)\n",
      "74/618:         >>> e1.update_results('r2', 'ndp', 1)\n",
      "74/619:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/620:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/621:         >>> e2.update_results('r1', 'ndp', 1)\n",
      "74/622:         >>> e2.update_results('r3', 'pc', 1)\n",
      "74/623:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/624:         >>> j._history[date(2000, 2, 8)]._ridings\n",
      "74/625:         >>> j._history[date(2004, 5, 16)]._ridings\n",
      "74/626:         >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "74/627:         >>> j.riding_changes()\n",
      "74/628:         >>> print(j.riding_changes())\n",
      "74/629:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:          # DONE\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) -> None: # DONE\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "\n",
      "        >>> c = Jurisdiction('Canada')\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/parkdale-highpark.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/nunavut.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/labrador.csv'))\n",
      "        >>> c._history[date(2015, 2, 3)]._results\n",
      "        \"\"\"\n",
      "        dt = date(year, month, day)\n",
      "        if dt in self._history.keys(): # if results already exist for it\n",
      "            self._history[dt].read_results(instream)\n",
      "        else:\n",
      "            self._history[dt] = Election(dt)\n",
      "            self._history[dt].read_results(instream)\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:          # DONE\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:     # DONE\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> print(j.party_history('lib'))\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        return {dt: e.popular_vote()[party] / sum(e.popular_vote().values()) for dt, e in self._history.items()}\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j._history[date(2000, 2, 8)]._ridings\n",
      "        >>> j._history[date(2004, 5, 16)]._ridings\n",
      "        >>> print(j.riding_changes())\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        all_ridings = []\n",
      "        for i in l.items():\n",
      "            all_ridings.append(set(i[1].keys()))\n",
      "        setdiffs = []\n",
      "        for j in range(len(all_ridings)-1):\n",
      "            k = j + 1\n",
      "            setdiffs.append((all_ridings[j] - all_ridings[k], all_ridings[k] - all_ridings[j]))\n",
      "        return setdiffs\n",
      "74/630:         >>> j = Jurisdiction('Canada')\n",
      "74/631:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/632:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/633:         >>> e1.update_results('r1', 'lib', 1)\n",
      "74/634:         >>> e1.update_results('r1', 'pc', 1)\n",
      "74/635:         >>> e1.update_results('r2', 'pc', 1)\n",
      "74/636:         >>> e1.update_results('r2', 'lib', 1)\n",
      "74/637:         >>> e1.update_results('r2', 'green', 1)\n",
      "74/638:         >>> e1.update_results('r2', 'ndp', 1)\n",
      "74/639:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/640:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/641:         >>> e2.update_results('r1', 'ndp', 1)\n",
      "74/642:         >>> e2.update_results('r3', 'pc', 1)\n",
      "74/643:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/644:         >>> j._history[date(2000, 2, 8)]._ridings\n",
      "74/645:         >>> j._history[date(2004, 5, 16)]._ridings\n",
      "74/646:         >>> print(j.riding_changes())\n",
      "74/647:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:          # DONE\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) -> None: # DONE\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "\n",
      "        >>> c = Jurisdiction('Canada')\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/parkdale-highpark.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/nunavut.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/labrador.csv'))\n",
      "        >>> c._history[date(2015, 2, 3)]._results\n",
      "        \"\"\"\n",
      "        dt = date(year, month, day)\n",
      "        if dt in self._history.keys(): # if results already exist for it\n",
      "            self._history[dt].read_results(instream)\n",
      "        else:\n",
      "            self._history[dt] = Election(dt)\n",
      "            self._history[dt].read_results(instream)\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:          # DONE\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:     # DONE\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> print(j.party_history('lib'))\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        return {dt: e.popular_vote()[party] / sum(e.popular_vote().values()) for dt, e in self._history.items()}\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j._history[date(2000, 2, 8)]._ridings\n",
      "        >>> j._history[date(2004, 5, 16)]._ridings\n",
      "        >>> print(j.riding_changes())\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        all_ridings = []\n",
      "        for i in self._history.items():\n",
      "            all_ridings.append(set(i[1].keys()))\n",
      "        setdiffs = []\n",
      "        for j in range(len(all_ridings)-1):\n",
      "            k = j + 1\n",
      "            setdiffs.append((all_ridings[j] - all_ridings[k], all_ridings[k] - all_ridings[j]))\n",
      "        return setdiffs\n",
      "74/648:         >>> j = Jurisdiction('Canada')\n",
      "74/649:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/650:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/651:         >>> e1.update_results('r1', 'lib', 1)\n",
      "74/652:         >>> e1.update_results('r1', 'pc', 1)\n",
      "74/653:         >>> e1.update_results('r2', 'pc', 1)\n",
      "74/654:         >>> e1.update_results('r2', 'lib', 1)\n",
      "74/655:         >>> e1.update_results('r2', 'green', 1)\n",
      "74/656:         >>> e1.update_results('r2', 'ndp', 1)\n",
      "74/657:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/658:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/659:         >>> e2.update_results('r1', 'ndp', 1)\n",
      "74/660:         >>> e2.update_results('r3', 'pc', 1)\n",
      "74/661:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/662:         >>> j._history[date(2000, 2, 8)]._ridings\n",
      "74/663:         >>> j._history[date(2004, 5, 16)]._ridings\n",
      "74/664:         >>> print(j.riding_changes())\n",
      "74/665:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:          # DONE\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) -> None: # DONE\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "\n",
      "        >>> c = Jurisdiction('Canada')\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/parkdale-highpark.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/nunavut.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/labrador.csv'))\n",
      "        >>> c._history[date(2015, 2, 3)]._results\n",
      "        \"\"\"\n",
      "        dt = date(year, month, day)\n",
      "        if dt in self._history.keys(): # if results already exist for it\n",
      "            self._history[dt].read_results(instream)\n",
      "        else:\n",
      "            self._history[dt] = Election(dt)\n",
      "            self._history[dt].read_results(instream)\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:          # DONE\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:     # DONE\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> print(j.party_history('lib'))\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        return {dt: e.popular_vote()[party] / sum(e.popular_vote().values()) for dt, e in self._history.items()}\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j._history[date(2000, 2, 8)]._ridings\n",
      "        >>> j._history[date(2004, 5, 16)]._ridings\n",
      "        >>> print(j.riding_changes())\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        all_ridings = []\n",
      "        for i in self._history.items():\n",
      "            all_ridings.append(set(i[1].ridings_of().keys()))\n",
      "        setdiffs = []\n",
      "        for j in range(len(all_ridings)-1):\n",
      "            k = j + 1\n",
      "            setdiffs.append((all_ridings[j] - all_ridings[k], all_ridings[k] - all_ridings[j]))\n",
      "        return setdiffs\n",
      "74/666:         >>> j = Jurisdiction('Canada')\n",
      "74/667:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/668:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/669:         >>> e1.update_results('r1', 'lib', 1)\n",
      "74/670:         >>> e1.update_results('r1', 'pc', 1)\n",
      "74/671:         >>> e1.update_results('r2', 'pc', 1)\n",
      "74/672:         >>> e1.update_results('r2', 'lib', 1)\n",
      "74/673:         >>> e1.update_results('r2', 'green', 1)\n",
      "74/674:         >>> e1.update_results('r2', 'ndp', 1)\n",
      "74/675:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/676:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/677:         >>> e2.update_results('r1', 'ndp', 1)\n",
      "74/678:         >>> e2.update_results('r3', 'pc', 1)\n",
      "74/679:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/680:         >>> j._history[date(2000, 2, 8)]._ridings\n",
      "74/681:         >>> j._history[date(2004, 5, 16)]._ridings\n",
      "74/682:         >>> print(j.riding_changes())\n",
      "74/683:\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j._history[date(2000, 2, 8)]._ridings\n",
      "        >>> j._history[date(2004, 5, 16)]._ridings\n",
      "        >>> print(j.riding_changes())\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        all_ridings = []\n",
      "        for i in self._history.items():\n",
      "            all_ridings.append(set(i[1].ridings_of()))\n",
      "        setdiffs = []\n",
      "        for j in range(len(all_ridings)-1):\n",
      "            k = j + 1\n",
      "            setdiffs.append((all_ridings[j] - all_ridings[k], all_ridings[k] - all_ridings[j]))\n",
      "        return setdiffs\n",
      "74/684:         >>> print(j.riding_changes())\n",
      "74/685:\n",
      "class Jurisdiction:\n",
      "    \"\"\"The election history for a jurisdiction that is a parliamentary\n",
      "    democracy.\n",
      "\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _name: the name of this jurisdiction.\n",
      "    _history: the election history for this jurisdiction.  Each key is a date,\n",
      "        and its value holds the results of an election that was held on that\n",
      "        date.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    None.\n",
      "\n",
      "    === Sample Usage ===\n",
      "    # See the method docstrings for sample usage.\n",
      "    \"\"\"\n",
      "    _name: str\n",
      "    _history: Dict[date, Election]\n",
      "\n",
      "    def __init__(self, name: str) -> None:          # DONE\n",
      "        \"\"\"Initialize this jurisdiction, with no elections so far.\n",
      "\n",
      "        >>> country = Jurisdiction('Canada')\n",
      "        >>> country._name\n",
      "        'Canada'\n",
      "        >>> country._history\n",
      "        {}\n",
      "        \"\"\"\n",
      "        self._name = name\n",
      "        self._history = {}\n",
      "\n",
      "    def read_results(self, year: int, month: int, day: int, instream: IO[str]) -> None: # DONE\n",
      "        \"\"\"Read and record results for an election in this jurisdiction.\n",
      "\n",
      "        If there are already some results stored for an election on this date,\n",
      "        add to them.\n",
      "\n",
      "        >>> c = Jurisdiction('Canada')\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/parkdale-highpark.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/nunavut.csv'))\n",
      "        >>> c.read_results(2015, 2, 3, open('../data/labrador.csv'))\n",
      "        >>> c._history[date(2015, 2, 3)]._results\n",
      "        \"\"\"\n",
      "        dt = date(year, month, day)\n",
      "        if dt in self._history.keys(): # if results already exist for it\n",
      "            self._history[dt].read_results(instream)\n",
      "        else:\n",
      "            self._history[dt] = Election(dt)\n",
      "            self._history[dt].read_results(instream)\n",
      "\n",
      "    def party_wins(self, party: str) -> List[date]:          # DONE\n",
      "        \"\"\"Return a list of all dates on which <party> won\n",
      "        an election in this jurisdiction.\n",
      "\n",
      "        If the party tied for most seats in an election, include that date\n",
      "        in the result.\n",
      "\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'lib', 10)\n",
      "        >>> e1.update_results('r2', 'pc', 20)\n",
      "        >>> e1.update_results('r3', 'ndp', 200)\n",
      "        >>> e1.update_results('r3', 'pc', 100)\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 10)\n",
      "        >>> e2.update_results('r1', 'lib', 20)\n",
      "        >>> e2.update_results('r2', 'lib', 50)\n",
      "        >>> e2.update_results('r2', 'pc', 5)\n",
      "        >>> e3 = Election(date(2008, 6, 1))\n",
      "        >>> e3.update_results('r1', 'ndp', 101)\n",
      "        >>> e3.update_results('r1', 'lib', 102)\n",
      "        >>> e3.update_results('r2', 'ndp', 1001)\n",
      "        >>> e3.update_results('r2', 'lib', 1002)\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> j._history[date(2003, 5, 16)] = e2\n",
      "        >>> j._history[date(2003, 6, 1)] = e3\n",
      "        >>> j.party_wins('lib')\n",
      "        [datetime.date(2003, 5, 16), datetime.date(2003, 6, 1)]\n",
      "        \"\"\"\n",
      "        win_dates = []\n",
      "        for dt, e in self._history.items():\n",
      "            if party in e.election_winners():\n",
      "                win_dates.append(dt)\n",
      "        return win_dates\n",
      "\n",
      "    def party_history(self, party: str) -> Dict[date, float]:     # DONE\n",
      "        \"\"\"Return this party's percentage of the popular vote\n",
      "        in each election in this jurisdiction's history.\n",
      "\n",
      "        Each key in the result is a date on which there was an election in\n",
      "        this jurisdiction.  Its value is the percentage of the popular vote\n",
      "        earned by party in that election.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 2)\n",
      "        >>> e1.update_results('r1', 'pc', 3)\n",
      "        >>> e1.update_results('r2', 'pc', 4)\n",
      "        >>> e1.update_results('r2', 'lib', 5)\n",
      "        >>> e1.update_results('r2', 'green', 6)\n",
      "        >>> e1.update_results('r2', 'ndp', 7)\n",
      "        >>> e1.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 40)\n",
      "        >>> e2.update_results('r1', 'lib', 5)\n",
      "        >>> e2.update_results('r2', 'lib', 10)\n",
      "        >>> e2.update_results('r2', 'pc', 20)\n",
      "        >>> e2.popular_vote() == {'ndp': 40, 'lib': 15, 'pc': 20}\n",
      "        True\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> print(j.party_history('lib'))\n",
      "        >>> j.party_history('lib') == {date(2000, 2, 8): 0.25, date(2004, 5, 16): 0.2}\n",
      "        True\n",
      "        \"\"\"\n",
      "        return {dt: e.popular_vote()[party] / sum(e.popular_vote().values()) for dt, e in self._history.items()}\n",
      "\n",
      "    def riding_changes(self) -> List[Tuple[Set[str], Set[str]]]:\n",
      "        \"\"\"Return the changes in ridings across elections in this jurisdiction.\n",
      "\n",
      "        Include a tuple for each pair of elections, in order by date.\n",
      "        The tuple should contain, first, a list of ridings that were removed\n",
      "        between these two elections, and then a list of ridings that were\n",
      "        added.\n",
      "\n",
      "        Precondition: There is at least one election recorded for this\n",
      "        jurisdiction.\n",
      "\n",
      "        >>> j = Jurisdiction('Canada')\n",
      "        >>> e1 = Election(date(2000, 2, 8))\n",
      "        >>> e1.update_results('r1', 'ndp', 1)\n",
      "        >>> e1.update_results('r1', 'lib', 1)\n",
      "        >>> e1.update_results('r1', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'pc', 1)\n",
      "        >>> e1.update_results('r2', 'lib', 1)\n",
      "        >>> e1.update_results('r2', 'green', 1)\n",
      "        >>> e1.update_results('r2', 'ndp', 1)\n",
      "        >>> j._history[date(2000, 2, 8)] = e1\n",
      "        >>> e2 = Election(date(2004, 5, 16))\n",
      "        >>> e2.update_results('r1', 'ndp', 1)\n",
      "        >>> e2.update_results('r3', 'pc', 1)\n",
      "        >>> j._history[date(2004, 5, 16)] = e2\n",
      "        >>> j._history[date(2000, 2, 8)]._ridings\n",
      "        >>> j._history[date(2004, 5, 16)]._ridings\n",
      "        >>> print(j.riding_changes())\n",
      "        >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "        True\n",
      "        \"\"\"\n",
      "        all_ridings = []\n",
      "        for i in self._history.items():\n",
      "            all_ridings.append(set(i[1].ridings_of()))\n",
      "        setdiffs = []\n",
      "        for j in range(len(all_ridings)-1):\n",
      "            k = j + 1\n",
      "            setdiffs.append((all_ridings[j] - all_ridings[k], all_ridings[k] - all_ridings[j]))\n",
      "        return setdiffs\n",
      "74/686:         >>> j = Jurisdiction('Canada')\n",
      "74/687:         >>> e1 = Election(date(2000, 2, 8))\n",
      "74/688:         >>> e1.update_results('r1', 'ndp', 1)\n",
      "74/689:         >>> e1.update_results('r1', 'lib', 1)\n",
      "74/690:         >>> e1.update_results('r1', 'pc', 1)\n",
      "74/691:         >>> e1.update_results('r2', 'pc', 1)\n",
      "74/692:         >>> e1.update_results('r2', 'lib', 1)\n",
      "74/693:         >>> e1.update_results('r2', 'green', 1)\n",
      "74/694:         >>> e1.update_results('r2', 'ndp', 1)\n",
      "74/695:         >>> j._history[date(2000, 2, 8)] = e1\n",
      "74/696:         >>> e2 = Election(date(2004, 5, 16))\n",
      "74/697:         >>> e2.update_results('r1', 'ndp', 1)\n",
      "74/698:         >>> e2.update_results('r3', 'pc', 1)\n",
      "74/699:         >>> j._history[date(2004, 5, 16)] = e2\n",
      "74/700:         >>> j._history[date(2000, 2, 8)]._ridings\n",
      "74/701:         >>> j._history[date(2004, 5, 16)]._ridings\n",
      "74/702:         >>> print(j.riding_changes())\n",
      "74/703:         >>> j.riding_changes() == [({'r2'}, {'r3'})]\n",
      "74/704:\n",
      "if __name__ == '__main__':\n",
      "    import python_ta\n",
      "    python_ta.check_all(config={\n",
      "        'allowed-io': ['Election.read_results', 'Jurisdiction.read_results'],\n",
      "        'allowed-import-modules': [\n",
      "            'doctest', 'python_ta', 'datetime', 'typing'\n",
      "        ],\n",
      "        'max-attributes': 15\n",
      "    })\n",
      "\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "74/705:         >>> e = Election(date(2000, 2, 8))\n",
      "74/706:         >>> e._d\n",
      "74/707:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date.date()\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.read_results(open('../data/labrador.csv'))\n",
      "        >>> e._results\n",
      "        >>> e.read_results(open('../data/toronto-stpauls.csv'))\n",
      "        >>> e._results\n",
      "        \"\"\"\n",
      "        labels = next(instream)\n",
      "        dat = [line.strip().split(',') for line in instream]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for j in filtered:\n",
      "            self.update_results(j[0], j[1], j[2])\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:      # DONE\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:          # DONE\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:              # DONE\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:                 # DONE\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_seats = {i:0 for i in self._parties} # initialize dict with win counts\n",
      "        for riding in self._ridings: # for each riding\n",
      "            winner = self.riding_winners(riding) # get winner of riding\n",
      "            if len(winner) == 1: # only do stuff if no tie\n",
      "                init_seats[winner[0]] += 1\n",
      "        return init_seats\n",
      "\n",
      "    def election_winners(self) -> List[str]:          # DONE\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.party_seats()\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self.party_seats().values())\n",
      "        winners = [pt[0] for pt in self.party_seats().items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "74/708:\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e._d\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = date.date()\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "74/709:         >>> e = Election(date(2000, 2, 8))\n",
      "74/710:         >>> e._d\n",
      "74/711:         >>> e._d.date()\n",
      "74/712:         >>> e._d.date\n",
      "74/713:         >>> e._d.today()\n",
      "74/714:         >>> e._d.strftime\n",
      "74/715:         >>> e._d.strftime()\n",
      "74/716:         >>> e._d.isoformat()\n",
      "74/717:         >>> e._d.isoformat\n",
      "74/718:         >>> e._d\n",
      "74/719:         >>> date(e._d)\n",
      "74/720:         >>> e._d\n",
      "74/721:         >>> e._d.day\n",
      "74/722:         >>> e._d.day()\n",
      "74/723:         >>> e._d.day\n",
      "74/724:         >>> print(e._d)\n",
      "74/725:         >>> print(e._d.day)\n",
      "74/726:\n",
      "class Election:\n",
      "    \"\"\"Data for a single election in a parliamentary democracy.\n",
      "\n",
      "    === Private Attributes ===\n",
      "    _d: the date of this election.\n",
      "    _ridings: all ridings for which any votes have been recorded in this\n",
      "        election.\n",
      "    _parties: all parties for which any votes have been recorded in this\n",
      "        election.\n",
      "    _results: the vote counts for this election.  Each key is the name of a\n",
      "        riding, and its value is a dictionary of results for that one riding.\n",
      "        Each of its keys, in turn, is the name of a party, and the associated\n",
      "        value is the number of votes earned by that party in that riding.\n",
      "\n",
      "    === Representation Invariants ==\n",
      "    For all strings s, s in self._ridings iff s in self._results.\n",
      "    For all strings s, s in self._parties iff s in self._results[r] for some r\n",
      "\n",
      "    === Sample Usage ===\n",
      "    >>> e = Election(date(2000, 2, 8))\n",
      "    >>> e.update_results('r1', 'ndp', 1234)\n",
      "    >>> e.update_results('r1', 'lib', 1345)\n",
      "    >>> e.update_results('r1', 'pc', 1456)\n",
      "    >>> e.riding_winners('r1')\n",
      "    ['pc']\n",
      "    >>> e.update_results('r2', 'pc', 1)\n",
      "    >>> e.popular_vote() == {'ndp': 1234, 'lib': 1345, 'pc': 1457}\n",
      "    True\n",
      "    >>> e.results_for('r1', 'lib')\n",
      "    1345\n",
      "    >>> e.party_seats() == {'ndp': 0, 'lib': 0, 'pc': 2}\n",
      "    True\n",
      "    \"\"\"\n",
      "    _d: date\n",
      "    _ridings: List[str]\n",
      "    _parties: List[str]\n",
      "    _results: Dict[str, Dict[str, int]]\n",
      "\n",
      "    def __init__(self, d: date) -> None:    ########### DONE\n",
      "        \"\"\"Initialize a new election on date d and with no votes recorded so\n",
      "        far.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>>\n",
      "        datetime.date(2000, 2, 8)\n",
      "        \"\"\"\n",
      "        self._d = d\n",
      "        self._ridings = []\n",
      "        self._parties = []\n",
      "        self._results = {}\n",
      "\n",
      "    def ridings_of(self) -> List[str]:    ########### DONE\n",
      "        \"\"\"Return the ridings in which votes have been recorded in this\n",
      "         election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1']\n",
      "        >>> e.update_results('r2', 'ndp', 1)\n",
      "        >>> e.ridings_of()\n",
      "        ['r1', 'r2']\n",
      "        \"\"\"\n",
      "        return self._ridings\n",
      "\n",
      "    def update_results(self, riding: str, party: str, votes: int) -> None:    ########### DONE\n",
      "        \"\"\"Update this election to reflect that in <riding>, <party> received\n",
      "        <votes> additional votes.\n",
      "\n",
      "        <riding> may or may not already have some votes recorded in this\n",
      "        election.  <party> may or may not already have some votes recorded in\n",
      "        this riding in this election.\n",
      "\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r1', 'lib', 5)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r2', 'ndp', 6)\n",
      "        >>> e._results\n",
      "        >>> e.update_results('r3', 'lib', 0)\n",
      "        >>> e._results\n",
      "\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1\n",
      "        >>> e.update_results('r1', 'ndp', 1000)\n",
      "        >>> e.results_for('r1', 'ndp')\n",
      "        1001\n",
      "        \"\"\"\n",
      "        if riding not in self._ridings:\n",
      "            self._ridings.append(riding) # add riding to list of ridings\n",
      "            self._results[riding] = {}   # initialize riding in results\n",
      "\n",
      "        if party not in self._parties:\n",
      "            self._parties.append(party)  # add party to list of parties\n",
      "\n",
      "        if party not in self._results[riding].keys():\n",
      "            self._results[riding][party] = votes  # initialize party in results\n",
      "        else:\n",
      "            self._results[riding][party] += votes  # add votes to appropriate riding-party\n",
      "\n",
      "    def read_results(self, instream: IO[str]) -> None:      # DONE\n",
      "        \"\"\"Update this election with the results in instream.\n",
      "\n",
      "        Precondition: instream is an open csv file, in the format defined\n",
      "        in the A0 handout.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.read_results(open('../data/labrador.csv'))\n",
      "        >>> e._results\n",
      "        >>> e.read_results(open('../data/toronto-stpauls.csv'))\n",
      "        >>> e._results\n",
      "        \"\"\"\n",
      "        labels = next(instream)\n",
      "        dat = [line.strip().split(',') for line in instream]\n",
      "        filtered = [[i[1].replace(\"\\\"\",\"\"), i[13].replace(\"\\\"\", \"\"), int(i[17])] for i in dat]\n",
      "        for j in filtered:\n",
      "            self.update_results(j[0], j[1], j[2])\n",
      "\n",
      "    def results_for(self, riding: str, party: str) -> Optional[int]:      # DONE\n",
      "        \"\"\"Return the number of votes received in <riding> by <party> in\n",
      "        this election.\n",
      "\n",
      "        Return None if <riding> does not have any votes recorded in this\n",
      "        election, or if it does, but <party> does not have any votes recorded\n",
      "        in this riding in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1234)\n",
      "        >>> e.update_results('r1', 'lib', 1345)\n",
      "        >>> e.update_results('r1', 'pc', 1456)\n",
      "        >>> e.update_results('r2', 'pc', 1)\n",
      "        >>> e.results_for('r1', 'pc')\n",
      "        1456\n",
      "        >>> e.results_for('r2', 'pc')\n",
      "        1\n",
      "        \"\"\"\n",
      "        if (riding not in self._ridings) or (party not in self._parties):\n",
      "            return None\n",
      "        else:\n",
      "            return self._results[riding][party]\n",
      "\n",
      "    def riding_winners(self, riding: str) -> List[str]:          # DONE\n",
      "        \"\"\"Return the winners, in <riding>, of this election.\n",
      "\n",
      "        The winner is the party or parties that received the most votes in\n",
      "        total.  (There may have been a tie.)  The return value is a list so\n",
      "        that, in the case of ties, we can return a list of election_winners.\n",
      "        If there is no tie, the length of the returned list is 1.\n",
      "\n",
      "        Precondition: <riding> has at least 1 vote recorded in this election.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.riding_winners('r1')\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self._results[riding].values())\n",
      "        winners = [pt[0] for pt in self._results[riding].items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "\n",
      "    def popular_vote(self) -> Dict[str, int]:              # DONE\n",
      "        \"\"\"Return the total number of votes earned by each party, across\n",
      "        all ridings, in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e._results\n",
      "        >>> e.popular_vote() == {'ndp': 8, 'lib': 7, 'pc': 7, 'green': 6}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_part = {i:0 for i in self._parties}\n",
      "        for riding in self._results.values():\n",
      "            for pt in riding.items():\n",
      "                init_part[pt[0]] += pt[1]\n",
      "        return init_part\n",
      "\n",
      "    def party_seats(self) -> Dict[str, int]:                 # DONE\n",
      "        \"\"\"Return the number of ridings that each party won in this election.\n",
      "\n",
      "        Include all parties that have at least one vote recorded in at least\n",
      "        one riding.  If there was a tie in a riding, it doesn't contribute to\n",
      "        the seat count for any of the parties that tied in that riding.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'pc', 4)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.party_seats() == {'pc': 1, 'ndp': 1, 'lib': 0, 'green': 0}\n",
      "        True\n",
      "        \"\"\"\n",
      "        init_seats = {i:0 for i in self._parties} # initialize dict with win counts\n",
      "        for riding in self._ridings: # for each riding\n",
      "            winner = self.riding_winners(riding) # get winner of riding\n",
      "            if len(winner) == 1: # only do stuff if no tie\n",
      "                init_seats[winner[0]] += 1\n",
      "        return init_seats\n",
      "\n",
      "    def election_winners(self) -> List[str]:          # DONE\n",
      "        \"\"\"Return the party (or parties, in the case of a tie) that won the\n",
      "        most seats in this election.\n",
      "\n",
      "        If no votes have been recorded in any riding in this election,\n",
      "        return the empty list.\n",
      "\n",
      "        >>> e = Election(date(2000, 2, 8))\n",
      "        >>> e.update_results('r1', 'ndp', 1)\n",
      "        >>> e.update_results('r1', 'lib', 2)\n",
      "        >>> e.update_results('r1', 'pc', 3)\n",
      "        >>> e.update_results('r2', 'lib', 5)\n",
      "        >>> e.update_results('r2', 'green', 6)\n",
      "        >>> e.update_results('r2', 'ndp', 7)\n",
      "        >>> e.update_results('r2', 'pc', 8)\n",
      "        >>> e.party_seats()\n",
      "        >>> e.election_winners()\n",
      "        ['pc']\n",
      "        \"\"\"\n",
      "        win_vote_count = max(self.party_seats().values())\n",
      "        winners = [pt[0] for pt in self.party_seats().items() if pt[1] == win_vote_count]\n",
      "        return winners\n",
      "74/727:         >>> e = Election(date(2000, 2, 8))\n",
      "74/728:         >>> e._d\n",
      "74/729:         >>> e = Election(date(2000, 2, 8))\n",
      "74/730:         >>> e.update_results('r1', 'ndp', 1)\n",
      "74/731:         >>> e.update_results('r1', 'lib', 2)\n",
      "74/732:         >>> e.update_results('r1', 'pc', 3)\n",
      "74/733:         >>> e.update_results('r2', 'lib', 5)\n",
      "74/734:         >>> e.update_results('r2', 'green', 6)\n",
      "74/735:         >>> e.update_results('r2', 'ndp', 7)\n",
      "74/736:         >>> e.update_results('r2', 'pc', 8)\n",
      "74/737:         >>> e.party_seats()\n",
      "75/1:\n",
      "def peek(stack: Stack) -> Optional[Any]:\n",
      "    \"\"\"Return the top item on the given stack.\n",
      "\n",
      "    If the stack is empty, return None.\n",
      "\n",
      "    Unlike Stack.pop, this function should leave the stack unchanged when the\n",
      "    function ends. You can (and should) still call pop and push, just make\n",
      "    sure that if you take any items off the stack, you put them back on!\n",
      "\n",
      "    >>> stack = Stack()\n",
      "    >>> stack.push(1)\n",
      "    >>> stack.push(2)\n",
      "    >>> peek(stack)\n",
      "    2\n",
      "    >>> stack.pop()\n",
      "    2\n",
      "    \"\"\"\n",
      "    return stack[-1]\n",
      "75/2: from typing import Any, Optional\n",
      "75/3: from adts import Stack, Queue\n",
      "75/4:\n",
      "def peek(stack: Stack) -> Optional[Any]:\n",
      "    \"\"\"Return the top item on the given stack.\n",
      "\n",
      "    If the stack is empty, return None.\n",
      "\n",
      "    Unlike Stack.pop, this function should leave the stack unchanged when the\n",
      "    function ends. You can (and should) still call pop and push, just make\n",
      "    sure that if you take any items off the stack, you put them back on!\n",
      "\n",
      "    >>> stack = Stack()\n",
      "    >>> stack.push(1)\n",
      "    >>> stack.push(2)\n",
      "    >>> peek(stack)\n",
      "    2\n",
      "    >>> stack.pop()\n",
      "    2\n",
      "    \"\"\"\n",
      "    return stack[-1]\n",
      "75/5:     >>> stack = Stack()\n",
      "75/6:     >>> stack.push(1)\n",
      "75/7:     >>> stack.push(2)\n",
      "75/8:     >>> peek(stack)\n",
      "75/9:\n",
      "def peek(stack: Stack) -> Optional[Any]:\n",
      "    \"\"\"Return the top item on the given stack.\n",
      "\n",
      "    If the stack is empty, return None.\n",
      "\n",
      "    Unlike Stack.pop, this function should leave the stack unchanged when the\n",
      "    function ends. You can (and should) still call pop and push, just make\n",
      "    sure that if you take any items off the stack, you put them back on!\n",
      "\n",
      "    >>> stack = Stack()\n",
      "    >>> stack.push(1)\n",
      "    >>> stack.push(2)\n",
      "    >>> peek(stack)\n",
      "    2\n",
      "    >>> stack.pop()\n",
      "    2\n",
      "    \"\"\"\n",
      "    lastItem = stack.pop()\n",
      "    stack.push(lastItem)\n",
      "    return lastItem\n",
      "75/10:     >>> stack = Stack()\n",
      "75/11:     >>> stack.push(1)\n",
      "75/12:     >>> stack.push(2)\n",
      "75/13:     >>> peek(stack)\n",
      "75/14:     2\n",
      "75/15:     >>> stack.pop()\n",
      "75/16:     2\n",
      "75/17:\n",
      "def reverse_top_two(stack: Stack) -> None:\n",
      "    \"\"\"Reverse the top two elements on <stack>.\n",
      "\n",
      "    Precondition: <stack> has at least two items.\n",
      "\n",
      "    >>> stack = Stack()\n",
      "    >>> stack.push(1)\n",
      "    >>> stack.push(2)\n",
      "    >>> reverse_top_two(stack)\n",
      "    >>> stack.pop()\n",
      "    1\n",
      "    >>> stack.pop()\n",
      "    2\n",
      "    >>> stack.is_empty()\n",
      "    True\n",
      "    \"\"\"\n",
      "    Last = stack.pop()\n",
      "    secondLast = stack.pop()\n",
      "    stack.push(Last)\n",
      "    stack.push(secondLast)\n",
      "75/18:     >>> stack = Stack()\n",
      "75/19:     >>> stack.push(1)\n",
      "75/20:     >>> stack.push(2)\n",
      "75/21:     >>> reverse_top_two(stack)\n",
      "75/22:     >>> stack.pop()\n",
      "75/23:     1\n",
      "75/24:     >>> stack.pop()\n",
      "75/25:     2\n",
      "75/26:     >>> stack.is_empty()\n",
      "75/27:     True\n",
      "75/28:\n",
      "def remove_all(queue: Queue) -> None:\n",
      "    \"\"\"Remove all items from the given queue.\n",
      "\n",
      "    >>> queue = Queue()\n",
      "    >>> queue.enqueue(1)\n",
      "    >>> queue.enqueue(2)\n",
      "    >>> queue.enqueue(3)\n",
      "    >>> remove_all(queue)\n",
      "    >>> queue.is_empty()\n",
      "    True\n",
      "    \"\"\"\n",
      "    return len(queue)\n",
      "75/29:     >>> queue = Queue()\n",
      "75/30:     >>> remove_all(queue)\n",
      "75/31:\n",
      "def remove_all(queue: Queue) -> None:\n",
      "    \"\"\"Remove all items from the given queue.\n",
      "\n",
      "    >>> queue = Queue()\n",
      "    >>> queue.enqueue(1)\n",
      "    >>> queue.enqueue(2)\n",
      "    >>> queue.enqueue(3)\n",
      "    >>> remove_all(queue)\n",
      "    >>> queue.is_empty()\n",
      "    True\n",
      "    \"\"\"\n",
      "    while not queue.is_empty():\n",
      "        queue.dequeue()\n",
      "75/32:     >>> queue = Queue()\n",
      "75/33:     >>> queue.enqueue(1)\n",
      "75/34:     >>> queue.enqueue(2)\n",
      "75/35:     >>> queue.enqueue(3)\n",
      "75/36:     >>> remove_all(queue)\n",
      "75/37:     >>> queue.is_empty()\n",
      "75/38:     True\n",
      "75/39:\n",
      "def remove_all_but_one(queue: Queue) -> None:\n",
      "    \"\"\"Remove all items from the given queue except the last one.\n",
      "\n",
      "    Precondition: <queue> contains at least one item.\n",
      "                  or: not queue.is_empty()\n",
      "\n",
      "    >>> queue = Queue()\n",
      "    >>> queue.enqueue(1)\n",
      "    >>> queue.enqueue(2)\n",
      "    >>> queue.enqueue(3)\n",
      "    >>> remove_all_but_one(queue)\n",
      "    >>> queue.is_empty()\n",
      "    False\n",
      "    >>> queue.dequeue()\n",
      "    3\n",
      "    >>> queue.is_empty()\n",
      "    True\n",
      "    \"\"\"\n",
      "    while not queue.is_empty():\n",
      "        saved = queue.dequeue()\n",
      "    queue.enqueue(saved)\n",
      "75/40:     >>> queue = Queue()\n",
      "75/41:     >>> queue.enqueue(1)\n",
      "75/42:     >>> queue.enqueue(2)\n",
      "75/43:     >>> queue.enqueue(3)\n",
      "75/44:     >>> remove_all_but_one(queue)\n",
      "75/45:     >>> queue.is_empty()\n",
      "75/46:     False\n",
      "75/47:     >>> queue.dequeue()\n",
      "75/48:     3\n",
      "75/49:     >>> queue.is_empty()\n",
      "75/50:     True\n",
      "76/1: from __future__ import annotations\n",
      "76/2:\n",
      "class _Node:\n",
      "    \"\"\"A node in a linked list.\n",
      "\n",
      "    Note that this is considered a \"private class\", one which is only meant\n",
      "    to be used in this module by the LinkedList class, but not by client code.\n",
      "\n",
      "    === Attributes ===\n",
      "    item:\n",
      "        The data stored in this node.\n",
      "    next:\n",
      "        The next node in the list, or None if there are no more nodes.\n",
      "    \"\"\"\n",
      "    item: Any\n",
      "    next: Optional[_Node]\n",
      "\n",
      "    def __init__(self, item: Any) -> None:\n",
      "        \"\"\"Initialize a new node storing <item>, with no next node.\n",
      "        \"\"\"\n",
      "        self.item = item\n",
      "        self.next = None  # Initially pointing to nothing\n",
      "76/3: class LinkedList:\n",
      "76/4: class LinkedList:\n",
      "76/5:\n",
      "class _Node:\n",
      "    \"\"\"A node in a linked list.\n",
      "\n",
      "    Note that this is considered a \"private class\", one which is only meant\n",
      "    to be used in this module by the LinkedList class, but not by client code.\n",
      "\n",
      "    === Attributes ===\n",
      "    item:\n",
      "        The data stored in this node.\n",
      "    next:\n",
      "        The next node in the list, or None if there are no more nodes.\n",
      "    \"\"\"\n",
      "    item: Any\n",
      "    next: Optional[_Node]\n",
      "\n",
      "    def __init__(self, item: Any) -> None:\n",
      "        \"\"\"Initialize a new node storing <item>, with no next node.\n",
      "        \"\"\"\n",
      "        self.item = item\n",
      "        self.next = None  # Initially pointing to nothing\n",
      "76/6: class LinkedList:\n",
      "76/7:\n",
      "    def __init__(self) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        self._first = None\n",
      "76/8:\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        # >>> LinkedList([]).is_empty()\n",
      "        # True\n",
      "        # >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        # False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "76/9:\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        # >>> str(LinkedList([1, 2, 3]))\n",
      "        # '[1 -> 2 -> 3]'\n",
      "        # >>> str(LinkedList([]))\n",
      "        # '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "76/10:\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "76/11:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        # >>> lst.insert(2, 300)\n",
      "        # >>> str(lst)\n",
      "        # '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        # >>> lst.insert(5, -1)\n",
      "        # >>> str(lst)\n",
      "        # '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        # >>> lst.insert(100, 2)\n",
      "        # Traceback (most recent call last):\n",
      "        # IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "76/12:     def __len__(self) -> int:\n",
      "76/13:     def __len__(self):\n",
      "76/14:     def __len__(self) -> int:\n",
      "76/15:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        # >>> lst = LinkedList([])\n",
      "        # >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        # 0\n",
      "        # >>> lst = LinkedList([1, 2, 3])\n",
      "        # >>> len(lst)\n",
      "        # 3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "76/16:         # >>> lst = LinkedList([])\n",
      "76/17:         # >>> len(lst)              # Equivalent to lst.__len__()\n",
      "76/18:         # 0\n",
      "76/19:         # >>> lst = LinkedList([1, 2, 3])\n",
      "76/20:         # >>> len(lst)\n",
      "76/21:\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        # >>> lst.count(1)\n",
      "        # 3\n",
      "        # >>> lst.count(2)\n",
      "        # 2\n",
      "        # >>> lst.count(3)\n",
      "        # 1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item = item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "76/22:\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        # >>> lst.count(1)\n",
      "        # 3\n",
      "        # >>> lst.count(2)\n",
      "        # 2\n",
      "        # >>> lst.count(3)\n",
      "        # 1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "76/23:\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        # >>> lst.index(1)\n",
      "        # 0\n",
      "        # >>> lst.index(3)\n",
      "        # 3\n",
      "        # >>> lst.index(148)\n",
      "        # Traceback (most recent call last):\n",
      "        # ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "76/24:         # >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "76/25:         # >>> lst.index(1)\n",
      "76/26:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        self._first = None\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        # >>> LinkedList([]).is_empty()\n",
      "        # True\n",
      "        # >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        # False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        # >>> str(LinkedList([1, 2, 3]))\n",
      "        # '[1 -> 2 -> 3]'\n",
      "        # >>> str(LinkedList([]))\n",
      "        # '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        # >>> lst.insert(2, 300)\n",
      "        # >>> str(lst)\n",
      "        # '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        # >>> lst.insert(5, -1)\n",
      "        # >>> str(lst)\n",
      "        # '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        # >>> lst.insert(100, 2)\n",
      "        # Traceback (most recent call last):\n",
      "        # IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        # >>> lst = LinkedList([])\n",
      "        # >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        # 0\n",
      "        # >>> lst = LinkedList([1, 2, 3])\n",
      "        # >>> len(lst)\n",
      "        # 3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    # TODO: implement this method\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        # >>> lst.count(1)\n",
      "        # 3\n",
      "        # >>> lst.count(2)\n",
      "        # 2\n",
      "        # >>> lst.count(3)\n",
      "        # 1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    # TODO: implement this method\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        # >>> lst.index(1)\n",
      "        # 0\n",
      "        # >>> lst.index(3)\n",
      "        # 3\n",
      "        # >>> lst.index(148)\n",
      "        # Traceback (most recent call last):\n",
      "        # ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    # TODO: implement this method\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 3])\n",
      "        # >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        # >>> lst[1] = 200\n",
      "        # >>> lst[2] = 300\n",
      "        # >>> str(lst)\n",
      "        # '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        pass\n",
      "76/27:         # >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "76/28:         # >>> lst.index(1)\n",
      "76/29:         # 0\n",
      "76/30:         # >>> lst.index(3)\n",
      "76/31:         # 3\n",
      "76/32:         # >>> lst.index(148)\n",
      "76/33:\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 3])\n",
      "        # >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        # >>> lst[1] = 200\n",
      "        # >>> lst[2] = 300\n",
      "        # >>> str(lst)\n",
      "        # '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        before = self[index - 1]\n",
      "        after = self[index]\n",
      "        before.next = itm\n",
      "        itm.next = after\n",
      "77/1:     import doctest\n",
      "77/2:     doctest.testmod()\n",
      "77/3:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(i) for i in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        before = self[index - 1]\n",
      "        after = self[index]\n",
      "        before.next = itm\n",
      "        itm.next = after\n",
      "77/4:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/5: from __future__ import annotations\n",
      "77/6: from typing import Any, List, Optional\n",
      "77/7:\n",
      "class _Node:\n",
      "    \"\"\"A node in a linked list.\n",
      "\n",
      "    Note that this is considered a \"private class\", one which is only meant\n",
      "    to be used in this module by the LinkedList class, but not by client code.\n",
      "\n",
      "    === Attributes ===\n",
      "    item:\n",
      "        The data stored in this node.\n",
      "    next:\n",
      "        The next node in the list, or None if there are no more nodes.\n",
      "    \"\"\"\n",
      "    item: Any\n",
      "    next: Optional[_Node]\n",
      "\n",
      "    def __init__(self, item: Any) -> None:\n",
      "        \"\"\"Initialize a new node storing <item>, with no next node.\n",
      "        \"\"\"\n",
      "        self.item = item\n",
      "        self.next = None  # Initially pointing to nothing\n",
      "77/8:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        \n",
      "        before = self[index - 1]\n",
      "        after = self[index]\n",
      "        before.next = itm\n",
      "        itm.next = after\n",
      "77/9:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/10:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/11:\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        \n",
      "        before = self[index - 1]\n",
      "        after = self[index]\n",
      "        before.next = itm\n",
      "        itm.next = after\n",
      "77/12:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/13:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/14:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/15:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "77/16:         >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "77/17:         >>> lst.index(1)\n",
      "77/18:         0\n",
      "77/19:         >>> lst.index(3)\n",
      "77/20:         3\n",
      "77/21:         >>> lst.index(148)\n",
      "77/22:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/23:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/24:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:        # at beginning:\n",
      "            self._first = itm\n",
      "            after = self[index]\n",
      "            itm.next = after\n",
      "        elif index == len(self)-1:        # at end\n",
      "            before = self[index - 1]\n",
      "            before.next = itm\n",
      "        else:                     # anywhere else\n",
      "            before = self[index - 1]\n",
      "            after = self[index]\n",
      "            before.next = itm\n",
      "            itm.next = after\n",
      "77/25:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/26:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/27:         >>> lst[1] = 200\n",
      "77/28:         >>> lst[2] = 300\n",
      "77/29:\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:        # at beginning:\n",
      "            self._first = itm\n",
      "            after = self[index]\n",
      "            itm.next = after\n",
      "        elif index == len(self):        # at end\n",
      "            before = self[index - 1]\n",
      "            before.next = itm\n",
      "        else:                     # anywhere else\n",
      "            before = self[index - 1]\n",
      "            after = self[index]\n",
      "            before.next = itm\n",
      "            itm.next = after\n",
      "77/30:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/31:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/32:         >>> lst[1] = 200\n",
      "77/33:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:        # at beginning:\n",
      "            self._first = itm\n",
      "            after = self[index]\n",
      "            itm.next = after\n",
      "        elif index == len(self):        # at end\n",
      "            before = self[index - 1]\n",
      "            before.next = itm\n",
      "        else:                     # anywhere else\n",
      "            before = self[index - 1]\n",
      "            after = self[index]\n",
      "            before.next = itm\n",
      "            itm.next = after\n",
      "77/34:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/35:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/36:         >>> lst[1] = 200\n",
      "77/37:         >>> lst\n",
      "77/38:         >>> lst[0]\n",
      "77/39:         >>> len(lst)\n",
      "77/40:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[0]\n",
      "        >>> len(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:        # at beginning:\n",
      "            self._first = itm\n",
      "            after = self[index]\n",
      "            itm.next = after\n",
      "        elif index == len(self):        # at end\n",
      "            before = self[index - 1]\n",
      "            before.next = itm\n",
      "        else:                     # anywhere else\n",
      "            before = self[index - 1]\n",
      "            after = self[index]\n",
      "            before.next = itm\n",
      "            itm.next = after\n",
      "77/41:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/42:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/43:         >>> lst[0]\n",
      "77/44:         >>> len(lst)\n",
      "77/45:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[0]\n",
      "        >>> len(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        assert type(itm) == _Node\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:        # at beginning:\n",
      "            self._first = itm\n",
      "            after = self[index]\n",
      "            itm.next = after\n",
      "        elif index == len(self):        # at end\n",
      "            before = self[index - 1]\n",
      "            before.next = itm\n",
      "        else:                     # anywhere else\n",
      "            before = self[index - 1]\n",
      "            after = self[index]\n",
      "            before.next = itm\n",
      "            itm.next = after\n",
      "77/46:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/47:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/48:         >>> lst[0]\n",
      "77/49:         >>> len(lst)\n",
      "77/50:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/51:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/52:         >>> lst[0]\n",
      "77/53:         >>> len(lst)\n",
      "77/54:         >>> lst[1] = 200\n",
      "77/55:         >>> lst[1] = 200\n",
      "77/56:         >>> lst = LinkedList([])\n",
      "77/57:         >>> len(lst)              # Equivalent to lst.__len__()\n",
      "77/58:         0\n",
      "77/59:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/60:         >>> len(lst)\n",
      "77/61:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[0]\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        # itm = _Node(item)\n",
      "        # if index > len(self):\n",
      "        #     raise IndexError\n",
      "        # elif index == 0:        # at beginning:\n",
      "        #     self._first = itm\n",
      "        #     after = self[index]\n",
      "        #     itm.next = after\n",
      "        # elif index == len(self):        # at end\n",
      "        #     before = self[index - 1]\n",
      "        #     before.next = itm\n",
      "        # else:                     # anywhere else\n",
      "        #     before = self[index - 1]\n",
      "        #     after = self[index]\n",
      "        #     before.next = itm\n",
      "        #     itm.next = after\n",
      "        self.insert(index, item)\n",
      "77/62:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/63:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/64:         >>> lst[0]\n",
      "77/65:         >>> lst[1] = 200\n",
      "77/66:         >>> lst[2] = 300\n",
      "77/67:         >>> str(lst)\n",
      "77/68:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[0]\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            itm.next = self._first\n",
      "            self._first = itm\n",
      "        else:\n",
      "            itm.next = self[index]\n",
      "            self[index-1].next = itm\n",
      "77/69:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/70:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/71:         >>> lst[0]\n",
      "77/72:         >>> lst[1] = 200\n",
      "77/73:         >>> type(lst[0])\n",
      "77/74:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[0]\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        new_itm = _Node(item)\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            new_itm.next = self._first\n",
      "            self._first = new_itm\n",
      "        else:\n",
      "            new_itm.next = self[index]\n",
      "            self[index-1].next = new_itm\n",
      "77/75:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/76:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/77:         >>> lst[0]\n",
      "77/78:         >>> lst[1] = 200\n",
      "77/79:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = LinkedList([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        ValueError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[0]\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        else:\n",
      "            if index == 0:\n",
      "                itm.next = self._first.next\n",
      "                self._first = itm\n",
      "            else:\n",
      "                curr = self._first\n",
      "                idx = 0\n",
      "                while not idx == index :\n",
      "                    idx += 1\n",
      "                    curr = curr.next\n",
      "                curr.item = itm.item\n",
      "77/80:         >>> lst = LinkedList([1, 2, 3])\n",
      "77/81:         >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "77/82:         >>> lst[0]\n",
      "77/83:         >>> lst[1] = 200\n",
      "77/84:         >>> lst[2] = 300\n",
      "77/85:         >>> str(lst)\n",
      "77/86:         IndexError\n",
      "78/1: from timeit import timeit\n",
      "78/2: NUM_TRIALS = 3000                        # The number of trials to run.\n",
      "78/3: SIZES = [1000, 2000, 4000, 8000, 16000]  # The list sizes to try.\n",
      "78/4:\n",
      "def profile_len(list_class: type, size: int) -> float:\n",
      "    \"\"\"Return the time taken to call len on a list of the given class and size.\n",
      "\n",
      "    Precondition: list_class is either list or LinkedList.\n",
      "    \"\"\"\n",
      "    my_list = list_class([0] * size])\n",
      "    time = 0\n",
      "    time += timeit('len(my_list)', number=100, globals=locals())\n",
      "    return time\n",
      "78/5:     my_list = list_class([0] * size)\n",
      "78/6:\n",
      "def profile_len(list_class: type, size: int) -> float:\n",
      "    \"\"\"Return the time taken to call len on a list of the given class and size.\n",
      "\n",
      "    Precondition: list_class is either list or LinkedList.\n",
      "    \"\"\"\n",
      "    my_list = list_class([0] * size)\n",
      "    time = 0\n",
      "    time += timeit('len(my_list)', number=100, globals=locals())\n",
      "    return time\n",
      "78/7:\n",
      "if __name__ == '__main__':\n",
      "    for list_class in [LinkedList]:\n",
      "        # Try each list size\n",
      "        for s in SIZES:\n",
      "            time = profile_len(list_class, s)\n",
      "            print(f'[{list_class.__name__}] Size {s:>6}: {time}')\n",
      "78/8: from linked_list import LinkedList\n",
      "78/9: from ./linked_list.py import LinkedList\n",
      "78/10: from linked_list import LinkedList\n",
      "78/11: from timeit import timeit\n",
      "78/12: from linked_list import LinkedList\n",
      "78/13: from linked_list import LinkedList\n",
      "78/14: import linked_list\n",
      "78/15: from wk5.linked_list import LinkedList\n",
      "78/16: >>> sys.path\n",
      "78/17: import sys\n",
      "78/18: >>> sys.path\n",
      "77/87:\n",
      "class Augmented:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    # _length:\n",
      "    #     Length of list.\n",
      "    _first: Optional[_Node]\n",
      "    _length: int\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "        \"\"\"\n",
      "        # convert all items in list to nodes\n",
      "        noded = [_Node(itm) for itm in items]\n",
      "        self._first = noded[0] if len(noded) > 0 else None\n",
      "        l = len(noded)\n",
      "        if l > 0:\n",
      "            for i in range(l-1):\n",
      "                noded[i].next = noded[i+1]\n",
      "        self._length = l\n",
      "\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> Augmented([]).is_empty()\n",
      "        True\n",
      "        >>> Augmented([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(Augmented([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(Augmented([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        >>> lst = Augmented([1, 2, 10, 200])\n",
      "        >>> lst.insert(2, 300)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        >>> lst.insert(5, -1)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        >>> lst.insert(100, 2)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "        self._length += 1\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Lab Task 1\n",
      "    # ------------------------------------------------------------------------\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = Augmented([])\n",
      "        >>> len(lst)              # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = Augmented([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        return self._length\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = Augmented([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                count += 1\n",
      "            curr = curr.next\n",
      "        return count\n",
      "\n",
      "    def index(self, item: Any) -> int:\n",
      "        \"\"\"Return the index of the first occurrence of <item> in this list.\n",
      "\n",
      "        Raise ValueError if the <item> is not present.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = Augmented([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.index(1)\n",
      "        0\n",
      "        >>> lst.index(3)\n",
      "        3\n",
      "        >>> lst.index(148)\n",
      "        Traceback (most recent call last):\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        curr = self._first\n",
      "        while not curr is None:\n",
      "            if curr.item == item:\n",
      "                return idx\n",
      "            curr = curr.next\n",
      "            idx += 1\n",
      "        raise IndexError\n",
      "\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if index >= len(self).\n",
      "\n",
      "        >>> lst = Augmented([1, 2, 3])\n",
      "        >>> lst[0] = 100  # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> str(lst)\n",
      "        '[100 -> 200 -> 300]'\n",
      "        \"\"\"\n",
      "        itm = _Node(item)\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        else:\n",
      "            if index == 0:\n",
      "                itm.next = self._first.next\n",
      "                self._first = itm\n",
      "            else:\n",
      "                curr = self._first\n",
      "                idx = 0\n",
      "                while not idx == index :\n",
      "                    idx += 1\n",
      "                    curr = curr.next\n",
      "                curr.item = itm.item\n",
      "79/1: slns = csv_to_list('solutions.csv')\n",
      "80/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "import csv\n",
      "from torch import nn, optim\n",
      "import torch.utils.data\n",
      "80/2:\n",
      "def csv_to_list(filepath):\n",
      "    with open(filepath, 'r') as f:\n",
      "        reader = csv.reader(f)\n",
      "        return np.array(list(reader))\n",
      "80/3:\n",
      "puz = csv_to_list('puzzles.csv')\n",
      "sln = csv_to_list('solutions.csv')\n",
      "80/4:\n",
      "class net(nn.Module):\n",
      "    def __init__(self, n_inputs, n_outputs):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(n_inputs, 512)\n",
      "        self.fc2 = nn.Linear(512, 4096)\n",
      "        self.fc3 = nn.Linear(4096, 1024)\n",
      "        self.fc4 = nn.Linear(1024, n_outputs)\n",
      "        self.drop = nn.Dropout(p=0.7)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "\n",
      "    def forward(self, x):\n",
      "        identity = x\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.drop(self.lrelu(self.fc4(x)))\n",
      "        x += identity\n",
      "        return x\n",
      "80/5:\n",
      "model = net(81, 81)\n",
      "print(model)\n",
      "80/6:\n",
      "loss_fn = nn.CrossEntropyLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "80/7:\n",
      "puz = csv_to_list('puzzles.csv')\n",
      "sln = csv_to_list('solutions.csv')\n",
      "print(puz.shape)\n",
      "80/8:\n",
      "puz = csv_to_list('puzzles.csv')\n",
      "sln = csv_to_list('solutions.csv')\n",
      "print(puz.shape)\n",
      "80/9:\n",
      "import numpy as np\n",
      "import torch\n",
      "import csv\n",
      "from torch import nn, optim\n",
      "import torch.utils.data\n",
      "80/10:\n",
      "import numpy as np\n",
      "import torch\n",
      "import csv\n",
      "from torch import nn, optim\n",
      "import torch.utils.data\n",
      "from sklearn.model_selection import train_test_split\n",
      "80/11:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "\n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "\n",
      "def preprocess(fp, feature_cols, label_cols, test_size, batch_size):\n",
      "\n",
      "    features, = csv_to_list('puzzles.csv')\n",
      "    labels = csv_to_list('solutions.csv')\n",
      "\n",
      "    split = train_test_split(features, labels, test_size=test_size)\n",
      "\n",
      "    x_train, x_test, y_train, y_test = map(lambda x: torch.tensor(x), split)\n",
      "\n",
      "    train_ds = ds(x_train, y_train)\n",
      "    test_ds = ds(x_test, y_test)\n",
      "\n",
      "    trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "    testloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "\n",
      "    return trainloader, testloader\n",
      "80/12: trainloader, testloader = preprocess()\n",
      "80/13:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "\n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "\n",
      "def preprocess(test_size=0.3, batch_size=64):\n",
      "\n",
      "    features, = csv_to_list('puzzles.csv')\n",
      "    labels = csv_to_list('solutions.csv')\n",
      "\n",
      "    split = train_test_split(features, labels, test_size=test_size)\n",
      "\n",
      "    x_train, x_test, y_train, y_test = map(lambda x: torch.tensor(x), split)\n",
      "\n",
      "    train_ds = ds(x_train, y_train)\n",
      "    test_ds = ds(x_test, y_test)\n",
      "\n",
      "    trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "    testloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "\n",
      "    return trainloader, testloader\n",
      "80/14: trainloader, testloader = preprocess()\n",
      "80/15:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "\n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "\n",
      "def preprocess(test_size=0.3, batch_size=64):\n",
      "\n",
      "    features = csv_to_list('puzzles.csv')\n",
      "    labels = csv_to_list('solutions.csv')\n",
      "\n",
      "    split = train_test_split(features, labels, test_size=test_size)\n",
      "\n",
      "    x_train, x_test, y_train, y_test = map(lambda x: torch.tensor(x), split)\n",
      "\n",
      "    train_ds = ds(x_train, y_train)\n",
      "    test_ds = ds(x_test, y_test)\n",
      "\n",
      "    trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "    testloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "\n",
      "    return trainloader, testloader\n",
      "80/16: trainloader, testloader = preprocess()\n",
      "80/17:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "\n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "\n",
      "def preprocess(fp, feature_cols, label_cols, test_size, batch_size):\n",
      "\n",
      "    features = csv_to_list('puzzles.csv')\n",
      "    labels = csv_to_list('solutions.csv')\n",
      "\n",
      "    features = [[int(i) for i in row] for row in features]\n",
      "    labels = [[int(j) for j in row] for row in labels]\n",
      "\n",
      "    split = train_test_split(features, labels, test_size=test_size)\n",
      "\n",
      "    x_train, x_test, y_train, y_test = map(lambda x: torch.tensor(x), split)\n",
      "\n",
      "    train_ds = ds(x_train, y_train)\n",
      "    test_ds = ds(x_test, y_test)\n",
      "\n",
      "    trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "    testloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "\n",
      "    return trainloader, testloader\n",
      "80/18: trainloader, testloader = preprocess()\n",
      "80/19:\n",
      "class ds(torch.utils.data.Dataset):\n",
      "    def __init__(self, features, labels):\n",
      "        self.features = features\n",
      "        self.labels = labels\n",
      "\n",
      "    def __len__(self):\n",
      "        return(len(self.labels))\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        feature = self.features[index]\n",
      "        label = self.labels[index]\n",
      "        return(feature, label)\n",
      "\n",
      "def preprocess(test_size=0.3, batch_size=64):\n",
      "\n",
      "    features = csv_to_list('puzzles.csv')\n",
      "    labels = csv_to_list('solutions.csv')\n",
      "\n",
      "    features = [[int(i) for i in row] for row in features]\n",
      "    labels = [[int(j) for j in row] for row in labels]\n",
      "\n",
      "    split = train_test_split(features, labels, test_size=test_size)\n",
      "\n",
      "    x_train, x_test, y_train, y_test = map(lambda x: torch.tensor(x), split)\n",
      "\n",
      "    train_ds = ds(x_train, y_train)\n",
      "    test_ds = ds(x_test, y_test)\n",
      "\n",
      "    trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
      "    testloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
      "\n",
      "    return trainloader, testloader\n",
      "80/20: trainloader, testloader = preprocess()\n",
      "80/21:\n",
      "trainloader, testloader = preprocess()\n",
      "print(trainloader, testloader)\n",
      "80/22:\n",
      "trainloader, testloader = preprocess()\n",
      "print(len(trainloader))\n",
      "80/23:\n",
      "trainloader, testloader = preprocess()\n",
      "print(len(trainloader), len(testloader))\n",
      "80/24:\n",
      "trainloader, testloader = preprocess(test_size=0.2, batch_size=32)\n",
      "print(len(trainloader), len(testloader))\n",
      "80/25:\n",
      "class net(nn.Module):\n",
      "    def __init__(self, n_inputs, n_outputs):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(n_inputs, 512)\n",
      "        self.fc2 = nn.Linear(512, 4096)\n",
      "        self.fc3 = nn.Linear(4096, 1024)\n",
      "        self.fc4 = nn.Linear(1024, n_outputs)\n",
      "        self.drop = nn.Dropout(p=0.7)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "\n",
      "    def forward(self, x):\n",
      "        identity = x\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.drop(self.lrelu(self.fc4(x)))\n",
      "        x += identity\n",
      "        return x\n",
      "80/26:\n",
      "model = net(81, 81)\n",
      "print(model)\n",
      "80/27:\n",
      "loss_fn = nn.CrossEntropyLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "80/28:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label)\n",
      "        loss = loss_fn(output, target)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label)\n",
      "        loss = loss_fn(output, target)\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/29:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/30:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target)\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/31: target, label = next(iter(trainloader))\n",
      "80/32: model(target)\n",
      "80/33: model(target.float())\n",
      "80/34: model(target.float()).shape\n",
      "80/35: model(target.float()).shape\n",
      "80/36: model(target.float()).shape, label.shape\n",
      "80/37: model(target.float()) - label\n",
      "80/38: model(target.float()) - label.float()\n",
      "80/39:\n",
      "output = model(target.float())\n",
      "print(output)\n",
      "print(label)\n",
      "print(output - label)\n",
      "80/40:\n",
      "output = model(target.float())\n",
      "print(output)\n",
      "print(label)\n",
      "print(output - label.float())\n",
      "80/41:\n",
      "output = model(target.float())\n",
      "print(output)\n",
      "print(label.float())\n",
      "print(output - label.float())\n",
      "80/42:\n",
      "output = model(target.float())\n",
      "print(output)\n",
      "print(label.float())\n",
      "print((output - label.float()).sum(dim=1).shape)\n",
      "80/43:\n",
      "def loss_x(target, label):\n",
      "    return (output - label.float()).sum(dim=1)\n",
      "\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "80/44:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target)\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target)\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/45:\n",
      "epochs = 3\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/46:\n",
      "def loss_x(target, label):\n",
      "    return (output - label.float()).sum(dim=1)\n",
      "\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)\n",
      "80/47:\n",
      "epochs = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/48:\n",
      "def loss_x(target, label):\n",
      "    return (output - label.float()).sum(dim=1)\n",
      "\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "80/49:\n",
      "epochs = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/50:\n",
      "def loss_x(target, label):\n",
      "    return (output - label.float()).sum(dim=1)\n",
      "\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "80/51:\n",
      "epochs = 5\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/52:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
      "80/53:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/54:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "80/55:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader))\n",
      "    scheduler.step()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        scheduler.step()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/56:\n",
      "label, target = next(iter(trainloader))\n",
      "output = model(label.float())\n",
      "loss = loss_fn(output, label.float())\n",
      "print(loss.item())\n",
      "80/57:\n",
      "label, target = next(iter(trainloader))\n",
      "output = model(label.float())\n",
      "loss = loss_fn(output, label.float())\n",
      "print(output)\n",
      "80/58:\n",
      "label, target = next(iter(trainloader))\n",
      "output = model(label.float())\n",
      "loss = loss_fn(output, label.float())\n",
      "print(label)\n",
      "80/59:\n",
      "label, target = next(iter(trainloader))\n",
      "output = model(label.float())\n",
      "loss = loss_fn(output, label.float())\n",
      "print(target)\n",
      "80/60:\n",
      "label, target = next(iter(trainloader))\n",
      "output = model(label.float())\n",
      "loss = loss_fn(output, label.float())\n",
      "print(label)\n",
      "80/61:\n",
      "label, target = next(iter(trainloader))\n",
      "output = model(label.float())\n",
      "loss = loss_fn(output, label.float())\n",
      "print(target)\n",
      "80/62:\n",
      "label, target = next(iter(trainloader))\n",
      "output = model(label.float())\n",
      "loss = loss_fn(output, label.float())\n",
      "print(output)\n",
      "80/63:\n",
      "label, target = next(iter(trainloader))\n",
      "output = model(label.float())\n",
      "loss = loss_fn(output, label.float())\n",
      "model(label.float())\n",
      "80/64:\n",
      "model = net(81, 81)\n",
      "print(model)\n",
      "80/65:\n",
      "label, target = next(iter(trainloader))\n",
      "output = model(label.float())\n",
      "loss = loss_fn(output, label.float())\n",
      "print(loss.item())\n",
      "80/66:\n",
      "model = net(81, 81)\n",
      "print(model)\n",
      "80/67:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "80/68:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader))\n",
      "    scheduler.step()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        scheduler.step()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/69:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
      "80/70:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader))\n",
      "    scheduler.step()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        scheduler.step()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/71:\n",
      "model.eval()\n",
      "label, target = next(iter(testloader))\n",
      "output = model(label.float())\n",
      "print(output)\n",
      "print(target)\n",
      "80/72:\n",
      "model.eval()\n",
      "label, target = next(iter(testloader))\n",
      "output = model(label.float())\n",
      "print(output.round())\n",
      "print(target)\n",
      "80/73:\n",
      "model.eval()\n",
      "label, target = next(iter(testloader))\n",
      "output = model(label.float())\n",
      "print(output)\n",
      "print(target)\n",
      "80/74:\n",
      "model.eval()\n",
      "label, target = next(iter(testloader))\n",
      "output = model(label.float())\n",
      "print(output.round())\n",
      "print(target)\n",
      "80/75:\n",
      "model.eval()\n",
      "label, target = next(iter(testloader))\n",
      "output = model(label.float())\n",
      "print(output.round())\n",
      "print(target)\n",
      "80/76:\n",
      "model.eval()\n",
      "label, target = next(iter(testloader))\n",
      "output = model(label.float())\n",
      "print(output.round())\n",
      "print(target)\n",
      "80/77:\n",
      "model.eval()\n",
      "label, target = next(iter(testloader))\n",
      "output = model(label.float())\n",
      "print(output)\n",
      "print(target)\n",
      "80/78:\n",
      "class net(nn.Module):\n",
      "    def __init__(self, n_inputs, n_outputs):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(n_inputs, 512)\n",
      "        self.fc2 = nn.Linear(512, 4096)\n",
      "        self.fc3 = nn.Linear(4096, 1024)\n",
      "        self.fc4 = nn.Linear(1024, n_outputs)\n",
      "        self.drop = nn.Dropout(p=0.7)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "\n",
      "    def forward(self, x):\n",
      "        identity = x\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.drop(self.lrelu(self.fc4(x)))\n",
      "        x += identity\n",
      "        return x.round()\n",
      "80/79:\n",
      "model = net(81, 81)\n",
      "print(model)\n",
      "80/80:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
      "80/81:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader))\n",
      "    scheduler.step()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        scheduler.step()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "80/82:\n",
      "class net(nn.Module):\n",
      "    def __init__(self, n_inputs, n_outputs):\n",
      "        super().__init__()\n",
      "        self.fc1 = nn.Linear(n_inputs, 512)\n",
      "        self.fc2 = nn.Linear(512, 4096)\n",
      "        self.fc3 = nn.Linear(4096, 1024)\n",
      "        self.fc4 = nn.Linear(1024, n_outputs)\n",
      "        self.drop = nn.Dropout(p=0.7)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "\n",
      "    def forward(self, x):\n",
      "        identity = x\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.drop(self.lrelu(self.fc4(x)))\n",
      "        return x\n",
      "80/83:\n",
      "model = net(81, 81)\n",
      "print(model)\n",
      "80/84:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
      "80/85:\n",
      "epochs = 10\n",
      "\n",
      "for e in range(epochs):\n",
      "    train_loss = 0\n",
      "    model.train()\n",
      "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader))\n",
      "    scheduler.step()\n",
      "    for label, target in trainloader:\n",
      "        optimizer.zero_grad()\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        train_loss += loss.item()\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        scheduler.step()\n",
      "    \n",
      "    test_loss = 0\n",
      "    model.eval()\n",
      "    for label, target in testloader:\n",
      "        output = model(label.float())\n",
      "        loss = loss_fn(output, target.float())\n",
      "        test_loss += loss.item()\n",
      "        \n",
      "    print(f'Epoch: {e+1}/{epochs} | Training loss: {train_loss} | Testing loss: {test_loss}')\n",
      "81/1: from typing import Union, List\n",
      "81/2:\n",
      "def num_positives(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the number of positive integers in <obj>.\n",
      "\n",
      "    Remember, 0 is *not* positive.\n",
      "\n",
      "    >>> num_positives(17)\n",
      "    1\n",
      "    >>> num_positives(-10)\n",
      "    0\n",
      "    >>> num_positives([1, -2, [-10, 2, [3], 4, -5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        if obj > 0:\n",
      "            return 1\n",
      "    else:\n",
      "        count = 0\n",
      "        for sublist in obj:\n",
      "            count += num_positives(sublist)\n",
      "        return count\n",
      "81/3:     >>> num_positives(17)\n",
      "81/4:     1\n",
      "81/5:     >>> num_positives(-10)\n",
      "81/6:     0\n",
      "81/7:     >>> num_positives([1, -2, [-10, 2, [3], 4, -5], 4])\n",
      "81/8:     >>> num_positives([1, -2, [-10, 2, [3], 4, -5], 4])\n",
      "81/9:     >>> num_positives(-10)\n",
      "81/10:     >>> print(num_positives(-10))\n",
      "81/11:\n",
      "def num_positives(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the number of positive integers in <obj>.\n",
      "\n",
      "    Remember, 0 is *not* positive.\n",
      "\n",
      "    >>> num_positives(17)\n",
      "    1\n",
      "    >>> print(num_positives(-10))\n",
      "    0\n",
      "    >>> num_positives([1, -2, [-10, 2, [3], 4, -5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return 1 if obj > 0 else 0\n",
      "    else:\n",
      "        count = 0\n",
      "        for sublist in obj:\n",
      "            count += num_positives(sublist)\n",
      "        return count\n",
      "81/12:     >>> num_positives(17)\n",
      "81/13:     1\n",
      "81/14:     >>> print(num_positives(-10))\n",
      "81/15:     0\n",
      "81/16:     >>> num_positives([1, -2, [-10, 2, [3], 4, -5], 4])\n",
      "81/17:     >>> max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/18:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return obj if obj > curmax else curmax\n",
      "    else:\n",
      "        curmax = 0\n",
      "        for sublist in obj:\n",
      "            curmax = max(obj)\n",
      "        return curmax\n",
      "81/19:     >>> nested_max(17)\n",
      "81/20:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    curmax = 0\n",
      "    if isinstance(obj, int):\n",
      "        return obj if obj > curmax else curmax\n",
      "    else:\n",
      "        for sublist in obj:\n",
      "            curmax = max(obj)\n",
      "        return curmax\n",
      "81/21:     >>> nested_max(17)\n",
      "81/22:     17\n",
      "81/23:     >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/24:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    curmax = 0\n",
      "    if isinstance(obj, int):\n",
      "        return obj if obj > curmax else curmax\n",
      "    else:\n",
      "        for sublist in obj:\n",
      "            curmax = nested_max(obj)\n",
      "        return curmax\n",
      "81/25:     >>> nested_max(17)\n",
      "81/26:     17\n",
      "81/27:     >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/28:     >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/29:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    curmax = 0\n",
      "    if isinstance(obj, int):\n",
      "        if obj > curmax:\n",
      "            curmax = obj\n",
      "            return curmax\n",
      "    else:\n",
      "        for sublist in obj:\n",
      "            curmax = nested_max(obj)\n",
      "        return curmax\n",
      "81/30:     >>> nested_max(17)\n",
      "81/31:     17\n",
      "81/32:     >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/33:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    curmax = 0\n",
      "    if isinstance(obj, int):\n",
      "        if obj > curmax:\n",
      "            curmax = obj\n",
      "            return curmax\n",
      "    else:\n",
      "        for sublist in obj:\n",
      "            curmax = nested_max(sublist)\n",
      "        return curmax\n",
      "81/34:\n",
      "def max_length(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum length of any list in nested list <obj>.\n",
      "\n",
      "    The *maximum length* of a nested list is defined as:\n",
      "    1. 0, if <obj> is a number.\n",
      "    2. The maximum of len(obj) and the lengths of the nested lists contained\n",
      "       in <obj>, if <obj> is a list.\n",
      "\n",
      "    >>> max_length(17)\n",
      "    0\n",
      "    >>> max_length([1, 2, [1, 2], 4])\n",
      "    4\n",
      "    >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    pass\n",
      "81/35:     >>> nested_max(17)\n",
      "81/36:     17\n",
      "81/37:     >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/38:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    curmax = 0\n",
      "    if isinstance(obj, int):\n",
      "        return obj if obj > curmax else curmax\n",
      "    else:\n",
      "        for sublist in obj:\n",
      "            curmax = nested_max(sublist)\n",
      "        return curmax\n",
      "81/39:     >>> nested_max(17)\n",
      "81/40:     17\n",
      "81/41:     >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/42:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    curmax = 0\n",
      "    if isinstance(obj, int):\n",
      "        return obj if obj > curmax else curmax\n",
      "    else:\n",
      "        for sublist in obj:\n",
      "            curmax = nested_max(sublist)\n",
      "        return curmax\n",
      "81/43:     >>> nested_max(17)\n",
      "81/44:     17\n",
      "81/45:     >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "81/46:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    curmax = 0\n",
      "    if isinstance(obj, int):\n",
      "        return obj if obj > curmax else curmax\n",
      "    else:\n",
      "        for sublist in obj:\n",
      "            nested_max(sublist)\n",
      "        return curmax\n",
      "81/47:     >>> nested_max(17)\n",
      "81/48:     17\n",
      "81/49:     >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "81/50:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    curmax = 0\n",
      "    if isinstance(obj, int):\n",
      "        return obj if obj > curmax else curmax\n",
      "    else:\n",
      "        nestmax = 0\n",
      "        for sublist in obj:\n",
      "            nestmax = nested_max(sublist)\n",
      "        return nestmax\n",
      "81/51:\n",
      "def max_length(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum length of any list in nested list <obj>.\n",
      "\n",
      "    The *maximum length* of a nested list is defined as:\n",
      "    1. 0, if <obj> is a number.\n",
      "    2. The maximum of len(obj) and the lengths of the nested lists contained\n",
      "       in <obj>, if <obj> is a list.\n",
      "\n",
      "    >>> max_length(17)\n",
      "    0\n",
      "    >>> max_length([1, 2, [1, 2], 4])\n",
      "    4\n",
      "    >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    pass\n",
      "81/52:     >>> nested_max(17)\n",
      "81/53:     17\n",
      "81/54:     >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "81/55:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return obj if obj > curmax else curmax\n",
      "    else:\n",
      "        curmax = 0\n",
      "        for sublist in obj:\n",
      "            curmax = nested_max(sublist)\n",
      "        return nestmax\n",
      "81/56:     >>> nested_max(17)\n",
      "81/57:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        if curmax:\n",
      "            return obj if obj > curmax else curmax\n",
      "        else:\n",
      "            return obj\n",
      "    else:\n",
      "        curmax = 0\n",
      "        for sublist in obj:\n",
      "            curmax = nested_max(sublist)\n",
      "        return nestmax\n",
      "81/58:     >>> nested_max(17)\n",
      "81/59:\n",
      "def nested_max(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum integer stored in nested list <obj>.\n",
      "\n",
      "    Return 0 if <obj> does not contain any integers.\n",
      "\n",
      "    Precondition: all integers in <obj> are > 0.\n",
      "\n",
      "    >>> nested_max(17)\n",
      "    17\n",
      "    >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return obj\n",
      "    else:\n",
      "        curmax = 0\n",
      "        for sublist in obj:\n",
      "            nestmax = nested_max(sublist)\n",
      "            curmax = nestmax if nestmax > curmax else curmax\n",
      "        return curmax\n",
      "81/60:     >>> nested_max(17)\n",
      "81/61:     17\n",
      "81/62:     >>> nested_max([1, 2, [1, 2, [3], 6, 5], 4])\n",
      "81/63:     >>> nested_max([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/64:     5\n",
      "81/65:\n",
      "def max_length(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum length of any list in nested list <obj>.\n",
      "\n",
      "    The *maximum length* of a nested list is defined as:\n",
      "    1. 0, if <obj> is a number.\n",
      "    2. The maximum of len(obj) and the lengths of the nested lists contained\n",
      "       in <obj>, if <obj> is a list.\n",
      "\n",
      "    >>> max_length(17)\n",
      "    0\n",
      "    >>> max_length([1, 2, [1, 2], 4])\n",
      "    4\n",
      "    >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, list):\n",
      "        return len(obj)\n",
      "    else:\n",
      "        curmax = 0\n",
      "        for sublist in obj:\n",
      "            nestmax = max_length(sublist)\n",
      "            curmax = nestmax if nestmax > curmax else curmax\n",
      "        return curmax\n",
      "81/66:     >>> max_length(17)\n",
      "81/67:\n",
      "def max_length(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum length of any list in nested list <obj>.\n",
      "\n",
      "    The *maximum length* of a nested list is defined as:\n",
      "    1. 0, if <obj> is a number.\n",
      "    2. The maximum of len(obj) and the lengths of the nested lists contained\n",
      "       in <obj>, if <obj> is a list.\n",
      "\n",
      "    >>> max_length(17)\n",
      "    0\n",
      "    >>> max_length([1, 2, [1, 2], 4])\n",
      "    4\n",
      "    >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return 0\n",
      "    if isinstance(obj, list):\n",
      "        return len(obj)\n",
      "    else:\n",
      "        curmax = 0\n",
      "        for sublist in obj:\n",
      "            nestmax = max_length(sublist)\n",
      "            curmax = nestmax if nestmax > curmax else curmax\n",
      "        return curmax\n",
      "81/68:     >>> max_length(17)\n",
      "81/69:     0\n",
      "81/70:     >>> max_length([1, 2, [1, 2], 4])\n",
      "81/71:     4\n",
      "81/72:     >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/73:\n",
      "def max_length(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum length of any list in nested list <obj>.\n",
      "\n",
      "    The *maximum length* of a nested list is defined as:\n",
      "    1. 0, if <obj> is a number.\n",
      "    2. The maximum of len(obj) and the lengths of the nested lists contained\n",
      "       in <obj>, if <obj> is a list.\n",
      "\n",
      "    >>> max_length(17)\n",
      "    0\n",
      "    >>> max_length([1, 2, [1, 2], 4])\n",
      "    4\n",
      "    >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return 0\n",
      "    else:\n",
      "        curmax = 0\n",
      "        for sublist in obj:\n",
      "            nestmax = max_length(sublist)\n",
      "            curmax = len(nestmax) if len(nestmax) > len(curmax) else curmax\n",
      "        return curmax\n",
      "81/74:     >>> max_length(17)\n",
      "81/75:     0\n",
      "81/76:     >>> max_length([1, 2, [1, 2], 4])\n",
      "81/77:\n",
      "def max_length(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum length of any list in nested list <obj>.\n",
      "\n",
      "    The *maximum length* of a nested list is defined as:\n",
      "    1. 0, if <obj> is a number.\n",
      "    2. The maximum of len(obj) and the lengths of the nested lists contained\n",
      "       in <obj>, if <obj> is a list.\n",
      "\n",
      "    >>> max_length(17)\n",
      "    0\n",
      "    >>> max_length([1, 2, [1, 2], 4])\n",
      "    4\n",
      "    >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return 0\n",
      "    else:\n",
      "        curmax = len(obj)\n",
      "        for sublist in obj:\n",
      "            nestmax = max_length(sublist)\n",
      "            curmax = len(nestmax) if len(nestmax) > len(curmax) else curmax\n",
      "        return curmax\n",
      "81/78:     >>> max_length(17)\n",
      "81/79:     0\n",
      "81/80:     >>> max_length([1, 2, [1, 2], 4])\n",
      "81/81:\n",
      "def max_length(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum length of any list in nested list <obj>.\n",
      "\n",
      "    The *maximum length* of a nested list is defined as:\n",
      "    1. 0, if <obj> is a number.\n",
      "    2. The maximum of len(obj) and the lengths of the nested lists contained\n",
      "       in <obj>, if <obj> is a list.\n",
      "\n",
      "    >>> max_length(17)\n",
      "    0\n",
      "    >>> max_length([1, 2, [1, 2], 4])\n",
      "    4\n",
      "    >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return 0\n",
      "    else:\n",
      "        curmax = len(obj)\n",
      "        for sublist in obj:\n",
      "            nestmax = max_length(sublist)\n",
      "            curmax = len(nestmax) if len(nestmax) > curmax else curmax\n",
      "        return curmax\n",
      "81/82:     >>> max_length(17)\n",
      "81/83:     0\n",
      "81/84:     >>> max_length([1, 2, [1, 2], 4])\n",
      "81/85:\n",
      "def max_length(obj: Union[int, List]) -> int:\n",
      "    \"\"\"Return the maximum length of any list in nested list <obj>.\n",
      "\n",
      "    The *maximum length* of a nested list is defined as:\n",
      "    1. 0, if <obj> is a number.\n",
      "    2. The maximum of len(obj) and the lengths of the nested lists contained\n",
      "       in <obj>, if <obj> is a list.\n",
      "\n",
      "    >>> max_length(17)\n",
      "    0\n",
      "    >>> max_length([1, 2, [1, 2], 4])\n",
      "    4\n",
      "    >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "    5\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return 0\n",
      "    else:\n",
      "        curmax = len(obj)\n",
      "        for sublist in obj:\n",
      "            nestmax = max_length(sublist)\n",
      "            curmax = nestmax if nestmax > curmax else curmax\n",
      "        return curmax\n",
      "81/86:     0\n",
      "81/87:     >>> max_length(17)\n",
      "81/88:     0\n",
      "81/89:     >>> max_length([1, 2, [1, 2], 4])\n",
      "81/90:     4\n",
      "81/91:     >>> max_length([1, 2, [1, 2, [3], 4, 5], 4])\n",
      "81/92:\n",
      "if __name__ == '__main__':\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "\n",
      "    import python_ta\n",
      "    python_ta.check_all()\n",
      "82/1: from typing import Union, List\n",
      "82/2:\n",
      "def add_n(obj: Union[int, List], n: int) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list where <n> is added to every item in <obj>.\n",
      "\n",
      "    >>> add_n(10, 3)\n",
      "    13\n",
      "    >>> add_n([1, 2, [1, 2], 4], 10)\n",
      "    [11, 12, [11, 12], 14]\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return obj + n\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            l.append(add_n(sublist))\n",
      "        return l\n",
      "82/3:     >>> add_n(10, 3)\n",
      "82/4:     13\n",
      "82/5:     >>> add_n([1, 2, [1, 2], 4], 10)\n",
      "82/6:\n",
      "def add_n(obj: Union[int, List], n: int) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list where <n> is added to every item in <obj>.\n",
      "\n",
      "    >>> add_n(10, 3)\n",
      "    13\n",
      "    >>> add_n([1, 2, [1, 2], 4], 10)\n",
      "    [11, 12, [11, 12], 14]\n",
      "    \"\"\"\n",
      "    if isinstance(obj, int):\n",
      "        return obj + n\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            l.append(add_n(sublist, n))\n",
      "        return l\n",
      "82/7:     >>> add_n(10, 3)\n",
      "82/8:     >>> add_n([1, 2, [1, 2], 4], 10)\n",
      "82/9:     [11, 12, [11, 12], 14]\n",
      "82/10:     >>> [1, 2, [1, 2], 4] == [4, 2, [2, 1], 3]\n",
      "82/11:\n",
      "def nested_list_equal(obj1: Union[int, List], obj2: Union[int, List]) -> bool:\n",
      "    \"\"\"Return whether two nested lists are equal, i.e., have the same value.\n",
      "\n",
      "    Note: order matters.\n",
      "\n",
      "    >>> nested_list_equal(17, [1, 2, 3])\n",
      "    False\n",
      "    >>> nested_list_equal([1, 2, [1, 2], 4], [1, 2, [1, 2], 4])\n",
      "    True\n",
      "    >>> nested_list_equal([1, 2, [1, 2], 4], [4, 2, [2, 1], 3])\n",
      "    False\n",
      "    \"\"\"\n",
      "    # HINT: You'll need to modify the basic pattern to loop over indexes,\n",
      "    # so that you can iterate through both obj1 and obj2 in parallel.\n",
      "    return obj1 == obj2\n",
      "    if isinstance(sublist1, int) and isinstance(sublist2):\n",
      "        ...\n",
      "    else:\n",
      "        for sublist_index in range(len(obj)):\n",
      "            nested_list_equal(sublist)\n",
      "82/12:     >>> nested_list_equal(17, [1, 2, 3])\n",
      "82/13:     False\n",
      "82/14:     >>> nested_list_equal([1, 2, [1, 2], 4], [1, 2, [1, 2], 4])\n",
      "82/15:     True\n",
      "82/16:     >>> nested_list_equal([1, 2, [1, 2], 4], [4, 2, [2, 1], 3])\n",
      "82/17:     False\n",
      "82/18:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return obj, obj\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/19:     >>> duplicate(1)\n",
      "82/20:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/21:     >>> duplicate(1)\n",
      "82/22:     [1, 1]\n",
      "82/23:     >>> duplicate([])\n",
      "82/24:     []\n",
      "82/25:     >>> duplicate([1, 2])\n",
      "82/26:     [1, 1, 2, 2]\n",
      "82/27:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/28:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.extend(duplicate(sublist))\n",
      "        return l\n",
      "82/29:     [1, 1]\n",
      "82/30:     >>> duplicate(1)\n",
      "82/31:     [1, 1]\n",
      "82/32:     >>> duplicate([])\n",
      "82/33:     []\n",
      "82/34:     >>> duplicate([1, 2])\n",
      "82/35:     [1, 1, 2, 2]\n",
      "82/36:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/37:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.extend([duplicate(sublist)])\n",
      "        return l\n",
      "82/38:     >>> duplicate(1)\n",
      "82/39:     [1, 1]\n",
      "82/40:     >>> duplicate([])\n",
      "82/41:     []\n",
      "82/42:     >>> duplicate([1, 2])\n",
      "82/43:     [1, 1, 2, 2]\n",
      "82/44:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/45:     >>> duplicate(1)\n",
      "82/46:     [1, 1]\n",
      "82/47:     >>> duplicate([])\n",
      "82/48:     []\n",
      "82/49:     >>> duplicate([1, 2])\n",
      "82/50:     [1, 1, 2, 2]\n",
      "82/51:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/52:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/53:     >>> duplicate(1)\n",
      "82/54:     [1, 1]\n",
      "82/55:     >>> duplicate([])\n",
      "82/56:     []\n",
      "82/57:     >>> duplicate([1, 2])\n",
      "82/58:     [1, 1, 2, 2]\n",
      "82/59:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/60:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/61:     >>> duplicate(1)\n",
      "82/62:     [1, 1]\n",
      "82/63:     >>> duplicate([])\n",
      "82/64:     []\n",
      "82/65:     >>> duplicate([1, 2])\n",
      "82/66:     [1, 1, 2, 2]\n",
      "82/67:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/68:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return obj, obj\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/69:     >>> duplicate(1)\n",
      "82/70:     [1, 1]\n",
      "82/71:     >>> duplicate([])\n",
      "82/72:     []\n",
      "82/73:     >>> duplicate([1, 2])\n",
      "82/74:     [1, 1, 2, 2]\n",
      "82/75:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/76:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.append(*duplicate(sublist))\n",
      "        return l\n",
      "82/77:\n",
      "if __name__ == '__main__':\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "82/78:     >>> duplicate(1)\n",
      "82/79:     [1, 1]\n",
      "82/80:     >>> duplicate([])\n",
      "82/81:     []\n",
      "82/82:     >>> duplicate([1, 2])\n",
      "82/83:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/84:     >>> duplicate(1)\n",
      "82/85:     [1, 1]\n",
      "82/86:     >>> duplicate([])\n",
      "82/87:     []\n",
      "82/88:     >>> duplicate([1, 2])\n",
      "82/89:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return obj, obj\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "             l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/90:     >>> duplicate(1)\n",
      "82/91:     [1, 1]\n",
      "82/92:     >>> duplicate([])\n",
      "82/93:     []\n",
      "82/94:     >>> duplicate([1, 2])\n",
      "82/95:     [1, 1, 2, 2]\n",
      "82/96:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/97:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return obj, obj\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            x = duplicate(sublist)\n",
      "            for i in x:\n",
      "                l.append(i)\n",
      "        return l\n",
      "82/98:     >>> duplicate(1)\n",
      "82/99:     [1, 1]\n",
      "82/100:     >>> duplicate([])\n",
      "82/101:     []\n",
      "82/102:     >>> duplicate([1, 2])\n",
      "82/103:     [1, 1, 2, 2]\n",
      "82/104:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/105:     [1, 1, [2, 2, 3, 3]]\n",
      "82/106:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return obj, obj\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/107:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/108:     >>> duplicate(1)\n",
      "82/109:     [1, 1]\n",
      "82/110:     >>> duplicate([])\n",
      "82/111:     []\n",
      "82/112:     >>> duplicate([1, 2])\n",
      "82/113:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return obj, obj\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/114:     >>> duplicate(1)\n",
      "82/115:     [1, 1]\n",
      "82/116:     >>> duplicate([])\n",
      "82/117:     []\n",
      "82/118:     >>> duplicate([1, 2])\n",
      "82/119:     [1, 1, 2, 2]\n",
      "82/120:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/121:     >>> duplicate(1)\n",
      "82/122:     [1, 1]\n",
      "82/123:     >>> duplicate([])\n",
      "82/124:     []\n",
      "82/125:     >>> duplicate([1, 2])\n",
      "82/126:     [1, 1, 2, 2]\n",
      "82/127:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/128:     [1, 1, [2, 2, 3, 3]]\n",
      "82/129:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return obj, obj\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            l.extend(duplicate(sublist))\n",
      "        return l\n",
      "82/130:     >>> duplicate(1)\n",
      "82/131:     [1, 1]\n",
      "82/132:     >>> duplicate([])\n",
      "82/133:     []\n",
      "82/134:     >>> duplicate([1, 2])\n",
      "82/135:     [1, 1, 2, 2]\n",
      "82/136:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/137:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            l.extend(duplicate(sublist))\n",
      "        return l\n",
      "82/138:     >>> duplicate(1)\n",
      "82/139:     [1, 1]\n",
      "82/140:     >>> duplicate([])\n",
      "82/141:     []\n",
      "82/142:     >>> duplicate([1, 2])\n",
      "82/143:     [1, 1, 2, 2]\n",
      "82/144:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/145:     [1, 1, [2, 2, 3, 3]]\n",
      "82/146:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            l.extend([duplicate(sublist)])\n",
      "        return l\n",
      "82/147:\n",
      "if __name__ == '__main__':\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "82/148:     >>> duplicate(1)\n",
      "82/149:     [1, 1]\n",
      "82/150:     >>> duplicate([])\n",
      "82/151:     []\n",
      "82/152:     >>> duplicate([1, 2])\n",
      "82/153:     [1, 1, 2, 2]\n",
      "82/154:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/155:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            if isinstance(sublist, int):\n",
      "                l.append([sublist, sublist])\n",
      "            else:\n",
      "                l.extend(duplicate(sublist))\n",
      "        return l\n",
      "82/156:     >>> duplicate(1)\n",
      "82/157:     [1, 1]\n",
      "82/158:     >>> duplicate([])\n",
      "82/159:     []\n",
      "82/160:     >>> duplicate([1, 2])\n",
      "82/161:     [1, 1, 2, 2]\n",
      "82/162:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/163:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return obj, obj\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            if isinstance(sublist, int):\n",
      "                l.append([sublist, sublist])\n",
      "            else:\n",
      "                l.extend(duplicate(sublist))\n",
      "        return l\n",
      "82/164:     >>> duplicate(1)\n",
      "82/165:     [1, 1]\n",
      "82/166:     >>> duplicate([])\n",
      "82/167:     []\n",
      "82/168:     >>> duplicate([1, 2])\n",
      "82/169:     [1, 1, 2, 2]\n",
      "82/170:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/171:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return obj, obj\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            if isinstance(sublist, int):\n",
      "                l.extend([sublist, sublist])\n",
      "            else:\n",
      "                l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/172:     >>> duplicate(1)\n",
      "82/173:     [1, 1]\n",
      "82/174:     >>> duplicate([])\n",
      "82/175:     []\n",
      "82/176:     >>> duplicate([1, 2])\n",
      "82/177:     [1, 1, 2, 2]\n",
      "82/178:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/179:     [1, 1, [2, 2, 3, 3]]\n",
      "82/180:\n",
      "def duplicate(obj: Union[int, List]) -> Union[int, List]:\n",
      "    \"\"\"Return a new nested list with all numbers in <obj> duplicated.\n",
      "\n",
      "    Each integer in <obj> should appear twice *consecutively* in the\n",
      "    output nested list. The nesting structure is the same as the input,\n",
      "    only with some new numbers added. See doctest examples for details.\n",
      "\n",
      "    If <obj> is an int, return a list containing two copies of it.\n",
      "\n",
      "    >>> duplicate(1)\n",
      "    [1, 1]\n",
      "    >>> duplicate([])\n",
      "    []\n",
      "    >>> duplicate([1, 2])\n",
      "    [1, 1, 2, 2]\n",
      "    >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "    [1, 1, [2, 2, 3, 3]]\n",
      "    \"\"\"\n",
      "    # HINT: in the recursive case, you'll need to distinguish between\n",
      "    # a <sublist> that is an int and a <sublist> that is a list\n",
      "    # (put an isinstance check inside the loop).\n",
      "\n",
      "    if isinstance(obj, int):\n",
      "        return [obj, obj]\n",
      "    else:\n",
      "        l = []\n",
      "        for sublist in obj:\n",
      "            if isinstance(sublist, int):\n",
      "                l.extend([sublist, sublist])\n",
      "            else:\n",
      "                l.append(duplicate(sublist))\n",
      "        return l\n",
      "82/181:     >>> duplicate(1)\n",
      "82/182:     [1, 1]\n",
      "82/183:     >>> duplicate([])\n",
      "82/184:     []\n",
      "82/185:     >>> duplicate([1, 2])\n",
      "82/186:     [1, 1, 2, 2]\n",
      "82/187:     >>> duplicate([1, [2, 3]])  # NOT [1, 1, [2, 2, 3, 3], [2, 2, 3, 3]]\n",
      "82/188:     [1, 1, [2, 2, 3, 3]]\n",
      "82/189:\n",
      "def nested_list_equal(obj1: Union[int, List], obj2: Union[int, List]) -> bool:\n",
      "    \"\"\"Return whether two nested lists are equal, i.e., have the same value.\n",
      "\n",
      "    Note: order matters.\n",
      "\n",
      "    >>> nested_list_equal(17, [1, 2, 3])\n",
      "    False\n",
      "    >>> nested_list_equal([1, 2, [1, 2], 4], [1, 2, [1, 2], 4])\n",
      "    True\n",
      "    >>> nested_list_equal([1, 2, [1, 2], 4], [4, 2, [2, 1], 3])\n",
      "    False\n",
      "    \"\"\"\n",
      "    # HINT: You'll need to modify the basic pattern to loop over indexes,\n",
      "    # so that you can iterate through both obj1 and obj2 in parallel.\n",
      "    \n",
      "    # return obj1 == obj2 #???????????????????????????\n",
      "\n",
      "    if isinstance(obj1, int) and isinstance(obj2, int):\n",
      "        return 0 if obj1 == obj2 else 1\n",
      "    else:\n",
      "        tracking = 0\n",
      "        for sublist_index in range(len(obj1)):\n",
      "            tracking += nested_list_equal(obj1[sublist_index], \n",
      "                                          obj2[sublist_index])\n",
      "            if tracking == 1:\n",
      "                return False\n",
      "        return True\n",
      "82/190:     >>> nested_list_equal(17, [1, 2, 3])\n",
      "82/191:\n",
      "def nested_list_equal(obj1: Union[int, List], obj2: Union[int, List]) -> bool:\n",
      "    \"\"\"Return whether two nested lists are equal, i.e., have the same value.\n",
      "\n",
      "    Note: order matters.\n",
      "\n",
      "    >>> nested_list_equal(17, [1, 2, 3])\n",
      "    False\n",
      "    >>> nested_list_equal([1, 2, [1, 2], 4], [1, 2, [1, 2], 4])\n",
      "    True\n",
      "    >>> nested_list_equal([1, 2, [1, 2], 4], [4, 2, [2, 1], 3])\n",
      "    False\n",
      "    \"\"\"\n",
      "    # HINT: You'll need to modify the basic pattern to loop over indexes,\n",
      "    # so that you can iterate through both obj1 and obj2 in parallel.\n",
      "    \n",
      "    return obj1 == obj2 #???????????????????????????\n",
      "82/192:     >>> nested_list_equal(17, [1, 2, 3])\n",
      "82/193:     False\n",
      "82/194:     >>> nested_list_equal([1, 2, [1, 2], 4], [1, 2, [1, 2], 4])\n",
      "82/195:     True\n",
      "82/196:     >>> nested_list_equal([1, 2, [1, 2], 4], [4, 2, [2, 1], 3])\n",
      "83/1: from __future__ import annotations\n",
      "83/2:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        for \n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/3:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "83/4:         >>> lst = RecursiveList([])\n",
      "83/5:         >>> len(lst) # Equivalent to lst.__len__()\n",
      "83/6:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/7:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "83/8:         >>> lst = RecursiveList([])\n",
      "83/9:         >>> len(lst) # Equivalent to lst.__len__()\n",
      "83/10:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/11:         >>> lst._first\n",
      "83/12:         >>> lst._first\n",
      "83/13:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/14:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst._first\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        count += __len__(self.next)\n",
      "        return count\n",
      "83/15:         >>> lst = RecursiveList([])\n",
      "83/16:         >>> len(lst) # Equivalent to lst.__len__()\n",
      "83/17:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst._first\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        count += __len__(self.next)\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/18:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst._first\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        count += __len__(self.next)\n",
      "        return count\n",
      "83/19:         >>> lst = RecursiveList([])\n",
      "83/20:         >>> len(lst) # Equivalent to lst.__len__()\n",
      "83/21:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst._first\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        count += __len__(self._rest)\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/22:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst._first\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        count += __len__(self._rest)\n",
      "        return count\n",
      "83/23:         >>> lst = RecursiveList([])\n",
      "83/24:         >>> len(lst) # Equivalent to lst.__len__()\n",
      "83/25:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst._first\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest)\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/26:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst._first\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest)\n",
      "        return count\n",
      "83/27:         >>> lst = RecursiveList([])\n",
      "83/28:         >>> len(lst) # Equivalent to lst.__len__()\n",
      "83/29:         0\n",
      "83/30:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/31:         >>> lst._first\n",
      "83/32:         >>> len(lst)\n",
      "83/33:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst._first\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/34:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst._first\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "83/35:         >>> lst = RecursiveList([])\n",
      "83/36:         >>> len(lst) # Equivalent to lst.__len__()\n",
      "83/37:         0\n",
      "83/38:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/39:         >>> lst._first\n",
      "83/40:         >>> len(lst)\n",
      "83/41:         >>> lst = RecursiveList([0])\n",
      "83/42:         >>> len(lst)\n",
      "83/43:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            count += 1\n",
      "        else:\n",
      "            count += count(self._rest)\n",
      "        return count\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/44:\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            count += 1\n",
      "        else:\n",
      "            count += count(self._rest)\n",
      "        return count\n",
      "83/45:         >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "83/46:         >>> lst.count(1)\n",
      "83/47:         3\n",
      "83/48:         >>> lst.count(2)\n",
      "83/49:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        else:\n",
      "            matches += count(self._rest)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/50:\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        else:\n",
      "            matches += count(self._rest)\n",
      "        return matches\n",
      "83/51:         >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "83/52:         >>> lst.count(1)\n",
      "83/53:         3\n",
      "83/54:         >>> lst.count(2)\n",
      "83/55:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        else:\n",
      "            matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/56:\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        else:\n",
      "            matches += count(self._rest, item)\n",
      "        return matches\n",
      "83/57:         >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "83/58:         >>> lst.count(1)\n",
      "83/59:         3\n",
      "83/60:         >>> lst.count(2)\n",
      "83/61:         2\n",
      "83/62:         >>> lst.count(3)\n",
      "83/63:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/64:\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "83/65:         >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "83/66:         >>> lst.count(1)\n",
      "83/67:         3\n",
      "83/68:         >>> lst.count(2)\n",
      "83/69:         2\n",
      "83/70:         >>> lst.count(3)\n",
      "83/71:         1\n",
      "83/72:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/73:\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "83/74:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/75:         >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "83/76:         1\n",
      "83/77:         >>> lst[1]\n",
      "83/78:         2\n",
      "83/79:         >>> lst[2]\n",
      "83/80:         3\n",
      "83/81:         >>> lst[3]\n",
      "83/82:\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "83/83:         >>> lst = RecursiveList([4, 2, 7])\n",
      "83/84:         >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "83/85:         1\n",
      "83/86:         >>> lst[1]\n",
      "83/87:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/88:\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "83/89:         >>> lst = RecursiveList([4, 2, 7])\n",
      "83/90:         >>> lst[0] # Equivalent to lst.__getitem__(0)\n",
      "83/91:         1\n",
      "83/92:         >>> lst[1]\n",
      "83/93:         2\n",
      "83/94:         >>> lst[2]\n",
      "83/95:         3\n",
      "83/96:         >>> lst[3]\n",
      "83/97:         >>> lst[0]\n",
      "83/98:         >>> lst[0]\n",
      "83/99:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "        raise IndexError\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/100:         >>> lst = RecursiveList([4, 2, 7])\n",
      "83/101:         >>> lst[0]\n",
      "83/102:         1\n",
      "83/103:         >>> lst[1]\n",
      "83/104:         2\n",
      "83/105:         >>> lst[2]\n",
      "83/106:         3\n",
      "83/107:         >>> lst[3]\n",
      "83/108:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/109:         >>> lst = RecursiveList([4, 2, 7])\n",
      "83/110:         >>> lst[0]\n",
      "83/111:         1\n",
      "83/112:         >>> lst[1]\n",
      "83/113:         2\n",
      "83/114:         >>> lst[2]\n",
      "83/115:         3\n",
      "83/116:         >>> lst[3]\n",
      "83/117:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1)\n",
      "        \n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/118:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/119:         >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "83/120:         >>> lst[1] = 200\n",
      "83/121:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/122:\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1)\n",
      "83/123:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/124:         >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "83/125:         >>> lst[1] = 200\n",
      "83/126:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/127:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/128:         >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "83/129:         >>> lst[1] = 200\n",
      "83/130:         >>> lst[2] = 300\n",
      "83/131:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/132:         >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "83/133:         >>> str(lst)\n",
      "83/134:         >>> lst[1] = 200\n",
      "83/135:         >>> str(lst)\n",
      "83/136:         >>> lst[2] = 300\n",
      "83/137:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/138:\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "83/139:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/140:         >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "83/141:         >>> str(lst)\n",
      "83/142:         >>> lst[1] = 200\n",
      "83/143:         >>> str(lst)\n",
      "83/144:         >>> lst[2] = 300\n",
      "83/145:         >>> lst[3] = 400\n",
      "83/146:         >>> str(lst)\n",
      "83/147:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/148:\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/149:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/150:         >>> lst.pop(2)\n",
      "83/151:         3\n",
      "83/152:         >>> str(lst)\n",
      "83/153:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList()\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _insert_first(self, item: Any) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/154:\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList()\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "83/155:\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "83/156:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/157:         >>> lst.pop(2)\n",
      "83/158:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/159:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/160:         >>> lst.pop(2)\n",
      "83/161:\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "83/162:\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "83/163:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/164:         >>> lst.pop(2)\n",
      "83/165:         3\n",
      "83/166:         >>> str(lst)\n",
      "83/167:         '1 -> 2'\n",
      "83/168:         >>> lst.pop(1)\n",
      "83/169:         2\n",
      "83/170:         >>> str(lst)\n",
      "83/171:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = None\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/172:\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = None\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "83/173:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/174:         >>> lst.pop(2)\n",
      "83/175:         3\n",
      "83/176:         >>> str(lst)\n",
      "83/177:\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "83/178:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/179:         >>> lst.pop(2)\n",
      "83/180:         3\n",
      "83/181:         >>> str(lst)\n",
      "83/182:         '1 -> 2'\n",
      "83/183:         >>> lst.pop(1)\n",
      "83/184:         2\n",
      "83/185:         >>> str(lst)\n",
      "83/186:         '1'\n",
      "83/187:         >>> lst.pop(0)\n",
      "83/188:         1\n",
      "83/189:         >>> str(lst)\n",
      "83/190:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/191:         >>> lst.pop(2)\n",
      "83/192:         >>> lst\n",
      "83/193:         >>> print(lst)\n",
      "83/194:         >>> lst.__getitem__(2)\n",
      "83/195:         >>> lst[2]]\n",
      "83/196:         >>> lst[2]\n",
      "83/197:         >>> lst[3\n",
      "83/198:         >>> lst[3]\n",
      "83/199:         >>> lst[2]\n",
      "83/200:         >>> lst[1]\n",
      "83/201:\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = None\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "83/202:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/203:         >>> lst.pop(2)\n",
      "83/204:         3\n",
      "83/205:         >>> lst[1]\n",
      "83/206:         >>> str(lst)\n",
      "83/207:\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> str(lst)\n",
      "        ''\n",
      "        >>> lst.pop(0)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "83/208:         >>> lst = RecursiveList([1, 2, 3])\n",
      "83/209:         >>> lst.pop(2)\n",
      "83/210:         3\n",
      "83/211:         >>> lst[1]\n",
      "83/212:         >>> str(lst)\n",
      "83/213:         '1 -> 2'\n",
      "83/214:         >>> lst.pop(1)\n",
      "83/215:         2\n",
      "83/216:         >>> str(lst)\n",
      "83/217:         '1'\n",
      "83/218:         >>> lst.pop(0)\n",
      "83/219:         1\n",
      "83/220:         >>> str(lst)\n",
      "83/221:         >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "83/222:         >>> lst.pop(2)\n",
      "83/223:         >>> str(lst)\n",
      "83/224:         >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "83/225:         >>> lst.pop(2)\n",
      "83/226:         3\n",
      "83/227:         >>> lst[1]\n",
      "83/228:         >>> str(lst)\n",
      "83/229:         '1 -> 2 -> 4'\n",
      "83/230:         >>> lst.pop(1)\n",
      "83/231:         2\n",
      "83/232:         >>> str(lst)\n",
      "83/233:         '1 -> 4'\n",
      "83/234:         >>> lst.pop(0)\n",
      "83/235:         1\n",
      "83/236:         >>> str(lst)\n",
      "83/237:         >>> lst.pop(1)\n",
      "83/238:         >>> lst.pop(0)\n",
      "83/239:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self._first\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/240:         >>> lst = RecursiveList(['c'])\n",
      "83/241:         >>> lst.insert(0, 'a')\n",
      "83/242:         >>> str(lst)\n",
      "83/243:         'a -> c'\n",
      "83/244:         >>> lst.insert(1, 'b')\n",
      "83/245:         >>> str(lst)\n",
      "83/246:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self._first\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/247:         >>> lst = RecursiveList(['c'])\n",
      "83/248:         >>> lst.insert(0, 'a')\n",
      "83/249:         >>> str(lst)\n",
      "83/250:         'a -> c'\n",
      "83/251:         >>> lst.insert(1, 'b')\n",
      "83/252:         >>> str(lst)\n",
      "83/253:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self._first\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/254:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self._first\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/255:         >>> lst = RecursiveList(['c'])\n",
      "83/256:         >>> lst.insert(0, 'a')\n",
      "83/257:         >>> str(lst)\n",
      "83/258:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/259:         >>> lst = RecursiveList(['c'])\n",
      "83/260:         >>> lst.insert(0, 'a')\n",
      "83/261:         >>> str(lst)\n",
      "83/262:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/263:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/264:         >>> lst = RecursiveList(['c'])\n",
      "83/265:         >>> lst.insert(0, 'a')\n",
      "83/266:         >>> str(lst)\n",
      "83/267:         >>> lst.insert(0, 'a')\n",
      "83/268:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self\n",
      "            newList = RecursiveList(item)\n",
      "            newList._next = stored\n",
      "            return newList\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/269:         >>> lst = RecursiveList(['c'])\n",
      "83/270:         >>> lst.insert(0, 'a')\n",
      "83/271:         >>> str(lst)\n",
      "83/272:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self\n",
      "            newList = RecursiveList(item)\n",
      "            newList._next = stored\n",
      "            return newList\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/273:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self\n",
      "            newList = RecursiveList(item)\n",
      "            newList._next = stored\n",
      "            return newList\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/274:         >>> lst = RecursiveList(['c'])\n",
      "83/275:         >>> lst.insert(0, 'a')\n",
      "83/276:         >>> lst = RecursiveList(['c'])\n",
      "83/277:         >>> lst.insert(0, 'a')\n",
      "83/278:         >>> lst = RecursiveList(['c'])\n",
      "83/279:         >>> lst.insert(0, ['a'])\n",
      "83/280:         >>> str(lst)\n",
      "83/281:         'a -> c'\n",
      "83/282:         >>> lst.insert(1, 'b')\n",
      "83/283:         >>> str(lst)\n",
      "83/284:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, ['a'])\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._next = self\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/285:         >>> lst = RecursiveList(['c'])\n",
      "83/286:         >>> lst.insert(0, ['a'])\n",
      "83/287:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, ['a'])\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._next = self\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/288:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, ['a'])\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._next = self\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/289:         >>> lst = RecursiveList(['c'])\n",
      "83/290:         >>> lst.insert(0, ['a'])\n",
      "83/291:         >>> str(lst)\n",
      "83/292:         'a -> c'\n",
      "83/293:         >>> lst.insert(1, 'b')\n",
      "83/294:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._next = self\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/295:         >>> lst = RecursiveList(['c'])\n",
      "83/296:         >>> lst.insert(0, 'a')\n",
      "83/297:         >>> str(lst)\n",
      "83/298:         'a -> c'\n",
      "83/299:         >>> lst.insert(1, 'b')\n",
      "83/300:         >>> lst = RecursiveList(['c'])\n",
      "83/301:         >>> str(lst)\n",
      "83/302:         >>> print(lst)\n",
      "83/303:         >>> lst\n",
      "83/304:         >>> lst._first\n",
      "83/305:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/306:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/307:         >>> lst = RecursiveList(['c'])\n",
      "83/308:         >>> str(lst)\n",
      "83/309:         >>> lst.insert(0, 'a')\n",
      "83/310:         >>> str(lst)\n",
      "83/311:         >>> lst._first\n",
      "83/312:         >>> lst = RecursiveList(['c'])\n",
      "83/313:         >>> str(lst)\n",
      "83/314:         >>> lst._first\n",
      "83/315:         >>> lst._first\n",
      "83/316:         >>> lst._rest\n",
      "83/317:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self._rest\n",
      "            self = RecursiveList([item])\n",
      "            self._next = stored\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/318:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self._rest\n",
      "            self = RecursiveList([item])\n",
      "            self._next = stored\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/319:         >>> lst = RecursiveList(['c'])\n",
      "83/320:         >>> str(lst)\n",
      "83/321:         >>> lst._first\n",
      "83/322:         >>> lst._rest\n",
      "83/323:         >>> lst.insert(0, 'a')\n",
      "83/324:         >>> str(lst)\n",
      "83/325:         'a -> c'\n",
      "83/326:         >>> lst.insert(1, 'b')\n",
      "83/327:         >>> lst.insert(3, 'd')\n",
      "83/328:         >>> str(lst)\n",
      "83/329:         >>> lst._first\n",
      "83/330:         >>> lst = RecursiveList(['c'])\n",
      "83/331:         >>> str(lst)\n",
      "83/332:         >>> lst._first\n",
      "83/333:         >>> lst._rest\n",
      "83/334:         >>> lst.insert(0, 'a')\n",
      "83/335:         >>> print(lst._rest)\n",
      "83/336:         >>> lst.insert(0, 'a')\n",
      "83/337:         >>> lst._first\n",
      "83/338:         >>> lst._rest\n",
      "83/339:         >>> print(lst._rest)\n",
      "83/340:         >>> lst = RecursiveList(['c'])\n",
      "83/341:         >>> str(lst)\n",
      "83/342:         >>> lst._first\n",
      "83/343:         >>> lst._rest\n",
      "83/344:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self\n",
      "            self = RecursiveList([item])\n",
      "            self._next = stored\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/345:         >>> lst = RecursiveList(['c'])\n",
      "83/346:         >>> str(lst)\n",
      "83/347:         >>> lst._first\n",
      "83/348:         >>> lst._rest\n",
      "83/349:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self\n",
      "            self = RecursiveList([item])\n",
      "            self._next = stored\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/350:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self\n",
      "            self = RecursiveList([item])\n",
      "            self._next = stored\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/351:         >>> lst = RecursiveList(['c'])\n",
      "83/352:         >>> str(lst)\n",
      "83/353:         >>> lst._first\n",
      "83/354:         >>> lst._rest\n",
      "83/355:         >>> lst.insert(0, 'a')\n",
      "83/356:         >>> lst._first\n",
      "83/357:         >>> lst._rest\n",
      "83/358:         >>> lst = RecursiveList(['c'])\n",
      "83/359:         >>> str(lst)\n",
      "83/360:         >>> lst._first\n",
      "83/361:         >>> lst._rest\n",
      "83/362:         >>> lst.insert(0, 'a')\n",
      "83/363:         >>> lst._first\n",
      "83/364:         >>> lst._rest\n",
      "83/365:         >>> lst = RecursiveList(['c'])\n",
      "83/366:         >>> str(lst)\n",
      "83/367:         >>> lst._first\n",
      "83/368:         >>> lst._rest\n",
      "83/369:         >>> lst.insert(0, 'a')\n",
      "83/370:         >>> lst._first\n",
      "83/371:         >>> lst._rest\n",
      "83/372:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self\n",
      "            self = RecursiveList([item, stored])\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "    def _pop_first(self) -> Any:\n",
      "        \"\"\"Remove and return the first item in this list.\n",
      "\n",
      "        Raise an IndexError if this list is empty.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/373:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            stored = self\n",
      "            self = RecursiveList([item, stored])\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/374:         >>> lst = RecursiveList(['c'])\n",
      "83/375:         >>> str(lst)\n",
      "83/376:         >>> lst._first\n",
      "83/377:         >>> lst._rest\n",
      "83/378:         >>> lst.insert(0, 'a')\n",
      "83/379:         >>> lst._first\n",
      "83/380:         >>> lst._rest\n",
      "83/381:         >>> str(lst)\n",
      "83/382:         'a -> c'\n",
      "83/383:         >>> lst.insert(1, 'b')\n",
      "83/384:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        newlist = [item]\n",
      "        while len(self) > 0:\n",
      "            newlist.append(self.pop(0))\n",
      "        self = RecursiveList(newlist)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/385:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        newlist = [item]\n",
      "        while len(self) > 0:\n",
      "            newlist.append(self.pop(0))\n",
      "        self = RecursiveList(newlist)\n",
      "83/386:         >>> lst = RecursiveList(['c'])\n",
      "83/387:         >>> str(lst)\n",
      "83/388:         >>> lst._first\n",
      "83/389:         >>> lst._rest\n",
      "83/390:         >>> lst.insert(0, 'a')\n",
      "83/391:         >>> lst = RecursiveList(['c'])\n",
      "83/392:         >>> str(lst)\n",
      "83/393:         >>> lst._first\n",
      "83/394:         >>> lst._rest\n",
      "83/395:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        newlist = [item]\n",
      "        length = len(self)\n",
      "        for i in range(length):\n",
      "            newlist.append(self.pop(0))\n",
      "        self = RecursiveList(newlist)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/396:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        newlist = [item]\n",
      "        length = len(self)\n",
      "        for i in range(length):\n",
      "            newlist.append(self.pop(0))\n",
      "        self = RecursiveList(newlist)\n",
      "83/397:         >>> lst = RecursiveList(['c'])\n",
      "83/398:         >>> str(lst)\n",
      "83/399:         >>> lst._first\n",
      "83/400:         >>> lst._rest\n",
      "83/401:         >>> lst.insert(0, 'a')\n",
      "83/402:         >>> lst._first\n",
      "83/403:         >>> lst._rest\n",
      "83/404:         >>> str(lst)\n",
      "83/405:         'a -> c'\n",
      "83/406:         >>> lst.insert(1, 'b')\n",
      "83/407:         >>> str(lst)\n",
      "83/408:         'a -> b -> c'\n",
      "83/409:         >>> lst.insert(3, 'd')\n",
      "83/410:         >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "83/411:         >>> lst.pop(2)\n",
      "83/412:         3\n",
      "83/413:         >>> lst[1]\n",
      "83/414:         >>> str(lst)\n",
      "83/415:         '1 -> 2 -> 4'\n",
      "83/416:         >>> lst.pop(1)\n",
      "83/417:         2\n",
      "83/418:         >>> str(lst)\n",
      "83/419:         '1 -> 4'\n",
      "83/420:         >>> lst.pop(0)\n",
      "83/421:         1\n",
      "83/422:         >>> lst.pop(1)\n",
      "83/423:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self._first\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/424:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = self._first\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/425:         >>> lst = RecursiveList(['c'])\n",
      "83/426:         >>> str(lst)\n",
      "83/427:         >>> lst._first\n",
      "83/428:         >>> lst._rest\n",
      "83/429:         >>> lst.insert(0, 'a')\n",
      "83/430:         >>> lst._first\n",
      "83/431:         >>> lst._rest\n",
      "83/432:         >>> str(lst)\n",
      "83/433:         >>> str(lst)\n",
      "83/434:         >>> lst.insert(1, 'b')\n",
      "83/435:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/436:         >>> lst = RecursiveList(['c'])\n",
      "83/437:         >>> str(lst)\n",
      "83/438:         >>> lst._first\n",
      "83/439:         >>> lst._rest\n",
      "83/440:         >>> lst.insert(0, 'a')\n",
      "83/441:         >>> lst._first\n",
      "83/442:         >>> lst._rest\n",
      "83/443:         >>> str(lst)\n",
      "83/444:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/445:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "83/446:         >>> lst = RecursiveList(['c'])\n",
      "83/447:         >>> str(lst)\n",
      "83/448:         >>> lst._first\n",
      "83/449:         >>> lst._rest\n",
      "83/450:         >>> lst.insert(0, 'a')\n",
      "83/451:         >>> lst._first\n",
      "83/452:         >>> lst._rest\n",
      "83/453:         >>> str(lst)\n",
      "83/454:         'a -> c'\n",
      "83/455:         >>> lst.insert(1, 'b')\n",
      "83/456:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "83/457:         >>> lst = RecursiveList(['c'])\n",
      "83/458:         >>> str(lst)\n",
      "83/459:         >>> lst._first\n",
      "83/460:         >>> lst._rest\n",
      "83/461:         >>> lst.insert(0, 'a')\n",
      "83/462:         >>> lst._first\n",
      "83/463:         >>> lst._rest\n",
      "83/464:         >>> str(lst)\n",
      "83/465:         'a -> c'\n",
      "83/466:         >>> lst.insert(1, 'b')\n",
      "83/467:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/468:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "83/469:         >>> lst = RecursiveList(['c'])\n",
      "83/470:         >>> str(lst)\n",
      "83/471:         >>> lst._first\n",
      "83/472:         >>> lst._rest\n",
      "83/473:         >>> lst.insert(0, 'a')\n",
      "83/474:         >>> lst._first\n",
      "83/475:         >>> lst._rest\n",
      "83/476:         >>> str(lst)\n",
      "83/477:         'a -> c'\n",
      "83/478:         >>> lst.insert(1, 'b')\n",
      "83/479:         >>> lst.insert(3, 'd')\n",
      "83/480:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "            break\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/481:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "            break\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "83/482:         >>> lst = RecursiveList(['c'])\n",
      "83/483:         >>> str(lst)\n",
      "83/484:         >>> lst._first\n",
      "83/485:         >>> lst._rest\n",
      "83/486:         >>> lst.insert(0, 'a')\n",
      "83/487:         >>> lst._first\n",
      "83/488:         >>> lst._rest\n",
      "83/489:         >>> str(lst)\n",
      "83/490:         'a -> c'\n",
      "83/491:         >>> lst.insert(1, 'b')\n",
      "83/492:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "            return None\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "83/493:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "            return None\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "83/494:         >>> lst = RecursiveList(['c'])\n",
      "83/495:         >>> str(lst)\n",
      "83/496:         >>> lst._first\n",
      "83/497:         >>> lst._rest\n",
      "83/498:         >>> lst.insert(0, 'a')\n",
      "83/499:         >>> lst._first\n",
      "83/500:         >>> lst._rest\n",
      "83/501:         >>> str(lst)\n",
      "83/502:         'a -> c'\n",
      "83/503:         >>> lst.insert(1, 'b')\n",
      "84/1: from __future__ import annotations\n",
      "84/2:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "            return None\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "84/3:         >>> lst = RecursiveList(['c'])\n",
      "84/4:         >>> str(lst)\n",
      "84/5:         >>> lst._first\n",
      "84/6:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "            return None\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/7: from typing import Any, Callable, Optional\n",
      "84/8:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "            return None\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "84/9:         >>> lst = RecursiveList(['c'])\n",
      "84/10:         >>> str(lst)\n",
      "84/11:         >>> lst._first\n",
      "84/12:         >>> lst._rest\n",
      "84/13:         >>> lst.insert(0, 'a')\n",
      "84/14:\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "84/15:\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "84/16:\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "84/17:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "84/18:\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "84/19:\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "84/20:\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "84/21:\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "84/22:\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "84/23:\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "84/24:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "            return None\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "84/25:         >>> lst = RecursiveList(['c'])\n",
      "84/26:         >>> str(lst)\n",
      "84/27:         >>> lst._first\n",
      "84/28:         >>> lst._rest\n",
      "84/29:         >>> lst.insert(0, 'a')\n",
      "84/30:         >>> lst._first\n",
      "84/31:         >>> lst._rest\n",
      "84/32:         >>> str(lst)\n",
      "84/33:         'a -> c'\n",
      "84/34:         >>> lst.insert(1, 'b')\n",
      "84/35:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, [item])\n",
      "84/36:         >>> lst = RecursiveList(['c'])\n",
      "84/37:         >>> str(lst)\n",
      "84/38:         >>> lst._first\n",
      "84/39:         >>> lst._rest\n",
      "84/40:         >>> lst.insert(0, 'a')\n",
      "84/41:         >>> lst._first\n",
      "84/42:         >>> lst._rest\n",
      "84/43:         >>> str(lst)\n",
      "84/44:         'a -> c'\n",
      "84/45:         >>> lst.insert(1, 'b')\n",
      "84/46:         >>> str(lst)\n",
      "84/47:         >>> lst.insert(1, 'b')\n",
      "84/48:         >>> str(lst)\n",
      "84/49:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "84/50:         >>> lst = RecursiveList(['c'])\n",
      "84/51:         >>> str(lst)\n",
      "84/52:         >>> lst._first\n",
      "84/53:         >>> lst._rest\n",
      "84/54:         >>> lst.insert(0, 'a')\n",
      "84/55:         >>> lst._first\n",
      "84/56:         >>> lst._rest\n",
      "84/57:         >>> str(lst)\n",
      "84/58:         'a -> c'\n",
      "84/59:         >>> lst.insert(1, 'b')\n",
      "84/60:         >>> str(lst)\n",
      "84/61:         >>> str(lst)\n",
      "84/62:         >>> str(lst)\n",
      "84/63:         >>> lst = RecursiveList(['c'])\n",
      "84/64:         >>> str(lst)\n",
      "84/65:         >>> lst = RecursiveList(['c'])\n",
      "84/66:         >>> str(lst)\n",
      "84/67:         >>> lst._first\n",
      "84/68:         >>> lst._rest\n",
      "84/69:         >>> lst.insert(0, 'a')\n",
      "84/70:         >>> lst._first\n",
      "84/71:         >>> lst._rest\n",
      "84/72:         >>> str(lst)\n",
      "84/73:         'a -> c'\n",
      "84/74:         >>> lst.insert(1, 'b')\n",
      "84/75:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "            index -= 1\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/76:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            insert(self._rest, index - 1, item)\n",
      "            index -= 1\n",
      "84/77:         >>> lst = RecursiveList(['c'])\n",
      "84/78:         >>> str(lst)\n",
      "84/79:         >>> lst._first\n",
      "84/80:         >>> lst._rest\n",
      "84/81:         >>> lst.insert(0, 'a')\n",
      "84/82:         >>> lst._first\n",
      "84/83:         >>> lst._rest\n",
      "84/84:         >>> str(lst)\n",
      "84/85:         'a -> c'\n",
      "84/86:         >>> lst.insert(1, 'b')\n",
      "84/87:         >>> str(lst)\n",
      "84/88:         'a -> b -> c'\n",
      "84/89:         >>> lst.insert(3, 'd')\n",
      "84/90:         >>> str(lst)\n",
      "84/91:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/92:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> lst._first\n",
      "        >>> lst._rest\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "84/93:         >>> lst = RecursiveList(['c'])\n",
      "84/94:         >>> str(lst)\n",
      "84/95:         >>> lst._first\n",
      "84/96:         >>> lst._rest\n",
      "84/97:         >>> lst.insert(0, 'a')\n",
      "84/98:         >>> lst._first\n",
      "84/99:         >>> lst._rest\n",
      "84/100:         >>> str(lst)\n",
      "84/101:         'a -> c'\n",
      "84/102:         >>> lst.insert(1, 'b')\n",
      "84/103:         >>> str(lst)\n",
      "84/104:         'a -> b -> c'\n",
      "84/105:         >>> lst.insert(3, 'd')\n",
      "84/106:         >>> str(lst)\n",
      "84/107:         'a -> b -> c -> d'\n",
      "84/108:         >>> lst.insert(5, 'd')\n",
      "84/109:         >>> str(lst)\n",
      "84/110:         >>> lst = RecursiveList(['c'])\n",
      "84/111:         >>> str(lst)\n",
      "84/112:         >>> lst.insert(0, 'a')\n",
      "84/113:         >>> str(lst)\n",
      "84/114:         'a -> c'\n",
      "84/115:         >>> lst.insert(1, 'b')\n",
      "84/116:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == len(self):\n",
      "            self._rest = RecursiveList([item])\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/117:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == len(self):\n",
      "            self._rest = RecursiveList([item])\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "84/118:         >>> lst = RecursiveList(['c'])\n",
      "84/119:         >>> str(lst)\n",
      "84/120:         >>> lst.insert(0, 'a')\n",
      "84/121:         >>> str(lst)\n",
      "84/122:         'a -> c'\n",
      "84/123:         >>> lst.insert(1, 'b')\n",
      "84/124:         >>> str(lst)\n",
      "84/125:         'a -> b -> c'\n",
      "84/126:         >>> lst.insert(3, 'd')\n",
      "84/127:         >>> len(lst)\n",
      "84/128:         >>> lst = RecursiveList(['c'])\n",
      "84/129:         >>> str(lst)\n",
      "84/130:         >>> lst.insert(0, 'a')\n",
      "84/131:         >>> str(lst)\n",
      "84/132:         'a -> c'\n",
      "84/133:         >>> lst.insert(1, 'b')\n",
      "84/134:         >>> str(lst)\n",
      "84/135:         'a -> b -> c'\n",
      "84/136:         >>> len(lst)\n",
      "84/137:         >>> lst.insert(3, 'd')\n",
      "84/138:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            self._rest = RecursiveList([item])\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/139:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            self._rest = RecursiveList([item])\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "84/140:         >>> lst = RecursiveList(['c'])\n",
      "84/141:         >>> str(lst)\n",
      "84/142:         >>> lst.insert(0, 'a')\n",
      "84/143:         >>> str(lst)\n",
      "84/144:         'a -> c'\n",
      "84/145:         >>> lst.insert(1, 'b')\n",
      "84/146:         >>> str(lst)\n",
      "84/147:         'a -> b -> c'\n",
      "84/148:         >>> len(lst)\n",
      "84/149:         >>> lst.insert(3, 'd')\n",
      "84/150:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            self._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/151:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            self._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "84/152:         >>> lst = RecursiveList(['c'])\n",
      "84/153:         >>> str(lst)\n",
      "84/154:         >>> lst.insert(0, 'a')\n",
      "84/155:         >>> str(lst)\n",
      "84/156:         'a -> c'\n",
      "84/157:         >>> lst.insert(1, 'b')\n",
      "84/158:         >>> str(lst)\n",
      "84/159:         'a -> b -> c'\n",
      "84/160:         >>> len(lst)\n",
      "84/161:         >>> lst.insert(3, 'd')\n",
      "84/162:         >>> len(lst)\n",
      "84/163:         >>> str(lst)\n",
      "84/164:         >>> lst = RecursiveList(['c'])\n",
      "84/165:         >>> str(lst)\n",
      "84/166:         >>> lst.insert(0, 'a')\n",
      "84/167:         >>> str(lst)\n",
      "84/168:         'a -> c'\n",
      "84/169:         >>> lst.insert(1, 'b')\n",
      "84/170:         >>> str(lst)\n",
      "84/171:         'a -> b -> c'\n",
      "84/172:         >>> len(lst)\n",
      "84/173:         >>> len(lst)\n",
      "84/174:         >>> lst._rest = RecursiveList(['d'])\n",
      "84/175:         >>> str(lst)\n",
      "84/176:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            while not self._rest.is_empty():\n",
      "                self = self._rest\n",
      "            self._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "84/177:         >>> lst = RecursiveList(['c'])\n",
      "84/178:         >>> str(lst)\n",
      "84/179:         >>> lst.insert(0, 'a')\n",
      "84/180:         >>> str(lst)\n",
      "84/181:         'a -> c'\n",
      "84/182:         >>> lst.insert(1, 'b')\n",
      "84/183:         >>> str(lst)\n",
      "84/184:         'a -> b -> c'\n",
      "84/185:         >>> len(lst)\n",
      "84/186:         >>> lst.insert(3, 'd')\n",
      "84/187:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            while not self._rest.is_empty():\n",
      "                self = self._rest\n",
      "            self._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/188:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            while not self._rest.is_empty():\n",
      "                self = self._rest\n",
      "            self._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "84/189:         >>> lst = RecursiveList(['c'])\n",
      "84/190:         >>> str(lst)\n",
      "84/191:         >>> lst.insert(0, 'a')\n",
      "84/192:         >>> str(lst)\n",
      "84/193:         'a -> c'\n",
      "84/194:         >>> lst.insert(1, 'b')\n",
      "84/195:         >>> str(lst)\n",
      "84/196:         'a -> b -> c'\n",
      "84/197:         >>> len(lst)\n",
      "84/198:         >>> lst.insert(3, 'd')\n",
      "84/199:         >>> lst = RecursiveList(['c'])\n",
      "84/200:         >>> str(lst)\n",
      "84/201:         >>> lst.insert(0, 'a')\n",
      "84/202:         >>> str(lst)\n",
      "84/203:         'a -> c'\n",
      "84/204:         >>> lst.insert(1, 'b')\n",
      "84/205:         >>> str(lst)\n",
      "84/206:         'a -> b -> c'\n",
      "84/207:         >>> len(lst)\n",
      "84/208:         >>> lst\n",
      "84/209:         >>> str(lst)\n",
      "84/210:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            x = self.rest\n",
      "            while not x.is_empty():\n",
      "                x = self._rest\n",
      "            x._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/211:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            x = self.rest\n",
      "            while not x.is_empty():\n",
      "                x = self._rest\n",
      "            x._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "84/212:         >>> lst = RecursiveList(['c'])\n",
      "84/213:         >>> str(lst)\n",
      "84/214:         >>> lst.insert(0, 'a')\n",
      "84/215:         >>> str(lst)\n",
      "84/216:         'a -> c'\n",
      "84/217:         >>> lst.insert(1, 'b')\n",
      "84/218:         >>> str(lst)\n",
      "84/219:         'a -> b -> c'\n",
      "84/220:         >>> len(lst)\n",
      "84/221:         >>> lst.\n",
      "84/222:         >>> lst.insert(3, 'd')\n",
      "84/223:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            x = self._rest\n",
      "            while not x.is_empty():\n",
      "                x = self._rest\n",
      "            x._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "84/224:         >>> lst = RecursiveList(['c'])\n",
      "84/225:         >>> str(lst)\n",
      "84/226:         >>> lst.insert(0, 'a')\n",
      "84/227:         >>> str(lst)\n",
      "84/228:         'a -> c'\n",
      "84/229:         >>> lst.insert(1, 'b')\n",
      "84/230:         >>> str(lst)\n",
      "84/231:         'a -> b -> c'\n",
      "84/232:         >>> len(lst)\n",
      "84/233:         >>> lst.\n",
      "84/234:         >>> lst.insert(3, 'd')\n",
      "84/235:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            x = self._rest\n",
      "            while not x.is_empty():\n",
      "                x = self._rest\n",
      "            x._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/236:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index == len(self):\n",
      "            x = self._rest\n",
      "            while not x.is_empty():\n",
      "                x = self._rest\n",
      "            x._rest = RecursiveList([item])\n",
      "        elif index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        while index > 0:\n",
      "            index -= 1\n",
      "            insert(self._rest, index, item)\n",
      "84/237:         >>> lst = RecursiveList(['c'])\n",
      "84/238:         >>> str(lst)\n",
      "84/239:         >>> lst.insert(0, 'a')\n",
      "84/240:         >>> str(lst)\n",
      "84/241:         'a -> c'\n",
      "84/242:         >>> lst.insert(1, 'b')\n",
      "84/243:         >>> str(lst)\n",
      "84/244:         'a -> b -> c'\n",
      "84/245:         >>> len(lst)\n",
      "84/246:         >>> lst.insert(3, 'd')\n",
      "84/247:         >>> str(lst)\n",
      "84/248:         >>> len(lst)\n",
      "84/249:         >>> index = 3\n",
      "84/250:         >>> lst._rest\n",
      "84/251:         >>> print(lst._rest)\n",
      "84/252:         >>> x = (lst._rest)\n",
      "84/253:         >>> x.is_empty()\n",
      "84/254:         >>> x._rest\n",
      "84/255:         >>> len(lst)\n",
      "84/256:         >>> index = 3\n",
      "84/257:         >>> print(lst._rest)\n",
      "84/258:         >>> x = (lst._rest)\n",
      "84/259:         >>> x.is_empty()\n",
      "84/260:         >>> print(x._rest)\n",
      "84/261:         >>> print(x._rest)\n",
      "84/262:         >>> x = (lst._rest)\n",
      "84/263:         >>> x.is_empty()\n",
      "84/264:         >>> print(x._rest)\n",
      "84/265:         >>> len(lst)\n",
      "84/266:         >>> index = 3\n",
      "84/267:         >>> print(lst._rest)\n",
      "84/268:         >>> len(lst)\n",
      "84/269:         >>> index = 3\n",
      "84/270:         >>> print(lst._rest)\n",
      "84/271:         >>> x = (lst._rest)\n",
      "84/272:         >>> x.is_empty()\n",
      "84/273:         >>> print(x._rest)\n",
      "84/274:         >>> x = (x._rest)\n",
      "84/275:         >>> x.is_empty()\n",
      "84/276:         >>> print(x._rest)\n",
      "84/277:         >>> x = (x._rest)\n",
      "84/278:         >>> x.is_empty()\n",
      "84/279:         >>> item = 'd'\n",
      "84/280:         >>> index = 3\n",
      "84/281:         >>> x = RecursiveList([item])\n",
      "84/282:         >>> print(x)\n",
      "84/283:         >>> print(x._rest)\n",
      "84/284:         >>> print(lst)\n",
      "84/285:         >>> print(x)\n",
      "84/286:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            while index > 0:\n",
      "                insert(self._rest, index - 1, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/287:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            while index > 0:\n",
      "                insert(self._rest, index - 1, item)\n",
      "84/288:         >>> lst = RecursiveList(['c'])\n",
      "84/289:         >>> str(lst)\n",
      "84/290:         >>> lst.insert(0, 'a')\n",
      "84/291:         >>> str(lst)\n",
      "84/292:         'a -> c'\n",
      "84/293:         >>> lst.insert(1, 'b')\n",
      "84/294:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        while index > 0:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/295:\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            insert(self._rest, index - 1, item)\n",
      "84/296:         >>> lst = RecursiveList(['c'])\n",
      "84/297:         >>> str(lst)\n",
      "84/298:         >>> lst.insert(0, 'a')\n",
      "84/299:         >>> str(lst)\n",
      "84/300:         'a -> c'\n",
      "84/301:         >>> lst.insert(1, 'b')\n",
      "84/302:         >>> str(lst)\n",
      "84/303:         'a -> b -> c'\n",
      "84/304:         >>> len(lst)\n",
      "84/305:         >>> lst.insert(3, 'd')\n",
      "84/306:         >>> str(lst)\n",
      "84/307:         'a -> b -> c -> d'\n",
      "84/308:         >>> lst.insert(5, 'd')\n",
      "84/309:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        pass\n",
      "84/310:         >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "84/311:         >>> lst.pop(2)\n",
      "84/312:         3\n",
      "84/313:         >>> lst[1]\n",
      "84/314:         >>> str(lst)\n",
      "84/315:         '1 -> 2 -> 4'\n",
      "84/316:         >>> lst.pop(1)\n",
      "84/317:         2\n",
      "84/318:         >>> str(lst)\n",
      "84/319:         '1 -> 4'\n",
      "84/320:         >>> lst.pop(0)\n",
      "84/321:         1\n",
      "84/322:         >>> lst.pop(1)\n",
      "84/323:\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "         return f(self._first)\n",
      "84/324:\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return f(self._first)\n",
      "84/325:         >>> func = str.upper\n",
      "84/326:         >>> func('hi')\n",
      "84/327:         >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "84/328:         >>> str(lst.map(func))\n",
      "84/329:         >>> lst._first\n",
      "84/330:         >>> func(lst._first)\n",
      "84/331:\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> func(lst._first)\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList(f(self._first))\n",
      "84/332:         >>> func = str.upper\n",
      "84/333:         >>> func('hi')\n",
      "84/334:         'HI'\n",
      "84/335:         >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "84/336:         >>> func(lst._first)\n",
      "84/337:         >>> str(lst.map(func))\n",
      "84/338:\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> func(lst._first)\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self._first)])\n",
      "84/339:         >>> func = str.upper\n",
      "84/340:         >>> func('hi')\n",
      "84/341:         'HI'\n",
      "84/342:         >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "84/343:         >>> func(lst._first)\n",
      "84/344:         >>> str(lst.map(func))\n",
      "84/345:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> func(lst._first)\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self._first)])\n",
      "84/346:\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> func(lst._first)\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self._first)])\n",
      "84/347:         >>> func = str.upper\n",
      "84/348:         >>> func('hi')\n",
      "84/349:         'HI'\n",
      "84/350:         >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "84/351:         >>> func(lst._first)\n",
      "84/352:         >>> str(lst.map(func))\n",
      "84/353:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> func(lst._first)\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return [f(self[i]) for i in range(len(self))]\n",
      "84/354:\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> func(lst._first)\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return [f(self[i]) for i in range(len(self))]\n",
      "84/355:         >>> func = str.upper\n",
      "84/356:         >>> func('hi')\n",
      "84/357:         'HI'\n",
      "84/358:         >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "84/359:         >>> func(lst._first)\n",
      "84/360:         >>> str(lst.map(func))\n",
      "84/361:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        count = 0\n",
      "        if self._rest is not None:\n",
      "            count += __len__(self._rest) + 1\n",
      "        return count\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += count(self._rest, item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        1\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        3\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return __getitem__(self._rest, index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> str(lst)\n",
      "        >>> lst[1] = 200\n",
      "        >>> str(lst)\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return __setitem__(self._rest, index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> lst[1]\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return pop(self._rest, index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> str(lst)\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(5, 'd')\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            insert(self._rest, index - 1, item)\n",
      "\n",
      "\n",
      "    ###########################################################################\n",
      "    # Additional Exercises\n",
      "    ###########################################################################\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> func(lst._first)\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "84/362:\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> func(lst._first)\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "84/363:         >>> func = str.upper\n",
      "84/364:         >>> func('hi')\n",
      "84/365:         'HI'\n",
      "84/366:         >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "84/367:         >>> func(lst._first)\n",
      "84/368:         >>> str(lst.map(func))\n",
      "84/369:         'HELLO -> GOODBYE'\n",
      "84/370:         >>> str(lst.map(len))\n",
      "84/371:         '5 -> 7'\n",
      "84/372:         >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "84/373:         >>> lst.pop(2)\n",
      "84/374:         3\n",
      "84/375:         >>> lst[1]\n",
      "84/376:         >>> str(lst)\n",
      "84/377:         '1 -> 2 -> 4'\n",
      "84/378:         >>> lst.pop(1)\n",
      "84/379:         2\n",
      "84/380:         >>> str(lst)\n",
      "84/381:         '1 -> 4'\n",
      "84/382:         >>> lst.pop(0)\n",
      "84/383:         1\n",
      "84/384:         >>> lst.pop(1)\n",
      "84/385:         >>> str(lst)\n",
      "84/386:         >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "84/387:         >>> lst.pop(2)\n",
      "84/388:         3\n",
      "84/389:         >>> str(lst)\n",
      "84/390:         >>> lst = RecursiveList(['c'])\n",
      "84/391:         >>> lst.insert(0, 'a')\n",
      "84/392:         >>> str(lst)\n",
      "84/393:         'a -> c'\n",
      "84/394:         >>> lst.insert(1, 'b')\n",
      "84/395:         >>> str(lst)\n",
      "84/396:         'a -> b -> c'\n",
      "84/397:         >>> lst.insert(3, 'd')\n",
      "84/398:         >>> str(lst)\n",
      "84/399:         'a -> b -> c -> d'\n",
      "84/400:         >>> lst.insert(5, 'd')\n",
      "84/401:         >>> str(lst)\n",
      "84/402:         >>> len(lst)\n",
      "84/403:         >>> lst[5]\n",
      "84/404:         >>> lst[6]\n",
      "84/405:         >>> lst[7]\n",
      "84/406:         >>> lst = RecursiveList(['c'])\n",
      "84/407:         >>> lst.insert(0, 'a')\n",
      "84/408:         >>> str(lst)\n",
      "84/409:         'a -> c'\n",
      "84/410:         >>> lst.insert(1, 'b')\n",
      "84/411:         >>> str(lst)\n",
      "84/412:         'a -> b -> c'\n",
      "84/413:         >>> len(lst)\n",
      "84/414:         >>> lst.insert(3, 'd')\n",
      "84/415:         >>> str(lst)\n",
      "84/416:         'a -> b -> c -> d'\n",
      "84/417:         >>> len(lst)\n",
      "84/418:         4\n",
      "84/419:         >>> str(lst)\n",
      "84/420:         'a -> b -> c -> d'\n",
      "84/421:         >>> len(lst)\n",
      "84/422:\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if not self._rest.is_empty():\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "84/423:         >>> lst = RecursiveList(['c'])\n",
      "84/424:         >>> lst.insert(0, 'a')\n",
      "84/425:         >>> str(lst)\n",
      "84/426:         'a -> c'\n",
      "84/427:         >>> lst.insert(1, 'b')\n",
      "84/428:         >>> lst = RecursiveList(['c'])\n",
      "84/429:         >>> lst.insert(0, 'a')\n",
      "85/1:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import import pandas_datareader.data as web\n",
      "import datetime\n",
      "85/2:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pandas_datareader.data as web\n",
      "import datetime\n",
      "85/3:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import pandas_datareader.data as web\n",
      "import datetime\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "85/4:\n",
      "start = datetime.date(2002, 3, 1)\n",
      "end = datetime.datetime(2019, 3, 1)\n",
      "85/5: prices = web.DataReader('vti', 'morningstar', start, end)\n",
      "85/6: prices = web.DataReader('vti', 'google', start, end)\n",
      "85/7: prices = web.DataReader('vti', 'quandl', start, end)\n",
      "85/8: prices = web.DataReader('vti', 'fred', start, end)\n",
      "85/9: ALPHAVANTAGE_API_KEY = BLVOC7VF7XK9EC2A\n",
      "85/10: ALPHAVANTAGE_API_KEY = 'BLVOC7VF7XK9EC2A'\n",
      "85/11: ALPHAVANTAGE_API_KEY = 'BLVOC7VF7XK9EC2A'\n",
      "85/12:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime\n",
      "import matplotlib.pyplot as plt\n",
      "from alpha_vantage.timeseries import TimeSeries\n",
      "%matplotlib inline\n",
      "85/13: ts = TimeSeries(function=TIME_SERIES_DAILY, symbol=MSFT, outputsize=full)\n",
      "85/14: ts = TimeSeries(function='TIME_SERIES_DAILY', symbol='MSFT', outputsize='full')\n",
      "85/15:\n",
      "ts = TimeSeries()\n",
      "data, meta = ts.get_daily()\n",
      "85/16:\n",
      "ts = TimeSeries(key=ALPHAVANTAGE_API_KEY)\n",
      "data, meta = ts.get_daily()\n",
      "85/17:\n",
      "ts = TimeSeries(key=ALPHAVANTAGE_API_KEY)\n",
      "data, meta = ts.get_daily('vti')\n",
      "85/18: data\n",
      "85/19:\n",
      "ts = TimeSeries(key=ALPHAVANTAGE_API_KEY)\n",
      "data, meta = ts.get_daily(symbol='vti', outputsize='full')\n",
      "85/20: data\n",
      "85/21: data.keys()\n",
      "85/22:\n",
      "ts = TimeSeries(key=ALPHAVANTAGE_API_KEY, output_format='pandas')\n",
      "data, meta = ts.get_daily(symbol='vti', outputsize='full')\n",
      "85/23: data\n",
      "85/24: data.open\n",
      "85/25: data.dtypes\n",
      "85/26: data\n",
      "85/27: data['close']\n",
      "85/28: data\n",
      "85/29: data.columns\n",
      "85/30: data.columns = ['open', 'high', 'low', 'close', 'volume']\n",
      "85/31: data\n",
      "85/32: data['close']\n",
      "85/33: data['close'].mean()\n",
      "85/34: data['close']\n",
      "85/35: data['close'][-1]\n",
      "85/36: (data['close'][-1] - data['close'][1]) / (data['close'][-1])\n",
      "85/37: data['close']\n",
      "85/38: meta\n",
      "85/39:\n",
      "def t(x):\n",
      "    print(str(x))\n",
      "85/40: t(asdf)\n",
      "85/41:\n",
      "def get_stock_data(ticker):\n",
      "    data, meta = ts.get_daily(symbol=ticker, outputsize='full')\n",
      "    data.columns = ['open', 'high', 'low', 'close', 'volume']\n",
      "    return data\n",
      "85/42:\n",
      "def initialize():\n",
      "    ALPHAVANTAGE_API_KEY = 'BLVOC7VF7XK9EC2A'\n",
      "    ts = TimeSeries(key=ALPHAVANTAGE_API_KEY, output_format='pandas')\n",
      "85/43: initialize()\n",
      "85/44: dat = get_stock_data('msft')\n",
      "85/45: dat\n",
      "85/46:\n",
      "def get_stock_data(ticker):\n",
      "    data, meta = ts.get_daily_adjusted(symbol=ticker, outputsize='full')\n",
      "    data.columns = ['open', 'high', 'low', 'close', 'volume']\n",
      "    return data\n",
      "85/47: initialize()\n",
      "85/48: dat = get_stock_data('msft')\n",
      "85/49: data, meta = ts.get_daily_adjusted(symbol='vti', outputsize='full')\n",
      "85/50: dat\n",
      "85/51: data, meta = ts.get_daily_adjusted(symbol='msft', outputsize='full')\n",
      "85/52: dat\n",
      "85/53:\n",
      "def get_stock_data(ticker):\n",
      "    data, meta = ts.get_daily_adjusted(symbol=ticker, outputsize='full')\n",
      "    data.columns = ['open', 'high', 'low', 'close', 'volume']\n",
      "    return data\n",
      "85/54: dat = get_stock_data('msft')\n",
      "85/55: data, meta = ts.get_daily_adjusted(symbol='msft', outputsize='full')\n",
      "85/56: data.columns\n",
      "85/57: data\n",
      "85/58: len(data)\n",
      "85/59: data.tail(3000)\n",
      "85/60: dat = data.tail(3500)\n",
      "85/61: dat\n",
      "85/62: dat[3]\n",
      "85/63: dat\n",
      "85/64: dat['4. close']\n",
      "85/65: dat['4. close'].plot()\n",
      "85/66: dat = data.tail(4000)\n",
      "85/67: dat['4. close'].plot()\n",
      "85/68: dat = data.tail(5000)\n",
      "85/69: dat['4. close'].plot()\n",
      "85/70: dat = data.tail(4000)\n",
      "85/71: dat['4. close'].plot()\n",
      "85/72: returns = dat.pct_change()\n",
      "85/73: dat\n",
      "85/74: returns\n",
      "85/75:\n",
      "returns = dat.pct_change()\n",
      "returns\n",
      "85/76: data, meta = ts.get_daily(symbol='msft', outputsize='full')\n",
      "85/77: dat = data.tail(4000)\n",
      "85/78: dat['4. close'].plot()\n",
      "85/79:\n",
      "returns = dat.pct_change()\n",
      "returns\n",
      "85/80:\n",
      "def get_stock_data(ticker):\n",
      "    data, meta = ts.get_daily(symbol=ticker, outputsize='full')\n",
      "    data.columns = ['open', 'high', 'low', 'close', 'volume']\n",
      "    return data\n",
      "85/81: dat = get_stock_data('msft').tail(4000)\n",
      "85/82: dat['close'].plot()\n",
      "85/83:\n",
      "returns = dat.pct_change()\n",
      "returns\n",
      "85/84: prices = dat['close']\n",
      "85/85:\n",
      "prices = dat['close']\n",
      "prices\n",
      "85/86:\n",
      "last_price = prices[-1]\n",
      "last_price\n",
      "85/87:\n",
      "num_trials = 1000\n",
      "num_days = 252\n",
      "85/88: simulation_df = pd.DataFrame()\n",
      "85/89:\n",
      "prices = dat['close']\n",
      "print(prices.head(6))\n",
      "returns = prices.pct_change()\n",
      "print(returns.head(6))\n",
      "85/90:\n",
      "prices = dat['close']\n",
      "print(prices.head(6))\n",
      "returns = prices.pct_change()\n",
      "print(returns.head(6))\n",
      "last_price = prices[-1]\n",
      "print(last_price)\n",
      "daily_std = returns.std()\n",
      "print(daily_std)\n",
      "85/91: dat = get_stock_data('msft').tail(250)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/92: dat['close'].plot()\n",
      "85/93: dat\n",
      "85/94:\n",
      "print(dat.head(5))\n",
      "print(dat.tail(5))\n",
      "86/1:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import quandl \n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "86/2: key = umQRdEcxaVzMFsfVPJ_y\n",
      "86/3: key = 'umQRdEcxaVzMFsfVPJ_y'\n",
      "86/4: quandl.ApiConfig.api_key = 'umQRdEcxaVzMFsfVPJ_y'\n",
      "86/5: quandl.get('WIKI/AAPL')\n",
      "86/6: quandl.get('WIKI/AAPL')\n",
      "86/7: data = quandl.get('WIKI/AAPL')\n",
      "86/8: data.columns\n",
      "86/9: plt.plot(data['Adj. Close'])\n",
      "86/10:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import quandl \n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from pandas.plotting import register_matplotlib_converters\n",
      "86/11:\n",
      "quandl.ApiConfig.api_key = 'umQRdEcxaVzMFsfVPJ_y'\n",
      "register_matplotlib_converters()\n",
      "86/12: plt.plot(data['Adj. Close'])\n",
      "88/1:\n",
      "import numpy as np\n",
      "import csv\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import os\n",
      "import pickle\n",
      "\n",
      "torch.manual_seed(1)\n",
      "88/2:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/individual_stocks_5yr/TIF_data.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "88/3:\n",
      "filepath = '/Users/js/Desktop/datasets/sp500/REGN.csv'\n",
      "\n",
      "values = []\n",
      "\n",
      "with open(filepath, 'r') as f:\n",
      "    reader = csv.reader(f)\n",
      "    next(reader)\n",
      "    for row in reader:\n",
      "        values.append(row[4])\n",
      "\n",
      "values = [float(j) for j in values]\n",
      "\n",
      "values = torch.tensor(values)\n",
      "\n",
      "x = values[:-1].unsqueeze(1)\n",
      "y = values[1:].unsqueeze(1)\n",
      "\n",
      "batch_size = 64\n",
      "chunks = len(x) // 64\n",
      "\n",
      "times = torch.arange(1, chunks * batch_size + 1)\n",
      "\n",
      "x = x[:chunks * batch_size]\n",
      "x = x.reshape(batch_size, -1, 1)\n",
      "\n",
      "y = y[:chunks * batch_size]\n",
      "y = y.reshape(batch_size, -1, 1)\n",
      "88/4:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "88/5:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "model\n",
      "88/6: hidden = None\n",
      "88/7:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'rb')\n",
      "hidden = pickle.load(f)\n",
      "f.close()\n",
      "\n",
      "model = torch.load(PATH)\n",
      "model.eval()\n",
      "88/8:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'rb')\n",
      "hidden = pickle.load(f)\n",
      "f.close()\n",
      "\n",
      "model = torch.load('/Users/js/programs/lstm-stock-time-series.pt')\n",
      "model.eval()\n",
      "88/9:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.Adadelta(model.parameters(), eps=1e-5, rho=0.95, lr=1e-2)\n",
      "88/10:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "88/11:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
      "88/12:\n",
      "epochs = 2000\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "89/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "from torchvision import transforms, datasets, models\n",
      "from PIL import Image\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from collections import OrderedDict\n",
      "89/2:\n",
      "data_dir = '/home/js/flower_data'\n",
      "train_dir = data_dir + '/train'\n",
      "test_dir = data_dir + '/valid'\n",
      "89/3:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "from torchvision import transforms, datasets, models\n",
      "from PIL import Image\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from collections import OrderedDict\n",
      "89/4:\n",
      "data_dir = '/home/js/Desktop/datasets/flower_data'\n",
      "train_dir = data_dir + '/train'\n",
      "test_dir = data_dir + '/valid'\n",
      "89/5:\n",
      "\n",
      "transforms_224 = transforms.Compose([\n",
      "    transforms.Resize(250),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "traindat = datasets.ImageFolder(train_dir, transform=transforms_224)\n",
      "testdat= datasets.ImageFolder(test_dir, transform=transforms_224)\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(train_dat_224, batch_size=4, shuffle=True, num_workers=4)\n",
      "testloader = torch.utils.data.DataLoader(test_dat_224, batch_size=4, shuffle=True, num_workers=4)\n",
      "89/6:\n",
      "data_dir = '/Users/js/Desktop/datasets/flower_data'\n",
      "train_dir = data_dir + '/train'\n",
      "test_dir = data_dir + '/valid'\n",
      "89/7:\n",
      "transforms_224 = transforms.Compose([\n",
      "    transforms.Resize(250),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "traindat = datasets.ImageFolder(train_dir, transform=transforms_224)\n",
      "testdat= datasets.ImageFolder(test_dir, transform=transforms_224)\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(traindat, batch_size=4, shuffle=True, num_workers=4)\n",
      "testloader = torch.utils.data.DataLoader(testdat, batch_size=4, shuffle=True, num_workers=4)\n",
      "89/8:\n",
      "#inception = models.inception_v3(pretrained=True)\n",
      "resnet = models.resnet152(pretrained=False)\n",
      "\n",
      "#print(inception)\n",
      "# print(resnet)\n",
      "89/9:\n",
      "class net(nn.Module):\n",
      "    def __init__(self, in_dims, out_dims):\n",
      "        super(net, self).__init__()\n",
      "        self.fc1 = nn.Linear(in_dims, 1024)\n",
      "        self.fc2 = nn.Linear(1024, 512)\n",
      "        self.fc3 = nn.Linear(512, out_dims)\n",
      "        self.lsm = nn.LogSoftmax(dim=1)\n",
      "        self.lrelu = nn.LeakyReLU()\n",
      "        self.drop = nn.Dropout(p=0.4)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = self.drop(self.lrelu(self.fc1(x)))\n",
      "        x = self.drop(self.lrelu(self.fc2(x)))\n",
      "        x = self.drop(self.lrelu(self.fc3(x)))\n",
      "        x = self.lsm(x)\n",
      "        return(x)\n",
      "89/10:\n",
      "resnet_clf = net(2048, 102)\n",
      "resnet.fc = resnet_clf\n",
      "\n",
      "print(resnet)\n",
      "89/11:\n",
      "if torch.cuda.is_available():\n",
      "    resnet = resnet.cuda()\n",
      "    print('GPU Available')\n",
      "else: \n",
      "    print('Using CPU')\n",
      "89/12:\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "optimizer = optim.SGD(resnet.parameters(), lr=1e-3, momentum=0.9, nesterov=True, weight_decay=1e-5)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader))\n",
      "89/13:\n",
      "resnet = models.resnet152(pretrained=False)\n",
      "print(resnet)\n",
      "89/14:\n",
      "resnet_clf = net(2048, 102)\n",
      "resnet.fc = resnet_clf\n",
      "\n",
      "print(resnet)\n",
      "89/15:\n",
      "if torch.cuda.is_available():\n",
      "    resnet = resnet.cuda()\n",
      "    print('GPU Available')\n",
      "else: \n",
      "    print('Using CPU')\n",
      "89/16:\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "optimizer = optim.SGD(resnet.parameters(), lr=1e-3, momentum=0.9, nesterov=True, weight_decay=1e-5)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader))\n",
      "89/17:\n",
      "for param in resnet.parameters():\n",
      "    param.requires_grad = False\n",
      "89/18:\n",
      "resnet.load_state_dict(torch.load('resnet.pt'))\n",
      "print(resnet)\n",
      "89/19:\n",
      "resnet.load_state_dict(torch.load('resnet.pt'), map_location='cpu')\n",
      "print(resnet)\n",
      "89/20:\n",
      "resnet.load_state_dict(torch.load('resnet.pt', map_location='cpu'))\n",
      "print(resnet)\n",
      "89/21:\n",
      "loss_fn = nn.NLLLoss()\n",
      "\n",
      "optimizer = optim.SGD(resnet.parameters(), lr=1e-3, momentum=0.9, nesterov=True, weight_decay=1e-5)\n",
      "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader))\n",
      "89/22:\n",
      "for param in resnet.parameters():\n",
      "    param.requires_grad = False\n",
      "89/23:\n",
      "resnet.eval()\n",
      "correct = 0\n",
      "for feature, label in test_loader_224:\n",
      "    feature, label = feature.cuda(), label.cuda()\n",
      "    batch_size, n_crops, channels, height, width = feature.shape\n",
      "    flattened = feature.view(-1, channels, height, width)\n",
      "    output = resnet(flattened)\n",
      "    output = output.view(batch_size, n_crops, -1).mean(1)\n",
      "    preds = output.exp().max(dim=1)[1]\n",
      "    correct += (preds == label).sum().item()\n",
      "print(correct/len(test_dat_224))\n",
      "89/24:\n",
      "resnet.eval()\n",
      "correct = 0\n",
      "for feature, label in testloader:\n",
      "    feature, label = feature.cuda(), label.cuda()\n",
      "    batch_size, n_crops, channels, height, width = feature.shape\n",
      "    flattened = feature.view(-1, channels, height, width)\n",
      "    output = resnet(flattened)\n",
      "    output = output.view(batch_size, n_crops, -1).mean(1)\n",
      "    preds = output.exp().max(dim=1)[1]\n",
      "    correct += (preds == label).sum().item()\n",
      "print(correct/len(test_dat_224))\n",
      "89/25:\n",
      "resnet.eval()\n",
      "correct = 0\n",
      "for feature, label in testloader:\n",
      "    batch_size, n_crops, channels, height, width = feature.shape\n",
      "    flattened = feature.view(-1, channels, height, width)\n",
      "    output = resnet(flattened)\n",
      "    output = output.view(batch_size, n_crops, -1).mean(1)\n",
      "    preds = output.exp().max(dim=1)[1]\n",
      "    correct += (preds == label).sum().item()\n",
      "print(correct/len(test_dat_224))\n",
      "89/26: transforms_224\n",
      "89/27:\n",
      "transforms_224 = transforms.Compose([\n",
      "    transforms.Resize(250),\n",
      "    transforms.TenCrop(224),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "traindat = datasets.ImageFolder(train_dir, transform=transforms_224)\n",
      "testdat = datasets.ImageFolder(test_dir, transform=transforms_224)\n",
      "\n",
      "trainloader = torch.utils.data.DataLoader(traindat, batch_size=4, shuffle=True, num_workers=4)\n",
      "testloader = torch.utils.data.DataLoader(testdat, batch_size=4, shuffle=True, num_workers=4)\n",
      "89/28: transforms_224\n",
      "89/29: lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])\n",
      "91/1:\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "from torchvision import transforms, datasets, models\n",
      "from PIL import Image\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "%matplotlib inline\n",
      "from collections import OrderedDict\n",
      "91/2:\n",
      "data_dir = '/Users/js/Desktop/datasets/flower_data'\n",
      "train_dir = data_dir + '/train'\n",
      "val_dir = data_dir + '/valid'\n",
      "91/3:\n",
      "data_transforms = transforms.Compose([\n",
      "    transforms.Resize(320),\n",
      "    transforms.TenCrop(299),\n",
      "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
      "])\n",
      "\n",
      "train_dat = datasets.ImageFolder(train_dir, transform=data_transforms)\n",
      "val_dat = datasets.ImageFolder(val_dir, transform=data_transforms)\n",
      "\n",
      "train_loader = torch.utils.data.DataLoader(train_dat, batch_size=1, shuffle=True, num_workers=4)\n",
      "val_loader = torch.utils.data.DataLoader(val_dat, batch_size=1, shuffle=True, num_workers=4)\n",
      "91/4:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/5:\n",
      "import json\n",
      "\n",
      "with open('cat_to_name.json', 'r') as f:\n",
      "    cat_to_name = json.load(f)\n",
      "91/6:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/7:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/8:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/9:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/10:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/11:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/12:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/13:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/14:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/15:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/16:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "91/17: label\n",
      "91/18: train_dat.classes\n",
      "91/19:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[train_dat.classes[label]])\n",
      "print(label)\n",
      "91/20:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[val_dat.classes[label]])\n",
      "print(label)\n",
      "91/21:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[val_dat.classes[label]])\n",
      "print(label)\n",
      "91/22:\n",
      "image, label = next(iter(train_loader))\n",
      "for i in range(10):\n",
      "    t = image[0][i].numpy().transpose((1,2,0))\n",
      "    plt.imshow(t)\n",
      "plt.show()\n",
      "print(cat_to_name[val_dat.classes[label]])\n",
      "print(label)\n",
      "92/1:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "92/2:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import csv\n",
      "92/3:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "92/4: dat = pd.read_csv('KSI_07x17.csv')\n",
      "92/5: dat\n",
      "92/6: dat['time']\n",
      "92/7: dat['TIME']\n",
      "92/8: dat['TIME'][0]\n",
      "92/9: type(dat['TIME'][0])\n",
      "92/10: dat['TIME'][0][:2]\n",
      "92/11: dat['TIME'].astype(str)\n",
      "92/12: dat['TIME'].astype(str)[0][:2]\n",
      "92/13: dat['TIME'].astype(str)\n",
      "92/14: set([len(x) for x in dat['TIME'].astype(str)])\n",
      "92/15: min(dat['TIME'])\n",
      "92/16: sorted(dat['TIME'])\n",
      "92/17: sorted(dat['TIME'])[0]\n",
      "92/18: type(sorted(dat['TIME'])[0])\n",
      "92/19: str(sorted(dat['TIME'])[0])\n",
      "92/20: (dat['HOUR'])[0]\n",
      "92/21: dat['HOUR'][0]\n",
      "92/22: dat['Hour'][0]\n",
      "92/23: dat['Hour'][0]*100\n",
      "92/24: dat['TIME'][0] % dat['Hour'][0]*100\n",
      "92/25: dat['TIME'][0] % (dat['Hour'][0]*100)\n",
      "92/26: dat['Minute'] = dat['TIME'] % (dat['Hour']*100)\n",
      "92/27: dat\n",
      "92/28: dat['time'] = dat['Hour'] * 60 + dat['Minute']\n",
      "92/29: dat\n",
      "92/30: dat\n",
      "92/31: dat.groupby('time')\n",
      "92/32: dat.groupby(['time'])\n",
      "92/33: dat.groupby(['time']).agg(['count'])\n",
      "92/34: dat['time'].agg(['count'])\n",
      "92/35: dat['time'].groupby(['time']).agg(['count'])\n",
      "92/36: dat.groupby(['time']).size()\n",
      "92/37: dat\n",
      "92/38: dat.groupby(['time']).size()\n",
      "92/39: type(dat.groupby(['time']).size())\n",
      "92/40:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "92/41: dat\n",
      "92/42: dat.groupby(['time']).size().plot()\n",
      "92/43: dat.groupby(['time']).size().plot('kde')\n",
      "92/44: dat.groupby(['time']).size().plot('hist')\n",
      "92/45: dat.groupby(['time']).size().plot('bar')\n",
      "92/46: dat.groupby(['time']).size().plot()\n",
      "92/47: dat.groupby(['Hour']).size().plot()\n",
      "92/48: dat.groupby(['time']).size().plot()\n",
      "92/49:\n",
      "dat.groupby(['time']).size().plot()\n",
      "dat.groupby(['hour']).size().plot()\n",
      "92/50: dat.groupby(['time', 'hour']).size().plot()\n",
      "92/51: dat.groupby(['time', 'hour']).size().unstack()plot()\n",
      "92/52: dat.groupby(['time', 'hour']).size().unstack().plot()\n",
      "92/53: dat.groupby(['time', 'Hour']).size().plot()\n",
      "92/54: dat.groupby(['time', 'Hour']).size().unstack().plot()\n",
      "92/55: dat.groupby(['Minute']).size().plot()\n",
      "92/56: fig, axes = plt.subplot(2, 1)\n",
      "92/57: fig, axes = plt.subplot(nrows=1, ncols=2)\n",
      "92/58: fig, axes = plt.subplots(1, 2)\n",
      "92/59:\n",
      "fig, axes = plt.subplots(1, 2)\n",
      "dat.groupby(['Hour']).size().plot(ax=axes[0,0])\n",
      "dat.groupby(['Minute']).size().plot(ax=axes[0,1])\n",
      "92/60:\n",
      "fig, axes = plt.subplots(1, 2)\n",
      "dat.groupby(['Hour']).size().plot(ax=axes[0])\n",
      "dat.groupby(['Minute']).size().plot(ax=axes[1])\n",
      "92/61:\n",
      "fig, axes = plt.subplots(2, sharex=True, figsize=(16, 8))\n",
      "dat.groupby(['Hour']).size().plot(ax=axes[0])\n",
      "dat.groupby(['Minute']).size().plot(ax=axes[1])\n",
      "92/62:\n",
      "fig, axes = plt.subplots(2, sharey=True, figsize=(16, 8))\n",
      "dat.groupby(['Hour']).size().plot(ax=axes[0])\n",
      "dat.groupby(['Minute']).size().plot(ax=axes[1])\n",
      "92/63:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "dat.groupby(['Hour']).size().plot(ax=axes[0])\n",
      "dat.groupby(['Minute']).size().plot(ax=axes[1])\n",
      "92/64:\n",
      "fig, axes = plt.subplots(2, figsize=(20, 8))\n",
      "dat.groupby(['Hour']).size().plot(ax=axes[0])\n",
      "dat.groupby(['Minute']).size().plot(ax=axes[1])\n",
      "92/65:\n",
      "fig, axes = plt.subplots(2, figsize=(10, 8))\n",
      "dat.groupby(['Hour']).size().plot(ax=axes[0])\n",
      "dat.groupby(['Minute']).size().plot(ax=axes[1])\n",
      "92/66:\n",
      "fig, axes = plt.subplots(2, figsize=(15, 8))\n",
      "dat.groupby(['Hour']).size().plot(ax=axes[0])\n",
      "dat.groupby(['Minute']).size().plot(ax=axes[1])\n",
      "93/1:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "93/2: dat = pd.read_csv('MCI_14x17.csv')\n",
      "93/3:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat\n",
      "93/4:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y'])\n",
      "dat\n",
      "93/5:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y'], axis=1)\n",
      "dat\n",
      "93/6:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y'], axis=0)\n",
      "dat\n",
      "93/7:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y'], axis=1)\n",
      "dat\n",
      "93/8:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y'], axis=1, inplace=1)\n",
      "dat\n",
      "93/9:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y'], axis=1, inplace=True)\n",
      "dat\n",
      "93/10:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y'], axis=1, inplace=T)\n",
      "dat\n",
      "93/11:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y'], axis=1, inplace=True)\n",
      "dat\n",
      "93/12:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "93/13:\n",
      "dat = pd.read_csv('MCI_14x17.csv')\n",
      "dat.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "dat\n",
      "93/14: dat.groupby(['offence']).size().plot()\n",
      "93/15: dat.groupby(['offence']).size().plot(rot=90)\n",
      "93/16: dat.groupby(['offence']).size()\n",
      "93/17: dat.groupby(['offence']).size().plot(figsize=16, 4)\n",
      "93/18: dat.groupby(['offence']).size().plot(figsize=(16, 4))\n",
      "93/19: sorted(dat.groupby(['offence']).size())\n",
      "93/20: sort(dat.groupby(['offence']).size())\n",
      "93/21: dat.groupby(['offence']).size()\n",
      "93/22: dat.groupby(['offence']).size().sort_values()\n",
      "93/23: dat.groupby(['offence']).size().sort_values(ascending)\n",
      "93/24: dat.groupby(['offence']).size().sort_values(ascending=True)\n",
      "93/25: dat.groupby(['offence']).size().sort_values(ascending=False)\n",
      "93/26: dat.groupby(['offence']).size().sort_values(ascending=False).plot()\n",
      "93/27: num_type = dat.groupby(['offence']).size().sort_values(ascending=False)\n",
      "93/28: num_type\n",
      "93/29: sum(num_type)\n",
      "93/30: num_type / sum(num_type)\n",
      "93/31: num_type / sum(num_type) * 100\n",
      "93/32: num_type.columns\n",
      "93/33: num_type = dat.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "93/34: num_type.columns\n",
      "93/35: num_type\n",
      "93/36:\n",
      "num_type = dat.groupby(['offence']).size().sort_values(ascending=False)\n",
      "num_type\n",
      "93/37:\n",
      "num_type = dat.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type\n",
      "93/38:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "93/39:\n",
      "df = pd.read_csv('MCI_14x17.csv')\n",
      "df.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "df\n",
      "93/40:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type\n",
      "93/41: df.loc[df['offence'].str.contains('Assault', case=False), 'offence'] = 'Assault'\n",
      "93/42: str.contains\n",
      "93/43: df['offence']\n",
      "93/44: df['offence'][0]\n",
      "93/45: df['offence'][1]\n",
      "93/46: df['offence'][1].str.contains('B&')\n",
      "93/47: df['offence'][1].contains('B&')\n",
      "93/48: df['offence'].str.contains('B&')\n",
      "93/49: df['offence'].str.contains('B&|Ass')\n",
      "93/50: df['offence'].str.contains('B&\\&Int')\n",
      "93/51: df['offence'].str.contains('B&')\n",
      "93/52: df['offence'].str.contains('B&') and df['offence'].str.contains('Int')\n",
      "93/53: df['offence'].str.contains('Int')\n",
      "93/54: df['offence'].str.contains('Int') + df['offence'].str.contains('B&') and\n",
      "93/55: df['offence'].str.contains('Int') + df['offence'].str.contains('B&')\n",
      "93/56: df['offence'].str.contains('Int') & df['offence'].str.contains('B&')\n",
      "93/57:\n",
      "df.loc[df['offence'].str.contains('Assault|Aslt', case=False), 'offence'] = 'Assault'\n",
      "df.loc[df['offence'].str.contains('Theft', case=False) & df['offence'].str.contains('Over', case=False), 'offence'] = 'Theft Over'\n",
      "df.loc[df['offence'].str.contains('Robbery', case=False), 'offence'] = 'Robbery'\n",
      "df.loc[df['offence'].str.contains('B&E', case=False), 'offence'] = 'B&E'\n",
      "93/58: df\n",
      "93/59:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type\n",
      "93/60:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.plot()\n",
      "93/61:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.plot(logx)\n",
      "93/62:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.plot(logx=Tru)\n",
      "93/63:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.plot(logx=True)\n",
      "93/64:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.plot()\n",
      "93/65:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type\n",
      "93/66:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "93/67: df.offence\n",
      "93/68:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type.assign(Percentage=(num_type.Count / sum(num_type.Count)))\n",
      "num_type\n",
      "93/69:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type.assign(Percentage=(num_type.Count / sum(num_type.Count)), inplace=True)\n",
      "num_type\n",
      "93/70:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type.assign(Percentage=(num_type.Count / sum(num_type.Count)))\n",
      "93/71:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type.assign(Percentage=(num_type.Count / sum(num_type.Count)))\n",
      "93/72:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count)))\n",
      "num_type\n",
      "93/73:\n",
      "df.loc[df['offence'].str.contains('Assault|Aslt', case=False), 'offence'] = 'Assault'\n",
      "df.loc[df['offence'].str.contains('Theft', case=False) & df['offence'].str.contains('Over', case=False), 'offence'] = 'Theft Over 5000'\n",
      "df.loc[df['offence'].str.contains('Robbery', case=False), 'offence'] = 'Robbery'\n",
      "df.loc[df['offence'].str.contains('B&E', case=False), 'offence'] = 'B&E'\n",
      "93/74:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count)))\n",
      "num_type\n",
      "93/75:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "num_type\n",
      "93/76:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "num_type\n",
      "num_type.Percentage[:4].sum()\n",
      "93/77:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "num_type\n",
      "93/78:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type)\n",
      "93/79:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "print(num_type.0.sum())\n",
      "num_type\n",
      "93/80:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "print(num_type['0'].sum())\n",
      "num_type\n",
      "93/81:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "print(num_type.sum())\n",
      "num_type\n",
      "93/82:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "print(num_type)\n",
      "93/83:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type)\n",
      "print(num_type.sum())\n",
      "93/84:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type)\n",
      "print(num_type.Count.sum())\n",
      "93/85:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type.Count.sum())\n",
      "print(num_type)\n",
      "93/86:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type)\n",
      "93/87: date_diff = df.reporteddate - df.occurrencedate\n",
      "93/88:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "import datetime\n",
      "93/89: date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "93/90:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff\n",
      "93/91:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "sum(date_diff)\n",
      "93/92:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff\n",
      "93/93:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "max(date_diff)\n",
      "93/94:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.plot()\n",
      "93/95:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.plot(type='hist')\n",
      "93/96:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.plot('hist')\n",
      "93/97:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.plot()\n",
      "93/98:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff\n",
      "93/99:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.minutes\n",
      "93/100:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.days\n",
      "93/101:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff\n",
      "93/102:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.to_frame().rename('days')\n",
      "93/103:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.to_frame()\n",
      "93/104:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.to_frame().rename(index=str, columns='days')\n",
      "93/105:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "93/106:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.plot('hist')\n",
      "93/107:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.plot('hist')\n",
      "93/108:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.plot('hist')\n",
      "93/109:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.=\n",
      "93/110:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff?\"\"\n",
      "93/111:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff\n",
      "93/112:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.days\n",
      "93/113:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.day\n",
      "93/114:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.day\n",
      "93/115:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days\n",
      "93/116:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.minutes\n",
      "93/117:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.seconds\n",
      "93/118:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.minutes\n",
      "93/119:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.minute\n",
      "93/120:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days\n",
      "93/121:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot('hist')\n",
      "93/122:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot()\n",
      "93/123:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot('hist')\n",
      "93/124:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot.density()\n",
      "93/125:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot()\n",
      "93/126:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.max()\n",
      "93/127:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.sort()\n",
      "93/128:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.sorted()\n",
      "93/129:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "sorted(date_diff.days.dt.days)\n",
      "93/130:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "sorted(date_diff.days.dt.days, ascending=False)\n",
      "93/131:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "sorted(date_diff.days.dt.days, reverse)\n",
      "93/132:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "sorted(date_diff.days.dt.days, reverse=True)\n",
      "93/133:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days\n",
      "93/134:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.values()\n",
      "93/135:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.values\n",
      "93/136:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.values.plot()\n",
      "93/137:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "plt.plot(date_diff.days.dt.days.values)\n",
      "93/138:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "plt.hist(date_diff.days.dt.days.values)\n",
      "93/139:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "sns.distplot(date_diff.days.dt.days.values)\n",
      "93/140:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "sns.plt(date_diff.days.dt.days.values)\n",
      "93/141:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "sns.plot(date_diff.days.dt.days.values)\n",
      "93/142:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "sns.line(date_diff.days.dt.days.values)\n",
      "93/143:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "sns.lineplot(date_diff.days.dt.days.values)\n",
      "93/144:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot.density()\n",
      "93/145:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot('hist')\n",
      "93/146:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot('hist', bins='1000')\n",
      "93/147:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot.hist()\n",
      "93/148:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot.hist(bins=1000)\n",
      "93/149:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot.hist(bins=100)\n",
      "93/150:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot.hist(bins=100, figsize=16, 10)\n",
      "93/151:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot.hist(bins=100, figsize=(16, 10))\n",
      "93/152:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/153:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/154:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/155:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.values\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/156:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.size()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/157:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.size()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/158:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.size()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/159:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/160:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.groupby()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/161:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(days)\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/162:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(['days'])\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/163:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(['days']).size()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/164:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(['days']).size()[0]\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/165:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(['days']).size()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/166:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(['days']).rank()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/167:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(['days']).mean()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/168:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(['days'])\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/169:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(['days']).size()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/170:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.groupby(['days']).size()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/171:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.groupby(['days']).size()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/172:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.groupby(['days']).size()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/173:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/174:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/175:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.values\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/176:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.values.hist()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/177:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.values.plot.hist()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/178:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.values.plot()\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/179:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "plt.hist(date_diff.days.dt.days.values)\n",
      "#date_diff.days.dt.days.plot.hist(bins=100, figsize=(10, 5))\n",
      "93/180:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "plt.hist(date_diff.days.dt.days.values, bins=200)\n",
      "93/181:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "plt.hist(date_diff.days.dt.days.values, density)\n",
      "93/182:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "plt.hist(date_diff.days.dt.days.values, density=True)\n",
      "93/183:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "plt.hist(date_diff.days.dt.days.values, bins=100)\n",
      "93/184:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "plt.hist(date_diff.days.dt.days.values)\n",
      "93/185:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.values\n",
      "93/186: df.offence.value_counts()\n",
      "93/187:\n",
      "num_type = df.offence.value_counts().to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type)\n",
      "93/188:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days\n",
      "93/189:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.to_frame()\n",
      "93/190:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.to_frame().value_counts()\n",
      "93/191:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff\n",
      "93/192:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.value_counts()\n",
      "93/193:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff\n",
      "93/194:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.value_counts()\n",
      "93/195:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days\n",
      "93/196:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.\n",
      "93/197:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff\n",
      "93/198:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "93/199:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "93/200:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff\n",
      "93/201:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.value_counts()\n",
      "93/202:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff.days.value_counts()\n",
      "93/203:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff\n",
      "93/204:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.value_counts()\n",
      "93/205:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts()\n",
      "93/206:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts()\n",
      "diff_count\n",
      "93/207:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count\n",
      "93/208:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count)\n",
      "93/209:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index())\n",
      "93/210:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index())\n",
      "print(diff_count[2:])\n",
      "93/211:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[2:])\n",
      "93/212:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[2:].plot.density())\n",
      "93/213:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "diff_count.sort_index()[2:].plot.density()\n",
      "93/214:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "diff_count.sort_index()[2:].plot.hist()\n",
      "93/215:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[2:].days.plot.density())\n",
      "93/216:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[2:].days.plot.hist())\n",
      "93/217:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[3:].days.plot.hist())\n",
      "93/218:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[4:].days.plot.hist())\n",
      "93/219:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[5:].days.plot.hist())\n",
      "93/220:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[6:].days.plot.hist())\n",
      "93/221:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[6:].days)\n",
      "93/222:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[15:].days)\n",
      "93/223:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[15:].days.plot.density())\n",
      "93/224:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[15:].days.plot.hist())\n",
      "93/225:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[31:].days.plot.hist())\n",
      "93/226:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[366:].days.plot.hist())\n",
      "93/227:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[366:].days=)\n",
      "93/228:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index()[366:].days)\n",
      "93/229:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index())\n",
      "93/230: diff_count[15:]\n",
      "93/231: diff_count[15:].assign(percentage=(diff_count[15:].days / sum(diff_count[15:].days) * 100)))\n",
      "93/232: diff_count2 = diff_count[15:]\n",
      "93/233:\n",
      "diff_count2 = diff_count[15:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.percentage[:2].sum())\n",
      "print(diff_count2.sort_index())\n",
      "93/234:\n",
      "diff_count2 = diff_count[15:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.percentage[:2].sum())\n",
      "print(diff_count2.sort_index())\n",
      "diff_count2.percentage.plot()\n",
      "93/235:\n",
      "diff_count2 = diff_count[15:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.percentage[:2].sum())\n",
      "print(diff_count2.sort_index())\n",
      "diff_count2.percentage.plot.density()\n",
      "93/236:\n",
      "diff_count2 = diff_count[15:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.percentage[:2].sum())\n",
      "print(diff_count2.sort_index())\n",
      "diff_count2.percentage.plot.hist()\n",
      "93/237:\n",
      "diff_count2 = diff_count[15:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.percentage.plot.hist()\n",
      "93/238:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'days'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'days'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(percentage=(diff_count.days / sum(diff_count.days) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/239:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.percentage.plot.hist()\n",
      "93/240:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.percentage.plot()\n",
      "93/241:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.days.plot()\n",
      "93/242:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.days.hist()\n",
      "93/243:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.days.density()\n",
      "93/244:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.days.plot.density()\n",
      "93/245:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.days.plot.hist()\n",
      "93/246:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.index.plot.hist()\n",
      "93/247:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.index\n",
      "93/248:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2\n",
      "93/249:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.reset_index()\n",
      "93/250:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.days.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/251:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.days.dt.Count.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.days.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/252:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "print(diff_count.percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/253:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/254:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count.reset_index()\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/255:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/256:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/257:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.days / sum(diff_count2.days) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "diff_count2.reset_index()\n",
      "93/258:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.sort_index().head(n=5))\n",
      "93/259:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_index()\n",
      "print(diff_count.Percentage[:2].sum(by=Count))\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/260:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_index()\n",
      "print(diff_count.Percentage[:2].sum(by='Count'))\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/261:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_index(by='Count')\n",
      "print(diff_count.Percentage[:2].sum()\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/262:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_index(by='Count')\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/263:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_index(by='Days')\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.sort_index().head(n=5))\n",
      "93/264:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_index(by='Days')\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.head(n=5))\n",
      "93/265:\n",
      "diff_count2 = diff_count[31:]\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.head(n=5))\n",
      "93/266:\n",
      "diff_count2 = diff_count[31:].reset_index()\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.head(n=5))\n",
      "93/267:\n",
      "diff_count2 = diff_count[31:].reset_index().drop('index')\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.head(n=5))\n",
      "93/268:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'])\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.head(n=5))\n",
      "93/269:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.head(n=5))\n",
      "93/270:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.head(n=5))\n",
      "93/271:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_values(by='Days')\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.head(n=5))\n",
      "93/272: plt.hist(diff_count.Count)\n",
      "93/273: plt.hist(diff_count.Days)\n",
      "93/274: diff_count.Days\n",
      "93/275: diff_count.Days\n",
      "93/276: diff_count.Days.plot()\n",
      "93/277: diff_count.Days.scatter()\n",
      "93/278: diff_count.Days.hist()\n",
      "93/279: diff_count.Count.hist()\n",
      "93/280: diff_count.Percentage.hist()\n",
      "93/281: plt.plot(diff_count.Days, diff_count.Count)\n",
      "93/282: plt.hist(diff_count.Days, diff_count.Count)\n",
      "93/283: plt.bar(diff_count.Days, diff_count.Count)\n",
      "93/284: plt.scatter(diff_count.Days, diff_count.Count)\n",
      "93/285: plt.plot(diff_count.Days, diff_count.Count)\n",
      "93/286:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/287:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.scatter(diff_count2.Days, diff_count2.Count)\n",
      "93/288:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/289:\n",
      "diff_count2 = diff_count[366:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/290:\n",
      "diff_count2 = diff_count[8:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/291:\n",
      "diff_count2 = diff_count[15:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/292:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/293:\n",
      "diff_count2 = diff_count[15:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/294:\n",
      "diff_count2 = diff_count[61:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/295:\n",
      "diff_count2 = diff_count[61:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/296:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/297:\n",
      "diff_count2 = diff_count[30:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/298:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/299:\n",
      "diff_count2 = diff_count[366:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/300:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/301:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:-1000].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/302:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:-100].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/303:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count.Percentage[:].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/304:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count)\n",
      "print(diff_count2.Percentage[:].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/305:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[:].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/306:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[:-(892-335)].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/307:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[:-500].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/308:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[:-600].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/309:\n",
      "diff_count2 = diff_count[15:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[:-600].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/310:\n",
      "diff_count2 = diff_count[15:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[366:].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/311:\n",
      "diff_count2 = diff_count[15:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[366:])\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/312:\n",
      "diff_count2 = diff_count[15:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[366:].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/313:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[366:].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/314:\n",
      "diff_count2 = diff_count[14:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[:366].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/315:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(len(diff_count2))\n",
      "print(diff_count2.Percentage[:366].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/316:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.Percentage[:366].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/317: df.occurrencedayofweek\n",
      "93/318: plt.plot(df.occurrencedayofweek)\n",
      "93/319:\n",
      "df = pd.read_csv('MCI_14x17.csv')\n",
      "df.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "df = df.dropna()\n",
      "93/320:\n",
      "df = pd.read_csv('MCI_14x17.csv')\n",
      "df.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "df = df.dropna()\n",
      "df\n",
      "93/321:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "print(num_type)\n",
      "93/322:\n",
      "df.loc[df['offence'].str.contains('Assault|Aslt', case=False), 'offence'] = 'Assault'\n",
      "df.loc[df['offence'].str.contains('Theft', case=False) & df['offence'].str.contains('Over', case=False), 'offence'] = 'Theft Over 5000'\n",
      "df.loc[df['offence'].str.contains('Robbery', case=False), 'offence'] = 'Robbery'\n",
      "df.loc[df['offence'].str.contains('B&E', case=False), 'offence'] = 'B&E'\n",
      "93/323:\n",
      "num_type = df.offence.value_counts().to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type)\n",
      "93/324:\n",
      "num_type = df.offence.value_counts().to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type)\n",
      "93/325:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_values(by='Days')\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.head(n=5))\n",
      "93/326:\n",
      "df = pd.read_csv('MCI_14x17.csv')\n",
      "df.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "df = df.dropna()\n",
      "print(len(df))\n",
      "df\n",
      "93/327:\n",
      "df = pd.read_csv('MCI_14x17.csv')\n",
      "df.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "df = df.dropna()\n",
      "print(len(df))\n",
      "print(df)\n",
      "93/328:\n",
      "df = pd.read_csv('MCI_14x17.csv')\n",
      "df.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "df = df.dropna()\n",
      "print(len(df))\n",
      "df\n",
      "93/329:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "print(num_type)\n",
      "93/330:\n",
      "df.loc[df['offence'].str.contains('Assault|Aslt', case=False), 'offence'] = 'Assault'\n",
      "df.loc[df['offence'].str.contains('Theft', case=False) & df['offence'].str.contains('Over', case=False), 'offence'] = 'Theft Over 5000'\n",
      "df.loc[df['offence'].str.contains('Robbery', case=False), 'offence'] = 'Robbery'\n",
      "df.loc[df['offence'].str.contains('B&E', case=False), 'offence'] = 'B&E'\n",
      "93/331:\n",
      "num_type = df.offence.value_counts().to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type)\n",
      "93/332:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_values(by='Days')\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.head(n=5))\n",
      "93/333: plt.plot(diff_count.Days, diff_count.Count)\n",
      "93/334:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.Percentage[:366].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/335: df.occurrencedayofweek\n",
      "93/336: df.occurrencedayofweek.plot()\n",
      "93/337: plt.plot(df.Hood_ID)\n",
      "93/338: plt.hist(df.Hood_ID)\n",
      "93/339: plt.hist(df.Hood_ID, bins=len(df.Hood_ID) + 1)\n",
      "93/340: plt.hist(df.occurrencedayofyear)\n",
      "93/341: plt.hist(df.occurrencedayofyear, bins='auto')\n",
      "93/342: plt.hist(df.occurrencedayofyear, bins=4)\n",
      "93/343: plt.hist(df.occurrencedayofyear, bins=12)\n",
      "93/344: sns.hist(df.occurrencedayofyear, bins=12)\n",
      "93/345: sns.distplot(df.occurrencedayofyear, bins=12)\n",
      "93/346:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.Percentage[:366].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "sns.distplot(diff_count2.Days, diff_count2.Count)\n",
      "93/347:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.Percentage[:366].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/348: sns.distplot(df.occurrencedayofyear,)\n",
      "93/349: sns.distplot(df.occurrencedayofyear)\n",
      "93/350: sns.distplot(df.occurrencehour)\n",
      "93/351:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 5))\n",
      "sns.distplot(df.occurrencehour)\n",
      "93/352:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 5))\n",
      "sns.distplot(df.occurrencehour)\n",
      "sns.distplot(df.occurrencedayofweek)\n",
      "93/353:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek.map(days_of_week)\n",
      "df\n",
      "93/354:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek.map(days_of_week)\n",
      "93/355:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek\n",
      "93/356:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek[0]\n",
      "93/357:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek[1]\n",
      "93/358:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek[2]\n",
      "93/359:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek[3]\n",
      "93/360:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek[100]\n",
      "93/361:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek\n",
      "93/362:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek.strip()\n",
      "93/363:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek.apply(strip)\n",
      "93/364:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek.apply(strip())\n",
      "93/365:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.apply()\n",
      "93/366:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.apply(strip)\n",
      "93/367:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek.apply(str.strip\n",
      "93/368:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek.apply(str.strip)\n",
      "93/369:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurrencedayofweek.apply(str.strip).map(days_of_week)\n",
      "93/370:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df.occurenceday_of_week = df.occurrencedayofweek.apply(str.strip).map(days_of_week)\n",
      "93/371:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df = df.assign(occurrencedayofweek=(df.occurrencedayofweek.apply(str.strip).map(days_of_week)))\n",
      "93/372:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df = df.assign(occurrencedayofweek=(df.occurrencedayofweek.apply(str.strip).map(days_of_week)))\n",
      "df\n",
      "93/373: df\n",
      "93/374:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 5))\n",
      "sns.distplot(df.occurrencehour)\n",
      "sns.distplot(df.occurrencedayofweek)\n",
      "93/375:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 5))\n",
      "sns.distplot(df.occurrencehour, ax=axes[0])\n",
      "sns.distplot(df.occurrencedayofweek, ax=axes[1])\n",
      "93/376:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "sns.distplot(df.occurrencehour, ax=axes[0])\n",
      "sns.distplot(df.occurrencedayofweek, ax=axes[1])\n",
      "93/377:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "plt.hist(df.occurrencehour, ax=axes[0])\n",
      "plt.hist(df.occurrencedayofweek, ax=axes[1])\n",
      "93/378:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "plt.hist(df.occurrencehour)\n",
      "plt.hist(df.occurrencedayofweek)\n",
      "93/379:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "plt.density(df.occurrencehour)\n",
      "plt.density(df.occurrencedayofweek)\n",
      "93/380:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "plt.plot.density(df.occurrencehour)\n",
      "plt.density(df.occurrencedayofweek)\n",
      "93/381:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "plt.plot(df.occurrencehour)\n",
      "plt.plot(df.occurrencedayofweek)\n",
      "93/382:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "axes[0].hist(df.occurrencehour, )\n",
      "axes[1].hist(df.occurrencedayofweek)\n",
      "93/383:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "axes[0].hist(df.occurrencehour, bins='auto')\n",
      "axes[1].hist(df.occurrencedayofweek, bins='auto')\n",
      "93/384:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "axes[0].hist(df.occurrencehour, bins='auto')\n",
      "sns.distplot(df.occurencehour)\n",
      "axes[1].hist(df.occurrencedayofweek, bins='auto')\n",
      "93/385:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "axes[0].hist(df.occurrencehour, bins='auto')\n",
      "sns.distplot(df.occurrencehour)\n",
      "axes[1].hist(df.occurrencedayofweek, bins='auto')\n",
      "93/386:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "axes[0].hist(df.occurrencehour, bins='auto')\n",
      "sns.distplot(df.occurrencehour, ax=axes[0])\n",
      "axes[1].hist(df.occurrencedayofweek, bins='auto')\n",
      "93/387:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "axes[0].hist(df.occurrencehour, bins='auto')\n",
      "sns.distplot(df.occurrencehour, ax=axes[0]) * 8000\n",
      "axes[1].hist(df.occurrencedayofweek, bins='auto')\n",
      "93/388:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "axes[0].hist(df.occurrencehour, bins='auto')\n",
      "sns.distplot(df.occurrencehour * 8000, ax=axes[0])\n",
      "axes[1].hist(df.occurrencedayofweek, bins='auto')\n",
      "93/389:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "axes[0].hist(df.occurrencehour, bins='auto')\n",
      "axes[1].hist(df.occurrencedayofweek, bins='auto')\n",
      "93/390:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "# axes[0].hist(df.occurrencehour, bins='auto')\n",
      "# axes[1].hist(df.occurrencedayofweek, bins='auto')\n",
      "sns.distplot(df.occurrencehour, ax=axes[0])\n",
      "sns.distplot(df.occurrencedayofweek, ax=axes[1])\n",
      "93/391:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "sns.distplot(df.occurrencehour, ax=axes[0])\n",
      "sns.distplot(df.occurrencedayofweek, ax=axes[1])\n",
      "93/392: df.premisetype\n",
      "93/393: set(df.premisetype)\n",
      "93/394: df.groupby(['premisetype'])\n",
      "93/395: df.groupby(['premisetype']).sum()/\n",
      "93/396: df.groupby(['premisetype']).sum()\n",
      "93/397: df.groupby(['premisetype']).value_counts()\n",
      "93/398: df.groupby(['premisetype']).plot()\n",
      "93/399: df.groupby(['premisetype'])\n",
      "93/400: df.groupby(['premisetype']).occurrencehour.plot()\n",
      "93/401: df.groupby(['premisetype']).occurrencehour\n",
      "93/402: df.groupby(['premisetype'])\n",
      "93/403: print(df.groupby(['premisetype']))\n",
      "93/404: df.groupby(['premisetype'])\n",
      "93/405: set(df.premisetype)\n",
      "93/406:\n",
      "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
      "sns.distplot(df.occurrencehour, ax=axes[0])\n",
      "sns.distplot(df.occurrencedayofweek, ax=axes[1])\n",
      "93/407:\n",
      "fig, axes = plt.subplots(2, figsize=(14, 8))\n",
      "sns.distplot(df.occurrencehour, ax=axes[0])\n",
      "sns.distplot(df.occurrencedayofweek, ax=axes[1])\n",
      "93/408:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "sns.distplot(df.occurrencehour, ax=axes[0])\n",
      "sns.distplot(df.occurrencedayofweek, ax=axes[1])\n",
      "93/409:\n",
      "fig, axes = plt.subplots(5, figsize=(16, 20))\n",
      "for index, ptype in enumerate(set(df.premisetype)):\n",
      "    ftr = df.loc[df.premisetype == ptype]\n",
      "    sns.distplot(ftr.occurrencehour, ax=axes[index])\n",
      "93/410:\n",
      "fig, axes = plt.subplots(5, figsize=(16, 20))\n",
      "for index, ptype in enumerate(set(df.premisetype)):\n",
      "    ftr = df.loc[df.premisetype == ptype]\n",
      "    sns.distplot(ftr.occurrencehour, ax=axes[index], label=ptype)\n",
      "    sns.\n",
      "93/411:\n",
      "fig, axes = plt.subplots(5, figsize=(16, 20))\n",
      "for index, ptype in enumerate(set(df.premisetype)):\n",
      "    ftr = df.loc[df.premisetype == ptype]\n",
      "    sns.distplot(ftr.occurrencehour, ax=axes[index], label=ptype)\n",
      "93/412:\n",
      "fig, axes = plt.subplots(5, figsize=(16, 20))\n",
      "for index, ptype in enumerate(set(df.premisetype)):\n",
      "    ftr = df.loc[df.premisetype == ptype]\n",
      "    sns.distplot(ftr.occurrencehour, ax=axes[index], axlabel=ptype)\n",
      "93/413:\n",
      "fig, axes = plt.subplots(5, figsize=(16, 20))\n",
      "for index, ptype in enumerate(set(df.premisetype)):\n",
      "    ftr = df.loc[df.premisetype == ptype]\n",
      "    axes[index].hist(ftr.occurrencehour, bins='auto', axlabel=ptype)\n",
      "93/414:\n",
      "fig, axes = plt.subplots(5, figsize=(16, 20))\n",
      "for index, ptype in enumerate(set(df.premisetype)):\n",
      "    ftr = df.loc[df.premisetype == ptype]\n",
      "    axes[index].hist(ftr.occurrencehour, bins='auto')\n",
      "93/415:\n",
      "fig, axes = plt.subplots(5, figsize=(16, 20))\n",
      "for index, ptype in enumerate(set(df.premisetype)):\n",
      "    ftr = df.loc[df.premisetype == ptype]\n",
      "    sns.distplot(ftr.occurrencehour, ax=axes[index], axlabel=ptype)\n",
      "93/416:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "import datetime\n",
      "from mpl_toolkits.basemap import Basemap\n",
      "93/417:\n",
      "df = pd.read_csv('MCI_14x17.csv')\n",
      "df.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "df = df.dropna()\n",
      "93/418:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "import datetime\n",
      "from mpl_toolkits.basemap import Basemap\n",
      "93/419:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "import datetime\n",
      "import folium\n",
      "93/420: folium.Map(location='toronto')\n",
      "93/421: folium.Map(location=[43, 79])\n",
      "93/422: folium.Map(location=[43, -79])\n",
      "93/423: folium.Map(location=[44, -79])\n",
      "93/424: folium.Map(location=[43.6, -79])\n",
      "93/425: folium.Map(location=[43.6, -79.4])\n",
      "93/426: folium.Map(location=[43.6532, -79.3832])\n",
      "93/427: folium.Map(location=[43.6532, -79.3832], zoom=15)\n",
      "93/428: folium.Map(location=[43.6532, -79.3832], zoom_start=15)\n",
      "93/429: folium.Map(location=[43.6532, -79.3832], zoom_start=10)\n",
      "93/430: folium.Map(location=[43.6532, -79.3832], zoom_start=12)\n",
      "93/431: folium.Map(location=[43.6532, -79.3832], zoom_start=13)\n",
      "93/432: folium.Map(location=[43.6532, -79.3832], zoom_start=12)\n",
      "93/433: folium.Map(location=[43.7532, -79.3832], zoom_start=12)\n",
      "93/434: folium.Map(location=[43.6732, -79.3832], zoom_start=12)\n",
      "93/435: folium.Map(location=[43.6832, -79.3832], zoom_start=12)\n",
      "93/436: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='OpenStreetMap')\n",
      "93/437: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB')\n",
      "93/438: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/439: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB dark_matter')\n",
      "93/440: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='Mapbox Control Room')\n",
      "93/441: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='Mapbox Bright')\n",
      "93/442: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='MapboxBright')\n",
      "93/443: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='Mapbox')\n",
      "93/444: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='Stamen Watercolor')\n",
      "93/445: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='Stamen Terrain')\n",
      "93/446: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/447: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB dark_matter')\n",
      "93/448: folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/449: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/450: tmap\n",
      "93/451: folium.Marker([43.6426, -79.3871], popup'CN Tower').add_to(tmap)\n",
      "93/452: folium.Marker([43.6426, -79.3871], popup='CN Tower').add_to(tmap)\n",
      "93/453: tmap\n",
      "93/454:\n",
      "df = pd.read_csv('MCI_14x17.csv')\n",
      "df.drop(['X', 'Y', 'FID', 'Division', 'Index_', 'event_unique_id', 'ucr_code', 'ucr_ext'], axis=1, inplace=True)\n",
      "df = df.dropna()\n",
      "df\n",
      "93/455:\n",
      "num_type = df.groupby(['offence']).size().sort_values(ascending=False).to_frame()\n",
      "print(num_type)\n",
      "93/456:\n",
      "df.loc[df['offence'].str.contains('Assault|Aslt', case=False), 'offence'] = 'Assault'\n",
      "df.loc[df['offence'].str.contains('Theft', case=False) & df['offence'].str.contains('Over', case=False), 'offence'] = 'Theft Over 5000'\n",
      "df.loc[df['offence'].str.contains('Robbery', case=False), 'offence'] = 'Robbery'\n",
      "df.loc[df['offence'].str.contains('B&E', case=False), 'offence'] = 'B&E'\n",
      "93/457:\n",
      "num_type = df.offence.value_counts().to_frame()\n",
      "num_type.columns = ['Count']\n",
      "num_type = num_type.assign(Percentage=(num_type.Count / sum(num_type.Count) * 100))\n",
      "print(num_type.Percentage[:4].sum())\n",
      "print(num_type)\n",
      "93/458:\n",
      "date_diff = pd.to_datetime(df.reporteddate) - pd.to_datetime(df.occurrencedate)\n",
      "date_diff = date_diff.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "date_diff = date_diff.Count.dt.days.to_frame().rename(index=str, columns={0: 'Count'})\n",
      "diff_count = date_diff.Count.value_counts().to_frame()\n",
      "diff_count = diff_count.assign(Percentage=(diff_count.Count / sum(diff_count.Count) * 100))\n",
      "diff_count = diff_count.reset_index()\n",
      "diff_count = diff_count.rename(columns = {'index': 'Days'})\n",
      "diff_count = diff_count.sort_values(by='Days')\n",
      "print(diff_count.Percentage[:2].sum())\n",
      "print(diff_count.head(n=5))\n",
      "93/459: plt.plot(diff_count.Days, diff_count.Count)\n",
      "93/460:\n",
      "diff_count2 = diff_count[31:].reset_index().drop(['index'], axis=1)\n",
      "diff_count2 = diff_count2.assign(Percentage=(diff_count2.Count / sum(diff_count2.Count) * 100))\n",
      "print(diff_count2.Percentage[:366].sum())\n",
      "print(diff_count2.head(n=5))\n",
      "plt.plot(diff_count2.Days, diff_count2.Count)\n",
      "93/461:\n",
      "days_of_week = {\n",
      "    'Sunday': 0,\n",
      "    'Monday': 1,\n",
      "    'Tuesday': 2,\n",
      "    'Wednesday': 3,\n",
      "    'Thursday': 4,\n",
      "    'Friday': 5,\n",
      "    'Saturday': 6\n",
      "}\n",
      "\n",
      "df = df.assign(occurrencedayofweek=(df.occurrencedayofweek.apply(str.strip).map(days_of_week)))\n",
      "df\n",
      "93/462:\n",
      "fig, axes = plt.subplots(2, figsize=(16, 8))\n",
      "sns.distplot(df.occurrencehour, ax=axes[0])\n",
      "sns.distplot(df.occurrencedayofweek, ax=axes[1])\n",
      "93/463:\n",
      "fig, axes = plt.subplots(5, figsize=(16, 20))\n",
      "for index, ptype in enumerate(set(df.premisetype)):\n",
      "    ftr = df.loc[df.premisetype == ptype]\n",
      "    sns.distplot(ftr.occurrencehour, ax=axes[index], axlabel=ptype)\n",
      "93/464: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/465: tmap\n",
      "93/466: tmap\n",
      "93/467: heat_data = [[row['Lat'], row['Long']] for index, row in df.iterrows()]\n",
      "93/468: df['Lat', 'Long']\n",
      "93/469: df[['Lat', 'Long']]\n",
      "93/470: df[['Lat', 'Long']][0]\n",
      "93/471: df[['Lat', 'Long']].values()\n",
      "93/472: df[['Lat', 'Long']]\n",
      "93/473: list(df[['Lat', 'Long']])\n",
      "93/474: df[['Lat', 'Long']]\n",
      "93/475: type(df[['Lat', 'Long']])\n",
      "93/476: df[['Lat', 'Long']].values()\n",
      "93/477: df[['Lat', 'Long']].tolist()\n",
      "93/478: df[['Lat', 'Long']].values()\n",
      "93/479: df[['Lat', 'Long']].values\n",
      "93/480: heat_data\n",
      "93/481: heat_data = df[['Lat', 'Long']].values\n",
      "93/482: HeatMap(heat_data).add_to(tmap)\n",
      "93/483: folium.plugins.HeatMap(heat_data).add_to(tmap)\n",
      "93/484:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "import datetime\n",
      "import folium\n",
      "from folium.plugins import HeatMap\n",
      "93/485: HeatMap(heat_data).add_to(tmap)\n",
      "93/486: tmap\n",
      "93/487: heat_data = df[['Lat', 'Long']].values.tolist()\n",
      "93/488: HeatMap(heat_data).add_to(tmap)\n",
      "93/489: tmap\n",
      "93/490: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/491: tmap\n",
      "93/492: heat_data = df[['Lat', 'Long']].values.tolist()\n",
      "93/493: HeatMap(heat_data).add_to(tmap)\n",
      "93/494: tmap\n",
      "93/495: heat_data = df[:100][['Lat', 'Long']].values.tolist()\n",
      "93/496: HeatMap(heat_data).add_to(tmap)\n",
      "93/497: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/498: heat_data = df[:100][['Lat', 'Long']].values.tolist()\n",
      "93/499: HeatMap(heat_data).add_to(tmap)\n",
      "93/500: heat_data\n",
      "93/501: tmap\n",
      "93/502: heat_data = df[:1000][['Lat', 'Long']].values.tolist()\n",
      "93/503: HeatMap(heat_data).add_to(tmap)\n",
      "93/504: tmap\n",
      "93/505: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=10, tiles='CartoDB positron')\n",
      "93/506: tmap\n",
      "93/507: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=10, tiles='CartoDB positron')\n",
      "93/508: tmap\n",
      "93/509: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/510: tmap\n",
      "93/511: heat_data = df[:1000][['Lat', 'Long']].values.tolist()\n",
      "93/512: HeatMap(heat_data).add_to(tmap)\n",
      "93/513: tmap\n",
      "93/514: heat_data = df[:10000][['Lat', 'Long']].values.tolist()\n",
      "93/515: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/516: tmap\n",
      "93/517: heat_data = df[:10000][['Lat', 'Long']].values.tolist()\n",
      "93/518: HeatMap(heat_data).add_to(tmap)\n",
      "93/519: tmap\n",
      "93/520: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/521: heat_data = df[:50000][['Lat', 'Long']].values.tolist()\n",
      "93/522: HeatMap(heat_data).add_to(tmap)\n",
      "93/523: tmap\n",
      "93/524: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/525: tmap\n",
      "93/526: heat_data = df[:30000][['Lat', 'Long']].values.tolist()\n",
      "93/527: HeatMap(heat_data).add_to(tmap)\n",
      "93/528: tmap\n",
      "93/529: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/530: heat_data = df[:40000][['Lat', 'Long']].values.tolist()\n",
      "93/531: HeatMap(heat_data).add_to(tmap)\n",
      "93/532: tmap\n",
      "93/533: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/534: tmap\n",
      "93/535: heat_data = df[:45000][['Lat', 'Long']].values.tolist()\n",
      "93/536: HeatMap(heat_data).add_to(tmap)\n",
      "93/537: tmap\n",
      "93/538: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/539: tmap\n",
      "93/540: heat_data = df[:50000][['Lat', 'Long']].values.tolist()\n",
      "93/541: HeatMap(heat_data).add_to(tmap)\n",
      "93/542: tmap\n",
      "93/543: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/544: heat_data = df[:480000][['Lat', 'Long']].values.tolist()\n",
      "93/545: HeatMap(heat_data).add_to(tmap)\n",
      "93/546: tmap\n",
      "93/547: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/548: heat_data = df[['Lat', 'Long']].sample(10000).values.tolist()\n",
      "93/549: HeatMap(heat_data).add_to(tmap)\n",
      "93/550: tmap\n",
      "93/551: HeatMap(heat_data, max_opacity=0.6).add_to(tmap)\n",
      "93/552: HeatMap(heat_data, radius=1).add_to(tmap)\n",
      "93/553: tmap\n",
      "93/554: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/555: tmap\n",
      "93/556: heat_data = df[['Lat', 'Long']].sample(10000).values.tolist()\n",
      "93/557: HeatMap(heat_data, radius=1).add_to(tmap)\n",
      "93/558: tmap\n",
      "93/559: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/560: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=1, tiles='CartoDB positron')\n",
      "93/561:\n",
      "heat_data = df[['Lat', 'Long']].sample(10000).values.tolist()\n",
      "HeatMap(heat_data, radius=5).add_to(tmap)\n",
      "93/562: tmap\n",
      "93/563: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/564:\n",
      "heat_data = df[['Lat', 'Long']].sample(10000).values.tolist()\n",
      "HeatMap(heat_data, radius=5).add_to(tmap)\n",
      "93/565: tmap\n",
      "93/566: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/567:\n",
      "heat_data = df[['Lat', 'Long']].sample(10000).values.tolist()\n",
      "HeatMap(heat_data, radius=6).add_to(tmap)\n",
      "93/568: tmap\n",
      "93/569:\n",
      "heat_data = df[['Lat', 'Long']].sample(10000).values.tolist()\n",
      "HeatMap(heat_data, radius=10).add_to(tmap)\n",
      "93/570: tmap\n",
      "93/571: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/572:\n",
      "heat_data = df[['Lat', 'Long']].sample(10000).values.tolist()\n",
      "HeatMap(heat_data, radius=10).add_to(tmap)\n",
      "93/573: tmap\n",
      "93/574: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/575:\n",
      "heat_data = df[['Lat', 'Long']].sample(10000).values.tolist()\n",
      "HeatMap(heat_data, radius=5).add_to(tmap)\n",
      "93/576: tmap\n",
      "93/577: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/578:\n",
      "heat_data = df[['Lat', 'Long']].sample(25000).values.tolist()\n",
      "HeatMap(heat_data, radius=5).add_to(tmap)\n",
      "93/579: tmap\n",
      "93/580: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/581:\n",
      "heat_data = df[['Lat', 'Long']].sample(50000).values.tolist()\n",
      "HeatMap(heat_data, radius=5).add_to(tmap)\n",
      "93/582: tmap\n",
      "93/583: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/584:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=5).add_to(tmap)\n",
      "93/585: tmap\n",
      "93/586: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/587:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=10).add_to(tmap)\n",
      "93/588: tmap\n",
      "93/589: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/590:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=7.5).add_to(tmap)\n",
      "93/591: tmap\n",
      "93/592: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/593:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=7.5, max_val=0.7).add_to(tmap)\n",
      "93/594: tmap\n",
      "93/595:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=10, max_val=0.7).add_to(tmap)\n",
      "93/596: tmap\n",
      "93/597: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/598:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=10, max_val=0.7).add_to(tmap)\n",
      "93/599: tmap\n",
      "93/600: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11, tiles='CartoDB positron')\n",
      "93/601:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/602: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/603:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/604: tmap\n",
      "93/605: tmap\n",
      "93/606: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/607:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=6, max_val=0.7).add_to(tmap)\n",
      "93/608: tmap\n",
      "93/609:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/610: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/611:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/612: tmap\n",
      "93/613: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/614:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/615: tmap\n",
      "93/616:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, seed=1).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/617:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=1).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/618: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/619:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=1).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/620: tmap\n",
      "93/621: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB positron')\n",
      "93/622:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/623: tmap\n",
      "93/624: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12)\n",
      "93/625:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/626: tmap\n",
      "93/627: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=12, tiles='CartoDB dark_matter')\n",
      "93/628:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/629: tmap\n",
      "93/630: tmap = folium.Map(location=[43.6832, -79.3832], zoom_start=11.5, tiles='CartoDB dark_matter')\n",
      "93/631:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/632: tmap\n",
      "93/633: tmap = folium.Map(location=[43.6932, -79.3832], zoom_start=11.5, tiles='CartoDB dark_matter')\n",
      "93/634:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/635: tmap\n",
      "93/636: tmap = folium.Map(location=[43.6932, -79.3832], zoom_start=11, tiles='CartoDB dark_matter')\n",
      "93/637:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/638: tmap\n",
      "93/639: tmap = folium.Map(location=[43.6932, -79.4832], zoom_start=11, tiles='CartoDB dark_matter')\n",
      "93/640:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/641: tmap\n",
      "93/642: tmap = folium.Map(location=[43.6932, -79.2832], zoom_start=11, tiles='CartoDB dark_matter')\n",
      "93/643:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/644: tmap\n",
      "93/645: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11, tiles='CartoDB dark_matter')\n",
      "93/646:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/647: tmap\n",
      "93/648: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.25, tiles='CartoDB dark_matter')\n",
      "93/649:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/650: tmap\n",
      "93/651: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.5, tiles='CartoDB dark_matter')\n",
      "93/652:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/653: tmap\n",
      "93/654: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.2, tiles='CartoDB dark_matter')\n",
      "93/655:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/656: tmap\n",
      "93/657: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/658:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/659: tmap\n",
      "93/660: heat_data\n",
      "93/661: pd.DataFrame(heat_data)\n",
      "93/662: pd.DataFrame(heat_data).columns = ['Lat', 'Long']\n",
      "93/663: time_heat_data = pd.DataFrame(heat_data).columns = ['Lat', 'Long']\n",
      "93/664: time_heat_data\n",
      "93/665:\n",
      "time_heat_data = pd.DataFrame(heat_data)\n",
      "time_heat_data.columns = ['Lat', 'Long']\n",
      "time_heat_data\n",
      "93/666: time_heat_data = df[['Lat', 'Long', 'occurrencedata']].sample(45000)\n",
      "93/667: time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(45000)\n",
      "93/668: time_heat_data\n",
      "93/669:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "import datetime\n",
      "import folium\n",
      "from folium.plugins import HeatMap, HeatMapWithTime\n",
      "93/670: time_heat_data, time_index = df[['Lat', 'Long', 'occurrencedate']].sample(45000)\n",
      "93/671:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(45000)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "93/672: HeatMapWithTime(time_loc, index=time_index)\n",
      "93/673: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/674:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(45000)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "93/675: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/676: tmap\n",
      "93/677: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/678:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(30000)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "93/679: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/680: tmap\n",
      "93/681: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/682:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/683: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/684:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10000)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "93/685: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/686: tmap\n",
      "93/687: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/688:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(1000)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "93/689: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/690: tmap\n",
      "93/691: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/692:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "93/693: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/694: tmap\n",
      "93/695: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/696:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/697: tmap\n",
      "93/698: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/699:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "93/700: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/701: tmap\n",
      "93/702:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_loc\n",
      "93/703:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index\n",
      "93/704:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.sort()\n",
      "93/705:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "sorted(time_index)\n",
      "93/706:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "93/707: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/708: tmap\n",
      "93/709:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index\n",
      "93/710:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[0]\n",
      "93/711:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.value[0]\n",
      "93/712:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.value\n",
      "93/713:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index\n",
      "93/714:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.occurrencedate\n",
      "93/715:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.occurrencedate[0]\n",
      "93/716:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[0]\n",
      "93/717:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[1]\n",
      "93/718:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[1:]\n",
      "93/719:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[1,:]\n",
      "93/720:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[0,:]\n",
      "93/721:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[0,:0]\n",
      "93/722:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[0,:1]\n",
      "93/723:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[0,1]\n",
      "93/724:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index[:,1]\n",
      "93/725:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.head(n=1)\n",
      "93/726:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "type(time_index.head(n=1))\n",
      "93/727:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.head(n=1).value\n",
      "93/728:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index\n",
      "93/729:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.iloc[0]\n",
      "93/730:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.iloc[0][0]\n",
      "93/731:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "type(time_index.iloc[0][0])\n",
      "93/732:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "pd.to_datetime(time_index)\n",
      "93/733:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index\n",
      "93/734:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "pd.to_datetime(time_index.occurrencedate)\n",
      "93/735:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = pd.to_datetime(time_index.occurrencedate)\n",
      "93/736:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = pd.to_datetime(time_index.occurrencedate)\n",
      "time_index\n",
      "93/737:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = pd.to_datetime(time_index.occurrencedate).to_frame()\n",
      "time_index\n",
      "93/738: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/739: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/740:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = pd.to_datetime(time_index.occurrencedate).to_frame()\n",
      "time_index\n",
      "93/741: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/742: tmap\n",
      "93/743:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index\n",
      "93/744:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.apply(datetime.date)\n",
      "93/745:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.occurrencedate.apply(datetime.date)\n",
      "93/746:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.apply(datetime.date)\n",
      "93/747:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.occurrencedate.apply(datetime.date)\n",
      "93/748:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.occurrencedate\n",
      "93/749:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.occurrencedate..apply(datetime.datetime)\n",
      "93/750:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.occurrencedate.apply(datetime.datetime)\n",
      "93/751:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index.occurrencedate.iloc[0]\n",
      "93/752:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "datetime.date(time_index.occurrencedate.iloc[0])\n",
      "93/753:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "datetime.strptime(time_index.occurrencedate.iloc[0])\n",
      "93/754:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "datetime.strptime(time_index.occurrencedate.iloc[0])\n",
      "93/755:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "datetime.datetime.strptime(time_index.occurrencedate.iloc[0])\n",
      "93/756:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "datetime.datetime.strptime()\n",
      "93/757:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "datetime.datetime.strptime('%Y-%M-%D%T')\n",
      "93/758:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "datetime.datetime.strptime(time_index.occurrencedate.iloc[0], '%Y-%M-%D%T')\n",
      "93/759:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "datetime.datetime.strptime(time_index.occurrencedate.iloc[0], '%Y-%M-%d%T')\n",
      "93/760:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "datetime.datetime.strptime(time_index.occurrencedate.iloc[0], '%Y-%M-%d')\n",
      "93/761:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "datetime.datetime.strptime(time_index.occurrencedate.iloc[0].split('T')[0], '%Y-%M-%d')\n",
      "93/762:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "datetime.datetime.strptime(time_index.occurrencedate.iloc[0].split('T')[0], '%Y-%m-%d')\n",
      "93/763:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "datetime.datetime.strptime(time_index.occurrencedate.iloc[0].split('T')[0], '%Y-%M-%d').replace(tzinfo=timezone.utc).timestamp()\n",
      "93/764:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "datetime.datetime.strptime(time_index.occurrencedate.iloc[0].split('T')[0], '%Y-%M-%d').replace(tzinfo=datetime.timezone.utc).timestamp()\n",
      "93/765:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace(tzinfo=datetime.timezone.utc).timestamp())\n",
      "93/766:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "print(time_index.occurrencedate.iloc[0])\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace(tzinfo=datetime.timezone.utc).timestamp())\n",
      "93/767:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace(tzinfo=datetime.timezone.utc).timestamp())\n",
      "93/768: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/769:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace(tzinfo=datetime.timezone.utc).timestamp())\n",
      "93/770: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/771: tmap\n",
      "93/772:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d')).timestamp())\n",
      "93/773:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d')).timestamp()\n",
      "93/774:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace().timestamp())\n",
      "93/775: time_index\n",
      "93/776: sns.heatmap(time_loc)\n",
      "93/777: sns.heatmap(heat_data)\n",
      "93/778: sns.lineplot(time_index)\n",
      "93/779: sns.lineplot(time_index.occurrencedate)\n",
      "93/780: sns.lineplot(time_index)\n",
      "93/781: sns.lineplot(data=time_index)\n",
      "93/782: sns.lineplot(data=sorted(time_index))\n",
      "93/783: time_index\n",
      "93/784: time_index.value\n",
      "93/785: time_index.values\n",
      "93/786: sns.lineplot(data=sorted(time_index.values))\n",
      "93/787: sns.lineplot(data=time_loc)\n",
      "93/788: sns.lineplot(x=time_loc)\n",
      "93/789: sns.lineplot(x=time_loc[['Lat']], y=time_loc[['Long']])\n",
      "93/790: plt.plot(x=time_loc[['Lat']], y=time_loc[['Long']])\n",
      "93/791: time_loc[['Lat']]\n",
      "93/792: time_loc[['Lat']].value\n",
      "93/793: time_loc[['Lat']].values\n",
      "93/794: sns.lineplot(x=time_loc[['Lat']].values, y=time_loc[['Long']].values)\n",
      "93/795: plt.plot(x=time_loc[['Lat']].values, y=time_loc[['Long']].values)\n",
      "93/796: plt.scatter(x=time_loc[['Lat']].values, y=time_loc[['Long']].values)\n",
      "93/797:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(1000)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace().timestamp())\n",
      "93/798: plt.scatter(x=time_loc[['Lat']].values, y=time_loc[['Long']].values)\n",
      "93/799:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(10000)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace().timestamp())\n",
      "93/800: plt.scatter(x=time_loc[['Lat']].values, y=time_loc[['Long']].values)\n",
      "93/801:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100000)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace().timestamp())\n",
      "93/802: plt.scatter(x=time_loc[['Lat']].values, y=time_loc[['Long']].values)\n",
      "93/803: HeatMapWithTime(time_loc, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/804:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace().timestamp())\n",
      "93/805: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/806:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace().timestamp())\n",
      "93/807: HeatMapWithTime(time_loc, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/808: tmap\n",
      "93/809: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6)\n",
      "93/810: hmt = HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6)\n",
      "93/811: tmap.add_child(hmt)\n",
      "93/812:\n",
      "tmap.add_child(hmt)\n",
      "tmap\n",
      "93/813:\n",
      "hmt.add_to(tmap)\n",
      "tmap\n",
      "93/814: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/815: tmap\n",
      "93/816: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/817:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace().timestamp())\n",
      "93/818: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/819: tmap\n",
      "93/820: tmap = folium.Map(location=[43.6932, -79.3432], zoom_start=11.3, tiles='CartoDB dark_matter')\n",
      "93/821:\n",
      "heat_data = df[['Lat', 'Long']].sample(45000, random_state=0).values.tolist()\n",
      "HeatMap(heat_data, radius=8, max_val=0.7).add_to(tmap)\n",
      "93/822: tmap\n",
      "93/823: tmap\n",
      "93/824:\n",
      "time_heat_data = df[['Lat', 'Long', 'occurrencedate']].sample(100)\n",
      "time_loc = time_heat_data[['Lat', 'Long']]\n",
      "time_index = time_heat_data[['occurrencedate']]\n",
      "time_index = time_index.occurrencedate.apply(lambda x: datetime.datetime.strptime(x.split('T')[0], '%Y-%M-%d').replace().timestamp())\n",
      "93/825: HeatMapWithTime(time_loc, index=time_index, auto_play=True, max_opacity=0.6).add_to(tmap)\n",
      "93/826: tmap\n",
      "94/1:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import quandl \n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from pandas.plotting import register_matplotlib_converters\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "94/2:\n",
      "quandl.ApiConfig.api_key = 'umQRdEcxaVzMFsfVPJ_y'\n",
      "register_matplotlib_converters()\n",
      "94/3: data = quandl.get('WIKI/AAPL')\n",
      "94/4: data.columns\n",
      "94/5: plt.plot(data['Adj. Close'])\n",
      "94/6: data['Adj. Close']\n",
      "94/7: torch.tensor(data['Adj. Close'])\n",
      "94/8:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "x = dat[:-1]\n",
      "y = dat[1:]\n",
      "94/9: max(dat)\n",
      "94/10:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "94/11: min(x), max(x)\n",
      "94/12: min(dat)\n",
      "94/13: min(dat) / max(dat)\n",
      "94/14:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "94/15:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'rb')\n",
      "hidden = pickle.load(f)\n",
      "f.close()\n",
      "\n",
      "model = torch.load('/Users/js/programs/lstm-stock-time-series.pt')\n",
      "model.eval()\n",
      "94/16:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import quandl \n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from pandas.plotting import register_matplotlib_converters\n",
      "import torch\n",
      "from torch import nn, optim\n",
      "import pickle\n",
      "94/17:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'rb')\n",
      "hidden = pickle.load(f)\n",
      "f.close()\n",
      "\n",
      "model = torch.load('/Users/js/programs/lstm-stock-time-series.pt')\n",
      "model.eval()\n",
      "94/18:\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "94/19:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "print(model)\n",
      "94/20:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=64, dropout=0.0)\n",
      "print(model)\n",
      "94/21:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'rb')\n",
      "hidden = pickle.load(f)\n",
      "f.close()\n",
      "\n",
      "model = torch.load('/Users/js/programs/lstm-stock-time-series.pt')\n",
      "model.eval()\n",
      "94/22: prinnt(model)\n",
      "94/23: print(model)\n",
      "94/24: prediction, hidden = model(x, hidden)\n",
      "94/25: batch_size = 64\n",
      "94/26:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "truncate_length = len(dat) - (len(dat) // batch_size)\n",
      "dat = dat[truncate_length:]\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "94/27:\n",
      "class lstm(nn.Module):\n",
      "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, batch_size, dropout):\n",
      "        super(lstm, self).__init__()\n",
      "        self.input_dim = input_dim\n",
      "        self.output_dim = output_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.batch_size = batch_size\n",
      "        self.num_layers = num_layers\n",
      "        self.dropout = dropout\n",
      "\n",
      "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, dropout=self.dropout)\n",
      "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
      "        \n",
      "    def forward(self, x, hidden):\n",
      "        x = x.reshape(self.batch_size, -1, self.input_dim)\n",
      "        out, hidden = self.lstm(x)\n",
      "        out.reshape(-1, self.hidden_dim)\n",
      "        out = self.output(out)\n",
      "        return(out, hidden)\n",
      "94/28:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.0)\n",
      "print(model)\n",
      "94/29:\n",
      "f = open('/Users/js/programs/hidden.pckl', 'rb')\n",
      "hidden = pickle.load(f)\n",
      "f.close()\n",
      "\n",
      "model = torch.load('/Users/js/programs/lstm-stock-time-series.pt')\n",
      "model.eval()\n",
      "94/30: prediction, hidden = model(x, hidden)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/31: x.shape\n",
      "94/32: y.shape\n",
      "94/33:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "truncate_length = len(dat) - (len(dat) % batch_size)\n",
      "dat = dat[truncate_length:]\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "94/34: x.shape\n",
      "94/35: len(data['Adj. Close'])\n",
      "94/36: torch.tensor(len(data['Adj. Close']))\n",
      "94/37: len(torch.tensor(data['Adj. Close']))\n",
      "94/38: len(torch.tensor(data['Adj. Close'])) / 64\n",
      "94/39: int(len(torch.tensor(data['Adj. Close'])) / 64) * 64\n",
      "94/40: int(len(dat) / 64) * 64\n",
      "94/41:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "truncate_length = int(len(dat) / 64) * 64 \n",
      "dat = dat[truncate_length:]\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "94/42: x.shape\n",
      "94/43: truncate_lenght\n",
      "94/44: truncate_length\n",
      "94/45:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "truncate_length = len(dat) - (int(len(dat) / 64) * 64)\n",
      "dat = dat[truncate_length]\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "94/46:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "truncate_length = len(dat) - (int(len(dat) / 64) * 64)\n",
      "dat = dat[truncate_length]\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "94/47: dat = torch.tensor(data['Adj. Close'])\n",
      "94/48: len(dat)\n",
      "94/49: len(dat) / 64\n",
      "94/50: int(len(dat) / 64) * 64\n",
      "94/51: len(dat) - int(len(dat) / 64) * 64\n",
      "94/52:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "truncate_length = len(dat) - (int(len(dat) / 64) * 64)\n",
      "dat = dat[truncate_length:]\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "94/53: x.shape\n",
      "94/54: prediction, hidden = model(x, hidden)\n",
      "94/55: x.shape\n",
      "94/56:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "truncate_length = len(dat) - (int(len(dat) / 64) * 64)\n",
      "dat = dat[truncate_length:]\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "94/57: x.shape\n",
      "94/58: dat.shape\n",
      "94/59:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "truncate_length = len(dat) - (int(len(dat) / 64) * 64)\n",
      "dat = dat[truncate_length-1:]\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "94/60: dat.shape\n",
      "94/61: prediction, hidden = model(x, hidden)\n",
      "94/62:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "94/63: loss_fn = nn.MSELoss()\n",
      "94/64:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "94/65:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(np.arange(len(y), y.reshape(-1, 1), color='b')\n",
      "plt.scatter(np.arange(len(y), prediction, color='r')\n",
      "plt.show()\n",
      "94/66:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(np.arange(len(y)), y.reshape(-1, 1), color='b')\n",
      "plt.scatter(np.arange(len(y)), prediction, color='r')\n",
      "plt.show()\n",
      "94/67:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(np.arange(len(y)), y.reshape(-1, 1), color='b')\n",
      "plt.scatter(np.arange(len(y)), prediction, color='r')\n",
      "plt.show()\n",
      "94/68:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=1, batch_size=batch_size, dropout=0.7)\n",
      "print(model)\n",
      "94/69:\n",
      "model = lstm(input_dim=1, output_dim=1, hidden_dim=32, num_layers=2, batch_size=batch_size, dropout=0.7)\n",
      "print(model)\n",
      "94/70:\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(np.arange(len(y)), y.reshape(-1, 1), color='b')\n",
      "plt.scatter(np.arange(len(y)), prediction, color='r')\n",
      "plt.show()\n",
      "94/71:\n",
      "loss_fn = nn.MSELoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.5)\n",
      "94/72:\n",
      "epochs = 2500\n",
      "show_every = 500\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "94/73:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "94/74:\n",
      "dat = torch.tensor(data['Adj. Close'])\n",
      "truncate_length = len(dat) - (int(len(dat) / 64) * 64)\n",
      "dat = dat[truncate_length-1:]\n",
      "x = dat[:-1] / max(dat)\n",
      "y = dat[1:] / max(dat)\n",
      "times = np.arange(len(y))\n",
      "94/75:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "94/76:\n",
      "model.eval()\n",
      "prediction, hidden = model(x, hidden)\n",
      "loss = loss_fn(prediction, y)\n",
      "print(loss.item())\n",
      "plt.figure(figsize=(15, 5))\n",
      "prediction = prediction.reshape(-1, 1)\n",
      "prediction = prediction.detach().numpy()\n",
      "plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "plt.scatter(times, prediction, color='r')\n",
      "plt.show()\n",
      "94/77:\n",
      "epochs = 500\n",
      "show_every = 100\n",
      "\n",
      "model.train()\n",
      "for e in range(epochs):\n",
      "    model.zero_grad()\n",
      "    prediction, hidden = model(x, hidden)\n",
      "    loss = loss_fn(prediction, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "    if (e+1) % show_every == 0:\n",
      "        print(loss.item())\n",
      "        plt.figure(figsize=(15, 5))\n",
      "        prediction = prediction.reshape(-1, 1)\n",
      "        prediction = prediction.detach().numpy()\n",
      "        plt.scatter(times, y.reshape(-1, 1), color='b')\n",
      "        plt.scatter(times, prediction, color='r')\n",
      "        plt.show()\n",
      "98/1:\n",
      "import torch \n",
      "from torch import nn, optim\n",
      "import numpy as np\n",
      "98/2:\n",
      "import torch \n",
      "from torch import nn, optim\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "98/3: dat = np.array([np.sin(i) for i in np.arange(992)])\n",
      "98/4: plt.scatter(dat, times[:len(dat)])\n",
      "98/5:\n",
      "dat = np.array([np.sin(i) for i in np.arange(992)])\n",
      "times = np.arange(1024)\n",
      "98/6: plt.scatter(dat, times[:len(dat)])\n",
      "98/7: np.arange(1024)\n",
      "98/8: plt.scatter(times[:len(dat)], dat)\n",
      "98/9: dat\n",
      "98/10:\n",
      "import torch \n",
      "from torch import nn, optim\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "98/11: sns.scatterplot(times[:len(dat)], dat)\n",
      "98/12:\n",
      "dat = np.array([np.sin(np.pi/128*i) for i in np.arange(992)])\n",
      "times = np.arange(1024)\n",
      "98/13: sns.scatterplot(times[:len(dat)], dat)\n",
      "98/14: plt.scatter(times[:len(dat)], dat)\n",
      "98/15:\n",
      "dat = np.array([np.sin(np.pi/256*i) for i in np.arange(992)])\n",
      "times = np.arange(1024)\n",
      "98/16: plt.scatter(times[:len(dat)], dat)\n",
      "98/17:\n",
      "dat = np.array([np.sin(2*np.pi/256*i) for i in np.arange(992)])\n",
      "times = np.arange(2048)\n",
      "98/18: plt.scatter(times[:len(dat)], dat)\n",
      "98/19:\n",
      "dat = np.array([np.sin(2*np.pi/256*i) for i in np.arange(992)])[::2]\n",
      "times = np.arange(2048)\n",
      "98/20: plt.scatter(times[:len(dat)], dat)\n",
      "98/21:\n",
      "dat = np.array([np.sin(2*np.pi/256*i) for i in np.arange(992)])[::4]\n",
      "times = np.arange(2048)\n",
      "98/22: plt.scatter(times[:len(dat)], dat)\n",
      "98/23:\n",
      "dat = np.array([np.sin(2*np.pi/256*i) for i in np.arange(992)])[::8]\n",
      "times = np.arange(2048)\n",
      "98/24: plt.scatter(times[:len(dat)], dat)\n",
      "98/25:\n",
      "dat = np.array([np.sin(2*np.pi/256*i) for i in np.arange(992)])[::4]\n",
      "times = np.arange(2048)\n",
      "98/26: plt.scatter(times[:len(dat)], dat)\n",
      "98/27:\n",
      "dat = np.array([np.sin(2*np.pi/256*i) for i in np.arange(1024)])[::4]\n",
      "times = np.arange(2048)\n",
      "98/28: plt.scatter(times[:len(dat)], dat)\n",
      "98/29:\n",
      "dat = np.array([np.sin(2*np.pi/256*i) for i in np.arange(1024)])[::4]\n",
      "times = np.arange(2048)\n",
      "print(len(dat))\n",
      "98/30: plt.scatter(times[:len(dat)], dat)\n",
      "98/31:\n",
      "dat = np.array([np.sin(2*np.pi/256*i) for i in np.arange(1024)])[::6]\n",
      "times = np.arange(2048)\n",
      "print(len(dat))\n",
      "98/32: plt.scatter(times[:len(dat)], dat)\n",
      "98/33:\n",
      "dat = np.array([np.sin(2*np.pi/256*i) for i in np.arange(1024)])[::4]\n",
      "times = np.arange(2048)\n",
      "print(len(dat))\n",
      "98/34: plt.scatter(times[:len(dat)], dat)\n",
      "98/35:\n",
      "plt.stem(:len(dat)], dat)\n",
      "plt.scatter(times[:len(dat)], dat)\n",
      "98/36:\n",
      "plt.stem(times[:len(dat)], dat)\n",
      "plt.scatter(times[:len(dat)], dat)\n",
      "98/37:\n",
      "plt.stem(times[:len(dat)], dat, 'r')\n",
      "plt.scatter(times[:len(dat)], dat)\n",
      "98/38:\n",
      "plt.stem(times[:len(dat)], dat, 'r')\n",
      "sns.scatterplot(times[:len(dat)], dat)\n",
      "98/39: sns.scatterplot(times[:len(dat)], dat)\n",
      "98/40:\n",
      "fig, ax = plt.subplot(1, fig_size=(16, 4))\n",
      "sns.scatterplot(times[:len(dat)], dat, ax=ax)\n",
      "98/41:\n",
      "fig, ax1 = plt.subplot(1, fig_size=(16, 4))\n",
      "sns.scatterplot(times[:len(dat)], dat, ax=ax1)\n",
      "98/42:\n",
      "fig, ax1 = plt.subplots(1, fig_size=(16, 4))\n",
      "sns.scatterplot(times[:len(dat)], dat, ax=ax1)\n",
      "98/43:\n",
      "fig, ax1 = plt.subplots(1, figsize=(16, 4))\n",
      "sns.scatterplot(times[:len(dat)], dat, ax=ax1)\n",
      "98/44:\n",
      "fig, ax = plt.subplots(1, figsize=(16, 4))\n",
      "sns.scatterplot(times[:len(dat)], dat, ax=ax)\n",
      "98/45:\n",
      "fig, ax1 = plt.subplots(1, figsize=(16, 4))\n",
      "sns.scatterplot(times[:len(dat)], dat, ax=ax1)\n",
      "98/46:\n",
      "fig, ax1 = plt.subplots(1, figsize=(16, 4))\n",
      "ax1.stem(times[:len(dat)], dat)\n",
      "sns.scatterplot(times[:len(dat)], dat, ax=ax1)\n",
      "98/47:\n",
      "fig, ax1 = plt.subplots(1, figsize=(16, 4))\n",
      "sns.scatterplot(times[:len(dat)], dat, ax=ax1)\n",
      "99/1: from __future__ import annotations\n",
      "99/2:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "\n",
      "        Note: this is the inefficient version of the initializer from the\n",
      "        lecture notes. Feel free to replace it with your own version from Lab 5!\n",
      "        \"\"\"\n",
      "        self._first = None\n",
      "        for item in items:\n",
      "            self.append(item)\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def append(self, item: Any) -> None:\n",
      "        \"\"\"Append <item> to the end of this list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> lst.append(4)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 3 -> 4]'\n",
      "        \"\"\"\n",
      "        if self._first is None:\n",
      "            self._first = _Node(item)\n",
      "        else:\n",
      "            curr = self._first\n",
      "            while curr.next is not None:\n",
      "                curr = curr.next\n",
      "            curr.next = _Node(item)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        # >>> lst.insert(2, 300)\n",
      "        # >>> str(lst)\n",
      "        # '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        # >>> lst.insert(5, -1)\n",
      "        # >>> str(lst)\n",
      "        # '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        # >>> lst.insert(100, 2)\n",
      "        # Traceback (most recent call last):\n",
      "        # IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # TODO: Implement this method!\n",
      "    def __iter__(self) -> LinkedListIterator:\n",
      "        \"\"\"Return an iterator for this linked list.\n",
      "\n",
      "        It should be straightforward to initialize the iterator here\n",
      "        (see the class documentation below). Just remember to initialize\n",
      "        it to the first node in this linked list.\n",
      "        \"\"\"\n",
      "        return LinkedListIterator(self._first)\n",
      "99/3:\n",
      "class LinkedListIterator:\n",
      "    \"\"\"An object responsible for iterating through a linked list.\n",
      "\n",
      "    This enables linked lists to be used inside for loops!\n",
      "\n",
      "    >>> lst = LinkedList([1, 2, 3])\n",
      "    >>> for x in lst:\n",
      "    ...     print(x)\n",
      "    ...\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "    \"\"\"\n",
      "    # === Private attributes ===\n",
      "    # _curr:\n",
      "    #   The current node for this iterator.\n",
      "    #   This should start as the first node in a linked list,\n",
      "    #   and update to the \"next\" node every time __next__ is called.\n",
      "    _curr: Optional[_Node]\n",
      "\n",
      "    def __init__(self, first_node: Optional[_Node]) -> None:\n",
      "        \"\"\"Initialize a new linked list iterator with the given node.\"\"\"\n",
      "        self._curr = first_node\n",
      "\n",
      "    def __next__(self) -> Any:\n",
      "        \"\"\"Return the next item in the iteration.\n",
      "\n",
      "        Raise StopIteration if there are no more items to return.\n",
      "\n",
      "        Hint: If you have an attribute keeping track of the where the iteration\n",
      "        is currently at in the list, it should be straight-forward to return\n",
      "        the current item, and update the attribute to be the next node in\n",
      "        the list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> iterator = lst.__iter__()\n",
      "        >>> iterator.__next__()\n",
      "        1\n",
      "        >>> iterator.__next__()\n",
      "        2\n",
      "        >>> iterator.__next__()\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self._curr.next is not None:\n",
      "            self._curr = self._curr.next\n",
      "        else:\n",
      "            raise StopIteration\n",
      "        return self._curr\n",
      "99/4:         >>> lst = LinkedList([1, 2, 3])\n",
      "99/5:         >>> iterator = lst.__iter__()\n",
      "99/6:\n",
      "class _Node:\n",
      "    \"\"\"A node in a linked list.\n",
      "\n",
      "    Note that this is considered a \"private class\", one which is only meant\n",
      "    to be used in this module by the LinkedList class, but not by client code.\n",
      "\n",
      "    === Attributes ===\n",
      "    item:\n",
      "        The data stored in this node.\n",
      "    next:\n",
      "        The next node in the list, or None if there are no more nodes.\n",
      "    \"\"\"\n",
      "    item: Any\n",
      "    next: Optional[_Node]\n",
      "\n",
      "    def __init__(self, item: Any) -> None:\n",
      "        \"\"\"Initialize a new node storing <item>, with no next node.\n",
      "        \"\"\"\n",
      "        self.item = item\n",
      "        self.next = None  # Initially pointing to nothing\n",
      "99/7:\n",
      "class LinkedList:\n",
      "    \"\"\"A linked list implementation of the List ADT.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first node in the linked list, or None if the list is empty.\n",
      "    _first: Optional[_Node]\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new empty linked list containing the given items.\n",
      "\n",
      "        Note: this is the inefficient version of the initializer from the\n",
      "        lecture notes. Feel free to replace it with your own version from Lab 5!\n",
      "        \"\"\"\n",
      "        self._first = None\n",
      "        for item in items:\n",
      "            self.append(item)\n",
      "\n",
      "    # ------------------------------------------------------------------------\n",
      "    # Methods from lecture/readings\n",
      "    # ------------------------------------------------------------------------\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this linked list is empty.\n",
      "\n",
      "        >>> LinkedList([]).is_empty()\n",
      "        True\n",
      "        >>> LinkedList([1, 2, 3]).is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list in the form\n",
      "        '[item1 -> item2 -> ... -> item-n]'.\n",
      "\n",
      "        >>> str(LinkedList([1, 2, 3]))\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> str(LinkedList([]))\n",
      "        '[]'\n",
      "        \"\"\"\n",
      "        items = []\n",
      "        curr = self._first\n",
      "        while curr is not None:\n",
      "            items.append(str(curr.item))\n",
      "            curr = curr.next\n",
      "        return '[' + ' -> '.join(items) + ']'\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        \"\"\"\n",
      "        curr = self._first\n",
      "        curr_index = 0\n",
      "\n",
      "        while curr is not None and curr_index < index:\n",
      "            curr = curr.next\n",
      "            curr_index += 1\n",
      "\n",
      "        assert curr is None or curr_index == index\n",
      "\n",
      "        if curr is None:\n",
      "            raise IndexError\n",
      "        else:\n",
      "            return curr.item\n",
      "\n",
      "    def append(self, item: Any) -> None:\n",
      "        \"\"\"Append <item> to the end of this list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 3]'\n",
      "        >>> lst.append(4)\n",
      "        >>> str(lst)\n",
      "        '[1 -> 2 -> 3 -> 4]'\n",
      "        \"\"\"\n",
      "        if self._first is None:\n",
      "            self._first = _Node(item)\n",
      "        else:\n",
      "            curr = self._first\n",
      "            while curr.next is not None:\n",
      "                curr = curr.next\n",
      "            curr.next = _Node(item)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert a the given item at the given index in this list.\n",
      "\n",
      "        Raise IndexError if index > len(self) or index < 0.\n",
      "        Note that adding to the end of the list is okay.\n",
      "\n",
      "        # >>> lst = LinkedList([1, 2, 10, 200])\n",
      "        # >>> lst.insert(2, 300)\n",
      "        # >>> str(lst)\n",
      "        # '[1 -> 2 -> 300 -> 10 -> 200]'\n",
      "        # >>> lst.insert(5, -1)\n",
      "        # >>> str(lst)\n",
      "        # '[1 -> 2 -> 300 -> 10 -> 200 -> -1]'\n",
      "        # >>> lst.insert(100, 2)\n",
      "        # Traceback (most recent call last):\n",
      "        # IndexError\n",
      "        \"\"\"\n",
      "        # Create new node containing the item\n",
      "        new_node = _Node(item)\n",
      "\n",
      "        if index == 0:\n",
      "            self._first, new_node.next = new_node, self._first\n",
      "        else:\n",
      "            # Iterate to (index-1)-th node.\n",
      "            curr = self._first\n",
      "            curr_index = 0\n",
      "            while curr is not None and curr_index < index - 1:\n",
      "                curr = curr.next\n",
      "                curr_index += 1\n",
      "\n",
      "            if curr is None:\n",
      "                raise IndexError\n",
      "            else:\n",
      "                # Update links to insert new node\n",
      "                curr.next, new_node.next = new_node, curr.next\n",
      "\n",
      "    # TODO: Implement this method!\n",
      "    def __iter__(self) -> LinkedListIterator:\n",
      "        \"\"\"Return an iterator for this linked list.\n",
      "\n",
      "        It should be straightforward to initialize the iterator here\n",
      "        (see the class documentation below). Just remember to initialize\n",
      "        it to the first node in this linked list.\n",
      "        \"\"\"\n",
      "        return LinkedListIterator(self._first)\n",
      "99/8:\n",
      "class LinkedListIterator:\n",
      "    \"\"\"An object responsible for iterating through a linked list.\n",
      "\n",
      "    This enables linked lists to be used inside for loops!\n",
      "\n",
      "    >>> lst = LinkedList([1, 2, 3])\n",
      "    >>> for x in lst:\n",
      "    ...     print(x)\n",
      "    ...\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "    \"\"\"\n",
      "    # === Private attributes ===\n",
      "    # _curr:\n",
      "    #   The current node for this iterator.\n",
      "    #   This should start as the first node in a linked list,\n",
      "    #   and update to the \"next\" node every time __next__ is called.\n",
      "    _curr: Optional[_Node]\n",
      "\n",
      "    def __init__(self, first_node: Optional[_Node]) -> None:\n",
      "        \"\"\"Initialize a new linked list iterator with the given node.\"\"\"\n",
      "        self._curr = first_node\n",
      "\n",
      "    def __next__(self) -> Any:\n",
      "        \"\"\"Return the next item in the iteration.\n",
      "\n",
      "        Raise StopIteration if there are no more items to return.\n",
      "\n",
      "        Hint: If you have an attribute keeping track of the where the iteration\n",
      "        is currently at in the list, it should be straight-forward to return\n",
      "        the current item, and update the attribute to be the next node in\n",
      "        the list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> iterator = lst.__iter__()\n",
      "        >>> iterator.__next__()\n",
      "        1\n",
      "        >>> iterator.__next__()\n",
      "        2\n",
      "        >>> iterator.__next__()\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self._curr.next is not None:\n",
      "            self._curr = self._curr.next\n",
      "        else:\n",
      "            raise StopIteration\n",
      "        return self._curr\n",
      "99/9:         >>> lst = LinkedList([1, 2, 3])\n",
      "99/10:         >>> iterator = lst.__iter__()\n",
      "99/11:         >>> iterator.__next__()\n",
      "99/12:\n",
      "class LinkedListIterator:\n",
      "    \"\"\"An object responsible for iterating through a linked list.\n",
      "\n",
      "    This enables linked lists to be used inside for loops!\n",
      "\n",
      "    >>> lst = LinkedList([1, 2, 3])\n",
      "    >>> for x in lst:\n",
      "    ...     print(x)\n",
      "    ...\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "    \"\"\"\n",
      "    # === Private attributes ===\n",
      "    # _curr:\n",
      "    #   The current node for this iterator.\n",
      "    #   This should start as the first node in a linked list,\n",
      "    #   and update to the \"next\" node every time __next__ is called.\n",
      "    _curr: Optional[_Node]\n",
      "\n",
      "    def __init__(self, first_node: Optional[_Node]) -> None:\n",
      "        \"\"\"Initialize a new linked list iterator with the given node.\"\"\"\n",
      "        self._curr = first_node\n",
      "\n",
      "    def __next__(self) -> Any:\n",
      "        \"\"\"Return the next item in the iteration.\n",
      "\n",
      "        Raise StopIteration if there are no more items to return.\n",
      "\n",
      "        Hint: If you have an attribute keeping track of the where the iteration\n",
      "        is currently at in the list, it should be straight-forward to return\n",
      "        the current item, and update the attribute to be the next node in\n",
      "        the list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> iterator = lst.__iter__()\n",
      "        >>> iterator.__next__()\n",
      "        1\n",
      "        >>> iterator.__next__()\n",
      "        2\n",
      "        >>> iterator.__next__()\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self._curr.next is not None:\n",
      "            self._curr = self._curr.next\n",
      "        else:\n",
      "            raise StopIteration\n",
      "        return self._curr.item\n",
      "99/13:         >>> lst = LinkedList([1, 2, 3])\n",
      "99/14:         >>> iterator = lst.__iter__()\n",
      "99/15:         >>> iterator.__next__()\n",
      "99/16:         1\n",
      "99/17:         >>> iterator.__next__()\n",
      "99/18:         2\n",
      "99/19:         >>> iterator.__next__()\n",
      "99/20:         >>> lst = LinkedList([1, 2, 3])\n",
      "99/21:         >>> iterator = lst.__iter__()\n",
      "99/22:\n",
      "class LinkedListIterator:\n",
      "    \"\"\"An object responsible for iterating through a linked list.\n",
      "\n",
      "    This enables linked lists to be used inside for loops!\n",
      "\n",
      "    >>> lst = LinkedList([1, 2, 3])\n",
      "    >>> for x in lst:\n",
      "    ...     print(x)\n",
      "    ...\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "    \"\"\"\n",
      "    # === Private attributes ===\n",
      "    # _curr:\n",
      "    #   The current node for this iterator.\n",
      "    #   This should start as the first node in a linked list,\n",
      "    #   and update to the \"next\" node every time __next__ is called.\n",
      "    _curr: Optional[_Node]\n",
      "\n",
      "    def __init__(self, first_node: Optional[_Node]) -> None:\n",
      "        \"\"\"Initialize a new linked list iterator with the given node.\"\"\"\n",
      "        self._curr = first_node\n",
      "\n",
      "    def __next__(self) -> Any:\n",
      "        \"\"\"Return the next item in the iteration.\n",
      "\n",
      "        Raise StopIteration if there are no more items to return.\n",
      "\n",
      "        Hint: If you have an attribute keeping track of the where the iteration\n",
      "        is currently at in the list, it should be straight-forward to return\n",
      "        the current item, and update the attribute to be the next node in\n",
      "        the list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> iterator = lst.__iter__()\n",
      "        >>> iterator.__next__()\n",
      "        1\n",
      "        >>> iterator.__next__()\n",
      "        2\n",
      "        >>> iterator.__next__()\n",
      "        3\n",
      "        \"\"\"\n",
      "        return self._curr.item\n",
      "        if self._curr.next is not None:\n",
      "            self._curr = self._curr.next\n",
      "        else:\n",
      "            raise StopIteration\n",
      "99/23:         >>> lst = LinkedList([1, 2, 3])\n",
      "99/24:         >>> iterator = lst.__iter__()\n",
      "99/25:         >>> iterator.__next__()\n",
      "99/26:         1\n",
      "99/27:         >>> iterator.__next__()\n",
      "99/28:         2\n",
      "99/29:         >>> iterator.__next__()\n",
      "99/30:\n",
      "class LinkedListIterator:\n",
      "    \"\"\"An object responsible for iterating through a linked list.\n",
      "\n",
      "    This enables linked lists to be used inside for loops!\n",
      "\n",
      "    >>> lst = LinkedList([1, 2, 3])\n",
      "    >>> for x in lst:\n",
      "    ...     print(x)\n",
      "    ...\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "    \"\"\"\n",
      "    # === Private attributes ===\n",
      "    # _curr:\n",
      "    #   The current node for this iterator.\n",
      "    #   This should start as the first node in a linked list,\n",
      "    #   and update to the \"next\" node every time __next__ is called.\n",
      "    _curr: Optional[_Node]\n",
      "\n",
      "    def __init__(self, first_node: Optional[_Node]) -> None:\n",
      "        \"\"\"Initialize a new linked list iterator with the given node.\"\"\"\n",
      "        self._curr = first_node\n",
      "\n",
      "    def __next__(self) -> Any:\n",
      "        \"\"\"Return the next item in the iteration.\n",
      "\n",
      "        Raise StopIteration if there are no more items to return.\n",
      "\n",
      "        Hint: If you have an attribute keeping track of the where the iteration\n",
      "        is currently at in the list, it should be straight-forward to return\n",
      "        the current item, and update the attribute to be the next node in\n",
      "        the list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> iterator = lst.__iter__()\n",
      "        >>> iterator.__next__()\n",
      "        1\n",
      "        >>> iterator.__next__()\n",
      "        2\n",
      "        >>> iterator.__next__()\n",
      "        3\n",
      "        \"\"\"\n",
      "        retItem = self._curr.item\n",
      "        if self._curr.next is not None:\n",
      "            self._curr = self._curr.next\n",
      "        else:\n",
      "            raise StopIteration\n",
      "        return retItem\n",
      "99/31:         >>> lst = LinkedList([1, 2, 3])\n",
      "99/32:         >>> iterator = lst.__iter__()\n",
      "99/33:         >>> iterator.__next__()\n",
      "99/34:         1\n",
      "99/35:         >>> iterator.__next__()\n",
      "99/36:         2\n",
      "99/37:         >>> iterator.__next__()\n",
      "99/38:\n",
      "class LinkedListIterator:\n",
      "    \"\"\"An object responsible for iterating through a linked list.\n",
      "\n",
      "    This enables linked lists to be used inside for loops!\n",
      "\n",
      "    >>> lst = LinkedList([1, 2, 3])\n",
      "    >>> for x in lst:\n",
      "    ...     print(x)\n",
      "    ...\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "    \"\"\"\n",
      "    # === Private attributes ===\n",
      "    # _curr:\n",
      "    #   The current node for this iterator.\n",
      "    #   This should start as the first node in a linked list,\n",
      "    #   and update to the \"next\" node every time __next__ is called.\n",
      "    _curr: Optional[_Node]\n",
      "\n",
      "    def __init__(self, first_node: Optional[_Node]) -> None:\n",
      "        \"\"\"Initialize a new linked list iterator with the given node.\"\"\"\n",
      "        self._curr = first_node\n",
      "\n",
      "    def __next__(self) -> Any:\n",
      "        \"\"\"Return the next item in the iteration.\n",
      "\n",
      "        Raise StopIteration if there are no more items to return.\n",
      "\n",
      "        Hint: If you have an attribute keeping track of the where the iteration\n",
      "        is currently at in the list, it should be straight-forward to return\n",
      "        the current item, and update the attribute to be the next node in\n",
      "        the list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> iterator = lst.__iter__()\n",
      "        >>> iterator.__next__()\n",
      "        1\n",
      "        >>> iterator.__next__()\n",
      "        2\n",
      "        >>> iterator.__next__()\n",
      "        3\n",
      "        \"\"\"\n",
      "        retItem = self._curr.item\n",
      "        if self._curr is not None:\n",
      "            self._curr = self._curr.next\n",
      "        else:\n",
      "            raise StopIteration\n",
      "        return retItem\n",
      "99/39:         >>> lst = LinkedList([1, 2, 3])\n",
      "99/40:         >>> iterator = lst.__iter__()\n",
      "99/41:         >>> iterator.__next__()\n",
      "99/42:         1\n",
      "99/43:         >>> iterator.__next__()\n",
      "99/44:         2\n",
      "99/45:         >>> iterator.__next__()\n",
      "99/46:         3\n",
      "99/47:     >>> lst = LinkedList([1, 2, 3])\n",
      "99/48:     >>> for x in lst:\n",
      "99/49:     >>> for x in lst:\n",
      "99/50:\n",
      "if __name__ == '__main__':\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "99/51:\n",
      "class LinkedListIterator:\n",
      "    \"\"\"An object responsible for iterating through a linked list.\n",
      "\n",
      "    This enables linked lists to be used inside for loops!\n",
      "\n",
      "    >>> lst = LinkedList([1, 2, 3])\n",
      "    >>> for x in lst:\n",
      "    ...     print(x)\n",
      "    ...\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "    \"\"\"\n",
      "    # === Private attributes ===\n",
      "    # _curr:\n",
      "    #   The current node for this iterator.\n",
      "    #   This should start as the first node in a linked list,\n",
      "    #   and update to the \"next\" node every time __next__ is called.\n",
      "    _curr: Optional[_Node]\n",
      "\n",
      "    def __init__(self, first_node: Optional[_Node]) -> None:\n",
      "        \"\"\"Initialize a new linked list iterator with the given node.\"\"\"\n",
      "        self._curr = first_node\n",
      "\n",
      "    def __next__(self) -> Any:\n",
      "        \"\"\"Return the next item in the iteration.\n",
      "\n",
      "        Raise StopIteration if there are no more items to return.\n",
      "\n",
      "        Hint: If you have an attribute keeping track of the where the iteration\n",
      "        is currently at in the list, it should be straight-forward to return\n",
      "        the current item, and update the attribute to be the next node in\n",
      "        the list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> iterator = lst.__iter__()\n",
      "        >>> iterator.__next__()\n",
      "        1\n",
      "        >>> iterator.__next__()\n",
      "        2\n",
      "        >>> iterator.__next__()\n",
      "        3\n",
      "        \"\"\"\n",
      "        retItem = self._curr.item\n",
      "        if self._curr is not None:\n",
      "            self._curr = self._curr.next\n",
      "            return retItem\n",
      "        else:\n",
      "            raise StopIteration\n",
      "99/52:         >>> iterator = lst.__iter__()\n",
      "99/53:         >>> lst = LinkedList([1, 2, 3])\n",
      "99/54:         >>> iterator = lst.__iter__()\n",
      "99/55:         >>> iterator.__next__()\n",
      "99/56:         1\n",
      "99/57:         >>> iterator.__next__()\n",
      "99/58:         2\n",
      "99/59:         >>> iterator.__next__()\n",
      "99/60:         3\n",
      "99/61:     >>> lst = LinkedList([1, 2, 3])\n",
      "99/62:     >>> for x in lst:\n",
      "99/63:\n",
      "if __name__ == '__main__':\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "99/64:\n",
      "class LinkedListIterator:\n",
      "    \"\"\"An object responsible for iterating through a linked list.\n",
      "\n",
      "    This enables linked lists to be used inside for loops!\n",
      "\n",
      "    >>> lst = LinkedList([1, 2, 3])\n",
      "    >>> for x in lst:\n",
      "    ...     print(x)\n",
      "    ...\n",
      "    1\n",
      "    2\n",
      "    3\n",
      "    \"\"\"\n",
      "    # === Private attributes ===\n",
      "    # _curr:\n",
      "    #   The current node for this iterator.\n",
      "    #   This should start as the first node in a linked list,\n",
      "    #   and update to the \"next\" node every time __next__ is called.\n",
      "    _curr: Optional[_Node]\n",
      "\n",
      "    def __init__(self, first_node: Optional[_Node]) -> None:\n",
      "        \"\"\"Initialize a new linked list iterator with the given node.\"\"\"\n",
      "        self._curr = first_node\n",
      "\n",
      "    def __next__(self) -> Any:\n",
      "        \"\"\"Return the next item in the iteration.\n",
      "\n",
      "        Raise StopIteration if there are no more items to return.\n",
      "\n",
      "        Hint: If you have an attribute keeping track of the where the iteration\n",
      "        is currently at in the list, it should be straight-forward to return\n",
      "        the current item, and update the attribute to be the next node in\n",
      "        the list.\n",
      "\n",
      "        >>> lst = LinkedList([1, 2, 3])\n",
      "        >>> iterator = lst.__iter__()\n",
      "        >>> iterator.__next__()\n",
      "        1\n",
      "        >>> iterator.__next__()\n",
      "        2\n",
      "        >>> iterator.__next__()\n",
      "        3\n",
      "        \"\"\"\n",
      "        retItem = self._curr\n",
      "        if self._curr is not None:\n",
      "            self._curr = self._curr.next\n",
      "            return retItem.item\n",
      "        else:\n",
      "            raise StopIteration\n",
      "99/65:\n",
      "if __name__ == '__main__':\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "99/66:     >>> lst = LinkedList([1, 2, 3])\n",
      "99/67:     >>> for x in lst:\n",
      "99/68:     >>> t = [i for i in lst]\n",
      "99/69:     >>> print(t)\n",
      "100/1: from __future__ import annotations\n",
      "100/2: from typing import Any, Callable, Optional\n",
      "100/3: from itertools import combinations\n",
      "100/4:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "     def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self._first, self._rest]\n",
      "100/6:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "     def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self._first, self._rest]\n",
      "        pass\n",
      "100/8:\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self._first, self._rest]\n",
      "        pass\n",
      "100/9:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self._first, self._rest]\n",
      "        pass\n",
      "100/10:         >>> lst1 = RecursiveList([])\n",
      "100/11:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/12:         >>> [lst2._first, lst2._rest]\n",
      "100/13:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/14:         >>> lst2\n",
      "100/15:         >>> len(lst2)\n",
      "100/16:         >>> lst2[1]\n",
      "100/17:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self[i] for i in range(len(self))]\n",
      "        return combinations(x, range(len(x)))\n",
      "100/18:         >>> lst1 = RecursiveList([])\n",
      "100/19:         >>> selections1 = lst1.selections()\n",
      "100/20:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self[i] for i in range(len(self))]\n",
      "        selections = [combinations(x, l) for l in range(len(x))]\n",
      "        return selections\n",
      "100/21:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/22:         >>> lst2.selections()\n",
      "100/23:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self[i] for i in range(len(self))]\n",
      "        selections = [RecursiveList(combinations(x, l)) for l in range(len(x))]\n",
      "        return selections\n",
      "100/24:         >>> lst1 = RecursiveList([])\n",
      "100/25:         >>> selections1 = lst1.selections()\n",
      "100/26:         >>> len(selections1)\n",
      "100/27:         1\n",
      "100/28:         >>> selections1[0].is_empty()\n",
      "100/29:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/30:         >>> lst2.selections()\n",
      "100/31:\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self[i] for i in range(len(self))]\n",
      "        selections = [RecursiveList(list(combinations(x, l))) for l in range(len(x))]\n",
      "        return selections\n",
      "100/32:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/33:         >>> lst2.selections()\n",
      "100/34:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self[i] for i in range(len(self))]\n",
      "        selections = [RecursiveList(list(combinations(x, l))) for l in range(len(x))]\n",
      "        return selections\n",
      "100/35:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/36:         >>> lst2.selections()\n",
      "100/37:         >>> len(lst2.selections())\n",
      "100/38:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self[i] for i in range(len(self))]\n",
      "        c = [combinations(x, l) for l in range(len(x))]\n",
      "        \n",
      "        return selections\n",
      "100/39:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/40:         >>> lst2.selections()\n",
      "100/41:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self[i] for i in range(len(self))]\n",
      "        c = [combinations(x, l) for l in range(len(x))]\n",
      "        \n",
      "        return c\n",
      "100/42:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/43:         >>> lst2.selections()\n",
      "100/44:         >>> lst2[0]\n",
      "100/45:         >>> lst2\n",
      "100/46:         >>> lst2.selections()[0]\n",
      "100/47:         >>> print(lst2.selections()[0])\n",
      "100/48:         >>> len(lst2.selections()[0])\n",
      "100/49:         >>> list(lst2.selections()[0])\n",
      "100/50:         >>> list(lst2.selections())[0]\n",
      "100/51:         >>> list(lst2.selections()[[1]])\n",
      "100/52:         >>> list(lst2.selections()[1])\n",
      "100/53:         >>> list(lst2.selections()[2])\n",
      "100/54:         >>> list(lst2.selections()[3])\n",
      "100/55:         >>> list(lst2.selections()[2])\n",
      "100/56:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> list(lst2.selections()[2])\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        x = [self[i] for i in range(len(self))]\n",
      "        c = [list(combinations(x, l)) for l in range(len(x))]\n",
      "\n",
      "        return c\n",
      "100/57:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/58:         >>> lst2.selections()\n",
      "100/59:         >>> len(lst2)\n",
      "100/60:         >>> [[comb for comb in sublen] for sublen in lst2.selections()]\n",
      "100/61:         >>> [comb for comb in sublen for sublen in lst2.selections()]\n",
      "100/62:         >>> [comb for sublen in lst2.selections() for comb in sublen]\n",
      "100/63:         >>> [comb for sublen in lst2.selections() for comb in sublen][1]\n",
      "100/64:         >>> len([comb for sublen in lst2.selections() for comb in sublen][1])\n",
      "100/65:         >>> [comb for sublen in lst2.selections() for comb in sublen]\n",
      "100/66:         >>> [comb for sublen in lst2.selections() for comb in sublen].map(RecursiveList)\n",
      "100/67:         >>> map(RecursiveList, [comb for sublen in lst2.selections() for comb in sublen])\n",
      "100/68:         >>> list(map(RecursiveList, [comb for sublen in lst2.selections() for comb in sublen]))\n",
      "100/69:         >>> [comb for sublen in lst2.selections() for comb in sublen]\n",
      "100/70:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2)\n",
      "        >>> [comb for sublen in lst2.selections() for comb in sublen]\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        xtract = [self[i] for i in range(len(self))]\n",
      "        combs = [list(combinations(xtract, l)) for l in range(len(xtract)+1)]\n",
      "        flat = [comb for combtype in combs for comb in combtype]\n",
      "        \n",
      "        return c\n",
      "100/71:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/72:         >>> lst2.selections()\n",
      "100/73:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2)\n",
      "        >>> [comb for sublen in lst2.selections() for comb in sublen]\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        xtract = [self[i] for i in range(len(self))]\n",
      "        combs = [list(combinations(xtract, l)) for l in range(len(xtract)+1)]\n",
      "        flat = [comb for combtype in combs for comb in combtype]\n",
      "\n",
      "        return flat\n",
      "100/74:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/75:         >>> lst2.selections()\n",
      "100/76:         >>> len(lst2)\n",
      "100/77:         >>> [comb for sublen in lst2.selections() for comb in sublen]\n",
      "100/78:         >>> len(lst2.selections())\n",
      "100/79:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        xtract = [self[i] for i in range(len(self))]\n",
      "        combs = [list(combinations(xtract, l)) for l in range(len(xtract)+1)]\n",
      "        flat = [RecursiveList(comb) for combtype in combs for comb in combtype]\n",
      "\n",
      "        return flat\n",
      "100/80:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/81:         >>> lst2.selections()\n",
      "100/82:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        xtract = [self[i] for i in range(len(self))]\n",
      "        combs = [list(combinations(xtract, l)) for l in range(len(xtract)+1)]\n",
      "        flat = [RecursiveList(list(comb)) for combtype in combs for comb in combtype]\n",
      "\n",
      "        return flat\n",
      "100/83:\n",
      "if __name__ == '__main__':\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "100/84:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/85:         >>> lst2.selections()\n",
      "100/86:         >>> len(lst2.selections())\n",
      "100/87:         >>> lst1 = RecursiveList([])\n",
      "100/88:         >>> selections1 = lst1.selections()\n",
      "100/89:         >>> len(selections1)\n",
      "100/90:         1\n",
      "100/91:         >>> selections1[0].is_empty()\n",
      "100/92:         True\n",
      "100/93:         >>> lst2 = RecursiveList([1, 2, 3])\n",
      "100/94:         >>> lst2.selections()\n",
      "100/95:         >>> len(lst2.selections())\n",
      "100/96:         8\n",
      "100/97:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        xtract = [self[i] for i in range(len(self))]\n",
      "        combs = [list(combinations(xtract, l)) for l in range(len(xtract)+1)]\n",
      "        flat = [RecursiveList(list(comb)) for combtype in combs for comb in combtype]\n",
      "\n",
      "        return flat\n",
      "\n",
      "    def permutations(self) -> List[RecursiveList]:\n",
      "        return permutations(self)\n",
      "100/98:         >>> lst = RecursiveList([1, 2, 3])\n",
      "100/99:         >>> lst.permutations()\n",
      "100/100: from itertools import combinations, permutations\n",
      "100/101:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        xtract = [self[i] for i in range(len(self))]\n",
      "        combs = [list(combinations(xtract, l)) for l in range(len(xtract)+1)]\n",
      "        flat = [RecursiveList(list(comb)) for combtype in combs for comb in combtype]\n",
      "\n",
      "        return flat\n",
      "\n",
      "    def permutations(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all permutations of this list\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.permutations()\n",
      "\n",
      "        \"\"\"\n",
      "        return permutations(self)\n",
      "100/102:         >>> lst = RecursiveList([1, 2, 3])\n",
      "100/103:         >>> lst.permutations()\n",
      "100/104:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        xtract = [self[i] for i in range(len(self))]\n",
      "        combs = [list(combinations(xtract, l)) for l in range(len(xtract)+1)]\n",
      "        flat = [RecursiveList(list(comb)) for combtype in combs for comb in combtype]\n",
      "\n",
      "        return flat\n",
      "\n",
      "    def permutations(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all permutations of this list\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.permutations()\n",
      "\n",
      "        \"\"\"\n",
      "        return list(permutations(self))\n",
      "100/105:         >>> lst = RecursiveList([1, 2, 3])\n",
      "100/106:         >>> lst.permutations()\n",
      "100/107:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        xtract = [self[i] for i in range(len(self))]\n",
      "        combs = [list(combinations(xtract, l)) for l in range(len(xtract)+1)]\n",
      "        flat = [RecursiveList(list(comb)) for combtype in combs for comb in combtype]\n",
      "\n",
      "        return flat\n",
      "\n",
      "    def permutations(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all permutations of this list\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.permutations()\n",
      "\n",
      "        \"\"\"\n",
      "        return [RecursiveList(i) for i in list(permutations(self))]\n",
      "100/108:         >>> lst = RecursiveList([1, 2, 3])\n",
      "100/109:         >>> lst.permutations()\n",
      "100/110:\n",
      "class RecursiveList:\n",
      "    \"\"\"A recursive implementation of the List ADT.\n",
      "\n",
      "    Note the structural differences between this implementation and the\n",
      "    node-based implementation of linked lists from the past few weeks.\n",
      "    Even though both classes have the same public interface,\n",
      "    how they implement their methods are quite different!\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # _first:\n",
      "    #     The first item in the list.\n",
      "    # _rest:\n",
      "    #     A list containing the items that come after\n",
      "    #     the first one.\n",
      "    _first: Optional[Any]\n",
      "    _rest: Optional[RecursiveList]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # _first is None if and only if _rest is None.\n",
      "    #     This represents an empty list.\n",
      "\n",
      "    def __init__(self, items: list) -> None:\n",
      "        \"\"\"Initialize a new list containing the given items.\n",
      "\n",
      "        The first node in the list contains the first item in <items>.\n",
      "        \"\"\"\n",
      "        if items == []:\n",
      "            self._first = None\n",
      "            self._rest = None\n",
      "        else:\n",
      "            self._first = items[0]\n",
      "            self._rest = RecursiveList(items[1:])\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return whether this list is empty.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> lst1.is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._first is None\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> str(lst) # Equivalent to lst.__str__()\n",
      "        '1 -> 2 -> 3'\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        elif self._rest.is_empty():\n",
      "            return str(self._first)\n",
      "        else:\n",
      "            return str(self._first) + ' -> ' + str(self._rest)\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of elements in this list.\n",
      "\n",
      "        >>> lst = RecursiveList([])\n",
      "        >>> len(lst) # Equivalent to lst.__len__()\n",
      "        0\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst = RecursiveList([0])\n",
      "        >>> len(lst)\n",
      "        1\n",
      "        \"\"\"\n",
      "        counter = 0\n",
      "        if self._rest is not None:\n",
      "            counter += len(self._rest) + 1\n",
      "        return counter\n",
      "\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether <item> is in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> 2 in lst # Equivalent to lst.__contains__(2)\n",
      "        True\n",
      "        >>> 4 in lst\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            return True\n",
      "        else:\n",
      "            return self._rest.__contains__(item)\n",
      "            # Equivalently, item in self._rest\n",
      "\n",
      "    def count(self, item: Any) -> int:\n",
      "        \"\"\"Return the number of times <item> occurs in this list.\n",
      "\n",
      "        Use == to compare items.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 1, 3, 2, 1])\n",
      "        >>> lst.count(1)\n",
      "        3\n",
      "        >>> lst.count(2)\n",
      "        2\n",
      "        >>> lst.count(3)\n",
      "        1\n",
      "        \"\"\"\n",
      "        matches = 0\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._first == item:\n",
      "            matches += 1\n",
      "        matches += self._rest.count(item)\n",
      "        return matches\n",
      "\n",
      "    def __getitem__(self, index: int) -> Any:\n",
      "        \"\"\"Return the item at position <index> in this list.\n",
      "        len(lst) is equivalent to lst.__getitem__(0).\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "        >>> lst = RecursiveList([4, 2, 7])\n",
      "        >>> lst[0]\n",
      "        4\n",
      "        >>> lst[1]\n",
      "        2\n",
      "        >>> lst[2]\n",
      "        7\n",
      "        >>> lst[3]\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            return self._first\n",
      "        while index > 0:\n",
      "            return self._rest.__getitem__(index - 1)\n",
      "\n",
      "    ###########################################################################\n",
      "    # Mutating methods: these methods modify the the list\n",
      "    ###########################################################################\n",
      "    def __setitem__(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Store item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if index is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst[0] = 100 # Equivalent to lst.__setitem__(0, 100)\n",
      "        >>> lst[1] = 200\n",
      "        >>> lst[2] = 300\n",
      "        >>> lst[3] = 400\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        >>> str(lst)\n",
      "        '100 -> 200 -> 300'\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            self._first = item\n",
      "            return self\n",
      "        while index > 0:\n",
      "            return self._rest.__setitem__(index - 1, item)\n",
      "\n",
      "    def insert_first(self, item: object) -> None:\n",
      "        \"\"\"Insert item at the front of this list.\n",
      "\n",
      "        This should work even if this list is empty.\n",
      "        \"\"\"\n",
      "        self._first = item\n",
      "\n",
      "    def pop(self, index: int) -> Any:\n",
      "        \"\"\"Remove and return the item at position <index> in this list.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise IndexError if <index> is >= the length of this list.\n",
      "\n",
      "        >>> lst = RecursiveList([1, 2, 3, 4])\n",
      "        >>> lst.pop(2)\n",
      "        3\n",
      "        >>> str(lst)\n",
      "        '1 -> 2 -> 4'\n",
      "        >>> lst.pop(1)\n",
      "        2\n",
      "        >>> str(lst)\n",
      "        '1 -> 4'\n",
      "        >>> lst.pop(0)\n",
      "        1\n",
      "        >>> lst.pop(1)\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        IndexError\n",
      "        \"\"\"\n",
      "        if index >= len(self):\n",
      "            raise IndexError\n",
      "        if index == 0:\n",
      "            removed = self._first\n",
      "            self._first = self._rest\n",
      "            self._rest = RecursiveList([])\n",
      "            return removed\n",
      "        else:\n",
      "            return self._rest.pop(index - 1)\n",
      "\n",
      "    def insert(self, index: int, item: Any) -> None:\n",
      "        \"\"\"Insert the given item in to this list at position <index>.\n",
      "\n",
      "        Precondition: index >= 0.\n",
      "        Raise an IndexError if index is > the length of the list.\n",
      "        Note that it is possible to add to the end of the list\n",
      "        (when index == len(self)).\n",
      "\n",
      "        >>> lst = RecursiveList(['c'])\n",
      "        >>> lst.insert(0, 'a')\n",
      "        >>> str(lst)\n",
      "        'a -> c'\n",
      "        >>> lst.insert(1, 'b')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c'\n",
      "        >>> len(lst)\n",
      "        3\n",
      "        >>> lst.insert(3, 'd')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d'\n",
      "        >>> lst.insert(4, 'e')\n",
      "        >>> str(lst)\n",
      "        'a -> b -> c -> d -> e'\n",
      "        \"\"\"\n",
      "        if index > len(self):\n",
      "            raise IndexError\n",
      "        elif index == 0:\n",
      "            self._rest = RecursiveList([self._first])\n",
      "            self._first = item\n",
      "        else:\n",
      "            self._rest.insert(index - 1, item)\n",
      "\n",
      "    def map(self, f: Callable[[Any], Any]) -> RecursiveList:\n",
      "        \"\"\"Return a new recursive list storing the items that are\n",
      "        obtained by applying f to each item in this recursive list.\n",
      "\n",
      "        >>> func = str.upper\n",
      "        >>> func('hi')\n",
      "        'HI'\n",
      "        >>> lst = RecursiveList(['Hello', 'Goodbye'])\n",
      "        >>> str(lst.map(func))\n",
      "        'HELLO -> GOODBYE'\n",
      "        >>> str(lst.map(len))\n",
      "        '5 -> 7'\n",
      "        \"\"\"\n",
      "        return RecursiveList([f(self[i]) for i in range(len(self))])\n",
      "\n",
      "    def selections(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all selections from this list.\n",
      "\n",
      "        You can return the selections in any order.\n",
      "\n",
      "        >>> lst1 = RecursiveList([])\n",
      "        >>> selections1 = lst1.selections()\n",
      "        >>> len(selections1)\n",
      "        1\n",
      "        >>> selections1[0].is_empty()\n",
      "        True\n",
      "        >>> lst2 = RecursiveList([1, 2, 3])\n",
      "        >>> lst2.selections()\n",
      "        >>> len(lst2.selections())\n",
      "        8\n",
      "        \"\"\"\n",
      "        xtract = [self[i] for i in range(len(self))]\n",
      "        combs = [list(combinations(xtract, l)) for l in range(len(xtract)+1)]\n",
      "        flat = [RecursiveList(list(comb)) for combtype in combs for comb in combtype]\n",
      "\n",
      "        return flat\n",
      "\n",
      "    def permutations(self) -> List[RecursiveList]:\n",
      "        \"\"\"Return a list of all permutations of this list\n",
      "        >>> lst = RecursiveList([1, 2, 3])\n",
      "        >>> lst.permutations()\n",
      "\n",
      "        \"\"\"\n",
      "        return [RecursiveList(list(i)) for i in list(permutations(self))]\n",
      "100/111:         >>> lst = RecursiveList([1, 2, 3])\n",
      "100/112:         >>> lst.permutations()\n",
      "100/113:         >>> len(lst.permutations()) == 6\n",
      "100/114:         >>> RecursiveList([3, 2, 1]) in lst.permutations()\n",
      "100/115:         True\n",
      "100/116:         >>> RecursiveList([2, 3, 1]) in lst.permutations()\n",
      "100/117:         True\n",
      "100/118:         >>> RecursiveList([1, 3, 2]) in lst.permutations()\n",
      "100/119:         >>> lst.permutations()[0]\n",
      "100/120:         >>> lst.permutations()[0].__str__()\n",
      "100/121:         >>> lst.permutations()[1].__str__()\n",
      "100/122:         >>> lst.permutations()[2].__str__()\n",
      "100/123:         >>> lst.permutations()[3].__str__()\n",
      "100/124:         >>> lst.permutations()[4].__str__()\n",
      "100/125:         >>> lst.permutations()[5].__str__()\n",
      "101/1: from __future__ import annotations\n",
      "101/2: from typing import Any, List, Optional\n",
      "101/3:\n",
      "class Tree:\n",
      "    \"\"\"A recursive tree data structure.\n",
      "\n",
      "    Note the relationship between this class and RecursiveList; the only major\n",
      "    difference is that _rest has been replaced by _subtrees to handle multiple\n",
      "    recursive sub-parts.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # The item stored at this tree's root, or None if the tree is empty.\n",
      "    _root: Optional[Any]\n",
      "    # The list of all subtrees of this tree.\n",
      "    _subtrees: List[Tree]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # - If self._root is None then self._subtrees is an empty list.\n",
      "    #   This setting of attributes represents an empty Tree.\n",
      "    #\n",
      "    #   Note: self._subtrees may be empty when self._root is not None.\n",
      "    #   This setting of attributes represents a tree consisting of just one\n",
      "    #   node.\n",
      "\n",
      "    def __init__(self, root: Any, subtrees: List[Tree]) -> None:\n",
      "        \"\"\"Initialize a new Tree with the given root value and subtrees.\n",
      "\n",
      "        If <root> is None, the tree is empty.\n",
      "        Precondition: if <root> is None, then <subtrees> is empty.\n",
      "        \"\"\"\n",
      "        self._root = root\n",
      "        self._subtrees = subtrees\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return True if this tree is empty.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> t1.is_empty()\n",
      "        True\n",
      "        >>> t2 = Tree(3, [])\n",
      "        >>> t2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._root is None\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of items contained in this tree.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> len(t1)\n",
      "        0\n",
      "        >>> t2 = Tree(3, [Tree(4, []), Tree(1, [])])\n",
      "        >>> len(t2)\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        else:\n",
      "            size = 1  # count the root\n",
      "            for subtree in self._subtrees:\n",
      "                size += subtree.__len__()  # could also do len(subtree) here\n",
      "            return size\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def num_positives(self) -> int:\n",
      "        \"\"\"Return the number of positive integers in this tree.\n",
      "\n",
      "        Precondition: all items in this tree are integers.\n",
      "\n",
      "        Remember, 0 is *not* positive.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.num_positives()\n",
      "        1\n",
      "        >>> t2 = Tree(-10, [])\n",
      "        >>> t2.num_positives()\n",
      "        0\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.num_positives()\n",
      "        2\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return 1 if self._root > 0 else 0\n",
      "        else:\n",
      "            count = 0\n",
      "            for subtree in self._subtrees:\n",
      "                count += subtree.num_positives()\n",
      "            return count\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def maximum(self: Tree) -> int:\n",
      "        \"\"\"Return the maximum item stored in this tree.\n",
      "\n",
      "        Return 0 if this tree is empty.\n",
      "\n",
      "        Precondition: all values in this tree are positive integers.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.maximum()\n",
      "        17\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.maximum()\n",
      "        10\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.maximum() ...\n",
      "        #     ...\n",
      "        pass\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def height(self: Tree) -> int:\n",
      "        \"\"\"Return the height of this tree.\n",
      "\n",
      "        Please refer to the prep readings for the definition of tree height.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.height()\n",
      "        1\n",
      "        >>> t2 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t2.height()\n",
      "        2\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.height() ...\n",
      "        #     ...\n",
      "        pass\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether this tree contains <item>.\n",
      "\n",
      "        >>> t = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t.__contains__(-30)  # Could also write -30 in t.\n",
      "        True\n",
      "        >>> t.__contains__(148)\n",
      "        False\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.__contains__(...) ...\n",
      "        #     ...\n",
      "        pass\n",
      "101/4:         >>> t1 = Tree(17, [])\n",
      "101/5:         >>> t1.num_positives()\n",
      "101/6:         1\n",
      "101/7:         >>> t2 = Tree(-10, [])\n",
      "101/8:         >>> t2.num_positives()\n",
      "101/9:         0\n",
      "101/10:         >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "101/11:         >>> t3.num_positives()\n",
      "101/12:\n",
      "class Tree:\n",
      "    \"\"\"A recursive tree data structure.\n",
      "\n",
      "    Note the relationship between this class and RecursiveList; the only major\n",
      "    difference is that _rest has been replaced by _subtrees to handle multiple\n",
      "    recursive sub-parts.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # The item stored at this tree's root, or None if the tree is empty.\n",
      "    _root: Optional[Any]\n",
      "    # The list of all subtrees of this tree.\n",
      "    _subtrees: List[Tree]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # - If self._root is None then self._subtrees is an empty list.\n",
      "    #   This setting of attributes represents an empty Tree.\n",
      "    #\n",
      "    #   Note: self._subtrees may be empty when self._root is not None.\n",
      "    #   This setting of attributes represents a tree consisting of just one\n",
      "    #   node.\n",
      "\n",
      "    def __init__(self, root: Any, subtrees: List[Tree]) -> None:\n",
      "        \"\"\"Initialize a new Tree with the given root value and subtrees.\n",
      "\n",
      "        If <root> is None, the tree is empty.\n",
      "        Precondition: if <root> is None, then <subtrees> is empty.\n",
      "        \"\"\"\n",
      "        self._root = root\n",
      "        self._subtrees = subtrees\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return True if this tree is empty.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> t1.is_empty()\n",
      "        True\n",
      "        >>> t2 = Tree(3, [])\n",
      "        >>> t2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._root is None\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of items contained in this tree.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> len(t1)\n",
      "        0\n",
      "        >>> t2 = Tree(3, [Tree(4, []), Tree(1, [])])\n",
      "        >>> len(t2)\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        else:\n",
      "            size = 1  # count the root\n",
      "            for subtree in self._subtrees:\n",
      "                size += subtree.__len__()  # could also do len(subtree) here\n",
      "            return size\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def num_positives(self) -> int:\n",
      "        \"\"\"Return the number of positive integers in this tree.\n",
      "\n",
      "        Precondition: all items in this tree are integers.\n",
      "\n",
      "        Remember, 0 is *not* positive.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.num_positives()\n",
      "        1\n",
      "        >>> t2 = Tree(-10, [])\n",
      "        >>> t2.num_positives()\n",
      "        0\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.num_positives()\n",
      "        2\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return 1 if self._root > 0 else 0\n",
      "        else:\n",
      "            count = 1\n",
      "            for subtree in self._subtrees:\n",
      "                count += subtree.num_positives()\n",
      "            return count\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def maximum(self: Tree) -> int:\n",
      "        \"\"\"Return the maximum item stored in this tree.\n",
      "\n",
      "        Return 0 if this tree is empty.\n",
      "\n",
      "        Precondition: all values in this tree are positive integers.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.maximum()\n",
      "        17\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.maximum()\n",
      "        10\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.maximum() ...\n",
      "        #     ...\n",
      "        pass\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def height(self: Tree) -> int:\n",
      "        \"\"\"Return the height of this tree.\n",
      "\n",
      "        Please refer to the prep readings for the definition of tree height.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.height()\n",
      "        1\n",
      "        >>> t2 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t2.height()\n",
      "        2\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.height() ...\n",
      "        #     ...\n",
      "        pass\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether this tree contains <item>.\n",
      "\n",
      "        >>> t = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t.__contains__(-30)  # Could also write -30 in t.\n",
      "        True\n",
      "        >>> t.__contains__(148)\n",
      "        False\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.__contains__(...) ...\n",
      "        #     ...\n",
      "        pass\n",
      "101/13:         >>> t1 = Tree(17, [])\n",
      "101/14:         >>> t1.num_positives()\n",
      "101/15:         1\n",
      "101/16:         >>> t2 = Tree(-10, [])\n",
      "101/17:         >>> t2.num_positives()\n",
      "101/18:         0\n",
      "101/19:         >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "101/20:         >>> t3.num_positives()\n",
      "101/21:         2\n",
      "101/22:\n",
      "class Tree:\n",
      "    \"\"\"A recursive tree data structure.\n",
      "\n",
      "    Note the relationship between this class and RecursiveList; the only major\n",
      "    difference is that _rest has been replaced by _subtrees to handle multiple\n",
      "    recursive sub-parts.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # The item stored at this tree's root, or None if the tree is empty.\n",
      "    _root: Optional[Any]\n",
      "    # The list of all subtrees of this tree.\n",
      "    _subtrees: List[Tree]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # - If self._root is None then self._subtrees is an empty list.\n",
      "    #   This setting of attributes represents an empty Tree.\n",
      "    #\n",
      "    #   Note: self._subtrees may be empty when self._root is not None.\n",
      "    #   This setting of attributes represents a tree consisting of just one\n",
      "    #   node.\n",
      "\n",
      "    def __init__(self, root: Any, subtrees: List[Tree]) -> None:\n",
      "        \"\"\"Initialize a new Tree with the given root value and subtrees.\n",
      "\n",
      "        If <root> is None, the tree is empty.\n",
      "        Precondition: if <root> is None, then <subtrees> is empty.\n",
      "        \"\"\"\n",
      "        self._root = root\n",
      "        self._subtrees = subtrees\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return True if this tree is empty.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> t1.is_empty()\n",
      "        True\n",
      "        >>> t2 = Tree(3, [])\n",
      "        >>> t2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._root is None\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of items contained in this tree.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> len(t1)\n",
      "        0\n",
      "        >>> t2 = Tree(3, [Tree(4, []), Tree(1, [])])\n",
      "        >>> len(t2)\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        else:\n",
      "            size = 1  # count the root\n",
      "            for subtree in self._subtrees:\n",
      "                size += subtree.__len__()  # could also do len(subtree) here\n",
      "            return size\n",
      "\n",
      "    def num_positives(self) -> int:\n",
      "        \"\"\"Return the number of positive integers in this tree.\n",
      "\n",
      "        Precondition: all items in this tree are integers.\n",
      "\n",
      "        Remember, 0 is *not* positive.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.num_positives()\n",
      "        1\n",
      "        >>> t2 = Tree(-10, [])\n",
      "        >>> t2.num_positives()\n",
      "        0\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.num_positives()\n",
      "        2\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return 1 if self._root > 0 else 0\n",
      "        else:\n",
      "            count = 1\n",
      "            for subtree in self._subtrees:\n",
      "                count += subtree.num_positives()\n",
      "            return count\n",
      "\n",
      "    def maximum(self: Tree) -> int:\n",
      "        \"\"\"Return the maximum item stored in this tree.\n",
      "\n",
      "        Return 0 if this tree is empty.\n",
      "\n",
      "        Precondition: all values in this tree are positive integers.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.maximum()\n",
      "        17\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.maximum()\n",
      "        10\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return self._root\n",
      "        else:\n",
      "            curmax = self._root\n",
      "            for subtree in self._subtrees:\n",
      "                curmax = max(curmax, subtree.maximum())\n",
      "            return curmax\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def height(self: Tree) -> int:\n",
      "        \"\"\"Return the height of this tree.\n",
      "\n",
      "        Please refer to the prep readings for the definition of tree height.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.height()\n",
      "        1\n",
      "        >>> t2 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t2.height()\n",
      "        2\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.height() ...\n",
      "        #     ...\n",
      "        pass\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether this tree contains <item>.\n",
      "\n",
      "        >>> t = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t.__contains__(-30)  # Could also write -30 in t.\n",
      "        True\n",
      "        >>> t.__contains__(148)\n",
      "        False\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.__contains__(...) ...\n",
      "        #     ...\n",
      "        pass\n",
      "101/23:         >>> t1 = Tree(17, [])\n",
      "101/24:         >>> t1.maximum()\n",
      "101/25:         17\n",
      "101/26:         >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "101/27:         >>> t3.maximum()\n",
      "101/28:         10\n",
      "101/29:         >>> print(t2)\n",
      "101/30:\n",
      "class Tree:\n",
      "    \"\"\"A recursive tree data structure.\n",
      "\n",
      "    Note the relationship between this class and RecursiveList; the only major\n",
      "    difference is that _rest has been replaced by _subtrees to handle multiple\n",
      "    recursive sub-parts.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # The item stored at this tree's root, or None if the tree is empty.\n",
      "    _root: Optional[Any]\n",
      "    # The list of all subtrees of this tree.\n",
      "    _subtrees: List[Tree]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # - If self._root is None then self._subtrees is an empty list.\n",
      "    #   This setting of attributes represents an empty Tree.\n",
      "    #\n",
      "    #   Note: self._subtrees may be empty when self._root is not None.\n",
      "    #   This setting of attributes represents a tree consisting of just one\n",
      "    #   node.\n",
      "\n",
      "    def __init__(self, root: Any, subtrees: List[Tree]) -> None:\n",
      "        \"\"\"Initialize a new Tree with the given root value and subtrees.\n",
      "\n",
      "        If <root> is None, the tree is empty.\n",
      "        Precondition: if <root> is None, then <subtrees> is empty.\n",
      "        \"\"\"\n",
      "        self._root = root\n",
      "        self._subtrees = subtrees\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return True if this tree is empty.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> t1.is_empty()\n",
      "        True\n",
      "        >>> t2 = Tree(3, [])\n",
      "        >>> t2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._root is None\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of items contained in this tree.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> len(t1)\n",
      "        0\n",
      "        >>> t2 = Tree(3, [Tree(4, []), Tree(1, [])])\n",
      "        >>> len(t2)\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        else:\n",
      "            size = 1  # count the root\n",
      "            for subtree in self._subtrees:\n",
      "                size += subtree.__len__()  # could also do len(subtree) here\n",
      "            return size\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this tree.\n",
      "        \"\"\"\n",
      "        return self._str_indented(0)\n",
      "    \n",
      "    def _str_indented(self, depth: int) -> str:\n",
      "        \"\"\"Return an indented string representation of this tree.\n",
      "\n",
      "        The indentation level is specified by the <depth> parameter.\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        else:\n",
      "            s = '  ' * depth + str(self._root) + '\\n'\n",
      "            for subtree in self._subtrees:\n",
      "                # Note that the 'depth' argument to the recursive call is\n",
      "                # modified.\n",
      "                s += subtree._str_indented(depth + 1)\n",
      "            return s\n",
      "\n",
      "    def num_positives(self) -> int:\n",
      "        \"\"\"Return the number of positive integers in this tree.\n",
      "\n",
      "        Precondition: all items in this tree are integers.\n",
      "\n",
      "        Remember, 0 is *not* positive.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.num_positives()\n",
      "        1\n",
      "        >>> t2 = Tree(-10, [])\n",
      "        >>> t2.num_positives()\n",
      "        0\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.num_positives()\n",
      "        2\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return 1 if self._root > 0 else 0\n",
      "        else:\n",
      "            count = 1\n",
      "            for subtree in self._subtrees:\n",
      "                count += subtree.num_positives()\n",
      "            return count\n",
      "\n",
      "    def maximum(self: Tree) -> int:\n",
      "        \"\"\"Return the maximum item stored in this tree.\n",
      "\n",
      "        Return 0 if this tree is empty.\n",
      "\n",
      "        Precondition: all values in this tree are positive integers.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.maximum()\n",
      "        17\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.maximum()\n",
      "        10\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return self._root\n",
      "        else:\n",
      "            curmax = self._root\n",
      "            for subtree in self._subtrees:\n",
      "                curmax = max(curmax, subtree.maximum())\n",
      "            return curmax\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def height(self: Tree) -> int:\n",
      "        \"\"\"Return the height of this tree.\n",
      "\n",
      "        Please refer to the prep readings for the definition of tree height.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.height()\n",
      "        1\n",
      "        >>> t2 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> print(t2)\n",
      "        >>> t2.height()\n",
      "        2\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            ...\n",
      "        else:\n",
      "            ...\n",
      "            for subtree in self._subtrees:\n",
      "                ... subtree.height() ...\n",
      "            ...\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether this tree contains <item>.\n",
      "\n",
      "        >>> t = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t.__contains__(-30)  # Could also write -30 in t.\n",
      "        True\n",
      "        >>> t.__contains__(148)\n",
      "        False\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.__contains__(...) ...\n",
      "        #     ...\n",
      "        pass\n",
      "101/31:\n",
      "class Tree:\n",
      "    \"\"\"A recursive tree data structure.\n",
      "\n",
      "    Note the relationship between this class and RecursiveList; the only major\n",
      "    difference is that _rest has been replaced by _subtrees to handle multiple\n",
      "    recursive sub-parts.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # The item stored at this tree's root, or None if the tree is empty.\n",
      "    _root: Optional[Any]\n",
      "    # The list of all subtrees of this tree.\n",
      "    _subtrees: List[Tree]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # - If self._root is None then self._subtrees is an empty list.\n",
      "    #   This setting of attributes represents an empty Tree.\n",
      "    #\n",
      "    #   Note: self._subtrees may be empty when self._root is not None.\n",
      "    #   This setting of attributes represents a tree consisting of just one\n",
      "    #   node.\n",
      "\n",
      "    def __init__(self, root: Any, subtrees: List[Tree]) -> None:\n",
      "        \"\"\"Initialize a new Tree with the given root value and subtrees.\n",
      "\n",
      "        If <root> is None, the tree is empty.\n",
      "        Precondition: if <root> is None, then <subtrees> is empty.\n",
      "        \"\"\"\n",
      "        self._root = root\n",
      "        self._subtrees = subtrees\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return True if this tree is empty.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> t1.is_empty()\n",
      "        True\n",
      "        >>> t2 = Tree(3, [])\n",
      "        >>> t2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._root is None\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of items contained in this tree.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> len(t1)\n",
      "        0\n",
      "        >>> t2 = Tree(3, [Tree(4, []), Tree(1, [])])\n",
      "        >>> len(t2)\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        else:\n",
      "            size = 1  # count the root\n",
      "            for subtree in self._subtrees:\n",
      "                size += subtree.__len__()  # could also do len(subtree) here\n",
      "            return size\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this tree.\n",
      "        \"\"\"\n",
      "        return self._str_indented(0)\n",
      "\n",
      "    def _str_indented(self, depth: int) -> str:\n",
      "        \"\"\"Return an indented string representation of this tree.\n",
      "\n",
      "        The indentation level is specified by the <depth> parameter.\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        else:\n",
      "            s = '  ' * depth + str(self._root) + '\\n'\n",
      "            for subtree in self._subtrees:\n",
      "                # Note that the 'depth' argument to the recursive call is\n",
      "                # modified.\n",
      "                s += subtree._str_indented(depth + 1)\n",
      "            return s\n",
      "\n",
      "    def num_positives(self) -> int:\n",
      "        \"\"\"Return the number of positive integers in this tree.\n",
      "\n",
      "        Precondition: all items in this tree are integers.\n",
      "\n",
      "        Remember, 0 is *not* positive.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.num_positives()\n",
      "        1\n",
      "        >>> t2 = Tree(-10, [])\n",
      "        >>> t2.num_positives()\n",
      "        0\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.num_positives()\n",
      "        2\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return 1 if self._root > 0 else 0\n",
      "        else:\n",
      "            count = 1\n",
      "            for subtree in self._subtrees:\n",
      "                count += subtree.num_positives()\n",
      "            return count\n",
      "\n",
      "    def maximum(self: Tree) -> int:\n",
      "        \"\"\"Return the maximum item stored in this tree.\n",
      "\n",
      "        Return 0 if this tree is empty.\n",
      "\n",
      "        Precondition: all values in this tree are positive integers.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.maximum()\n",
      "        17\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.maximum()\n",
      "        10\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return self._root\n",
      "        else:\n",
      "            curmax = self._root\n",
      "            for subtree in self._subtrees:\n",
      "                curmax = max(curmax, subtree.maximum())\n",
      "            return curmax\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def height(self: Tree) -> int:\n",
      "        \"\"\"Return the height of this tree.\n",
      "\n",
      "        Please refer to the prep readings for the definition of tree height.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.height()\n",
      "        1\n",
      "        >>> t2 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> print(t2)\n",
      "        >>> t2.height()\n",
      "        2\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     return 0\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.height() ...\n",
      "        #     ...\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether this tree contains <item>.\n",
      "\n",
      "        >>> t = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t.__contains__(-30)  # Could also write -30 in t.\n",
      "        True\n",
      "        >>> t.__contains__(148)\n",
      "        False\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.__contains__(...) ...\n",
      "        #     ...\n",
      "        pass\n",
      "101/32:         >>> t1 = Tree(17, [])\n",
      "101/33:         >>> t1.height()\n",
      "101/34:         1\n",
      "101/35:         >>> t2 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "101/36:         >>> print(t2)\n",
      "101/37:\n",
      "class Tree:\n",
      "    \"\"\"A recursive tree data structure.\n",
      "\n",
      "    Note the relationship between this class and RecursiveList; the only major\n",
      "    difference is that _rest has been replaced by _subtrees to handle multiple\n",
      "    recursive sub-parts.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # The item stored at this tree's root, or None if the tree is empty.\n",
      "    _root: Optional[Any]\n",
      "    # The list of all subtrees of this tree.\n",
      "    _subtrees: List[Tree]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # - If self._root is None then self._subtrees is an empty list.\n",
      "    #   This setting of attributes represents an empty Tree.\n",
      "    #\n",
      "    #   Note: self._subtrees may be empty when self._root is not None.\n",
      "    #   This setting of attributes represents a tree consisting of just one\n",
      "    #   node.\n",
      "\n",
      "    def __init__(self, root: Any, subtrees: List[Tree]) -> None:\n",
      "        \"\"\"Initialize a new Tree with the given root value and subtrees.\n",
      "\n",
      "        If <root> is None, the tree is empty.\n",
      "        Precondition: if <root> is None, then <subtrees> is empty.\n",
      "        \"\"\"\n",
      "        self._root = root\n",
      "        self._subtrees = subtrees\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return True if this tree is empty.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> t1.is_empty()\n",
      "        True\n",
      "        >>> t2 = Tree(3, [])\n",
      "        >>> t2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._root is None\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of items contained in this tree.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> len(t1)\n",
      "        0\n",
      "        >>> t2 = Tree(3, [Tree(4, []), Tree(1, [])])\n",
      "        >>> len(t2)\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        else:\n",
      "            size = 1  # count the root\n",
      "            for subtree in self._subtrees:\n",
      "                size += subtree.__len__()  # could also do len(subtree) here\n",
      "            return size\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this tree.\n",
      "        \"\"\"\n",
      "        return self._str_indented(0)\n",
      "\n",
      "    def _str_indented(self, depth: int) -> str:\n",
      "        \"\"\"Return an indented string representation of this tree.\n",
      "\n",
      "        The indentation level is specified by the <depth> parameter.\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        else:\n",
      "            s = '  ' * depth + str(self._root) + '\\n'\n",
      "            for subtree in self._subtrees:\n",
      "                # Note that the 'depth' argument to the recursive call is\n",
      "                # modified.\n",
      "                s += subtree._str_indented(depth + 1)\n",
      "            return s\n",
      "\n",
      "    def num_positives(self) -> int:\n",
      "        \"\"\"Return the number of positive integers in this tree.\n",
      "\n",
      "        Precondition: all items in this tree are integers.\n",
      "\n",
      "        Remember, 0 is *not* positive.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.num_positives()\n",
      "        1\n",
      "        >>> t2 = Tree(-10, [])\n",
      "        >>> t2.num_positives()\n",
      "        0\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.num_positives()\n",
      "        2\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return 1 if self._root > 0 else 0\n",
      "        else:\n",
      "            count = 1\n",
      "            for subtree in self._subtrees:\n",
      "                count += subtree.num_positives()\n",
      "            return count\n",
      "\n",
      "    def maximum(self: Tree) -> int:\n",
      "        \"\"\"Return the maximum item stored in this tree.\n",
      "\n",
      "        Return 0 if this tree is empty.\n",
      "\n",
      "        Precondition: all values in this tree are positive integers.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.maximum()\n",
      "        17\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.maximum()\n",
      "        10\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return self._root\n",
      "        else:\n",
      "            curmax = self._root\n",
      "            for subtree in self._subtrees:\n",
      "                curmax = max(curmax, subtree.maximum())\n",
      "            return curmax\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def height(self: Tree) -> int:\n",
      "        \"\"\"Return the height of this tree.\n",
      "\n",
      "        Please refer to the prep readings for the definition of tree height.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.height()\n",
      "        1\n",
      "        >>> t2 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> print(t2)\n",
      "        >>> t2.height()\n",
      "        2\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return 1\n",
      "        else:\n",
      "            h = 1\n",
      "            thislevel = [subtree.height() for subtree in self._subtrees]\n",
      "            h += max(thislevel)\n",
      "            return h\n",
      "\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether this tree contains <item>.\n",
      "\n",
      "        >>> t = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t.__contains__(-30)  # Could also write -30 in t.\n",
      "        True\n",
      "        >>> t.__contains__(148)\n",
      "        False\n",
      "        \"\"\"\n",
      "        # if self.is_empty():\n",
      "        #     ...\n",
      "        # elif self._subtrees == []:\n",
      "        #     ...\n",
      "        # else:\n",
      "        #     ...\n",
      "        #     for subtree in self._subtrees:\n",
      "        #         ... subtree.__contains__(...) ...\n",
      "        #     ...\n",
      "        pass\n",
      "101/38:         >>> t1 = Tree(17, [])\n",
      "101/39:         >>> t1.height()\n",
      "101/40:         1\n",
      "101/41:         >>> t2 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "101/42:         >>> print(t2)\n",
      "101/43:         >>> t2.height()\n",
      "101/44:         2\n",
      "101/45:         >>> t1 = Tree(1, [])\n",
      "101/46:         >>> t2 = Tree(2, [])\n",
      "101/47:         >>> t3 = Tree(3, [])\n",
      "101/48:         >>> t4 = Tree(4, [t1, t2, t3])\n",
      "101/49:         >>> t5 = Tree(5, [])\n",
      "101/50:         >>> t6 = Tree(6, [t4, t5])\n",
      "101/51:         >>> t6.height()\n",
      "101/52:\n",
      "class Tree:\n",
      "    \"\"\"A recursive tree data structure.\n",
      "\n",
      "    Note the relationship between this class and RecursiveList; the only major\n",
      "    difference is that _rest has been replaced by _subtrees to handle multiple\n",
      "    recursive sub-parts.\n",
      "    \"\"\"\n",
      "    # === Private Attributes ===\n",
      "    # The item stored at this tree's root, or None if the tree is empty.\n",
      "    _root: Optional[Any]\n",
      "    # The list of all subtrees of this tree.\n",
      "    _subtrees: List[Tree]\n",
      "\n",
      "    # === Representation Invariants ===\n",
      "    # - If self._root is None then self._subtrees is an empty list.\n",
      "    #   This setting of attributes represents an empty Tree.\n",
      "    #\n",
      "    #   Note: self._subtrees may be empty when self._root is not None.\n",
      "    #   This setting of attributes represents a tree consisting of just one\n",
      "    #   node.\n",
      "\n",
      "    def __init__(self, root: Any, subtrees: List[Tree]) -> None:\n",
      "        \"\"\"Initialize a new Tree with the given root value and subtrees.\n",
      "\n",
      "        If <root> is None, the tree is empty.\n",
      "        Precondition: if <root> is None, then <subtrees> is empty.\n",
      "        \"\"\"\n",
      "        self._root = root\n",
      "        self._subtrees = subtrees\n",
      "\n",
      "    def is_empty(self) -> bool:\n",
      "        \"\"\"Return True if this tree is empty.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> t1.is_empty()\n",
      "        True\n",
      "        >>> t2 = Tree(3, [])\n",
      "        >>> t2.is_empty()\n",
      "        False\n",
      "        \"\"\"\n",
      "        return self._root is None\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        \"\"\"Return the number of items contained in this tree.\n",
      "\n",
      "        >>> t1 = Tree(None, [])\n",
      "        >>> len(t1)\n",
      "        0\n",
      "        >>> t2 = Tree(3, [Tree(4, []), Tree(1, [])])\n",
      "        >>> len(t2)\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        else:\n",
      "            size = 1  # count the root\n",
      "            for subtree in self._subtrees:\n",
      "                size += subtree.__len__()  # could also do len(subtree) here\n",
      "            return size\n",
      "\n",
      "    def __str__(self) -> str:\n",
      "        \"\"\"Return a string representation of this tree.\n",
      "        \"\"\"\n",
      "        return self._str_indented(0)\n",
      "\n",
      "    def _str_indented(self, depth: int) -> str:\n",
      "        \"\"\"Return an indented string representation of this tree.\n",
      "\n",
      "        The indentation level is specified by the <depth> parameter.\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return ''\n",
      "        else:\n",
      "            s = '  ' * depth + str(self._root) + '\\n'\n",
      "            for subtree in self._subtrees:\n",
      "                # Note that the 'depth' argument to the recursive call is\n",
      "                # modified.\n",
      "                s += subtree._str_indented(depth + 1)\n",
      "            return s\n",
      "\n",
      "    def num_positives(self) -> int:\n",
      "        \"\"\"Return the number of positive integers in this tree.\n",
      "\n",
      "        Precondition: all items in this tree are integers.\n",
      "\n",
      "        Remember, 0 is *not* positive.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.num_positives()\n",
      "        1\n",
      "        >>> t2 = Tree(-10, [])\n",
      "        >>> t2.num_positives()\n",
      "        0\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.num_positives()\n",
      "        2\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return 1 if self._root > 0 else 0\n",
      "        else:\n",
      "            count = 1\n",
      "            for subtree in self._subtrees:\n",
      "                count += subtree.num_positives()\n",
      "            return count\n",
      "\n",
      "    def maximum(self: Tree) -> int:\n",
      "        \"\"\"Return the maximum item stored in this tree.\n",
      "\n",
      "        Return 0 if this tree is empty.\n",
      "\n",
      "        Precondition: all values in this tree are positive integers.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.maximum()\n",
      "        17\n",
      "        >>> t3 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t3.maximum()\n",
      "        10\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return self._root\n",
      "        else:\n",
      "            curmax = self._root\n",
      "            for subtree in self._subtrees:\n",
      "                curmax = max(curmax, subtree.maximum())\n",
      "            return curmax\n",
      "\n",
      "    def height(self: Tree) -> int:\n",
      "        \"\"\"Return the height of this tree.\n",
      "\n",
      "        Please refer to the prep readings for the definition of tree height.\n",
      "\n",
      "        >>> t1 = Tree(17, [])\n",
      "        >>> t1.height()\n",
      "        1\n",
      "        >>> t2 = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> print(t2)\n",
      "        >>> t2.height()\n",
      "        2\n",
      "        >>> t1 = Tree(1, [])\n",
      "        >>> t2 = Tree(2, [])\n",
      "        >>> t3 = Tree(3, [])\n",
      "        >>> t4 = Tree(4, [t1, t2, t3])\n",
      "        >>> t5 = Tree(5, [])\n",
      "        >>> t6 = Tree(6, [t4, t5])\n",
      "        >>> t6.height()\n",
      "        3\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return 0\n",
      "        elif self._subtrees == []:\n",
      "            return 1\n",
      "        else:\n",
      "            h = 1\n",
      "            thislevel = [subtree.height() for subtree in self._subtrees]\n",
      "            h += max(thislevel)\n",
      "            return h\n",
      "\n",
      "\n",
      "    # TODO: implement this method!\n",
      "    def __contains__(self, item: Any) -> bool:\n",
      "        \"\"\"Return whether this tree contains <item>.\n",
      "\n",
      "        >>> t = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "        >>> t.__contains__(-30)  # Could also write -30 in t.\n",
      "        True\n",
      "        >>> t.__contains__(148)\n",
      "        False\n",
      "        \"\"\"\n",
      "        if self.is_empty():\n",
      "            return False\n",
      "        elif self._subtrees == []:\n",
      "            return self._root == item\n",
      "        else:\n",
      "            has = False\n",
      "            for subtree in self._subtrees:\n",
      "                has = subtree.__contains__(item)\n",
      "                if has == True:\n",
      "                    return True\n",
      "            return False\n",
      "101/53:         >>> t = Tree(1, [Tree(-2, []), Tree(10, []), Tree(-30, [])])\n",
      "101/54:         >>> t.__contains__(-30)  # Could also write -30 in t.\n",
      "101/55:         True\n",
      "101/56:         >>> t.__contains__(148)\n",
      "101/57:         False\n",
      "   1: %history -g\n",
      "   2: %history -g -f 50\n",
      "   3: %history -g 50\n",
      "   4: %history -g 50/\n",
      "   5: %history -g 50\n",
      "   6: %history -g -n 50\n",
      "   7: %history -g -n 50/\n",
      "   8: %history -g -n 50/1-200\n"
     ]
    }
   ],
   "source": [
    "%history -g -n 50/1-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "cde6b3d4-73bb-4116-8159-89e972bb73b0"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '/Users/js/Desktop/datasets/flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "test_dir = data_dir + '/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbpresent": {
     "id": "19c3a5a0-b944-445b-a586-924eab5c59bc"
    }
   },
   "outputs": [],
   "source": [
    "transforms_224 = transforms.Compose([\n",
    "    transforms.Resize(250),\n",
    "    transforms.TenCrop(224),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
    "])\n",
    "\n",
    "traindat = datasets.ImageFolder(train_dir, transform=transforms_224)\n",
    "testdat = datasets.ImageFolder(test_dir, transform=transforms_224)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindat, batch_size=4, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testdat, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(crops)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "b8563073-c5bf-4618-b2b3-2e8a03ebc826"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (23): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (24): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (25): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (26): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (27): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (28): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (29): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (30): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (31): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (32): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (33): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (34): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (35): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet152(pretrained=False)\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "dcf191bb-bc6f-48ab-bcd3-e9688e48250a"
    }
   },
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, in_dims, out_dims):\n",
    "        super(net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dims, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, out_dims)\n",
    "        self.lsm = nn.LogSoftmax(dim=1)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.drop = nn.Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(self.lrelu(self.fc1(x)))\n",
    "        x = self.drop(self.lrelu(self.fc2(x)))\n",
    "        x = self.drop(self.lrelu(self.fc3(x)))\n",
    "        x = self.lsm(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "813922aa-fcf1-4761-aa47-d13bdb54f4e2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (23): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (24): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (25): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (26): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (27): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (28): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (29): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (30): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (31): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (32): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (33): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (34): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (35): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): net(\n",
      "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (fc3): Linear(in_features=512, out_features=102, bias=True)\n",
      "    (lsm): LogSoftmax()\n",
      "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
      "    (drop): Dropout(p=0.4)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet_clf = net(2048, 102)\n",
    "resnet.fc = resnet_clf\n",
    "\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbpresent": {
     "id": "1d3d3a7a-3cfc-430f-a941-2785452dd138"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    resnet = resnet.cuda()\n",
    "    print('GPU Available')\n",
    "else: \n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (23): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (24): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (25): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (26): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (27): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (28): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (29): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (30): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (31): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (32): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (33): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (34): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (35): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): net(\n",
      "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (fc3): Linear(in_features=512, out_features=102, bias=True)\n",
      "    (lsm): LogSoftmax()\n",
      "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
      "    (drop): Dropout(p=0.4)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet.load_state_dict(torch.load('resnet.pt', map_location='cpu'))\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbpresent": {
     "id": "51ef0aa2-a555-48a4-8468-e111e40b5c8c"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=1e-3, momentum=0.9, nesterov=True, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESNET... Epoch: 1/3  |  Training loss: 3251.571520  |  Testing accuracy: 0.980%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2138e48ba417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresnet_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0mparam_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    resnet.train()\n",
    "    for batch_idx, (feature, label) in enumerate(train_loader_224):\n",
    "        if torch.cuda.is_available():\n",
    "            feature, label = feature.cuda(), label.cuda()\n",
    "        resnet_optimizer.zero_grad()\n",
    "        batch_size, n_crops, channels, height, width = feature.shape\n",
    "        flattened = feature.view(-1, channels, height, width)\n",
    "        output = resnet(flattened)\n",
    "        output = output.view(batch_size, n_crops, -1).mean(1)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        resnet_optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        scheduler.step()\n",
    "    resnet_scheduler = optim.lr_scheduler.CosineAnnealingLR(resnet_optimizer, len(train_loader_224))\n",
    "    \n",
    "    resnet.eval()\n",
    "    correct = 0\n",
    "    for feature, label in test_loader_224:\n",
    "        if torch.cuda.is_available():\n",
    "            feature, label = feature.cuda(), label.cuda()\n",
    "        batch_size, n_crops, channels, height, width = feature.shape\n",
    "        flattened = feature.view(-1, channels, height, width)\n",
    "        output = resnet(flattened)\n",
    "        output = output.view(batch_size, n_crops, -1).mean(1)\n",
    "        preds = output.exp().max(dim=1)[1]\n",
    "        correct += (preds == label).sum().item()\n",
    "        \n",
    "    print(f\"RESNET... Epoch: {e+1}/{epochs}  |  Training loss: {train_loss:.6f}  |  Testing accuracy: {correct/len(test_dat_224):.3f}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6d06a1708ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_crops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mflattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_crops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resnet.eval()\n",
    "correct = 0\n",
    "for feature, label in testloader:\n",
    "    if torch.cuda.is_available():\n",
    "            feature, label = feature.cuda(), label.cuda()\n",
    "    batch_size, n_crops, channels, height, width = feature.shape\n",
    "    flattened = feature.view(-1, channels, height, width)\n",
    "    output = resnet(flattened)\n",
    "    output = output.view(batch_size, n_crops, -1).mean(1)\n",
    "    preds = output.exp().max(dim=1)[1]\n",
    "    correct += (preds == label).sum().item()\n",
    "print(correct/len(test_dat_224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'resnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "nbpresent": {
   "slides": {
    "2b291f05-e5f3-4fc9-b077-19d651778ca3": {
     "id": "2b291f05-e5f3-4fc9-b077-19d651778ca3",
     "prev": "3489561d-a8d7-4319-aeb2-1071df1f4522",
     "regions": {
      "07d7a96d-2592-462f-a884-0269c00ca54e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1d3d3a7a-3cfc-430f-a941-2785452dd138",
        "part": "whole"
       },
       "id": "07d7a96d-2592-462f-a884-0269c00ca54e"
      }
     }
    },
    "3489561d-a8d7-4319-aeb2-1071df1f4522": {
     "id": "3489561d-a8d7-4319-aeb2-1071df1f4522",
     "prev": "43aa09fc-a38f-468c-b2bc-80865915bea4",
     "regions": {
      "448b8c79-3020-4805-8405-5e16ba72f830": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "813922aa-fcf1-4761-aa47-d13bdb54f4e2",
        "part": "whole"
       },
       "id": "448b8c79-3020-4805-8405-5e16ba72f830"
      }
     }
    },
    "426b1311-8b7d-4a3f-b902-f0fe7be7f627": {
     "id": "426b1311-8b7d-4a3f-b902-f0fe7be7f627",
     "prev": "56339c1e-46ed-4da3-ab57-2442dc2e1d85",
     "regions": {
      "c2f9d811-449f-4759-8710-9cd287aed069": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "61126814-64c6-42e4-9c09-8acc55acb627",
        "part": "whole"
       },
       "id": "c2f9d811-449f-4759-8710-9cd287aed069"
      }
     }
    },
    "43aa09fc-a38f-468c-b2bc-80865915bea4": {
     "id": "43aa09fc-a38f-468c-b2bc-80865915bea4",
     "prev": "b4babd25-f9fd-4495-af92-ed6657065fd3",
     "regions": {
      "c1479bfc-7404-45f6-b473-67fae598dac7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "dcf191bb-bc6f-48ab-bcd3-e9688e48250a",
        "part": "whole"
       },
       "id": "c1479bfc-7404-45f6-b473-67fae598dac7"
      }
     }
    },
    "48bb65af-fa87-43d0-bf21-70fe3a66533f": {
     "id": "48bb65af-fa87-43d0-bf21-70fe3a66533f",
     "prev": "bdefeee5-af08-4855-bc6e-b742f53bde73",
     "regions": {
      "6b70f487-e321-439d-8ed4-546dce25b55c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cde6b3d4-73bb-4116-8159-89e972bb73b0",
        "part": "whole"
       },
       "id": "6b70f487-e321-439d-8ed4-546dce25b55c"
      }
     }
    },
    "56339c1e-46ed-4da3-ab57-2442dc2e1d85": {
     "id": "56339c1e-46ed-4da3-ab57-2442dc2e1d85",
     "prev": "9f9d71f3-5f6d-470c-9a96-36d7b6223caa",
     "regions": {
      "8d1cf019-e6f0-4a70-8458-4c58114f3dad": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c6f6f333-6def-40d4-aa06-b9cc61dea103",
        "part": "whole"
       },
       "id": "8d1cf019-e6f0-4a70-8458-4c58114f3dad"
      }
     }
    },
    "59284479-a73f-47db-a90e-a5d50fc775d3": {
     "id": "59284479-a73f-47db-a90e-a5d50fc775d3",
     "prev": "426b1311-8b7d-4a3f-b902-f0fe7be7f627",
     "regions": {
      "cf171b18-a7aa-427e-a806-2236dbb495fd": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b8563073-c5bf-4618-b2b3-2e8a03ebc826",
        "part": "whole"
       },
       "id": "cf171b18-a7aa-427e-a806-2236dbb495fd"
      }
     }
    },
    "7dc4b298-19f9-46b0-8561-ab2a3e367cd4": {
     "id": "7dc4b298-19f9-46b0-8561-ab2a3e367cd4",
     "prev": "8ffa325d-66d7-4fc8-b995-7ba116f9ddf2",
     "regions": {
      "6f48620c-62dc-4d1a-ad38-33f575d1eff8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "98b83254-bd94-432f-8f2f-036d37267a55",
        "part": "whole"
       },
       "id": "6f48620c-62dc-4d1a-ad38-33f575d1eff8"
      }
     }
    },
    "8ffa325d-66d7-4fc8-b995-7ba116f9ddf2": {
     "id": "8ffa325d-66d7-4fc8-b995-7ba116f9ddf2",
     "prev": "2b291f05-e5f3-4fc9-b077-19d651778ca3",
     "regions": {
      "234af504-6ced-41ed-aa77-38baf4805cf7": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "51ef0aa2-a555-48a4-8468-e111e40b5c8c",
        "part": "whole"
       },
       "id": "234af504-6ced-41ed-aa77-38baf4805cf7"
      }
     }
    },
    "9aa03237-0922-40e6-b3dc-bc3f455de923": {
     "id": "9aa03237-0922-40e6-b3dc-bc3f455de923",
     "prev": "a0a92d0e-dff8-4eee-a8ea-923da5c0b244",
     "regions": {
      "f4ba7fa1-03ba-4dcb-a7ed-778cdb9e161c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "23f24bd0-6094-4c15-92ef-0ea7537d695e",
        "part": "whole"
       },
       "id": "f4ba7fa1-03ba-4dcb-a7ed-778cdb9e161c"
      }
     }
    },
    "9f9d71f3-5f6d-470c-9a96-36d7b6223caa": {
     "id": "9f9d71f3-5f6d-470c-9a96-36d7b6223caa",
     "prev": "48bb65af-fa87-43d0-bf21-70fe3a66533f",
     "regions": {
      "6bd82d10-aad6-496b-bf9c-dcf89554b1b9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "19c3a5a0-b944-445b-a586-924eab5c59bc",
        "part": "whole"
       },
       "id": "6bd82d10-aad6-496b-bf9c-dcf89554b1b9"
      }
     }
    },
    "a0a92d0e-dff8-4eee-a8ea-923da5c0b244": {
     "id": "a0a92d0e-dff8-4eee-a8ea-923da5c0b244",
     "prev": "7dc4b298-19f9-46b0-8561-ab2a3e367cd4",
     "regions": {
      "80ecf9fd-e2c3-47a9-8449-2a704360ac82": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "815a2a36-90b3-43ae-816d-40af928f804d",
        "part": "whole"
       },
       "id": "80ecf9fd-e2c3-47a9-8449-2a704360ac82"
      }
     }
    },
    "b4babd25-f9fd-4495-af92-ed6657065fd3": {
     "id": "b4babd25-f9fd-4495-af92-ed6657065fd3",
     "prev": "59284479-a73f-47db-a90e-a5d50fc775d3",
     "regions": {
      "e321e7f2-1869-431e-8847-b96509cefb78": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1dfbd2ba-5932-4d7f-83ab-3b0c441c93cc",
        "part": "whole"
       },
       "id": "e321e7f2-1869-431e-8847-b96509cefb78"
      }
     }
    },
    "bdefeee5-af08-4855-bc6e-b742f53bde73": {
     "id": "bdefeee5-af08-4855-bc6e-b742f53bde73",
     "prev": null,
     "regions": {
      "5f0284b4-308a-49a8-924a-1e3567db9768": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cd1b1cc7-914a-4c94-b220-55ee416adac2",
        "part": "whole"
       },
       "id": "5f0284b4-308a-49a8-924a-1e3567db9768"
      }
     }
    }
   },
   "themes": {
    "default": "3ebae8d8-b3bf-4487-8706-a02ebb868739",
    "theme": {
     "3ebae8d8-b3bf-4487-8706-a02ebb868739": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "3ebae8d8-b3bf-4487-8706-a02ebb868739",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     },
     "606ae484-794b-496f-9cc9-3eff180de7c8": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "606ae484-794b-496f-9cc9-3eff180de7c8",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     },
     "b75b4863-9338-4fb6-b9bd-d2f17ee6ee3b": {
      "id": "b75b4863-9338-4fb6-b9bd-d2f17ee6ee3b",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
